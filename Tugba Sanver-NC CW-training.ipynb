{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, necessary libraries are imported and versions of the libraries are printed. Then the dataset is loaded to pandas DataFrame. Data columns are renamed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-10-10.0.19041-SP0\n",
      "Python 3.8.3 (default, Jul  2 2020, 17:30:36) [MSC v.1916 64 bit (AMD64)]\n",
      "NumPy 1.19.1\n",
      "SciPy 1.5.0\n",
      "Scikit-Learn 0.23.0\n",
      "Pytorch 1.7.1\n",
      "Pandas 1.7.1\n",
      "Matplotlib 3.3.1\n",
      "Seaborn 0.11.0\n",
      "imblearn 0.8.0\n",
      "skorch 0.7.0\n"
     ]
    }
   ],
   "source": [
    "import platform; print(platform.platform())\n",
    "import sys; print(\"Python\", sys.version)\n",
    "import numpy; print(\"NumPy\", numpy.__version__)\n",
    "import scipy; print(\"SciPy\", scipy.__version__)\n",
    "import sklearn; print(\"Scikit-Learn\", sklearn.__version__)\n",
    "import torch; print(\"Pytorch\", torch.__version__)\n",
    "import pandas; print(\"Pandas\", torch.__version__)\n",
    "import matplotlib.pyplot; print(\"Matplotlib\", matplotlib.__version__)\n",
    "import seaborn; print(\"Seaborn\", seaborn.__version__)\n",
    "import imblearn; print(\"imblearn\", imblearn.__version__)\n",
    "import skorch; print(\"skorch\", skorch.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.02 ms\n",
      "Shape of the Data:  (1728, 7)\n"
     ]
    }
   ],
   "source": [
    "%time data = pd.read_csv('car.data', header = None)\n",
    "\n",
    "print(\"Shape of the Data: \", data.shape )\n",
    "\n",
    "data.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'decision']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I checked the overall look of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety decision\n",
       "0  vhigh  vhigh     2       2    small    low    unacc\n",
       "1  vhigh  vhigh     2       2    small    med    unacc\n",
       "2  vhigh  vhigh     2       2    small   high    unacc\n",
       "3  vhigh  vhigh     2       2      med    low    unacc\n",
       "4  vhigh  vhigh     2       2      med    med    unacc"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I splitted the data into train and test set to keep test set on the side and avoid data leakage after encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['med', 'low', '3', 'more', 'small', 'low'],\n",
       "       ['high', 'high', '3', 'more', 'big', 'med'],\n",
       "       ['high', 'high', '5more', '2', 'med', 'med'],\n",
       "       ...,\n",
       "       ['vhigh', 'low', '4', '2', 'big', 'high'],\n",
       "       ['vhigh', 'vhigh', '3', 'more', 'med', 'med'],\n",
       "       ['vhigh', 'vhigh', '5more', '4', 'med', 'med']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.values[:,-1].copy()\n",
    "X = data.values[:,:-1].copy()\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X , y , test_size = 0.20, random_state = 1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I formed a test DataFrame to save and keep it as a seperate sheet: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>low</td>\n",
       "      <td>med</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>5more</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>low</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>low</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>3</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>5more</td>\n",
       "      <td>4</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    buying  maint  doors persons lug_boot safety decision\n",
       "0      med    low      3    more    small    low    unacc\n",
       "1     high   high      3    more      big    med      acc\n",
       "2     high   high  5more       2      med    med    unacc\n",
       "3      low    med      3       2      big    med    unacc\n",
       "4     high    med  5more       2    small    med    unacc\n",
       "..     ...    ...    ...     ...      ...    ...      ...\n",
       "341    low   high      3       2    small   high    unacc\n",
       "342    med    low      3    more      med   high    vgood\n",
       "343  vhigh    low      4       2      big   high    unacc\n",
       "344  vhigh  vhigh      3    more      med    med    unacc\n",
       "345  vhigh  vhigh  5more       4      med    med    unacc\n",
       "\n",
       "[346 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file=pd.DataFrame()\n",
    "test_file['buying']=X_test[:,0]\n",
    "test_file['maint']=X_test[:,1]\n",
    "test_file['doors']=X_test[:,2]\n",
    "test_file['persons']=X_test[:,3]\n",
    "test_file['lug_boot']=X_test[:,4]\n",
    "test_file['safety']=X_test[:,5]\n",
    "test_file['decision']=y_test\n",
    "test_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file.to_csv(\"test_notebook_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking splitting is all good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1382, 6), (1382,), (346, 6), (346,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also saved a dataframe version of the training target variable to make a distribution plot after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1382 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     1\n",
       "1     0\n",
       "2     2\n",
       "3     2\n",
       "4     2\n",
       "...  ..\n",
       "1377  0\n",
       "1378  0\n",
       "1379  0\n",
       "1380  2\n",
       "1381  2\n",
       "\n",
       "[1382 rows x 1 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df=pd.DataFrame(y_train)\n",
    "y_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And go back to the training set, since most of the variables are categorical type, it is needed to be encoded to make classification analysis. Therefore I used OneHotEncoder to make predictors binary and numerical and LabelEncoder to make target variable numerical labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "X_train = onehotencoder.fit_transform(X_train).toarray()\n",
    "labelencoder = LabelEncoder()\n",
    "y_train = labelencoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 2, ..., 0, 2, 2]),\n",
       " array([[0., 1., 0., ..., 0., 0., 1.],\n",
       "        [1., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 1., ..., 0., 0., 1.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 1., ..., 1., 0., 0.]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, training set is all numerical as seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making predictions for the target variable, it is crucial to check the distribution of our target variable. If it is unbalanced, our predictions can go wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train_df[0].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unacc    68.7\n",
       "acc      23.5\n",
       "good      4.0\n",
       "vgood     3.8\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_df[0].value_counts(normalize=True).mul(100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is seen above, the target variable is quite unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 325), (1, 55), (2, 950), (3, 52)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(sorted(Counter(y_train).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we match the category names and encoded numerical labels, we can say it is encoded as:\n",
    "unacceptable: 2,\n",
    "acceptable: 0,\n",
    "good: 1,\n",
    "very good: 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To rebalance our training target variable, we used SMOTE oversampling technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 950), (1, 950), (2, 950), (3, 950)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like all classes of the target variable are equally numbered now to overcome misclassification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all variables are ready to classify, we can make modelling parts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, I will do Multilayer Perceptron(MLP) model for classification. Relevant libraries are imported: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I wrap the data with tensors. It is essential to make it to work with the Pytorch library for MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.FloatTensor(X_resampled)\n",
    "y_train_torch = torch.LongTensor(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([950, 950, 950, 950])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bincount(y_train_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it is wrapped correctly. \n",
    "Then, I form my multilayer perceptron neural network. It will be three layer: input layer, only one hidden layer since our data is not so complex and huge, and output layer. I set the hidden layer size as input size for the first experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: 21, hidden size: 21, output size: 4\n"
     ]
    }
   ],
   "source": [
    "input_sz = X_train_torch.shape[1]\n",
    "hidden_sz = input_sz\n",
    "output_sz = y_train_torch.max().item()+1\n",
    "print('input size: %d, hidden size: %d, output size: %d'%(input_sz,hidden_sz, output_sz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I form my neural network classification class using object oriented structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarClassificationNN(nn.Module): #reference: lab 5\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim=input_sz,\n",
    "            hidden_dim=hidden_sz,\n",
    "            output_dim=output_sz,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(CarClassificationNN, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.hidden(x)) \n",
    "        x = self.dropout(x)\n",
    "        x = F.softmax(self.output(x), dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used tanh() activation function and softmax() function as my problem is classification type. The reason behind this usage is discussed on the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use Skorch library to modeling. Skorch is very useful library to form a neural network model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from skorch.callbacks import EpochScoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use Early Stopping criterion to avoid overfitting as Early Stopping stops the training if there is no improvement for valid loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "net = NeuralNetClassifier(\n",
    "    CarClassificationNN,\n",
    "    max_epochs=50,\n",
    "    callbacks=[EarlyStopping()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4389\u001b[0m       \u001b[32m0.2763\u001b[0m        \u001b[35m1.4108\u001b[0m  0.0618\n",
      "      2        \u001b[36m1.4169\u001b[0m       \u001b[32m0.3013\u001b[0m        \u001b[35m1.3974\u001b[0m  0.0618\n",
      "      3        \u001b[36m1.4094\u001b[0m       \u001b[32m0.3303\u001b[0m        \u001b[35m1.3845\u001b[0m  0.0588\n",
      "      4        \u001b[36m1.3930\u001b[0m       \u001b[32m0.3395\u001b[0m        \u001b[35m1.3723\u001b[0m  0.0618\n",
      "      5        \u001b[36m1.3818\u001b[0m       \u001b[32m0.3526\u001b[0m        \u001b[35m1.3602\u001b[0m  0.0728\n",
      "      6        \u001b[36m1.3724\u001b[0m       \u001b[32m0.3632\u001b[0m        \u001b[35m1.3484\u001b[0m  0.0549\n",
      "      7        \u001b[36m1.3605\u001b[0m       \u001b[32m0.3789\u001b[0m        \u001b[35m1.3371\u001b[0m  0.0808\n",
      "      8        \u001b[36m1.3458\u001b[0m       \u001b[32m0.4000\u001b[0m        \u001b[35m1.3254\u001b[0m  0.0568\n",
      "      9        \u001b[36m1.3387\u001b[0m       \u001b[32m0.4171\u001b[0m        \u001b[35m1.3137\u001b[0m  0.0539\n",
      "     10        \u001b[36m1.3230\u001b[0m       \u001b[32m0.4342\u001b[0m        \u001b[35m1.3020\u001b[0m  0.0678\n",
      "     11        \u001b[36m1.3080\u001b[0m       \u001b[32m0.4526\u001b[0m        \u001b[35m1.2902\u001b[0m  0.0628\n",
      "     12        \u001b[36m1.3056\u001b[0m       \u001b[32m0.4737\u001b[0m        \u001b[35m1.2780\u001b[0m  0.0648\n",
      "     13        \u001b[36m1.2836\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m1.2654\u001b[0m  0.0608\n",
      "     14        \u001b[36m1.2791\u001b[0m       \u001b[32m0.5263\u001b[0m        \u001b[35m1.2527\u001b[0m  0.0668\n",
      "     15        \u001b[36m1.2610\u001b[0m       \u001b[32m0.5461\u001b[0m        \u001b[35m1.2396\u001b[0m  0.0688\n",
      "     16        \u001b[36m1.2507\u001b[0m       \u001b[32m0.5553\u001b[0m        \u001b[35m1.2262\u001b[0m  0.0578\n",
      "     17        \u001b[36m1.2419\u001b[0m       \u001b[32m0.5750\u001b[0m        \u001b[35m1.2125\u001b[0m  0.0638\n",
      "     18        \u001b[36m1.2225\u001b[0m       \u001b[32m0.5868\u001b[0m        \u001b[35m1.1987\u001b[0m  0.0519\n",
      "     19        \u001b[36m1.2083\u001b[0m       \u001b[32m0.5987\u001b[0m        \u001b[35m1.1845\u001b[0m  0.0688\n",
      "     20        \u001b[36m1.1988\u001b[0m       \u001b[32m0.6237\u001b[0m        \u001b[35m1.1697\u001b[0m  0.0598\n",
      "     21        \u001b[36m1.1848\u001b[0m       \u001b[32m0.6342\u001b[0m        \u001b[35m1.1550\u001b[0m  0.0668\n",
      "     22        \u001b[36m1.1711\u001b[0m       \u001b[32m0.6539\u001b[0m        \u001b[35m1.1401\u001b[0m  0.0778\n",
      "     23        \u001b[36m1.1577\u001b[0m       \u001b[32m0.6711\u001b[0m        \u001b[35m1.1247\u001b[0m  0.0618\n",
      "     24        \u001b[36m1.1414\u001b[0m       \u001b[32m0.6763\u001b[0m        \u001b[35m1.1091\u001b[0m  0.0708\n",
      "     25        \u001b[36m1.1192\u001b[0m       \u001b[32m0.6816\u001b[0m        \u001b[35m1.0936\u001b[0m  0.0588\n",
      "     26        \u001b[36m1.1111\u001b[0m       \u001b[32m0.6882\u001b[0m        \u001b[35m1.0777\u001b[0m  0.0608\n",
      "     27        \u001b[36m1.0952\u001b[0m       \u001b[32m0.6908\u001b[0m        \u001b[35m1.0620\u001b[0m  0.0638\n",
      "     28        \u001b[36m1.0793\u001b[0m       \u001b[32m0.6947\u001b[0m        \u001b[35m1.0460\u001b[0m  0.0588\n",
      "     29        \u001b[36m1.0598\u001b[0m       \u001b[32m0.7000\u001b[0m        \u001b[35m1.0300\u001b[0m  0.0698\n",
      "     30        \u001b[36m1.0524\u001b[0m       \u001b[32m0.7039\u001b[0m        \u001b[35m1.0141\u001b[0m  0.0708\n",
      "     31        \u001b[36m1.0321\u001b[0m       \u001b[32m0.7079\u001b[0m        \u001b[35m0.9982\u001b[0m  0.0598\n",
      "     32        \u001b[36m1.0264\u001b[0m       \u001b[32m0.7105\u001b[0m        \u001b[35m0.9826\u001b[0m  0.0559\n",
      "     33        \u001b[36m1.0078\u001b[0m       \u001b[32m0.7171\u001b[0m        \u001b[35m0.9671\u001b[0m  0.0499\n",
      "     34        \u001b[36m0.9914\u001b[0m       \u001b[32m0.7211\u001b[0m        \u001b[35m0.9517\u001b[0m  0.0499\n",
      "     35        \u001b[36m0.9768\u001b[0m       \u001b[32m0.7276\u001b[0m        \u001b[35m0.9367\u001b[0m  0.0798\n",
      "     36        \u001b[36m0.9671\u001b[0m       \u001b[32m0.7355\u001b[0m        \u001b[35m0.9219\u001b[0m  0.0618\n",
      "     37        \u001b[36m0.9518\u001b[0m       \u001b[32m0.7382\u001b[0m        \u001b[35m0.9073\u001b[0m  0.0519\n",
      "     38        \u001b[36m0.9422\u001b[0m       \u001b[32m0.7408\u001b[0m        \u001b[35m0.8932\u001b[0m  0.0519\n",
      "     39        \u001b[36m0.9274\u001b[0m       \u001b[32m0.7434\u001b[0m        \u001b[35m0.8792\u001b[0m  0.0668\n",
      "     40        \u001b[36m0.9127\u001b[0m       \u001b[32m0.7461\u001b[0m        \u001b[35m0.8655\u001b[0m  0.0798\n",
      "     41        \u001b[36m0.9015\u001b[0m       \u001b[32m0.7500\u001b[0m        \u001b[35m0.8521\u001b[0m  0.0648\n",
      "     42        \u001b[36m0.8798\u001b[0m       \u001b[32m0.7553\u001b[0m        \u001b[35m0.8388\u001b[0m  0.0618\n",
      "     43        \u001b[36m0.8726\u001b[0m       \u001b[32m0.7566\u001b[0m        \u001b[35m0.8259\u001b[0m  0.0588\n",
      "     44        \u001b[36m0.8623\u001b[0m       0.7566        \u001b[35m0.8135\u001b[0m  0.0529\n",
      "     45        \u001b[36m0.8488\u001b[0m       \u001b[32m0.7618\u001b[0m        \u001b[35m0.8013\u001b[0m  0.0519\n",
      "     46        \u001b[36m0.8407\u001b[0m       \u001b[32m0.7645\u001b[0m        \u001b[35m0.7895\u001b[0m  0.0489\n",
      "     47        \u001b[36m0.8293\u001b[0m       \u001b[32m0.7684\u001b[0m        \u001b[35m0.7782\u001b[0m  0.0788\n",
      "     48        \u001b[36m0.8218\u001b[0m       \u001b[32m0.7737\u001b[0m        \u001b[35m0.7670\u001b[0m  0.0578\n",
      "     49        \u001b[36m0.8120\u001b[0m       0.7737        \u001b[35m0.7561\u001b[0m  0.0568\n",
      "     50        \u001b[36m0.8013\u001b[0m       \u001b[32m0.7763\u001b[0m        \u001b[35m0.7456\u001b[0m  0.0529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=CarClassificationNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (hidden): Linear(in_features=21, out_features=21, bias=True)\n",
       "    (output): Linear(in_features=21, out_features=4, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train_torch, y_train_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to choose best parameters and hyperparameters, I make grid search model selection technique. It forms different models with several combination from the parameters which I enter.\n",
    "\n",
    "I use different learning rates, hidden layer sizes, dropout values and optimisers. It is discussed detailed on the report.\n",
    "\n",
    "Also I use stratified cross validation with grid search to make the model performance better and without bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m3.3180\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m2.2844\u001b[0m  0.0608\n",
      "      2        3.8060       \u001b[32m0.3176\u001b[0m        \u001b[35m1.5387\u001b[0m  0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m2.1559\u001b[0m       \u001b[32m0.3945\u001b[0m        \u001b[35m1.2430\u001b[0m  0.0888\n",
      "      4        2.4150       \u001b[32m0.4990\u001b[0m        \u001b[35m1.0052\u001b[0m  0.0638\n",
      "      5        \u001b[36m1.4702\u001b[0m       \u001b[32m0.5779\u001b[0m        \u001b[35m0.8874\u001b[0m  0.0578\n",
      "      6        1.4813       \u001b[32m0.6805\u001b[0m        \u001b[35m0.7107\u001b[0m  0.0578\n",
      "      7        \u001b[36m1.3617\u001b[0m       0.6667        \u001b[35m0.7089\u001b[0m  0.0658\n",
      "      8        \u001b[36m1.2553\u001b[0m       \u001b[32m0.8205\u001b[0m        \u001b[35m0.5516\u001b[0m  0.0718\n",
      "      9        \u001b[36m1.1026\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.4872\u001b[0m  0.0668\n",
      "     10        1.1669       0.8679        \u001b[35m0.4226\u001b[0m  0.0618\n",
      "     11        1.2195       0.8284        0.5047  0.0598\n",
      "     12        1.1914       \u001b[32m0.9270\u001b[0m        \u001b[35m0.3374\u001b[0m  0.0628\n",
      "     13        \u001b[36m1.0871\u001b[0m       0.8955        0.4268  0.0838\n",
      "     14        \u001b[36m1.0376\u001b[0m       0.8797        0.3667  0.0668\n",
      "     15        1.0562       \u001b[32m0.9349\u001b[0m        \u001b[35m0.3112\u001b[0m  0.0618\n",
      "     16        \u001b[36m0.8567\u001b[0m       0.9132        0.4341  0.0638\n",
      "     17        1.1120       0.8836        0.3631  0.0668\n",
      "     18        \u001b[36m0.8539\u001b[0m       0.9112        0.5155  0.0718\n",
      "     19        1.3523       0.9053        0.3158  0.0559\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.6s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.8455\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m2.7372\u001b[0m  0.0519\n",
      "      2        4.0373       0.2505        \u001b[35m1.7108\u001b[0m  0.0589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m2.5801\u001b[0m       \u001b[32m0.4241\u001b[0m        \u001b[35m1.1743\u001b[0m  0.0638\n",
      "      4        \u001b[36m1.9737\u001b[0m       0.3037        1.3623  0.0519\n",
      "      5        2.3386       \u001b[32m0.4990\u001b[0m        \u001b[35m1.0087\u001b[0m  0.0568\n",
      "      6        \u001b[36m1.5850\u001b[0m       0.3846        1.2269  0.0568\n",
      "      7        1.9556       \u001b[32m0.5838\u001b[0m        \u001b[35m0.8102\u001b[0m  0.0688\n",
      "      8        \u001b[36m1.1554\u001b[0m       0.4773        1.1089  0.0489\n",
      "      9        2.0991       \u001b[32m0.6312\u001b[0m        \u001b[35m0.7740\u001b[0m  0.0539\n",
      "     10        1.2427       0.5542        0.9350  0.0489\n",
      "     11        1.6936       \u001b[32m0.6864\u001b[0m        \u001b[35m0.6333\u001b[0m  0.0598\n",
      "     12        1.2848       0.6450        0.6603  0.0698\n",
      "     13        1.2143       \u001b[32m0.8028\u001b[0m        \u001b[35m0.5500\u001b[0m  0.0598\n",
      "     14        \u001b[36m1.0590\u001b[0m       0.7673        0.7526  0.0658\n",
      "     15        1.5194       \u001b[32m0.8225\u001b[0m        \u001b[35m0.4859\u001b[0m  0.0698\n",
      "     16        1.1143       \u001b[32m0.8659\u001b[0m        0.5707  0.0618\n",
      "     17        1.0675       \u001b[32m0.8836\u001b[0m        \u001b[35m0.4417\u001b[0m  0.0598\n",
      "     18        \u001b[36m1.0494\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.3636\u001b[0m  0.0738\n",
      "     19        \u001b[36m0.8849\u001b[0m       0.9053        0.3747  0.0648\n",
      "     20        1.0162       0.9093        \u001b[35m0.3365\u001b[0m  0.0658\n",
      "     21        0.9068       0.9053        0.3673  0.0638\n",
      "     22        1.1141       0.8994        0.3400  0.0798\n",
      "     23        \u001b[36m0.8558\u001b[0m       0.8797        0.5395  0.0738\n",
      "     24        1.0769       \u001b[32m0.9408\u001b[0m        \u001b[35m0.2774\u001b[0m  0.0628\n",
      "     25        \u001b[36m0.7581\u001b[0m       0.9191        0.4305  0.0758\n",
      "     26        1.0106       0.9349        \u001b[35m0.2251\u001b[0m  0.0549\n",
      "     27        0.7620       0.9270        0.2576  0.0758\n",
      "     28        \u001b[36m0.7530\u001b[0m       0.9408        \u001b[35m0.1857\u001b[0m  0.0798\n",
      "     29        \u001b[36m0.6812\u001b[0m       0.9290        0.2001  0.0658\n",
      "     30        0.9131       0.9389        0.1868  0.0648\n",
      "     31        \u001b[36m0.5899\u001b[0m       0.9408        0.1879  0.0758\n",
      "     32        0.7630       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1391\u001b[0m  0.0728\n",
      "     33        \u001b[36m0.5683\u001b[0m       0.9329        0.2357  0.0778\n",
      "     34        0.7490       0.9448        0.1672  0.0618\n",
      "     35        0.5940       0.9211        0.2711  0.0549\n",
      "     36        0.6795       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1211\u001b[0m  0.0618\n",
      "     37        \u001b[36m0.5410\u001b[0m       0.9310        0.1877  0.0459\n",
      "     38        0.6466       \u001b[32m0.9645\u001b[0m        \u001b[35m0.1183\u001b[0m  0.0608\n",
      "     39        0.5478       0.9507        0.1389  0.0668\n",
      "     40        0.6497       0.9527        0.1591  0.0519\n",
      "     41        0.5930       0.9625        \u001b[35m0.1059\u001b[0m  0.0558\n",
      "     42        \u001b[36m0.5204\u001b[0m       0.9566        0.1516  0.0578\n",
      "     43        0.5742       0.9645        0.1078  0.0678\n",
      "     44        \u001b[36m0.4581\u001b[0m       0.9428        0.1577  0.0658\n",
      "     45        0.5147       0.9645        \u001b[35m0.1037\u001b[0m  0.0678\n",
      "     46        0.4906       0.9270        0.2389  0.0608\n",
      "     47        0.6084       0.9625        0.1062  0.0658\n",
      "     48        0.4842       0.9408        0.1659  0.0658\n",
      "     49        0.5178       0.9566        0.1196  0.0549\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m3.6356\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m2.5645\u001b[0m  0.0648\n",
      "      2        \u001b[36m3.2019\u001b[0m       \u001b[32m0.3018\u001b[0m        \u001b[35m1.4158\u001b[0m  0.0598\n",
      "      3        \u001b[36m2.6176\u001b[0m       \u001b[32m0.4852\u001b[0m        \u001b[35m1.0795\u001b[0m  0.0658\n",
      "      4        \u001b[36m1.4466\u001b[0m       \u001b[32m0.5759\u001b[0m        \u001b[35m0.9936\u001b[0m  0.0668\n",
      "      5        1.7386       \u001b[32m0.7357\u001b[0m        \u001b[35m0.6986\u001b[0m  0.0598\n",
      "      6        \u001b[36m1.4398\u001b[0m       0.6824        0.7946  0.0628\n",
      "      7        \u001b[36m1.3598\u001b[0m       \u001b[32m0.9487\u001b[0m        \u001b[35m0.4159\u001b[0m  0.0718\n",
      "      8        \u001b[36m0.9060\u001b[0m       0.7022        0.5828  0.0708\n",
      "      9        1.3136       0.8107        0.5069  0.0708\n",
      "     10        \u001b[36m0.8817\u001b[0m       0.7258        0.7367  0.0658\n",
      "     11        1.3622       0.8935        \u001b[35m0.3317\u001b[0m  0.0549\n",
      "     12        \u001b[36m0.8483\u001b[0m       0.7298        0.5310  0.0758\n",
      "     13        1.3470       0.9428        \u001b[35m0.2480\u001b[0m  0.0748\n",
      "     14        0.8830       0.9408        \u001b[35m0.2451\u001b[0m  0.0678\n",
      "     15        1.1418       0.9467        0.2567  0.0618\n",
      "     16        \u001b[36m0.7539\u001b[0m       0.9152        0.3283  0.0758\n",
      "     17        1.2843       0.9310        0.2595  0.0559\n",
      "     18        0.7924       0.9172        0.3247  0.0529\n",
      "     19        1.1304       0.9349        \u001b[35m0.2437\u001b[0m  0.0808\n",
      "     20        0.8028       0.9231        0.2660  0.0718\n",
      "     21        1.0438       \u001b[32m0.9507\u001b[0m        \u001b[35m0.2118\u001b[0m  0.0728\n",
      "     22        \u001b[36m0.6390\u001b[0m       0.9467        0.2812  0.0608\n",
      "     23        0.9851       0.9487        \u001b[35m0.1980\u001b[0m  0.0808\n",
      "     24        \u001b[36m0.6003\u001b[0m       0.9507        0.2958  0.0768\n",
      "     25        1.0637       0.9329        0.2453  0.0758\n",
      "     26        0.6047       0.9448        0.3531  0.0748\n",
      "     27        1.1287       0.8895        0.3872  0.0608\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3662\u001b[0m       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3112\u001b[0m  0.0598\n",
      "      2        \u001b[36m1.2828\u001b[0m       \u001b[32m0.3471\u001b[0m        \u001b[35m1.2465\u001b[0m  0.0429\n",
      "      3        \u001b[36m1.2159\u001b[0m       \u001b[32m0.4024\u001b[0m        \u001b[35m1.1745\u001b[0m  0.0529\n",
      "      4        \u001b[36m1.1326\u001b[0m       \u001b[32m0.4359\u001b[0m        \u001b[35m1.1037\u001b[0m  0.0748\n",
      "      5        \u001b[36m1.0535\u001b[0m       \u001b[32m0.4655\u001b[0m        \u001b[35m1.0276\u001b[0m  0.0588\n",
      "      6        \u001b[36m0.9735\u001b[0m       \u001b[32m0.5010\u001b[0m        \u001b[35m0.9604\u001b[0m  0.0718\n",
      "      7        \u001b[36m0.9082\u001b[0m       \u001b[32m0.5483\u001b[0m        \u001b[35m0.8974\u001b[0m  0.0668\n",
      "      8        \u001b[36m0.8598\u001b[0m       \u001b[32m0.6095\u001b[0m        \u001b[35m0.8375\u001b[0m  0.0748\n",
      "      9        \u001b[36m0.8102\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m0.7860\u001b[0m  0.0768\n",
      "     10        \u001b[36m0.7578\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m0.7379\u001b[0m  0.0688\n",
      "     11        \u001b[36m0.7102\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m0.6944\u001b[0m  0.0668\n",
      "     12        \u001b[36m0.6877\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m0.6567\u001b[0m  0.0648\n",
      "     13        \u001b[36m0.6478\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m0.6144\u001b[0m  0.0578\n",
      "     14        \u001b[36m0.6275\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m0.5838\u001b[0m  0.0529\n",
      "     15        \u001b[36m0.5993\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.5582\u001b[0m  0.0698\n",
      "     16        \u001b[36m0.5745\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m0.5289\u001b[0m  0.0559\n",
      "     17        \u001b[36m0.5426\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.5078\u001b[0m  0.0788\n",
      "     18        \u001b[36m0.5302\u001b[0m       \u001b[32m0.8205\u001b[0m        \u001b[35m0.4890\u001b[0m  0.0638\n",
      "     19        0.5333       \u001b[32m0.8245\u001b[0m        \u001b[35m0.4649\u001b[0m  0.0539\n",
      "     20        \u001b[36m0.5124\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4435\u001b[0m  0.0638\n",
      "     21        \u001b[36m0.4866\u001b[0m       0.8363        \u001b[35m0.4322\u001b[0m  0.0738\n",
      "     22        \u001b[36m0.4756\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.4223\u001b[0m  0.0608\n",
      "     23        0.4862       \u001b[32m0.8521\u001b[0m        \u001b[35m0.4103\u001b[0m  0.0638\n",
      "     24        \u001b[36m0.4557\u001b[0m       0.8521        \u001b[35m0.3996\u001b[0m  0.0668\n",
      "     25        \u001b[36m0.4520\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.3835\u001b[0m  0.0578\n",
      "     26        \u001b[36m0.4417\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3720\u001b[0m  0.0618\n",
      "     27        \u001b[36m0.4364\u001b[0m       0.8600        \u001b[35m0.3620\u001b[0m  0.0628\n",
      "     28        \u001b[36m0.4117\u001b[0m       0.8600        \u001b[35m0.3574\u001b[0m  0.0459\n",
      "     29        0.4245       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3456\u001b[0m  0.0549\n",
      "     30        \u001b[36m0.4056\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3328\u001b[0m  0.0608\n",
      "     31        0.4103       0.8659        \u001b[35m0.3307\u001b[0m  0.0539\n",
      "     32        \u001b[36m0.4034\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.3180\u001b[0m  0.0588\n",
      "     33        \u001b[36m0.3871\u001b[0m       0.8718        \u001b[35m0.3179\u001b[0m  0.0618\n",
      "     34        0.3945       0.8718        \u001b[35m0.3097\u001b[0m  0.0668\n",
      "     35        \u001b[36m0.3608\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.2977\u001b[0m  0.0578\n",
      "     36        0.3752       0.8718        \u001b[35m0.2970\u001b[0m  0.0598\n",
      "     37        0.3737       0.8738        \u001b[35m0.2924\u001b[0m  0.0578\n",
      "     38        0.3862       \u001b[32m0.8757\u001b[0m        \u001b[35m0.2856\u001b[0m  0.0618\n",
      "     39        \u001b[36m0.3497\u001b[0m       \u001b[32m0.8797\u001b[0m        \u001b[35m0.2766\u001b[0m  0.0568\n",
      "     40        0.3553       0.8738        0.2800  0.0489\n",
      "     41        \u001b[36m0.3459\u001b[0m       0.8738        \u001b[35m0.2747\u001b[0m  0.0469\n",
      "     42        0.3629       \u001b[32m0.8836\u001b[0m        \u001b[35m0.2679\u001b[0m  0.0658\n",
      "     43        \u001b[36m0.3417\u001b[0m       0.8777        0.2718  0.0708\n",
      "     44        0.3578       0.8797        \u001b[35m0.2656\u001b[0m  0.0549\n",
      "     45        0.3427       \u001b[32m0.8876\u001b[0m        \u001b[35m0.2604\u001b[0m  0.0499\n",
      "     46        0.3550       \u001b[32m0.8915\u001b[0m        \u001b[35m0.2542\u001b[0m  0.0479\n",
      "     47        \u001b[36m0.3366\u001b[0m       0.8856        0.2573  0.0539\n",
      "     48        0.3521       0.8895        \u001b[35m0.2459\u001b[0m  0.0688\n",
      "     49        \u001b[36m0.3257\u001b[0m       \u001b[32m0.8955\u001b[0m        0.2483  0.0628\n",
      "     50        0.3322       \u001b[32m0.8994\u001b[0m        \u001b[35m0.2405\u001b[0m  0.0598\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.8s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4509\u001b[0m       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3626\u001b[0m  0.0698\n",
      "      2        \u001b[36m1.3651\u001b[0m       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3094\u001b[0m  0.0668\n",
      "      3        \u001b[36m1.3145\u001b[0m       0.2919        \u001b[35m1.2642\u001b[0m  0.0688\n",
      "      4        \u001b[36m1.2556\u001b[0m       \u001b[32m0.3432\u001b[0m        \u001b[35m1.2123\u001b[0m  0.0459\n",
      "      5        \u001b[36m1.1952\u001b[0m       \u001b[32m0.3964\u001b[0m        \u001b[35m1.1480\u001b[0m  0.0539\n",
      "      6        \u001b[36m1.1320\u001b[0m       \u001b[32m0.4379\u001b[0m        \u001b[35m1.0864\u001b[0m  0.0539\n",
      "      7        \u001b[36m1.0699\u001b[0m       \u001b[32m0.5089\u001b[0m        \u001b[35m1.0220\u001b[0m  0.0698\n",
      "      8        \u001b[36m1.0096\u001b[0m       \u001b[32m0.5759\u001b[0m        \u001b[35m0.9547\u001b[0m  0.0539\n",
      "      9        \u001b[36m0.9415\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m0.9019\u001b[0m  0.0499\n",
      "     10        \u001b[36m0.8933\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m0.8433\u001b[0m  0.0628\n",
      "     11        \u001b[36m0.8624\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m0.8011\u001b[0m  0.0529\n",
      "     12        \u001b[36m0.7968\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m0.7527\u001b[0m  0.0678\n",
      "     13        \u001b[36m0.7619\u001b[0m       \u001b[32m0.7041\u001b[0m        \u001b[35m0.7127\u001b[0m  0.0568\n",
      "     14        \u001b[36m0.7314\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m0.6745\u001b[0m  0.0668\n",
      "     15        \u001b[36m0.6891\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.6379\u001b[0m  0.0529\n",
      "     16        \u001b[36m0.6685\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.5999\u001b[0m  0.0638\n",
      "     17        \u001b[36m0.6400\u001b[0m       \u001b[32m0.7850\u001b[0m        \u001b[35m0.5756\u001b[0m  0.0559\n",
      "     18        \u001b[36m0.6174\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.5472\u001b[0m  0.0708\n",
      "     19        \u001b[36m0.6012\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.5314\u001b[0m  0.0748\n",
      "     20        \u001b[36m0.5758\u001b[0m       \u001b[32m0.8166\u001b[0m        \u001b[35m0.5026\u001b[0m  0.0728\n",
      "     21        \u001b[36m0.5481\u001b[0m       0.8166        \u001b[35m0.4892\u001b[0m  0.0558\n",
      "     22        0.5520       \u001b[32m0.8264\u001b[0m        \u001b[35m0.4686\u001b[0m  0.0588\n",
      "     23        \u001b[36m0.5200\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4545\u001b[0m  0.0608\n",
      "     24        \u001b[36m0.5054\u001b[0m       \u001b[32m0.8442\u001b[0m        \u001b[35m0.4396\u001b[0m  0.0559\n",
      "     25        \u001b[36m0.4885\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.4228\u001b[0m  0.0588\n",
      "     26        \u001b[36m0.4831\u001b[0m       0.8422        \u001b[35m0.4090\u001b[0m  0.0598\n",
      "     27        \u001b[36m0.4726\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.3971\u001b[0m  0.0778\n",
      "     28        \u001b[36m0.4667\u001b[0m       0.8501        \u001b[35m0.3854\u001b[0m  0.0668\n",
      "     29        \u001b[36m0.4568\u001b[0m       \u001b[32m0.8521\u001b[0m        \u001b[35m0.3753\u001b[0m  0.0588\n",
      "     30        \u001b[36m0.4300\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3657\u001b[0m  0.0658\n",
      "     31        0.4340       0.8580        \u001b[35m0.3634\u001b[0m  0.0738\n",
      "     32        \u001b[36m0.4289\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3474\u001b[0m  0.0588\n",
      "     33        \u001b[36m0.4084\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.3443\u001b[0m  0.0559\n",
      "     34        0.4193       0.8679        0.3444  0.0738\n",
      "     35        \u001b[36m0.4057\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.3367\u001b[0m  0.0568\n",
      "     36        \u001b[36m0.3952\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.3246\u001b[0m  0.0519\n",
      "     37        \u001b[36m0.3927\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.3173\u001b[0m  0.0668\n",
      "     38        \u001b[36m0.3806\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.3110\u001b[0m  0.0718\n",
      "     39        0.4014       0.8856        \u001b[35m0.3085\u001b[0m  0.0778\n",
      "     40        0.3843       \u001b[32m0.8876\u001b[0m        \u001b[35m0.3008\u001b[0m  0.0718\n",
      "     41        \u001b[36m0.3727\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.2909\u001b[0m  0.0698\n",
      "     42        0.3730       0.8895        \u001b[35m0.2897\u001b[0m  0.0688\n",
      "     43        \u001b[36m0.3624\u001b[0m       0.8856        0.2974  0.0479\n",
      "     44        0.3722       \u001b[32m0.8915\u001b[0m        \u001b[35m0.2853\u001b[0m  0.0588\n",
      "     45        \u001b[36m0.3488\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.2831\u001b[0m  0.0638\n",
      "     46        0.3721       0.8915        \u001b[35m0.2745\u001b[0m  0.0479\n",
      "     47        \u001b[36m0.3476\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.2728\u001b[0m  0.0578\n",
      "     48        0.3498       0.8935        \u001b[35m0.2713\u001b[0m  0.0638\n",
      "     49        \u001b[36m0.3430\u001b[0m       0.8915        \u001b[35m0.2685\u001b[0m  0.0608\n",
      "     50        0.3610       \u001b[32m0.8994\u001b[0m        \u001b[35m0.2650\u001b[0m  0.0628\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3488\u001b[0m       \u001b[32m0.2899\u001b[0m        \u001b[35m1.3324\u001b[0m  0.0648\n",
      "      2        \u001b[36m1.3019\u001b[0m       \u001b[32m0.3511\u001b[0m        \u001b[35m1.2743\u001b[0m  0.0698\n",
      "      3        \u001b[36m1.2236\u001b[0m       \u001b[32m0.3787\u001b[0m        \u001b[35m1.2041\u001b[0m  0.0568\n",
      "      4        \u001b[36m1.1343\u001b[0m       \u001b[32m0.4320\u001b[0m        \u001b[35m1.1266\u001b[0m  0.0429\n",
      "      5        \u001b[36m1.0565\u001b[0m       \u001b[32m0.4635\u001b[0m        \u001b[35m1.0512\u001b[0m  0.0499\n",
      "      6        \u001b[36m0.9903\u001b[0m       \u001b[32m0.5049\u001b[0m        \u001b[35m0.9879\u001b[0m  0.0688\n",
      "      7        \u001b[36m0.9203\u001b[0m       \u001b[32m0.5542\u001b[0m        \u001b[35m0.9198\u001b[0m  0.0539\n",
      "      8        \u001b[36m0.8616\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m0.8574\u001b[0m  0.0618\n",
      "      9        \u001b[36m0.8254\u001b[0m       \u001b[32m0.6371\u001b[0m        \u001b[35m0.8073\u001b[0m  0.0588\n",
      "     10        \u001b[36m0.7703\u001b[0m       \u001b[32m0.6686\u001b[0m        \u001b[35m0.7562\u001b[0m  0.0648\n",
      "     11        \u001b[36m0.7354\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m0.7148\u001b[0m  0.0499\n",
      "     12        \u001b[36m0.6889\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0559\n",
      "     13        \u001b[36m0.6638\u001b[0m       \u001b[32m0.7199\u001b[0m        \u001b[35m0.6308\u001b[0m  0.0648\n",
      "     14        \u001b[36m0.6348\u001b[0m       \u001b[32m0.7456\u001b[0m        \u001b[35m0.5972\u001b[0m  0.0588\n",
      "     15        \u001b[36m0.6032\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m0.5743\u001b[0m  0.0588\n",
      "     16        \u001b[36m0.5790\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.5365\u001b[0m  0.0768\n",
      "     17        \u001b[36m0.5578\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.5155\u001b[0m  0.0489\n",
      "     18        \u001b[36m0.5457\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.4986\u001b[0m  0.0638\n",
      "     19        \u001b[36m0.5359\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.4732\u001b[0m  0.0628\n",
      "     20        \u001b[36m0.5264\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.4522\u001b[0m  0.0509\n",
      "     21        \u001b[36m0.5002\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.4297\u001b[0m  0.0419\n",
      "     22        \u001b[36m0.4819\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.4175\u001b[0m  0.0559\n",
      "     23        0.4823       \u001b[32m0.8619\u001b[0m        \u001b[35m0.4064\u001b[0m  0.0588\n",
      "     24        \u001b[36m0.4701\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3948\u001b[0m  0.0559\n",
      "     25        \u001b[36m0.4510\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.3733\u001b[0m  0.0489\n",
      "     26        0.4548       0.8777        \u001b[35m0.3709\u001b[0m  0.0539\n",
      "     27        \u001b[36m0.4394\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.3460\u001b[0m  0.0628\n",
      "     28        \u001b[36m0.4249\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.3358\u001b[0m  0.0439\n",
      "     29        \u001b[36m0.4186\u001b[0m       0.8955        \u001b[35m0.3315\u001b[0m  0.0459\n",
      "     30        \u001b[36m0.4115\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.3231\u001b[0m  0.0578\n",
      "     31        0.4130       0.8994        \u001b[35m0.3141\u001b[0m  0.0588\n",
      "     32        0.4122       \u001b[32m0.9014\u001b[0m        \u001b[35m0.3102\u001b[0m  0.0688\n",
      "     33        \u001b[36m0.3898\u001b[0m       0.9014        \u001b[35m0.3031\u001b[0m  0.0539\n",
      "     34        0.4043       \u001b[32m0.9053\u001b[0m        \u001b[35m0.2925\u001b[0m  0.0529\n",
      "     35        \u001b[36m0.3829\u001b[0m       0.9034        \u001b[35m0.2882\u001b[0m  0.0499\n",
      "     36        \u001b[36m0.3719\u001b[0m       0.9053        \u001b[35m0.2809\u001b[0m  0.0608\n",
      "     37        0.3781       \u001b[32m0.9073\u001b[0m        \u001b[35m0.2742\u001b[0m  0.0569\n",
      "     38        \u001b[36m0.3648\u001b[0m       0.9073        \u001b[35m0.2667\u001b[0m  0.0469\n",
      "     39        0.3682       0.9073        \u001b[35m0.2643\u001b[0m  0.0429\n",
      "     40        \u001b[36m0.3585\u001b[0m       0.9073        \u001b[35m0.2592\u001b[0m  0.0469\n",
      "     41        \u001b[36m0.3571\u001b[0m       \u001b[32m0.9112\u001b[0m        \u001b[35m0.2489\u001b[0m  0.0738\n",
      "     42        \u001b[36m0.3470\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.2451\u001b[0m  0.0598\n",
      "     43        \u001b[36m0.3378\u001b[0m       0.9132        \u001b[35m0.2435\u001b[0m  0.0798\n",
      "     44        0.3513       \u001b[32m0.9172\u001b[0m        \u001b[35m0.2398\u001b[0m  0.0638\n",
      "     45        0.3393       \u001b[32m0.9191\u001b[0m        \u001b[35m0.2317\u001b[0m  0.0559\n",
      "     46        0.3496       \u001b[32m0.9211\u001b[0m        \u001b[35m0.2304\u001b[0m  0.0549\n",
      "     47        \u001b[36m0.3344\u001b[0m       0.9191        \u001b[35m0.2299\u001b[0m  0.0568\n",
      "     48        \u001b[36m0.3329\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.2257\u001b[0m  0.0618\n",
      "     49        0.3420       \u001b[32m0.9250\u001b[0m        \u001b[35m0.2192\u001b[0m  0.0549\n",
      "     50        \u001b[36m0.3216\u001b[0m       \u001b[32m0.9270\u001b[0m        \u001b[35m0.2115\u001b[0m  0.0718\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.6s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.3050\u001b[0m       \u001b[32m0.2446\u001b[0m        \u001b[35m3.7057\u001b[0m  0.0568\n",
      "      2        6.0262       \u001b[32m0.2564\u001b[0m        \u001b[35m2.3591\u001b[0m  0.0658\n",
      "      3        \u001b[36m3.8549\u001b[0m       \u001b[32m0.4201\u001b[0m        \u001b[35m1.4832\u001b[0m  0.0738\n",
      "      4        \u001b[36m3.5703\u001b[0m       \u001b[32m0.4872\u001b[0m        \u001b[35m1.1731\u001b[0m  0.0628\n",
      "      5        \u001b[36m2.2879\u001b[0m       \u001b[32m0.5602\u001b[0m        \u001b[35m0.7908\u001b[0m  0.0598\n",
      "      6        \u001b[36m2.2525\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m0.5536\u001b[0m  0.0848\n",
      "      7        \u001b[36m1.4269\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.5180\u001b[0m  0.0628\n",
      "      8        \u001b[36m1.2412\u001b[0m       \u001b[32m0.9191\u001b[0m        \u001b[35m0.2999\u001b[0m  0.0778\n",
      "      9        \u001b[36m0.8265\u001b[0m       0.9132        0.3073  0.0698\n",
      "     10        1.3585       \u001b[32m0.9310\u001b[0m        \u001b[35m0.2679\u001b[0m  0.0738\n",
      "     11        0.8492       0.9231        0.2811  0.0748\n",
      "     12        1.1033       \u001b[32m0.9428\u001b[0m        \u001b[35m0.2180\u001b[0m  0.0668\n",
      "     13        \u001b[36m0.7202\u001b[0m       0.9270        0.3531  0.0598\n",
      "     14        1.0301       0.9369        \u001b[35m0.2144\u001b[0m  0.0638\n",
      "     15        \u001b[36m0.7178\u001b[0m       0.9270        0.2773  0.0648\n",
      "     16        0.9433       \u001b[32m0.9487\u001b[0m        \u001b[35m0.1667\u001b[0m  0.0618\n",
      "     17        0.7296       0.8876        0.3251  0.0618\n",
      "     18        0.7413       0.9428        0.1985  0.0878\n",
      "     19        0.8205       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1360\u001b[0m  0.0758\n",
      "     20        \u001b[36m0.5023\u001b[0m       0.9389        0.2752  0.0608\n",
      "     21        0.6362       \u001b[32m0.9763\u001b[0m        \u001b[35m0.0815\u001b[0m  0.0748\n",
      "     22        \u001b[36m0.4229\u001b[0m       0.9428        0.2845  0.0808\n",
      "     23        0.5928       0.9763        \u001b[35m0.0801\u001b[0m  0.0698\n",
      "     24        \u001b[36m0.4044\u001b[0m       0.9467        0.2455  0.0578\n",
      "     25        0.5606       0.9566        0.0984  0.0578\n",
      "     26        \u001b[36m0.3540\u001b[0m       0.9448        0.2612  0.0539\n",
      "     27        0.6587       0.9724        0.0941  0.0608\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m3.6806\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m5.0460\u001b[0m  0.0748\n",
      "      2        7.2593       0.2505        \u001b[35m2.5317\u001b[0m  0.0718\n",
      "      3        3.8455       \u001b[32m0.2978\u001b[0m        \u001b[35m1.2370\u001b[0m  0.0499\n",
      "      4        \u001b[36m3.4850\u001b[0m       \u001b[32m0.4477\u001b[0m        \u001b[35m1.2278\u001b[0m  0.0688\n",
      "      5        \u001b[36m1.9500\u001b[0m       \u001b[32m0.5247\u001b[0m        \u001b[35m0.7918\u001b[0m  0.0628\n",
      "      6        \u001b[36m1.9083\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m0.7553\u001b[0m  0.0738\n",
      "      7        \u001b[36m1.6219\u001b[0m       0.6824        \u001b[35m0.6300\u001b[0m  0.0588\n",
      "      8        \u001b[36m1.5142\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.4444\u001b[0m  0.0778\n",
      "      9        \u001b[36m1.3720\u001b[0m       0.8560        \u001b[35m0.3835\u001b[0m  0.0499\n",
      "     10        \u001b[36m1.3658\u001b[0m       \u001b[32m0.8698\u001b[0m        0.3973  0.0618\n",
      "     11        \u001b[36m1.2790\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.3531\u001b[0m  0.0718\n",
      "     12        1.3241       \u001b[32m0.9329\u001b[0m        \u001b[35m0.2409\u001b[0m  0.0539\n",
      "     13        \u001b[36m1.0660\u001b[0m       0.9112        0.3223  0.0688\n",
      "     14        1.2867       0.9250        0.2561  0.0778\n",
      "     15        1.1159       0.8817        0.5504  0.0638\n",
      "     16        1.7345       0.9310        0.3075  0.0718\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.4s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8716\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m7.4912\u001b[0m  0.0748\n",
      "      2        8.2024       0.2505        \u001b[35m3.0340\u001b[0m  0.0718\n",
      "      3        4.9197       \u001b[32m0.4951\u001b[0m        \u001b[35m1.4817\u001b[0m  0.0658\n",
      "      4        2.9224       0.3925        \u001b[35m1.2151\u001b[0m  0.0698\n",
      "      5        2.4077       \u001b[32m0.7219\u001b[0m        \u001b[35m0.8396\u001b[0m  0.0718\n",
      "      6        2.1707       \u001b[32m0.8501\u001b[0m        \u001b[35m0.4394\u001b[0m  0.0678\n",
      "      7        \u001b[36m1.4660\u001b[0m       0.8107        0.5354  0.0708\n",
      "      8        1.5299       \u001b[32m0.9034\u001b[0m        \u001b[35m0.3166\u001b[0m  0.0618\n",
      "      9        \u001b[36m0.9375\u001b[0m       \u001b[32m0.9112\u001b[0m        0.3257  0.0668\n",
      "     10        1.2233       \u001b[32m0.9507\u001b[0m        \u001b[35m0.2287\u001b[0m  0.0678\n",
      "     11        \u001b[36m0.7473\u001b[0m       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1692\u001b[0m  0.0539\n",
      "     12        0.8987       0.9310        0.2157  0.0678\n",
      "     13        0.8417       0.9527        0.1704  0.0588\n",
      "     14        \u001b[36m0.7438\u001b[0m       0.9546        \u001b[35m0.1556\u001b[0m  0.0708\n",
      "     15        \u001b[36m0.5933\u001b[0m       \u001b[32m0.9665\u001b[0m        \u001b[35m0.1326\u001b[0m  0.0539\n",
      "     16        0.6030       0.9546        0.2235  0.0559\n",
      "     17        0.7071       0.9606        \u001b[35m0.1128\u001b[0m  0.0718\n",
      "     18        \u001b[36m0.4401\u001b[0m       0.9546        0.2283  0.0708\n",
      "     19        0.6506       0.9527        0.1231  0.0708\n",
      "     20        \u001b[36m0.4217\u001b[0m       0.9448        0.3067  0.0598\n",
      "     21        0.8141       0.9665        \u001b[35m0.1116\u001b[0m  0.0708\n",
      "     22        0.5110       0.9665        0.1186  0.0628\n",
      "     23        0.5418       \u001b[32m0.9803\u001b[0m        \u001b[35m0.0926\u001b[0m  0.0708\n",
      "     24        0.4904       0.9527        0.2418  0.0568\n",
      "     25        0.7179       0.9625        0.1067  0.0608\n",
      "     26        \u001b[36m0.4076\u001b[0m       0.9566        0.2103  0.0758\n",
      "     27        0.6426       0.9783        0.0966  0.0628\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4030\u001b[0m       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3432\u001b[0m  0.0578\n",
      "      2        \u001b[36m1.3291\u001b[0m       0.2722        \u001b[35m1.2921\u001b[0m  0.0568\n",
      "      3        \u001b[36m1.2654\u001b[0m       \u001b[32m0.3195\u001b[0m        \u001b[35m1.2356\u001b[0m  0.0449\n",
      "      4        \u001b[36m1.1833\u001b[0m       \u001b[32m0.3688\u001b[0m        \u001b[35m1.1676\u001b[0m  0.0628\n",
      "      5        \u001b[36m1.0995\u001b[0m       \u001b[32m0.4162\u001b[0m        \u001b[35m1.0914\u001b[0m  0.0598\n",
      "      6        \u001b[36m1.0224\u001b[0m       \u001b[32m0.4931\u001b[0m        \u001b[35m1.0098\u001b[0m  0.0499\n",
      "      7        \u001b[36m0.9355\u001b[0m       \u001b[32m0.5365\u001b[0m        \u001b[35m0.9343\u001b[0m  0.0499\n",
      "      8        \u001b[36m0.8717\u001b[0m       \u001b[32m0.6036\u001b[0m        \u001b[35m0.8570\u001b[0m  0.0628\n",
      "      9        \u001b[36m0.8008\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m0.8010\u001b[0m  0.0638\n",
      "     10        \u001b[36m0.7418\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m0.7369\u001b[0m  0.0698\n",
      "     11        \u001b[36m0.6826\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m0.6873\u001b[0m  0.0519\n",
      "     12        \u001b[36m0.6541\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.6357\u001b[0m  0.0628\n",
      "     13        \u001b[36m0.6056\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.5915\u001b[0m  0.0549\n",
      "     14        \u001b[36m0.5874\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m0.5624\u001b[0m  0.0578\n",
      "     15        \u001b[36m0.5717\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.5323\u001b[0m  0.0559\n",
      "     16        \u001b[36m0.5367\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.5012\u001b[0m  0.0578\n",
      "     17        \u001b[36m0.5093\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.4717\u001b[0m  0.0479\n",
      "     18        \u001b[36m0.4800\u001b[0m       0.8245        \u001b[35m0.4539\u001b[0m  0.0668\n",
      "     19        0.4808       \u001b[32m0.8343\u001b[0m        \u001b[35m0.4330\u001b[0m  0.0588\n",
      "     20        \u001b[36m0.4416\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4126\u001b[0m  0.0559\n",
      "     21        \u001b[36m0.4376\u001b[0m       \u001b[32m0.8442\u001b[0m        \u001b[35m0.3990\u001b[0m  0.0628\n",
      "     22        \u001b[36m0.4298\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.3901\u001b[0m  0.0718\n",
      "     23        \u001b[36m0.4145\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.3698\u001b[0m  0.0628\n",
      "     24        \u001b[36m0.3869\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.3587\u001b[0m  0.0618\n",
      "     25        0.3946       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3462\u001b[0m  0.0688\n",
      "     26        \u001b[36m0.3774\u001b[0m       0.8600        \u001b[35m0.3381\u001b[0m  0.0559\n",
      "     27        0.3920       0.8600        \u001b[35m0.3298\u001b[0m  0.0598\n",
      "     28        \u001b[36m0.3614\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3166\u001b[0m  0.0479\n",
      "     29        \u001b[36m0.3495\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.3100\u001b[0m  0.0648\n",
      "     30        0.3564       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3071\u001b[0m  0.0568\n",
      "     31        0.3601       \u001b[32m0.8718\u001b[0m        \u001b[35m0.2955\u001b[0m  0.0738\n",
      "     32        \u001b[36m0.3340\u001b[0m       0.8718        \u001b[35m0.2902\u001b[0m  0.0718\n",
      "     33        \u001b[36m0.3304\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.2850\u001b[0m  0.0648\n",
      "     34        0.3318       0.8718        \u001b[35m0.2814\u001b[0m  0.0658\n",
      "     35        \u001b[36m0.3285\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.2776\u001b[0m  0.0718\n",
      "     36        \u001b[36m0.3140\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.2711\u001b[0m  0.0499\n",
      "     37        \u001b[36m0.3118\u001b[0m       0.8777        \u001b[35m0.2668\u001b[0m  0.0698\n",
      "     38        \u001b[36m0.3108\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.2576\u001b[0m  0.0588\n",
      "     39        \u001b[36m0.3059\u001b[0m       0.8817        0.2581  0.0588\n",
      "     40        \u001b[36m0.2899\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.2564\u001b[0m  0.0459\n",
      "     41        \u001b[36m0.2887\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.2533\u001b[0m  0.0549\n",
      "     42        \u001b[36m0.2833\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.2432\u001b[0m  0.0598\n",
      "     43        \u001b[36m0.2779\u001b[0m       0.8974        0.2467  0.0568\n",
      "     44        0.2874       \u001b[32m0.9014\u001b[0m        \u001b[35m0.2369\u001b[0m  0.0638\n",
      "     45        0.2832       \u001b[32m0.9034\u001b[0m        \u001b[35m0.2334\u001b[0m  0.0509\n",
      "     46        \u001b[36m0.2702\u001b[0m       0.9014        \u001b[35m0.2295\u001b[0m  0.0598\n",
      "     47        0.2765       0.9014        \u001b[35m0.2279\u001b[0m  0.0509\n",
      "     48        0.2751       0.9014        \u001b[35m0.2278\u001b[0m  0.0628\n",
      "     49        \u001b[36m0.2542\u001b[0m       0.8994        0.2283  0.0678\n",
      "     50        0.2660       0.9034        \u001b[35m0.2212\u001b[0m  0.0559\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.7s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4080\u001b[0m       \u001b[32m0.2761\u001b[0m        \u001b[35m1.3491\u001b[0m  0.0578\n",
      "      2        \u001b[36m1.3374\u001b[0m       \u001b[32m0.2978\u001b[0m        \u001b[35m1.2895\u001b[0m  0.0658\n",
      "      3        \u001b[36m1.2618\u001b[0m       \u001b[32m0.3195\u001b[0m        \u001b[35m1.2248\u001b[0m  0.0638\n",
      "      4        \u001b[36m1.1873\u001b[0m       \u001b[32m0.4122\u001b[0m        \u001b[35m1.1486\u001b[0m  0.0549\n",
      "      5        \u001b[36m1.1036\u001b[0m       \u001b[32m0.5148\u001b[0m        \u001b[35m1.0658\u001b[0m  0.0708\n",
      "      6        \u001b[36m1.0118\u001b[0m       \u001b[32m0.5523\u001b[0m        \u001b[35m0.9898\u001b[0m  0.0588\n",
      "      7        \u001b[36m0.9309\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m0.9140\u001b[0m  0.0638\n",
      "      8        \u001b[36m0.8551\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m0.8492\u001b[0m  0.0728\n",
      "      9        \u001b[36m0.7907\u001b[0m       \u001b[32m0.6726\u001b[0m        \u001b[35m0.7883\u001b[0m  0.0549\n",
      "     10        \u001b[36m0.7414\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m0.7370\u001b[0m  0.0778\n",
      "     11        \u001b[36m0.7033\u001b[0m       \u001b[32m0.7081\u001b[0m        \u001b[35m0.6918\u001b[0m  0.0708\n",
      "     12        \u001b[36m0.6510\u001b[0m       \u001b[32m0.7357\u001b[0m        \u001b[35m0.6486\u001b[0m  0.0738\n",
      "     13        \u001b[36m0.6148\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m0.6128\u001b[0m  0.0638\n",
      "     14        \u001b[36m0.5767\u001b[0m       \u001b[32m0.7594\u001b[0m        \u001b[35m0.5824\u001b[0m  0.0618\n",
      "     15        \u001b[36m0.5614\u001b[0m       \u001b[32m0.7751\u001b[0m        \u001b[35m0.5528\u001b[0m  0.0618\n",
      "     16        \u001b[36m0.5321\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.5296\u001b[0m  0.0718\n",
      "     17        \u001b[36m0.5094\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.5032\u001b[0m  0.0549\n",
      "     18        \u001b[36m0.4982\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.4811\u001b[0m  0.0529\n",
      "     19        \u001b[36m0.4806\u001b[0m       \u001b[32m0.8284\u001b[0m        \u001b[35m0.4599\u001b[0m  0.0698\n",
      "     20        \u001b[36m0.4656\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.4479\u001b[0m  0.0499\n",
      "     21        \u001b[36m0.4515\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.4335\u001b[0m  0.0578\n",
      "     22        \u001b[36m0.4339\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.4183\u001b[0m  0.0449\n",
      "     23        \u001b[36m0.4256\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.4062\u001b[0m  0.0788\n",
      "     24        \u001b[36m0.3988\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.3929\u001b[0m  0.0748\n",
      "     25        \u001b[36m0.3943\u001b[0m       0.8462        \u001b[35m0.3896\u001b[0m  0.0608\n",
      "     26        \u001b[36m0.3942\u001b[0m       0.8462        \u001b[35m0.3761\u001b[0m  0.0708\n",
      "     27        \u001b[36m0.3843\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.3632\u001b[0m  0.0708\n",
      "     28        \u001b[36m0.3747\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.3556\u001b[0m  0.0688\n",
      "     29        \u001b[36m0.3700\u001b[0m       0.8580        \u001b[35m0.3502\u001b[0m  0.0688\n",
      "     30        \u001b[36m0.3628\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3371\u001b[0m  0.0588\n",
      "     31        \u001b[36m0.3427\u001b[0m       0.8659        \u001b[35m0.3335\u001b[0m  0.0469\n",
      "     32        0.3429       0.8679        \u001b[35m0.3252\u001b[0m  0.0668\n",
      "     33        \u001b[36m0.3255\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.3218\u001b[0m  0.0668\n",
      "     34        0.3393       \u001b[32m0.8718\u001b[0m        \u001b[35m0.3192\u001b[0m  0.0519\n",
      "     35        \u001b[36m0.3193\u001b[0m       0.8718        \u001b[35m0.3112\u001b[0m  0.0409\n",
      "     36        0.3233       \u001b[32m0.8777\u001b[0m        \u001b[35m0.3053\u001b[0m  0.0469\n",
      "     37        \u001b[36m0.3139\u001b[0m       0.8757        \u001b[35m0.2998\u001b[0m  0.0489\n",
      "     38        \u001b[36m0.3091\u001b[0m       0.8718        0.3001  0.0549\n",
      "     39        \u001b[36m0.2944\u001b[0m       0.8738        \u001b[35m0.2951\u001b[0m  0.0718\n",
      "     40        0.3128       \u001b[32m0.8797\u001b[0m        \u001b[35m0.2869\u001b[0m  0.0568\n",
      "     41        0.2960       \u001b[32m0.8836\u001b[0m        \u001b[35m0.2780\u001b[0m  0.0658\n",
      "     42        \u001b[36m0.2833\u001b[0m       0.8836        \u001b[35m0.2776\u001b[0m  0.0668\n",
      "     43        \u001b[36m0.2812\u001b[0m       0.8817        0.2798  0.0628\n",
      "     44        0.2946       0.8836        \u001b[35m0.2749\u001b[0m  0.0668\n",
      "     45        0.2945       0.8836        \u001b[35m0.2708\u001b[0m  0.0449\n",
      "     46        \u001b[36m0.2804\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.2661\u001b[0m  0.0419\n",
      "     47        \u001b[36m0.2751\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.2648\u001b[0m  0.0549\n",
      "     48        0.2904       0.8876        0.2666  0.0568\n",
      "     49        0.2785       \u001b[32m0.8895\u001b[0m        \u001b[35m0.2553\u001b[0m  0.0499\n",
      "     50        \u001b[36m0.2661\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.2553\u001b[0m  0.0708\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.8s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3386\u001b[0m       \u001b[32m0.4024\u001b[0m        \u001b[35m1.2711\u001b[0m  0.0638\n",
      "      2        \u001b[36m1.2737\u001b[0m       0.3649        \u001b[35m1.2189\u001b[0m  0.0748\n",
      "      3        \u001b[36m1.2151\u001b[0m       0.4024        \u001b[35m1.1517\u001b[0m  0.0768\n",
      "      4        \u001b[36m1.1263\u001b[0m       \u001b[32m0.4734\u001b[0m        \u001b[35m1.0747\u001b[0m  0.0529\n",
      "      5        \u001b[36m1.0435\u001b[0m       \u001b[32m0.5306\u001b[0m        \u001b[35m1.0000\u001b[0m  0.0499\n",
      "      6        \u001b[36m0.9661\u001b[0m       \u001b[32m0.5799\u001b[0m        \u001b[35m0.9285\u001b[0m  0.0628\n",
      "      7        \u001b[36m0.8901\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m0.8690\u001b[0m  0.0539\n",
      "      8        \u001b[36m0.8332\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.8007\u001b[0m  0.0539\n",
      "      9        \u001b[36m0.7693\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m0.7457\u001b[0m  0.0618\n",
      "     10        \u001b[36m0.7310\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m0.7008\u001b[0m  0.0658\n",
      "     11        \u001b[36m0.6901\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.6553\u001b[0m  0.0698\n",
      "     12        \u001b[36m0.6538\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.6186\u001b[0m  0.0698\n",
      "     13        \u001b[36m0.6179\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.5814\u001b[0m  0.0509\n",
      "     14        \u001b[36m0.5799\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m0.5467\u001b[0m  0.0648\n",
      "     15        \u001b[36m0.5719\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.5222\u001b[0m  0.0688\n",
      "     16        \u001b[36m0.5409\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.4916\u001b[0m  0.0668\n",
      "     17        \u001b[36m0.5149\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.4709\u001b[0m  0.0568\n",
      "     18        \u001b[36m0.4982\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.4474\u001b[0m  0.0588\n",
      "     19        \u001b[36m0.4869\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.4296\u001b[0m  0.0598\n",
      "     20        \u001b[36m0.4607\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.4154\u001b[0m  0.0658\n",
      "     21        \u001b[36m0.4504\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.4055\u001b[0m  0.0549\n",
      "     22        \u001b[36m0.4331\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3867\u001b[0m  0.0558\n",
      "     23        \u001b[36m0.4263\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.3719\u001b[0m  0.0618\n",
      "     24        \u001b[36m0.4149\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.3554\u001b[0m  0.0529\n",
      "     25        \u001b[36m0.3978\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.3453\u001b[0m  0.0509\n",
      "     26        \u001b[36m0.3924\u001b[0m       0.8856        \u001b[35m0.3360\u001b[0m  0.0559\n",
      "     27        \u001b[36m0.3815\u001b[0m       0.8856        \u001b[35m0.3275\u001b[0m  0.0588\n",
      "     28        \u001b[36m0.3698\u001b[0m       0.8856        \u001b[35m0.3240\u001b[0m  0.0509\n",
      "     29        \u001b[36m0.3653\u001b[0m       0.8856        \u001b[35m0.3138\u001b[0m  0.0638\n",
      "     30        \u001b[36m0.3543\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.2996\u001b[0m  0.0549\n",
      "     31        \u001b[36m0.3325\u001b[0m       0.8895        \u001b[35m0.2940\u001b[0m  0.0728\n",
      "     32        0.3503       0.8915        \u001b[35m0.2904\u001b[0m  0.0618\n",
      "     33        \u001b[36m0.3263\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.2815\u001b[0m  0.0738\n",
      "     34        0.3368       0.9014        \u001b[35m0.2729\u001b[0m  0.0788\n",
      "     35        0.3330       0.9014        \u001b[35m0.2712\u001b[0m  0.0559\n",
      "     36        0.3317       0.9014        \u001b[35m0.2632\u001b[0m  0.0469\n",
      "     37        \u001b[36m0.3242\u001b[0m       \u001b[32m0.9034\u001b[0m        \u001b[35m0.2571\u001b[0m  0.0559\n",
      "     38        \u001b[36m0.3128\u001b[0m       0.9034        \u001b[35m0.2490\u001b[0m  0.0698\n",
      "     39        \u001b[36m0.3062\u001b[0m       0.9034        \u001b[35m0.2486\u001b[0m  0.0598\n",
      "     40        \u001b[36m0.2960\u001b[0m       \u001b[32m0.9112\u001b[0m        \u001b[35m0.2369\u001b[0m  0.0549\n",
      "     41        \u001b[36m0.2799\u001b[0m       0.9093        0.2409  0.0509\n",
      "     42        0.2905       0.9112        \u001b[35m0.2329\u001b[0m  0.0559\n",
      "     43        0.2886       0.9112        \u001b[35m0.2317\u001b[0m  0.0718\n",
      "     44        0.2817       \u001b[32m0.9132\u001b[0m        \u001b[35m0.2239\u001b[0m  0.0539\n",
      "     45        \u001b[36m0.2778\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.2202\u001b[0m  0.0578\n",
      "     46        \u001b[36m0.2762\u001b[0m       0.9152        0.2216  0.0678\n",
      "     47        0.2791       0.9152        \u001b[35m0.2136\u001b[0m  0.0529\n",
      "     48        \u001b[36m0.2697\u001b[0m       0.9152        \u001b[35m0.2133\u001b[0m  0.0638\n",
      "     49        \u001b[36m0.2622\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m0.2121\u001b[0m  0.0748\n",
      "     50        0.2623       0.9172        \u001b[35m0.2092\u001b[0m  0.0618\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.8s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.4619\u001b[0m       \u001b[32m0.2505\u001b[0m       \u001b[35m10.9342\u001b[0m  0.0678\n",
      "      2       11.6564       \u001b[32m0.3373\u001b[0m        \u001b[35m9.8150\u001b[0m  0.0588\n",
      "      3       11.2611       0.2959       10.2217  0.0578\n",
      "      4        9.8501       0.3116        9.8550  0.0818\n",
      "      5        9.1113       \u001b[32m0.3550\u001b[0m        9.9737  0.0688\n",
      "      6       10.0339       \u001b[32m0.4556\u001b[0m        \u001b[35m8.3975\u001b[0m  0.0798\n",
      "      7        8.6114       \u001b[32m0.4813\u001b[0m        \u001b[35m8.0636\u001b[0m  0.0539\n",
      "      8        6.9687       0.4536        8.4945  0.0778\n",
      "      9        8.6915       \u001b[32m0.4951\u001b[0m        \u001b[35m8.0062\u001b[0m  0.0658\n",
      "     10        7.9498       \u001b[32m0.4990\u001b[0m        \u001b[35m7.9868\u001b[0m  0.0628\n",
      "     11        6.0056       0.4675        \u001b[35m7.2034\u001b[0m  0.0658\n",
      "     12        8.5446       \u001b[32m0.5108\u001b[0m        \u001b[35m5.9172\u001b[0m  0.0618\n",
      "     13        6.6481       0.4793        6.3785  0.0898\n",
      "     14        6.7762       \u001b[32m0.5897\u001b[0m        \u001b[35m4.9098\u001b[0m  0.0598\n",
      "     15        5.4269       \u001b[32m0.6923\u001b[0m        \u001b[35m4.6952\u001b[0m  0.0628\n",
      "     16        5.7060       \u001b[32m0.7179\u001b[0m        \u001b[35m4.1863\u001b[0m  0.0828\n",
      "     17        4.7421       0.7061        4.5088  0.0758\n",
      "     18        4.7633       \u001b[32m0.7278\u001b[0m        \u001b[35m4.1594\u001b[0m  0.0748\n",
      "     19        4.4363       0.7101        4.4163  0.0798\n",
      "     20        4.5675       0.7120        4.2707  0.0718\n",
      "     21        4.4207       0.7081        4.5338  0.0738\n",
      "     22        4.7622       0.7199        \u001b[35m4.1023\u001b[0m  0.0768\n",
      "     23        4.4249       0.7120        4.5189  0.0668\n",
      "     24        4.6720       \u001b[32m0.7357\u001b[0m        4.1382  0.0818\n",
      "     25        4.3494       0.7160        4.2447  0.0668\n",
      "     26        4.3789       0.7298        4.1029  0.0718\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7694\u001b[0m       \u001b[32m0.2505\u001b[0m       \u001b[35m10.6202\u001b[0m  0.0778\n",
      "      2       11.7013       \u001b[32m0.2919\u001b[0m       \u001b[35m10.0424\u001b[0m  0.0768\n",
      "      3       12.9761       0.2485       11.9783  0.0628\n",
      "      4        8.2718       \u001b[32m0.4773\u001b[0m        \u001b[35m4.8315\u001b[0m  0.0768\n",
      "      5        8.4387       \u001b[32m0.5740\u001b[0m        \u001b[35m2.6569\u001b[0m  0.0708\n",
      "      6        6.0255       \u001b[32m0.6292\u001b[0m        \u001b[35m1.8218\u001b[0m  0.0728\n",
      "      7        3.6836       \u001b[32m0.8659\u001b[0m        \u001b[35m0.7047\u001b[0m  0.0598\n",
      "      8        2.9676       \u001b[32m0.8935\u001b[0m        \u001b[35m0.4487\u001b[0m  0.0708\n",
      "      9        \u001b[36m1.1804\u001b[0m       \u001b[32m0.9250\u001b[0m        0.4754  0.0798\n",
      "     10        1.3483       \u001b[32m0.9290\u001b[0m        \u001b[35m0.3007\u001b[0m  0.0648\n",
      "     11        \u001b[36m0.8515\u001b[0m       0.8994        0.7401  0.0638\n",
      "     12        1.5414       0.9250        \u001b[35m0.2764\u001b[0m  0.0598\n",
      "     13        1.0150       0.8895        0.9074  0.0568\n",
      "     14        1.8261       0.9073        0.5344  0.0549\n",
      "     15        0.9417       0.8679        1.1370  0.0748\n",
      "     16        1.4396       0.8402        1.1497  0.0529\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.4s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m2.4370\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m9.9770\u001b[0m  0.0878\n",
      "      2       11.1893       \u001b[32m0.4300\u001b[0m        \u001b[35m8.0188\u001b[0m  0.0718\n",
      "      3        7.9381       0.2959       10.4007  0.0559\n",
      "      4        9.9420       \u001b[32m0.4813\u001b[0m        \u001b[35m4.9349\u001b[0m  0.0838\n",
      "      5        5.4070       0.4517        7.8017  0.0638\n",
      "      6        8.0260       0.4418        6.6418  0.0818\n",
      "      7        7.5889       0.4635        7.4461  0.0598\n",
      "      8        5.5185       \u001b[32m0.5976\u001b[0m        \u001b[35m2.0241\u001b[0m  0.0738\n",
      "      9        7.0096       \u001b[32m0.6450\u001b[0m        4.6409  0.0648\n",
      "     10        5.5955       \u001b[32m0.6469\u001b[0m        4.8047  0.0688\n",
      "     11        5.1682       \u001b[32m0.9034\u001b[0m        \u001b[35m0.4800\u001b[0m  0.0519\n",
      "     12        2.7215       \u001b[32m0.9073\u001b[0m        0.8006  0.0678\n",
      "     13        \u001b[36m2.0793\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.3118\u001b[0m  0.0818\n",
      "     14        \u001b[36m1.4022\u001b[0m       0.9448        0.5073  0.0738\n",
      "     15        \u001b[36m1.1752\u001b[0m       \u001b[32m0.9527\u001b[0m        \u001b[35m0.1737\u001b[0m  0.0708\n",
      "     16        \u001b[36m0.6650\u001b[0m       0.9487        0.4685  0.0608\n",
      "     17        1.0028       0.9191        0.3840  0.0628\n",
      "     18        0.7650       0.9093        0.8779  0.0618\n",
      "     19        1.6284       0.9527        0.1801  0.0678\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.6s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3432\u001b[0m       \u001b[32m0.2663\u001b[0m        \u001b[35m1.3216\u001b[0m  0.0698\n",
      "      2        \u001b[36m1.2655\u001b[0m       \u001b[32m0.3077\u001b[0m        \u001b[35m1.2465\u001b[0m  0.0598\n",
      "      3        \u001b[36m1.1653\u001b[0m       \u001b[32m0.3728\u001b[0m        \u001b[35m1.1523\u001b[0m  0.0578\n",
      "      4        \u001b[36m1.0632\u001b[0m       \u001b[32m0.4418\u001b[0m        \u001b[35m1.0560\u001b[0m  0.0449\n",
      "      5        \u001b[36m0.9717\u001b[0m       \u001b[32m0.5187\u001b[0m        \u001b[35m0.9678\u001b[0m  0.0648\n",
      "      6        \u001b[36m0.8813\u001b[0m       \u001b[32m0.5838\u001b[0m        \u001b[35m0.8894\u001b[0m  0.0628\n",
      "      7        \u001b[36m0.8124\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m0.8190\u001b[0m  0.0519\n",
      "      8        \u001b[36m0.7375\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m0.7569\u001b[0m  0.0559\n",
      "      9        \u001b[36m0.6942\u001b[0m       \u001b[32m0.6746\u001b[0m        \u001b[35m0.7067\u001b[0m  0.0529\n",
      "     10        \u001b[36m0.6597\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m0.6560\u001b[0m  0.0578\n",
      "     11        \u001b[36m0.6021\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m0.6077\u001b[0m  0.0658\n",
      "     12        \u001b[36m0.5669\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m0.5740\u001b[0m  0.0668\n",
      "     13        \u001b[36m0.5272\u001b[0m       \u001b[32m0.7791\u001b[0m        \u001b[35m0.5461\u001b[0m  0.0678\n",
      "     14        \u001b[36m0.5059\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.5133\u001b[0m  0.0539\n",
      "     15        \u001b[36m0.4872\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4827\u001b[0m  0.0509\n",
      "     16        \u001b[36m0.4653\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.4638\u001b[0m  0.0459\n",
      "     17        \u001b[36m0.4535\u001b[0m       \u001b[32m0.8166\u001b[0m        \u001b[35m0.4466\u001b[0m  0.0778\n",
      "     18        \u001b[36m0.4273\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.4261\u001b[0m  0.0588\n",
      "     19        \u001b[36m0.4225\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.4151\u001b[0m  0.0529\n",
      "     20        \u001b[36m0.4024\u001b[0m       \u001b[32m0.8422\u001b[0m        \u001b[35m0.3943\u001b[0m  0.0618\n",
      "     21        \u001b[36m0.3840\u001b[0m       \u001b[32m0.8442\u001b[0m        \u001b[35m0.3850\u001b[0m  0.0638\n",
      "     22        \u001b[36m0.3824\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.3664\u001b[0m  0.0718\n",
      "     23        \u001b[36m0.3806\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.3594\u001b[0m  0.0598\n",
      "     24        \u001b[36m0.3536\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3427\u001b[0m  0.0678\n",
      "     25        \u001b[36m0.3474\u001b[0m       0.8600        \u001b[35m0.3415\u001b[0m  0.0698\n",
      "     26        \u001b[36m0.3436\u001b[0m       0.8600        \u001b[35m0.3304\u001b[0m  0.0529\n",
      "     27        \u001b[36m0.3345\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3214\u001b[0m  0.0598\n",
      "     28        \u001b[36m0.3203\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.3148\u001b[0m  0.0509\n",
      "     29        \u001b[36m0.3125\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.3031\u001b[0m  0.0529\n",
      "     30        \u001b[36m0.3092\u001b[0m       0.8639        \u001b[35m0.2998\u001b[0m  0.0698\n",
      "     31        \u001b[36m0.3091\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.2961\u001b[0m  0.0728\n",
      "     32        0.3130       \u001b[32m0.8698\u001b[0m        \u001b[35m0.2891\u001b[0m  0.0598\n",
      "     33        \u001b[36m0.3083\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.2842\u001b[0m  0.0539\n",
      "     34        \u001b[36m0.2892\u001b[0m       0.8718        \u001b[35m0.2805\u001b[0m  0.0678\n",
      "     35        0.2931       \u001b[32m0.8757\u001b[0m        \u001b[35m0.2736\u001b[0m  0.0688\n",
      "     36        \u001b[36m0.2854\u001b[0m       0.8738        0.2744  0.0728\n",
      "     37        \u001b[36m0.2830\u001b[0m       \u001b[32m0.8797\u001b[0m        \u001b[35m0.2669\u001b[0m  0.0588\n",
      "     38        0.2831       \u001b[32m0.8895\u001b[0m        \u001b[35m0.2561\u001b[0m  0.0638\n",
      "     39        \u001b[36m0.2580\u001b[0m       0.8836        0.2580  0.0638\n",
      "     40        0.2616       0.8817        \u001b[35m0.2539\u001b[0m  0.0638\n",
      "     41        0.2612       0.8895        \u001b[35m0.2497\u001b[0m  0.0738\n",
      "     42        0.2650       0.8895        \u001b[35m0.2486\u001b[0m  0.0678\n",
      "     43        \u001b[36m0.2491\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.2424\u001b[0m  0.0638\n",
      "     44        0.2538       0.8915        \u001b[35m0.2416\u001b[0m  0.0618\n",
      "     45        \u001b[36m0.2415\u001b[0m       0.8915        \u001b[35m0.2391\u001b[0m  0.0608\n",
      "     46        \u001b[36m0.2368\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.2308\u001b[0m  0.0549\n",
      "     47        0.2533       0.8955        \u001b[35m0.2285\u001b[0m  0.0608\n",
      "     48        0.2448       0.8994        \u001b[35m0.2264\u001b[0m  0.0768\n",
      "     49        \u001b[36m0.2356\u001b[0m       0.8994        \u001b[35m0.2255\u001b[0m  0.0578\n",
      "     50        \u001b[36m0.2291\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.2183\u001b[0m  0.0688\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.9s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3821\u001b[0m       \u001b[32m0.2643\u001b[0m        \u001b[35m1.3202\u001b[0m  0.0479\n",
      "      2        \u001b[36m1.2788\u001b[0m       \u001b[32m0.3649\u001b[0m        \u001b[35m1.2245\u001b[0m  0.0728\n",
      "      3        \u001b[36m1.1828\u001b[0m       \u001b[32m0.4655\u001b[0m        \u001b[35m1.1238\u001b[0m  0.0568\n",
      "      4        \u001b[36m1.0673\u001b[0m       \u001b[32m0.5187\u001b[0m        \u001b[35m1.0322\u001b[0m  0.0618\n",
      "      5        \u001b[36m0.9815\u001b[0m       \u001b[32m0.5621\u001b[0m        \u001b[35m0.9517\u001b[0m  0.0559\n",
      "      6        \u001b[36m0.8895\u001b[0m       \u001b[32m0.6075\u001b[0m        \u001b[35m0.8718\u001b[0m  0.0658\n",
      "      7        \u001b[36m0.8107\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m0.8045\u001b[0m  0.0628\n",
      "      8        \u001b[36m0.7424\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m0.7491\u001b[0m  0.0708\n",
      "      9        \u001b[36m0.6807\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m0.6904\u001b[0m  0.0698\n",
      "     10        \u001b[36m0.6328\u001b[0m       \u001b[32m0.7041\u001b[0m        \u001b[35m0.6531\u001b[0m  0.0529\n",
      "     11        \u001b[36m0.5899\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m0.6150\u001b[0m  0.0638\n",
      "     12        \u001b[36m0.5617\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.5822\u001b[0m  0.0708\n",
      "     13        \u001b[36m0.5286\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.5441\u001b[0m  0.0738\n",
      "     14        \u001b[36m0.5034\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.5195\u001b[0m  0.0698\n",
      "     15        \u001b[36m0.4694\u001b[0m       \u001b[32m0.7949\u001b[0m        \u001b[35m0.4960\u001b[0m  0.0549\n",
      "     16        \u001b[36m0.4574\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.4769\u001b[0m  0.0728\n",
      "     17        \u001b[36m0.4326\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.4542\u001b[0m  0.0678\n",
      "     18        \u001b[36m0.4199\u001b[0m       \u001b[32m0.8185\u001b[0m        \u001b[35m0.4399\u001b[0m  0.0618\n",
      "     19        \u001b[36m0.3941\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.4247\u001b[0m  0.0698\n",
      "     20        \u001b[36m0.3861\u001b[0m       \u001b[32m0.8284\u001b[0m        \u001b[35m0.4172\u001b[0m  0.0658\n",
      "     21        \u001b[36m0.3792\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.3967\u001b[0m  0.0678\n",
      "     22        \u001b[36m0.3717\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.3897\u001b[0m  0.0568\n",
      "     23        \u001b[36m0.3559\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.3790\u001b[0m  0.0648\n",
      "     24        \u001b[36m0.3465\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.3690\u001b[0m  0.0698\n",
      "     25        \u001b[36m0.3335\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.3587\u001b[0m  0.0559\n",
      "     26        \u001b[36m0.3268\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.3485\u001b[0m  0.0549\n",
      "     27        \u001b[36m0.3039\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3406\u001b[0m  0.0568\n",
      "     28        0.3118       0.8600        \u001b[35m0.3374\u001b[0m  0.0628\n",
      "     29        0.3084       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3292\u001b[0m  0.0618\n",
      "     30        \u001b[36m0.2997\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.3200\u001b[0m  0.0618\n",
      "     31        \u001b[36m0.2917\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.3149\u001b[0m  0.0618\n",
      "     32        \u001b[36m0.2847\u001b[0m       0.8659        \u001b[35m0.3058\u001b[0m  0.0549\n",
      "     33        \u001b[36m0.2773\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3013\u001b[0m  0.0668\n",
      "     34        \u001b[36m0.2746\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.2970\u001b[0m  0.0688\n",
      "     35        \u001b[36m0.2597\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.2920\u001b[0m  0.0489\n",
      "     36        0.2639       \u001b[32m0.8738\u001b[0m        \u001b[35m0.2902\u001b[0m  0.0598\n",
      "     37        \u001b[36m0.2586\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.2816\u001b[0m  0.0708\n",
      "     38        \u001b[36m0.2562\u001b[0m       0.8757        \u001b[35m0.2794\u001b[0m  0.0598\n",
      "     39        0.2588       0.8757        \u001b[35m0.2770\u001b[0m  0.0678\n",
      "     40        \u001b[36m0.2454\u001b[0m       0.8757        \u001b[35m0.2692\u001b[0m  0.0688\n",
      "     41        0.2593       0.8757        \u001b[35m0.2668\u001b[0m  0.0528\n",
      "     42        \u001b[36m0.2311\u001b[0m       \u001b[32m0.8797\u001b[0m        \u001b[35m0.2660\u001b[0m  0.0608\n",
      "     43        0.2379       0.8757        \u001b[35m0.2627\u001b[0m  0.0449\n",
      "     44        0.2341       \u001b[32m0.8817\u001b[0m        \u001b[35m0.2577\u001b[0m  0.0788\n",
      "     45        0.2410       0.8817        \u001b[35m0.2558\u001b[0m  0.0678\n",
      "     46        \u001b[36m0.2278\u001b[0m       0.8817        \u001b[35m0.2511\u001b[0m  0.0618\n",
      "     47        \u001b[36m0.2234\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.2492\u001b[0m  0.0588\n",
      "     48        0.2273       \u001b[32m0.8895\u001b[0m        \u001b[35m0.2439\u001b[0m  0.0519\n",
      "     49        0.2297       \u001b[32m0.8915\u001b[0m        \u001b[35m0.2401\u001b[0m  0.0638\n",
      "     50        \u001b[36m0.2207\u001b[0m       0.8876        0.2461  0.0668\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   4.0s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3633\u001b[0m       \u001b[32m0.3491\u001b[0m        \u001b[35m1.2893\u001b[0m  0.0728\n",
      "      2        \u001b[36m1.2587\u001b[0m       \u001b[32m0.4083\u001b[0m        \u001b[35m1.1953\u001b[0m  0.0588\n",
      "      3        \u001b[36m1.1472\u001b[0m       \u001b[32m0.4675\u001b[0m        \u001b[35m1.1033\u001b[0m  0.0658\n",
      "      4        \u001b[36m1.0484\u001b[0m       \u001b[32m0.5187\u001b[0m        \u001b[35m1.0106\u001b[0m  0.0608\n",
      "      5        \u001b[36m0.9459\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m0.9258\u001b[0m  0.0648\n",
      "      6        \u001b[36m0.8577\u001b[0m       \u001b[32m0.6154\u001b[0m        \u001b[35m0.8553\u001b[0m  0.0539\n",
      "      7        \u001b[36m0.7901\u001b[0m       \u001b[32m0.6489\u001b[0m        \u001b[35m0.7831\u001b[0m  0.0588\n",
      "      8        \u001b[36m0.7137\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m0.7205\u001b[0m  0.0598\n",
      "      9        \u001b[36m0.6718\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m0.6710\u001b[0m  0.0678\n",
      "     10        \u001b[36m0.6123\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.6197\u001b[0m  0.0559\n",
      "     11        \u001b[36m0.5748\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.5818\u001b[0m  0.0808\n",
      "     12        \u001b[36m0.5411\u001b[0m       \u001b[32m0.7554\u001b[0m        \u001b[35m0.5465\u001b[0m  0.0489\n",
      "     13        \u001b[36m0.5153\u001b[0m       \u001b[32m0.7791\u001b[0m        \u001b[35m0.5157\u001b[0m  0.0568\n",
      "     14        \u001b[36m0.4915\u001b[0m       \u001b[32m0.7949\u001b[0m        \u001b[35m0.4889\u001b[0m  0.0559\n",
      "     15        \u001b[36m0.4635\u001b[0m       \u001b[32m0.8185\u001b[0m        \u001b[35m0.4565\u001b[0m  0.0708\n",
      "     16        \u001b[36m0.4457\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.4376\u001b[0m  0.0608\n",
      "     17        \u001b[36m0.4263\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.4220\u001b[0m  0.0509\n",
      "     18        \u001b[36m0.4169\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.3991\u001b[0m  0.0549\n",
      "     19        \u001b[36m0.3973\u001b[0m       0.8580        \u001b[35m0.3823\u001b[0m  0.0628\n",
      "     20        \u001b[36m0.3857\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3709\u001b[0m  0.0738\n",
      "     21        \u001b[36m0.3709\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.3570\u001b[0m  0.0688\n",
      "     22        \u001b[36m0.3678\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.3472\u001b[0m  0.0618\n",
      "     23        \u001b[36m0.3518\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.3320\u001b[0m  0.0559\n",
      "     24        \u001b[36m0.3472\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.3210\u001b[0m  0.0718\n",
      "     25        \u001b[36m0.3339\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.3118\u001b[0m  0.0519\n",
      "     26        \u001b[36m0.3318\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.3026\u001b[0m  0.0598\n",
      "     27        \u001b[36m0.3212\u001b[0m       0.8935        \u001b[35m0.2983\u001b[0m  0.0608\n",
      "     28        \u001b[36m0.3182\u001b[0m       0.8955        \u001b[35m0.2905\u001b[0m  0.0588\n",
      "     29        \u001b[36m0.2947\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.2813\u001b[0m  0.0598\n",
      "     30        \u001b[36m0.2883\u001b[0m       \u001b[32m0.9034\u001b[0m        \u001b[35m0.2715\u001b[0m  0.0618\n",
      "     31        0.2900       0.9014        \u001b[35m0.2703\u001b[0m  0.0509\n",
      "     32        0.2886       0.9034        \u001b[35m0.2657\u001b[0m  0.0638\n",
      "     33        0.2896       0.9034        \u001b[35m0.2564\u001b[0m  0.0469\n",
      "     34        \u001b[36m0.2746\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.2503\u001b[0m  0.0499\n",
      "     35        \u001b[36m0.2626\u001b[0m       0.9034        \u001b[35m0.2489\u001b[0m  0.0618\n",
      "     36        0.2630       \u001b[32m0.9073\u001b[0m        \u001b[35m0.2420\u001b[0m  0.0598\n",
      "     37        \u001b[36m0.2565\u001b[0m       0.9073        \u001b[35m0.2379\u001b[0m  0.0489\n",
      "     38        0.2605       0.9053        \u001b[35m0.2361\u001b[0m  0.0778\n",
      "     39        0.2641       \u001b[32m0.9132\u001b[0m        \u001b[35m0.2299\u001b[0m  0.0479\n",
      "     40        \u001b[36m0.2424\u001b[0m       0.9132        \u001b[35m0.2280\u001b[0m  0.0618\n",
      "     41        \u001b[36m0.2392\u001b[0m       0.9112        \u001b[35m0.2233\u001b[0m  0.0778\n",
      "     42        0.2410       \u001b[32m0.9152\u001b[0m        \u001b[35m0.2200\u001b[0m  0.0608\n",
      "     43        0.2408       0.9152        \u001b[35m0.2179\u001b[0m  0.0549\n",
      "     44        0.2420       \u001b[32m0.9172\u001b[0m        \u001b[35m0.2131\u001b[0m  0.0558\n",
      "     45        \u001b[36m0.2346\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.2097\u001b[0m  0.0608\n",
      "     46        \u001b[36m0.2258\u001b[0m       \u001b[32m0.9270\u001b[0m        \u001b[35m0.2044\u001b[0m  0.0608\n",
      "     47        \u001b[36m0.2162\u001b[0m       0.9231        0.2054  0.0688\n",
      "     48        0.2238       0.9250        \u001b[35m0.2013\u001b[0m  0.0648\n",
      "     49        0.2170       0.9231        0.2013  0.0748\n",
      "     50        0.2207       0.9231        \u001b[35m0.2003\u001b[0m  0.0578\n",
      "[CV]  lr=0.1, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.8s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m3.2299\u001b[0m       \u001b[32m0.2485\u001b[0m        \u001b[35m2.5128\u001b[0m  0.0668\n",
      "      2        4.2653       0.2485        \u001b[35m2.1634\u001b[0m  0.0688\n",
      "      3        \u001b[36m2.8906\u001b[0m       0.2485        \u001b[35m1.5311\u001b[0m  0.0698\n",
      "      4        \u001b[36m2.7389\u001b[0m       0.2485        1.7899  0.0688\n",
      "      5        \u001b[36m2.6668\u001b[0m       0.2485        \u001b[35m1.3881\u001b[0m  0.0728\n",
      "      6        \u001b[36m2.2582\u001b[0m       0.2485        1.4037  0.0768\n",
      "      7        2.4572       \u001b[32m0.3333\u001b[0m        \u001b[35m1.2965\u001b[0m  0.0658\n",
      "      8        \u001b[36m2.0991\u001b[0m       \u001b[32m0.4477\u001b[0m        \u001b[35m1.1400\u001b[0m  0.0628\n",
      "      9        \u001b[36m2.0569\u001b[0m       \u001b[32m0.5168\u001b[0m        \u001b[35m1.0064\u001b[0m  0.0489\n",
      "     10        \u001b[36m1.7460\u001b[0m       0.4951        \u001b[35m0.8900\u001b[0m  0.0668\n",
      "     11        1.7816       \u001b[32m0.6529\u001b[0m        \u001b[35m0.7812\u001b[0m  0.0559\n",
      "     12        \u001b[36m1.7332\u001b[0m       0.6529        \u001b[35m0.7767\u001b[0m  0.0578\n",
      "     13        \u001b[36m1.5711\u001b[0m       0.3964        0.8709  0.0738\n",
      "     14        1.6536       \u001b[32m0.8580\u001b[0m        \u001b[35m0.6729\u001b[0m  0.0708\n",
      "     15        \u001b[36m1.4923\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m0.6112\u001b[0m  0.0588\n",
      "     16        1.5362       0.7890        0.6120  0.0618\n",
      "     17        1.5998       0.8856        \u001b[35m0.5893\u001b[0m  0.0568\n",
      "     18        1.6443       \u001b[32m0.9369\u001b[0m        0.5915  0.0558\n",
      "     19        1.5731       0.6903        0.7182  0.0479\n",
      "     20        1.6432       0.9369        \u001b[35m0.5276\u001b[0m  0.0529\n",
      "     21        1.6584       0.6884        0.5942  0.0509\n",
      "     22        1.5181       \u001b[32m0.9467\u001b[0m        \u001b[35m0.4663\u001b[0m  0.0559\n",
      "     23        1.6211       0.7140        0.5008  0.0708\n",
      "     24        1.5323       0.9389        0.4885  0.0708\n",
      "     25        1.6837       0.7101        0.5107  0.0588\n",
      "     26        \u001b[36m1.4427\u001b[0m       \u001b[32m0.9487\u001b[0m        0.5131  0.0568\n",
      "     27        1.6201       \u001b[32m0.9606\u001b[0m        \u001b[35m0.4318\u001b[0m  0.0608\n",
      "     28        \u001b[36m1.4151\u001b[0m       0.7081        0.5777  0.0718\n",
      "     29        1.6992       0.7160        0.4625  0.0718\n",
      "     30        \u001b[36m1.3725\u001b[0m       0.8718        0.5297  0.0688\n",
      "     31        1.8376       0.8836        0.4640  0.0668\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.5s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m3.5210\u001b[0m       \u001b[32m0.2919\u001b[0m        \u001b[35m1.7760\u001b[0m  0.0658\n",
      "      2        3.8324       0.2505        1.8099  0.0758\n",
      "      3        \u001b[36m2.9899\u001b[0m       0.2525        \u001b[35m1.4913\u001b[0m  0.0768\n",
      "      4        \u001b[36m2.4856\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m1.4381\u001b[0m  0.0648\n",
      "      5        2.6361       0.2505        \u001b[35m1.3317\u001b[0m  0.0568\n",
      "      6        \u001b[36m2.0461\u001b[0m       \u001b[32m0.5128\u001b[0m        \u001b[35m1.0499\u001b[0m  0.0519\n",
      "      7        2.0941       0.4201        1.0633  0.0688\n",
      "      8        \u001b[36m1.9964\u001b[0m       \u001b[32m0.5819\u001b[0m        \u001b[35m0.9865\u001b[0m  0.0768\n",
      "      9        \u001b[36m1.9528\u001b[0m       0.5168        \u001b[35m0.9022\u001b[0m  0.0868\n",
      "     10        \u001b[36m1.9083\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m0.7548\u001b[0m  0.0778\n",
      "     11        \u001b[36m1.6625\u001b[0m       0.6884        0.8800  0.0549\n",
      "     12        1.7402       0.7160        0.7694  0.0578\n",
      "     13        1.6697       \u001b[32m0.7594\u001b[0m        \u001b[35m0.6400\u001b[0m  0.0668\n",
      "     14        \u001b[36m1.5044\u001b[0m       0.6765        0.7875  0.0628\n",
      "     15        1.7686       \u001b[32m0.8580\u001b[0m        \u001b[35m0.6177\u001b[0m  0.0598\n",
      "     16        \u001b[36m1.4771\u001b[0m       0.8107        0.6833  0.0628\n",
      "     17        1.8043       0.6312        \u001b[35m0.5827\u001b[0m  0.0618\n",
      "     18        \u001b[36m1.3659\u001b[0m       0.7179        0.7817  0.0788\n",
      "     19        1.6619       \u001b[32m0.8757\u001b[0m        \u001b[35m0.4785\u001b[0m  0.0758\n",
      "     20        \u001b[36m1.2449\u001b[0m       0.7318        0.8021  0.0588\n",
      "     21        1.6526       0.8580        \u001b[35m0.4601\u001b[0m  0.0718\n",
      "     22        1.2720       0.7318        0.6942  0.0808\n",
      "     23        1.6023       \u001b[32m0.9625\u001b[0m        \u001b[35m0.3459\u001b[0m  0.0788\n",
      "     24        \u001b[36m1.1502\u001b[0m       0.9112        0.5157  0.0738\n",
      "     25        1.5701       0.9467        0.3543  0.0628\n",
      "     26        1.2337       0.7199        0.5957  0.0688\n",
      "     27        1.6429       0.9231        0.3786  0.0748\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.3s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m3.7582\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m2.9374\u001b[0m  0.0638\n",
      "      2        3.9391       0.2505        \u001b[35m2.2456\u001b[0m  0.0828\n",
      "      3        \u001b[36m2.9787\u001b[0m       0.2505        \u001b[35m1.6211\u001b[0m  0.0728\n",
      "      4        \u001b[36m2.9485\u001b[0m       0.2505        \u001b[35m1.6049\u001b[0m  0.0718\n",
      "      5        \u001b[36m2.1599\u001b[0m       \u001b[32m0.4260\u001b[0m        \u001b[35m1.1842\u001b[0m  0.0588\n",
      "      6        \u001b[36m1.8804\u001b[0m       0.3688        \u001b[35m1.1809\u001b[0m  0.0509\n",
      "      7        2.3621       \u001b[32m0.5010\u001b[0m        \u001b[35m1.0402\u001b[0m  0.0559\n",
      "      8        \u001b[36m1.7294\u001b[0m       0.3609        1.1743  0.0559\n",
      "      9        2.1286       0.4655        \u001b[35m0.8654\u001b[0m  0.0648\n",
      "     10        \u001b[36m1.5980\u001b[0m       \u001b[32m0.6371\u001b[0m        \u001b[35m0.8225\u001b[0m  0.0588\n",
      "     11        1.9540       \u001b[32m0.7968\u001b[0m        \u001b[35m0.7334\u001b[0m  0.0568\n",
      "     12        1.7156       0.6824        \u001b[35m0.7332\u001b[0m  0.0808\n",
      "     13        1.8009       0.6252        \u001b[35m0.6734\u001b[0m  0.0608\n",
      "     14        \u001b[36m1.4715\u001b[0m       0.7022        0.9017  0.0618\n",
      "     15        1.8855       0.7771        \u001b[35m0.5730\u001b[0m  0.0768\n",
      "     16        \u001b[36m1.3477\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.5701\u001b[0m  0.0638\n",
      "     17        1.4758       \u001b[32m0.9467\u001b[0m        \u001b[35m0.4729\u001b[0m  0.0628\n",
      "     18        1.3552       0.7318        0.6032  0.0559\n",
      "     19        1.6336       0.9448        \u001b[35m0.4193\u001b[0m  0.0559\n",
      "     20        \u001b[36m1.2638\u001b[0m       0.7081        0.5817  0.0648\n",
      "     21        1.5156       0.9467        \u001b[35m0.3787\u001b[0m  0.0748\n",
      "     22        1.2878       \u001b[32m0.9507\u001b[0m        0.4131  0.0678\n",
      "     23        1.4868       0.9389        0.3857  0.0459\n",
      "     24        \u001b[36m1.2580\u001b[0m       0.9408        \u001b[35m0.3668\u001b[0m  0.0588\n",
      "     25        1.3064       \u001b[32m0.9625\u001b[0m        \u001b[35m0.3302\u001b[0m  0.0499\n",
      "     26        \u001b[36m1.2071\u001b[0m       0.9448        0.3894  0.0688\n",
      "     27        \u001b[36m1.1792\u001b[0m       0.9329        0.3481  0.0748\n",
      "     28        1.4063       \u001b[32m0.9684\u001b[0m        0.3469  0.0519\n",
      "     29        1.2510       0.9270        0.3706  0.0489\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.3s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4086\u001b[0m       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3353\u001b[0m  0.0539\n",
      "      2        \u001b[36m1.3613\u001b[0m       \u001b[32m0.3156\u001b[0m        \u001b[35m1.2983\u001b[0m  0.0499\n",
      "      3        \u001b[36m1.3290\u001b[0m       \u001b[32m0.3570\u001b[0m        \u001b[35m1.2559\u001b[0m  0.0559\n",
      "      4        \u001b[36m1.2983\u001b[0m       \u001b[32m0.3984\u001b[0m        \u001b[35m1.1987\u001b[0m  0.0499\n",
      "      5        \u001b[36m1.2610\u001b[0m       \u001b[32m0.4359\u001b[0m        \u001b[35m1.1505\u001b[0m  0.0509\n",
      "      6        \u001b[36m1.2128\u001b[0m       \u001b[32m0.4753\u001b[0m        \u001b[35m1.0948\u001b[0m  0.0459\n",
      "      7        \u001b[36m1.1698\u001b[0m       \u001b[32m0.5069\u001b[0m        \u001b[35m1.0393\u001b[0m  0.0578\n",
      "      8        \u001b[36m1.1228\u001b[0m       \u001b[32m0.5247\u001b[0m        \u001b[35m0.9919\u001b[0m  0.0419\n",
      "      9        \u001b[36m1.0942\u001b[0m       \u001b[32m0.5759\u001b[0m        \u001b[35m0.9418\u001b[0m  0.0638\n",
      "     10        \u001b[36m1.0593\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m0.9027\u001b[0m  0.0658\n",
      "     11        \u001b[36m1.0230\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m0.8598\u001b[0m  0.0568\n",
      "     12        \u001b[36m0.9811\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m0.8196\u001b[0m  0.0519\n",
      "     13        \u001b[36m0.9502\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m0.7887\u001b[0m  0.0429\n",
      "     14        \u001b[36m0.9382\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m0.7562\u001b[0m  0.0578\n",
      "     15        \u001b[36m0.8842\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m0.7262\u001b[0m  0.0578\n",
      "     16        0.8983       \u001b[32m0.7140\u001b[0m        \u001b[35m0.6958\u001b[0m  0.0519\n",
      "     17        \u001b[36m0.8810\u001b[0m       \u001b[32m0.7357\u001b[0m        \u001b[35m0.6808\u001b[0m  0.0608\n",
      "     18        0.8813       \u001b[32m0.7515\u001b[0m        \u001b[35m0.6573\u001b[0m  0.0549\n",
      "     19        \u001b[36m0.8628\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.6406\u001b[0m  0.0499\n",
      "     20        \u001b[36m0.8323\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.6291\u001b[0m  0.0588\n",
      "     21        \u001b[36m0.8319\u001b[0m       \u001b[32m0.7909\u001b[0m        \u001b[35m0.6092\u001b[0m  0.0628\n",
      "     22        \u001b[36m0.8293\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m0.5977\u001b[0m  0.0588\n",
      "     23        \u001b[36m0.8159\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.5825\u001b[0m  0.0648\n",
      "     24        0.8185       \u001b[32m0.8205\u001b[0m        \u001b[35m0.5703\u001b[0m  0.0588\n",
      "     25        \u001b[36m0.8017\u001b[0m       0.8166        \u001b[35m0.5610\u001b[0m  0.0489\n",
      "     26        \u001b[36m0.7932\u001b[0m       \u001b[32m0.8264\u001b[0m        \u001b[35m0.5476\u001b[0m  0.0678\n",
      "     27        \u001b[36m0.7836\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.5396\u001b[0m  0.0628\n",
      "     28        0.7847       \u001b[32m0.8383\u001b[0m        \u001b[35m0.5294\u001b[0m  0.0549\n",
      "     29        \u001b[36m0.7612\u001b[0m       \u001b[32m0.8422\u001b[0m        \u001b[35m0.5199\u001b[0m  0.0539\n",
      "     30        0.7820       \u001b[32m0.8442\u001b[0m        \u001b[35m0.5099\u001b[0m  0.0439\n",
      "     31        0.7688       \u001b[32m0.8462\u001b[0m        \u001b[35m0.5046\u001b[0m  0.0648\n",
      "     32        \u001b[36m0.7596\u001b[0m       0.8422        0.5050  0.0608\n",
      "     33        \u001b[36m0.7519\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.4923\u001b[0m  0.0459\n",
      "     34        0.7619       0.8402        0.4955  0.0668\n",
      "     35        \u001b[36m0.7503\u001b[0m       0.8462        \u001b[35m0.4916\u001b[0m  0.0628\n",
      "     36        0.7588       0.8481        \u001b[35m0.4840\u001b[0m  0.0539\n",
      "     37        \u001b[36m0.7370\u001b[0m       0.8501        \u001b[35m0.4778\u001b[0m  0.0509\n",
      "     38        0.7515       0.8462        \u001b[35m0.4772\u001b[0m  0.0439\n",
      "     39        0.7580       \u001b[32m0.8600\u001b[0m        \u001b[35m0.4626\u001b[0m  0.0549\n",
      "     40        \u001b[36m0.7282\u001b[0m       0.8501        0.4643  0.0648\n",
      "     41        \u001b[36m0.7250\u001b[0m       0.8560        0.4648  0.0469\n",
      "     42        \u001b[36m0.7248\u001b[0m       0.8580        \u001b[35m0.4545\u001b[0m  0.0608\n",
      "     43        \u001b[36m0.7200\u001b[0m       0.8521        \u001b[35m0.4536\u001b[0m  0.0479\n",
      "     44        0.7365       0.8560        \u001b[35m0.4469\u001b[0m  0.0628\n",
      "     45        \u001b[36m0.7192\u001b[0m       0.8580        0.4470  0.0519\n",
      "     46        0.7336       \u001b[32m0.8619\u001b[0m        \u001b[35m0.4459\u001b[0m  0.0539\n",
      "     47        \u001b[36m0.7185\u001b[0m       0.8619        \u001b[35m0.4386\u001b[0m  0.0519\n",
      "     48        \u001b[36m0.6908\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.4349\u001b[0m  0.0658\n",
      "     49        0.7042       0.8600        \u001b[35m0.4340\u001b[0m  0.0459\n",
      "     50        0.7378       \u001b[32m0.8738\u001b[0m        \u001b[35m0.4183\u001b[0m  0.0559\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.5s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4051\u001b[0m       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3229\u001b[0m  0.0379\n",
      "      2        \u001b[36m1.3565\u001b[0m       \u001b[32m0.3393\u001b[0m        \u001b[35m1.2695\u001b[0m  0.0718\n",
      "      3        \u001b[36m1.2967\u001b[0m       \u001b[32m0.3787\u001b[0m        \u001b[35m1.2202\u001b[0m  0.0628\n",
      "      4        \u001b[36m1.2447\u001b[0m       \u001b[32m0.4241\u001b[0m        \u001b[35m1.1624\u001b[0m  0.0539\n",
      "      5        \u001b[36m1.1953\u001b[0m       \u001b[32m0.4615\u001b[0m        \u001b[35m1.1043\u001b[0m  0.0568\n",
      "      6        \u001b[36m1.1356\u001b[0m       \u001b[32m0.5128\u001b[0m        \u001b[35m1.0490\u001b[0m  0.0434\n",
      "      7        \u001b[36m1.1107\u001b[0m       \u001b[32m0.5503\u001b[0m        \u001b[35m0.9941\u001b[0m  0.0648\n",
      "      8        \u001b[36m1.0586\u001b[0m       \u001b[32m0.5819\u001b[0m        \u001b[35m0.9398\u001b[0m  0.0559\n",
      "      9        \u001b[36m1.0120\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m0.9010\u001b[0m  0.0758\n",
      "     10        \u001b[36m0.9989\u001b[0m       \u001b[32m0.6331\u001b[0m        \u001b[35m0.8546\u001b[0m  0.0738\n",
      "     11        \u001b[36m0.9737\u001b[0m       \u001b[32m0.6607\u001b[0m        \u001b[35m0.8206\u001b[0m  0.0678\n",
      "     12        \u001b[36m0.9394\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m0.7903\u001b[0m  0.0578\n",
      "     13        \u001b[36m0.9247\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m0.7606\u001b[0m  0.0549\n",
      "     14        \u001b[36m0.9039\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.7287\u001b[0m  0.0598\n",
      "     15        \u001b[36m0.8994\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.7134\u001b[0m  0.0728\n",
      "     16        \u001b[36m0.8658\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m0.6920\u001b[0m  0.0628\n",
      "     17        \u001b[36m0.8547\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m0.6701\u001b[0m  0.0549\n",
      "     18        \u001b[36m0.8192\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.6511\u001b[0m  0.0559\n",
      "     19        0.8288       \u001b[32m0.8067\u001b[0m        \u001b[35m0.6327\u001b[0m  0.0549\n",
      "     20        0.8205       \u001b[32m0.8107\u001b[0m        \u001b[35m0.6207\u001b[0m  0.0549\n",
      "     21        \u001b[36m0.8161\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.6050\u001b[0m  0.0519\n",
      "     22        \u001b[36m0.7723\u001b[0m       0.8126        \u001b[35m0.6006\u001b[0m  0.0628\n",
      "     23        \u001b[36m0.7722\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.5762\u001b[0m  0.0489\n",
      "     24        0.7802       0.8363        \u001b[35m0.5743\u001b[0m  0.0658\n",
      "     25        \u001b[36m0.7721\u001b[0m       0.8383        \u001b[35m0.5573\u001b[0m  0.0578\n",
      "     26        \u001b[36m0.7494\u001b[0m       \u001b[32m0.8422\u001b[0m        \u001b[35m0.5502\u001b[0m  0.0459\n",
      "     27        0.7654       \u001b[32m0.8521\u001b[0m        \u001b[35m0.5377\u001b[0m  0.0668\n",
      "     28        0.7565       \u001b[32m0.8560\u001b[0m        \u001b[35m0.5277\u001b[0m  0.0678\n",
      "     29        \u001b[36m0.7409\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.5178\u001b[0m  0.0529\n",
      "     30        0.7442       0.8501        0.5186  0.0509\n",
      "     31        \u001b[36m0.7107\u001b[0m       0.8580        \u001b[35m0.5075\u001b[0m  0.0429\n",
      "     32        0.7269       0.8560        \u001b[35m0.4980\u001b[0m  0.0658\n",
      "     33        0.7148       \u001b[32m0.8619\u001b[0m        \u001b[35m0.4911\u001b[0m  0.0658\n",
      "     34        0.7181       0.8580        \u001b[35m0.4826\u001b[0m  0.0459\n",
      "     35        \u001b[36m0.7002\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.4744\u001b[0m  0.0499\n",
      "     36        0.7125       \u001b[32m0.8718\u001b[0m        \u001b[35m0.4715\u001b[0m  0.0459\n",
      "     37        \u001b[36m0.6998\u001b[0m       0.8679        \u001b[35m0.4705\u001b[0m  0.0539\n",
      "     38        \u001b[36m0.6975\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.4612\u001b[0m  0.0578\n",
      "     39        \u001b[36m0.6882\u001b[0m       0.8659        \u001b[35m0.4591\u001b[0m  0.0529\n",
      "     40        0.7120       \u001b[32m0.8777\u001b[0m        \u001b[35m0.4499\u001b[0m  0.0598\n",
      "     41        0.7252       0.8777        \u001b[35m0.4415\u001b[0m  0.0539\n",
      "     42        \u001b[36m0.6784\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.4392\u001b[0m  0.0419\n",
      "     43        0.6957       0.8757        0.4470  0.0459\n",
      "     44        0.6984       \u001b[32m0.8895\u001b[0m        \u001b[35m0.4342\u001b[0m  0.0529\n",
      "     45        0.6903       0.8895        \u001b[35m0.4273\u001b[0m  0.0628\n",
      "     46        \u001b[36m0.6739\u001b[0m       0.8836        0.4356  0.0509\n",
      "     47        0.6744       0.8817        \u001b[35m0.4263\u001b[0m  0.0658\n",
      "     48        0.6901       0.8836        \u001b[35m0.4240\u001b[0m  0.0439\n",
      "     49        \u001b[36m0.6643\u001b[0m       0.8836        \u001b[35m0.4229\u001b[0m  0.0549\n",
      "     50        0.6750       0.8836        \u001b[35m0.4193\u001b[0m  0.0568\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.6s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4405\u001b[0m       \u001b[32m0.4477\u001b[0m        \u001b[35m1.3570\u001b[0m  0.0509\n",
      "      2        \u001b[36m1.3778\u001b[0m       0.4181        \u001b[35m1.3063\u001b[0m  0.0519\n",
      "      3        \u001b[36m1.3251\u001b[0m       0.4241        \u001b[35m1.2571\u001b[0m  0.0519\n",
      "      4        \u001b[36m1.2849\u001b[0m       0.3866        \u001b[35m1.2034\u001b[0m  0.0559\n",
      "      5        \u001b[36m1.2268\u001b[0m       0.4221        \u001b[35m1.1464\u001b[0m  0.0489\n",
      "      6        \u001b[36m1.1724\u001b[0m       \u001b[32m0.4556\u001b[0m        \u001b[35m1.0859\u001b[0m  0.0608\n",
      "      7        \u001b[36m1.1191\u001b[0m       \u001b[32m0.4990\u001b[0m        \u001b[35m1.0226\u001b[0m  0.0489\n",
      "      8        \u001b[36m1.0894\u001b[0m       \u001b[32m0.5621\u001b[0m        \u001b[35m0.9628\u001b[0m  0.0499\n",
      "      9        \u001b[36m1.0412\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m0.9071\u001b[0m  0.0539\n",
      "     10        \u001b[36m0.9946\u001b[0m       \u001b[32m0.6233\u001b[0m        \u001b[35m0.8699\u001b[0m  0.0688\n",
      "     11        \u001b[36m0.9660\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m0.8240\u001b[0m  0.0648\n",
      "     12        \u001b[36m0.9364\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m0.7904\u001b[0m  0.0449\n",
      "     13        \u001b[36m0.9000\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m0.7557\u001b[0m  0.0578\n",
      "     14        0.9046       \u001b[32m0.7179\u001b[0m        \u001b[35m0.7169\u001b[0m  0.0529\n",
      "     15        \u001b[36m0.8795\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m0.7023\u001b[0m  0.0449\n",
      "     16        \u001b[36m0.8649\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m0.6762\u001b[0m  0.0578\n",
      "     17        \u001b[36m0.8417\u001b[0m       \u001b[32m0.7613\u001b[0m        \u001b[35m0.6474\u001b[0m  0.0489\n",
      "     18        \u001b[36m0.8374\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.6264\u001b[0m  0.0598\n",
      "     19        \u001b[36m0.8237\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m0.6052\u001b[0m  0.0509\n",
      "     20        \u001b[36m0.7984\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m0.5932\u001b[0m  0.0598\n",
      "     21        0.8067       \u001b[32m0.7949\u001b[0m        \u001b[35m0.5797\u001b[0m  0.0529\n",
      "     22        0.8046       \u001b[32m0.8264\u001b[0m        \u001b[35m0.5573\u001b[0m  0.0439\n",
      "     23        \u001b[36m0.7646\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.5472\u001b[0m  0.0688\n",
      "     24        \u001b[36m0.7418\u001b[0m       0.8304        \u001b[35m0.5359\u001b[0m  0.0588\n",
      "     25        0.7729       \u001b[32m0.8481\u001b[0m        \u001b[35m0.5208\u001b[0m  0.0559\n",
      "     26        0.7570       0.8383        \u001b[35m0.5143\u001b[0m  0.0499\n",
      "     27        0.7603       0.8462        \u001b[35m0.5060\u001b[0m  0.0539\n",
      "     28        0.7661       \u001b[32m0.8659\u001b[0m        \u001b[35m0.4913\u001b[0m  0.0539\n",
      "     29        \u001b[36m0.7319\u001b[0m       0.8560        \u001b[35m0.4879\u001b[0m  0.0578\n",
      "     30        \u001b[36m0.7280\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.4737\u001b[0m  0.0549\n",
      "     31        0.7309       0.8679        \u001b[35m0.4666\u001b[0m  0.0668\n",
      "     32        \u001b[36m0.7187\u001b[0m       0.8659        \u001b[35m0.4641\u001b[0m  0.0529\n",
      "     33        \u001b[36m0.7144\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.4507\u001b[0m  0.0539\n",
      "     34        0.7226       0.8679        0.4507  0.0489\n",
      "     35        \u001b[36m0.7097\u001b[0m       0.8876        \u001b[35m0.4348\u001b[0m  0.0509\n",
      "     36        \u001b[36m0.6919\u001b[0m       0.8876        \u001b[35m0.4273\u001b[0m  0.0568\n",
      "     37        0.7117       0.8797        0.4317  0.0559\n",
      "     38        0.7100       0.8817        \u001b[35m0.4215\u001b[0m  0.0578\n",
      "     39        0.7316       \u001b[32m0.8915\u001b[0m        \u001b[35m0.4168\u001b[0m  0.0578\n",
      "     40        0.7027       0.8856        \u001b[35m0.4098\u001b[0m  0.0628\n",
      "     41        \u001b[36m0.6868\u001b[0m       0.8876        \u001b[35m0.4069\u001b[0m  0.0578\n",
      "     42        0.6874       0.8915        \u001b[35m0.3985\u001b[0m  0.0499\n",
      "     43        0.6870       \u001b[32m0.8935\u001b[0m        \u001b[35m0.3866\u001b[0m  0.0588\n",
      "     44        \u001b[36m0.6698\u001b[0m       0.8915        0.3887  0.0648\n",
      "     45        \u001b[36m0.6676\u001b[0m       0.8876        \u001b[35m0.3752\u001b[0m  0.0648\n",
      "     46        0.6877       0.8876        0.3827  0.0519\n",
      "     47        0.6701       0.8915        0.3771  0.0638\n",
      "     48        0.6762       0.8895        0.3776  0.0519\n",
      "     49        0.6772       0.8915        \u001b[35m0.3661\u001b[0m  0.0638\n",
      "     50        0.6686       0.8915        0.3672  0.0539\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.5s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.0186\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m3.5862\u001b[0m  0.0608\n",
      "      2        6.5556       0.2485        \u001b[35m2.9013\u001b[0m  0.0678\n",
      "      3        4.9840       \u001b[32m0.3728\u001b[0m        \u001b[35m1.4645\u001b[0m  0.0758\n",
      "      4        \u001b[36m3.5744\u001b[0m       \u001b[32m0.4536\u001b[0m        \u001b[35m1.3208\u001b[0m  0.0568\n",
      "      5        \u001b[36m3.0318\u001b[0m       0.3964        \u001b[35m1.0450\u001b[0m  0.0718\n",
      "      6        3.0670       \u001b[32m0.6252\u001b[0m        \u001b[35m0.9735\u001b[0m  0.0678\n",
      "      7        \u001b[36m1.9588\u001b[0m       0.5108        \u001b[35m0.9662\u001b[0m  0.0778\n",
      "      8        2.7494       \u001b[32m0.6667\u001b[0m        \u001b[35m0.5758\u001b[0m  0.0818\n",
      "      9        \u001b[36m1.7260\u001b[0m       \u001b[32m0.7396\u001b[0m        0.6678  0.0858\n",
      "     10        2.1966       \u001b[32m0.8363\u001b[0m        \u001b[35m0.5067\u001b[0m  0.1107\n",
      "     11        1.8831       \u001b[32m0.9053\u001b[0m        \u001b[35m0.3771\u001b[0m  0.0957\n",
      "     12        \u001b[36m1.6131\u001b[0m       0.6765        0.6885  0.0868\n",
      "     13        2.0484       0.8974        0.4232  0.0848\n",
      "     14        \u001b[36m1.4412\u001b[0m       0.8225        0.5123  0.1117\n",
      "     15        2.1438       0.8462        0.4781  0.0858\n",
      "     16        1.8891       \u001b[32m0.9349\u001b[0m        \u001b[35m0.2935\u001b[0m  0.0838\n",
      "     17        1.5616       0.9053        0.3551  0.0878\n",
      "     18        1.7038       \u001b[32m0.9566\u001b[0m        \u001b[35m0.2292\u001b[0m  0.0668\n",
      "     19        1.4813       0.9152        0.4222  0.0908\n",
      "     20        1.5392       0.8935        0.2691  0.0768\n",
      "     21        1.5192       0.8876        0.4103  0.0778\n",
      "     22        1.6934       0.9290        \u001b[35m0.2113\u001b[0m  0.0908\n",
      "     23        \u001b[36m1.4393\u001b[0m       0.9093        0.4419  0.0818\n",
      "     24        1.5500       0.9448        0.2173  0.0947\n",
      "     25        \u001b[36m1.2098\u001b[0m       0.9408        0.2380  0.0768\n",
      "     26        1.4801       0.9507        0.2460  0.0648\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.7s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m4.3026\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m4.1603\u001b[0m  0.0688\n",
      "      2        7.3019       0.2505        \u001b[35m2.6198\u001b[0m  0.0828\n",
      "      3        4.3516       0.2505        \u001b[35m1.4404\u001b[0m  0.0828\n",
      "      4        \u001b[36m3.1587\u001b[0m       \u001b[32m0.4320\u001b[0m        \u001b[35m1.1219\u001b[0m  0.0878\n",
      "      5        3.2191       \u001b[32m0.4458\u001b[0m        1.1628  0.1197\n",
      "      6        3.2680       \u001b[32m0.5108\u001b[0m        \u001b[35m1.0753\u001b[0m  0.0768\n",
      "      7        \u001b[36m2.4241\u001b[0m       0.5108        \u001b[35m0.8947\u001b[0m  0.0788\n",
      "      8        2.7195       0.4694        1.0843  0.0678\n",
      "      9        2.4548       \u001b[32m0.6509\u001b[0m        \u001b[35m0.8169\u001b[0m  0.0788\n",
      "     10        2.6239       0.6134        \u001b[35m0.8001\u001b[0m  0.0668\n",
      "     11        \u001b[36m1.9146\u001b[0m       0.6055        0.8807  0.0768\n",
      "     12        2.6663       \u001b[32m0.6844\u001b[0m        \u001b[35m0.6770\u001b[0m  0.0698\n",
      "     13        \u001b[36m1.5777\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0808\n",
      "     14        2.2517       \u001b[32m0.9191\u001b[0m        \u001b[35m0.3239\u001b[0m  0.0838\n",
      "     15        1.6046       0.6371        0.9914  0.0738\n",
      "     16        2.7069       0.8698        0.3791  0.0668\n",
      "     17        \u001b[36m1.4251\u001b[0m       0.7002        0.8209  0.0748\n",
      "     18        2.0833       \u001b[32m0.9310\u001b[0m        \u001b[35m0.2469\u001b[0m  0.0578\n",
      "     19        \u001b[36m1.3620\u001b[0m       0.9290        0.3562  0.0648\n",
      "     20        1.6258       0.9073        0.3065  0.0708\n",
      "     21        \u001b[36m1.3585\u001b[0m       0.9250        0.4236  0.0628\n",
      "     22        1.8221       \u001b[32m0.9408\u001b[0m        0.2508  0.0698\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.1s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m3.0493\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m5.7390\u001b[0m  0.0668\n",
      "      2        7.7997       0.2505        \u001b[35m2.2903\u001b[0m  0.0638\n",
      "      3        5.0646       \u001b[32m0.2939\u001b[0m        \u001b[35m1.7406\u001b[0m  0.0648\n",
      "      4        3.5797       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3474\u001b[0m  0.0628\n",
      "      5        3.5621       \u001b[32m0.6036\u001b[0m        \u001b[35m0.9372\u001b[0m  0.0618\n",
      "      6        \u001b[36m2.3288\u001b[0m       0.3649        1.0512  0.0698\n",
      "      7        2.7005       0.4635        \u001b[35m0.7465\u001b[0m  0.0738\n",
      "      8        \u001b[36m1.9201\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.6064\u001b[0m  0.0798\n",
      "      9        2.2812       0.4162        0.8481  0.0628\n",
      "     10        2.0669       0.5385        0.8556  0.0848\n",
      "     11        2.3290       \u001b[32m0.8501\u001b[0m        \u001b[35m0.4683\u001b[0m  0.0818\n",
      "     12        \u001b[36m1.8030\u001b[0m       0.8245        0.4797  0.0848\n",
      "     13        2.1036       \u001b[32m0.8777\u001b[0m        \u001b[35m0.4167\u001b[0m  0.0529\n",
      "     14        \u001b[36m1.4723\u001b[0m       0.7318        0.7977  0.0588\n",
      "     15        2.2132       \u001b[32m0.8817\u001b[0m        \u001b[35m0.3651\u001b[0m  0.0638\n",
      "     16        \u001b[36m1.3196\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m0.3155\u001b[0m  0.0608\n",
      "     17        1.7610       \u001b[32m0.9467\u001b[0m        \u001b[35m0.2207\u001b[0m  0.0738\n",
      "     18        1.4383       \u001b[32m0.9586\u001b[0m        0.2355  0.0658\n",
      "     19        1.5759       0.9073        0.3471  0.0638\n",
      "     20        1.5682       0.9191        0.2799  0.0768\n",
      "     21        1.5462       0.8915        0.3391  0.0738\n",
      "     22        1.5254       0.9546        \u001b[35m0.1761\u001b[0m  0.0608\n",
      "     23        1.3589       0.9349        0.2773  0.0519\n",
      "     24        1.3402       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1610\u001b[0m  0.0688\n",
      "     25        \u001b[36m1.2228\u001b[0m       0.9606        0.2128  0.0598\n",
      "     26        1.3712       0.9586        0.1753  0.0668\n",
      "     27        \u001b[36m1.1807\u001b[0m       0.9625        0.1754  0.0519\n",
      "     28        1.4290       \u001b[32m0.9645\u001b[0m        0.1881  0.0658\n",
      "     29        \u001b[36m1.0509\u001b[0m       0.9645        \u001b[35m0.1579\u001b[0m  0.0778\n",
      "     30        1.2219       \u001b[32m0.9744\u001b[0m        \u001b[35m0.1250\u001b[0m  0.0758\n",
      "     31        \u001b[36m1.0013\u001b[0m       0.9665        0.1338  0.0738\n",
      "     32        1.0238       0.9625        0.1361  0.0598\n",
      "     33        1.2376       0.9684        0.1442  0.0698\n",
      "     34        1.1648       0.9684        0.1435  0.0668\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.9s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3815\u001b[0m       \u001b[32m0.2821\u001b[0m        \u001b[35m1.3224\u001b[0m  0.0648\n",
      "      2        \u001b[36m1.3356\u001b[0m       \u001b[32m0.2919\u001b[0m        \u001b[35m1.2660\u001b[0m  0.0718\n",
      "      3        \u001b[36m1.2787\u001b[0m       \u001b[32m0.3531\u001b[0m        \u001b[35m1.2003\u001b[0m  0.0588\n",
      "      4        \u001b[36m1.2043\u001b[0m       \u001b[32m0.4004\u001b[0m        \u001b[35m1.1318\u001b[0m  0.0598\n",
      "      5        \u001b[36m1.1405\u001b[0m       \u001b[32m0.4615\u001b[0m        \u001b[35m1.0611\u001b[0m  0.0558\n",
      "      6        \u001b[36m1.0728\u001b[0m       \u001b[32m0.5128\u001b[0m        \u001b[35m0.9964\u001b[0m  0.0558\n",
      "      7        \u001b[36m1.0270\u001b[0m       \u001b[32m0.5483\u001b[0m        \u001b[35m0.9342\u001b[0m  0.0628\n",
      "      8        \u001b[36m0.9606\u001b[0m       \u001b[32m0.5878\u001b[0m        \u001b[35m0.8771\u001b[0m  0.0549\n",
      "      9        \u001b[36m0.9251\u001b[0m       \u001b[32m0.6193\u001b[0m        \u001b[35m0.8265\u001b[0m  0.0678\n",
      "     10        \u001b[36m0.8839\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m0.7777\u001b[0m  0.0618\n",
      "     11        \u001b[36m0.8422\u001b[0m       \u001b[32m0.6568\u001b[0m        \u001b[35m0.7285\u001b[0m  0.0509\n",
      "     12        \u001b[36m0.8063\u001b[0m       \u001b[32m0.6805\u001b[0m        \u001b[35m0.6994\u001b[0m  0.0559\n",
      "     13        \u001b[36m0.7908\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m0.6628\u001b[0m  0.0678\n",
      "     14        \u001b[36m0.7502\u001b[0m       \u001b[32m0.7199\u001b[0m        \u001b[35m0.6337\u001b[0m  0.0549\n",
      "     15        \u001b[36m0.7234\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.6059\u001b[0m  0.0688\n",
      "     16        \u001b[36m0.7121\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m0.5729\u001b[0m  0.0499\n",
      "     17        \u001b[36m0.6801\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m0.5561\u001b[0m  0.0499\n",
      "     18        \u001b[36m0.6700\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.5297\u001b[0m  0.0489\n",
      "     19        \u001b[36m0.6572\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.5085\u001b[0m  0.0539\n",
      "     20        \u001b[36m0.6359\u001b[0m       0.8008        \u001b[35m0.5040\u001b[0m  0.0578\n",
      "     21        0.6360       \u001b[32m0.8146\u001b[0m        \u001b[35m0.4777\u001b[0m  0.0568\n",
      "     22        \u001b[36m0.6044\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.4602\u001b[0m  0.0559\n",
      "     23        \u001b[36m0.6020\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.4494\u001b[0m  0.0618\n",
      "     24        \u001b[36m0.5977\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.4350\u001b[0m  0.0489\n",
      "     25        \u001b[36m0.5772\u001b[0m       \u001b[32m0.8442\u001b[0m        \u001b[35m0.4264\u001b[0m  0.0618\n",
      "     26        0.5794       \u001b[32m0.8501\u001b[0m        \u001b[35m0.4135\u001b[0m  0.0539\n",
      "     27        \u001b[36m0.5611\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.4038\u001b[0m  0.0429\n",
      "     28        0.5697       \u001b[32m0.8639\u001b[0m        \u001b[35m0.3825\u001b[0m  0.0618\n",
      "     29        \u001b[36m0.5558\u001b[0m       0.8619        0.3834  0.0668\n",
      "     30        \u001b[36m0.5378\u001b[0m       0.8600        \u001b[35m0.3785\u001b[0m  0.0698\n",
      "     31        0.5469       0.8619        \u001b[35m0.3774\u001b[0m  0.0628\n",
      "     32        0.5397       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3635\u001b[0m  0.0409\n",
      "     33        \u001b[36m0.5232\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.3523\u001b[0m  0.0768\n",
      "     34        \u001b[36m0.5082\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.3407\u001b[0m  0.0588\n",
      "     35        \u001b[36m0.5060\u001b[0m       0.8718        0.3421  0.0678\n",
      "     36        0.5238       \u001b[32m0.8817\u001b[0m        \u001b[35m0.3297\u001b[0m  0.0539\n",
      "     37        \u001b[36m0.4872\u001b[0m       0.8777        \u001b[35m0.3242\u001b[0m  0.0519\n",
      "     38        0.4957       0.8777        0.3245  0.0459\n",
      "     39        0.4969       \u001b[32m0.8836\u001b[0m        \u001b[35m0.3145\u001b[0m  0.0429\n",
      "     40        0.5064       0.8817        0.3157  0.0539\n",
      "     41        0.4926       0.8817        \u001b[35m0.3083\u001b[0m  0.0529\n",
      "     42        \u001b[36m0.4859\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.3024\u001b[0m  0.0439\n",
      "     43        \u001b[36m0.4771\u001b[0m       0.8836        \u001b[35m0.3002\u001b[0m  0.3461\n",
      "     44        0.4849       0.8856        \u001b[35m0.2939\u001b[0m  0.0638\n",
      "     45        \u001b[36m0.4543\u001b[0m       0.8757        0.2951  0.0588\n",
      "     46        0.4653       \u001b[32m0.8895\u001b[0m        \u001b[35m0.2860\u001b[0m  0.0658\n",
      "     47        \u001b[36m0.4456\u001b[0m       0.8895        0.2866  0.1037\n",
      "     48        0.4759       0.8876        \u001b[35m0.2792\u001b[0m  0.1007\n",
      "     49        0.4574       0.8797        0.2830  0.0868\n",
      "     50        0.4733       0.8817        0.2837  0.0947\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   4.2s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4671\u001b[0m       \u001b[32m0.2742\u001b[0m        \u001b[35m1.3783\u001b[0m  0.0838\n",
      "      2        \u001b[36m1.4075\u001b[0m       0.2682        \u001b[35m1.3355\u001b[0m  0.0758\n",
      "      3        \u001b[36m1.3608\u001b[0m       \u001b[32m0.2919\u001b[0m        \u001b[35m1.2873\u001b[0m  0.0768\n",
      "      4        \u001b[36m1.3161\u001b[0m       \u001b[32m0.3136\u001b[0m        \u001b[35m1.2414\u001b[0m  0.0598\n",
      "      5        \u001b[36m1.2580\u001b[0m       \u001b[32m0.3649\u001b[0m        \u001b[35m1.1893\u001b[0m  0.0588\n",
      "      6        \u001b[36m1.2232\u001b[0m       \u001b[32m0.4339\u001b[0m        \u001b[35m1.1289\u001b[0m  0.0429\n",
      "      7        \u001b[36m1.1486\u001b[0m       \u001b[32m0.4813\u001b[0m        \u001b[35m1.0659\u001b[0m  0.0509\n",
      "      8        \u001b[36m1.0906\u001b[0m       \u001b[32m0.5286\u001b[0m        \u001b[35m1.0033\u001b[0m  0.0509\n",
      "      9        \u001b[36m1.0410\u001b[0m       \u001b[32m0.5700\u001b[0m        \u001b[35m0.9509\u001b[0m  0.0469\n",
      "     10        \u001b[36m0.9866\u001b[0m       \u001b[32m0.6036\u001b[0m        \u001b[35m0.8901\u001b[0m  0.0439\n",
      "     11        \u001b[36m0.9456\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m0.8363\u001b[0m  0.0369\n",
      "     12        \u001b[36m0.8971\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m0.7893\u001b[0m  0.0479\n",
      "     13        \u001b[36m0.8616\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m0.7449\u001b[0m  0.0519\n",
      "     14        \u001b[36m0.8313\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m0.7088\u001b[0m  0.0439\n",
      "     15        \u001b[36m0.7946\u001b[0m       \u001b[32m0.7416\u001b[0m        \u001b[35m0.6719\u001b[0m  0.0549\n",
      "     16        \u001b[36m0.7712\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m0.6438\u001b[0m  0.0409\n",
      "     17        \u001b[36m0.7479\u001b[0m       \u001b[32m0.7613\u001b[0m        \u001b[35m0.6145\u001b[0m  0.0389\n",
      "     18        \u001b[36m0.7293\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.5888\u001b[0m  0.0519\n",
      "     19        \u001b[36m0.6861\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.5610\u001b[0m  0.0379\n",
      "     20        \u001b[36m0.6809\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.5402\u001b[0m  0.0439\n",
      "     21        \u001b[36m0.6662\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m0.5250\u001b[0m  0.0459\n",
      "     22        \u001b[36m0.6527\u001b[0m       \u001b[32m0.8166\u001b[0m        \u001b[35m0.5043\u001b[0m  0.0509\n",
      "     23        \u001b[36m0.6184\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.4802\u001b[0m  0.0519\n",
      "     24        \u001b[36m0.5958\u001b[0m       \u001b[32m0.8264\u001b[0m        \u001b[35m0.4748\u001b[0m  0.0658\n",
      "     25        \u001b[36m0.5834\u001b[0m       0.8225        \u001b[35m0.4674\u001b[0m  0.0399\n",
      "     26        \u001b[36m0.5816\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4449\u001b[0m  0.0509\n",
      "     27        \u001b[36m0.5684\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.4375\u001b[0m  0.0399\n",
      "     28        0.5767       0.8383        \u001b[35m0.4282\u001b[0m  0.0628\n",
      "     29        \u001b[36m0.5571\u001b[0m       0.8402        \u001b[35m0.4254\u001b[0m  0.0499\n",
      "     30        0.5651       \u001b[32m0.8442\u001b[0m        \u001b[35m0.4113\u001b[0m  0.0618\n",
      "     31        \u001b[36m0.5551\u001b[0m       \u001b[32m0.8521\u001b[0m        \u001b[35m0.4003\u001b[0m  0.0409\n",
      "     32        \u001b[36m0.5347\u001b[0m       0.8521        \u001b[35m0.3918\u001b[0m  0.0419\n",
      "     33        \u001b[36m0.5264\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.3848\u001b[0m  0.0489\n",
      "     34        \u001b[36m0.5222\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.3760\u001b[0m  0.0459\n",
      "     35        \u001b[36m0.5183\u001b[0m       0.8481        0.3762  0.0379\n",
      "     36        \u001b[36m0.5138\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3638\u001b[0m  0.0429\n",
      "     37        \u001b[36m0.5101\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.3610\u001b[0m  0.0409\n",
      "     38        \u001b[36m0.5026\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.3521\u001b[0m  0.0449\n",
      "     39        \u001b[36m0.4974\u001b[0m       0.8698        0.3523  0.0559\n",
      "     40        \u001b[36m0.4964\u001b[0m       0.8738        \u001b[35m0.3435\u001b[0m  0.0529\n",
      "     41        \u001b[36m0.4963\u001b[0m       0.8738        \u001b[35m0.3350\u001b[0m  0.0449\n",
      "     42        \u001b[36m0.4801\u001b[0m       0.8679        0.3421  0.0419\n",
      "     43        0.4863       0.8738        \u001b[35m0.3310\u001b[0m  0.0479\n",
      "     44        0.4825       0.8738        \u001b[35m0.3308\u001b[0m  0.0389\n",
      "     45        \u001b[36m0.4655\u001b[0m       0.8659        \u001b[35m0.3176\u001b[0m  0.0479\n",
      "     46        0.4954       0.8659        \u001b[35m0.3175\u001b[0m  0.0559\n",
      "     47        0.4734       0.8679        \u001b[35m0.3091\u001b[0m  0.0509\n",
      "     48        \u001b[36m0.4628\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.3000\u001b[0m  0.0469\n",
      "     49        0.4741       0.8659        0.3115  0.0429\n",
      "     50        \u001b[36m0.4520\u001b[0m       0.8757        0.3039  0.0509\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.1s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4335\u001b[0m       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3261\u001b[0m  0.0588\n",
      "      2        \u001b[36m1.3346\u001b[0m       \u001b[32m0.2998\u001b[0m        \u001b[35m1.2645\u001b[0m  0.0598\n",
      "      3        \u001b[36m1.2768\u001b[0m       \u001b[32m0.3353\u001b[0m        \u001b[35m1.2082\u001b[0m  0.0748\n",
      "      4        \u001b[36m1.2240\u001b[0m       \u001b[32m0.4083\u001b[0m        \u001b[35m1.1465\u001b[0m  0.0668\n",
      "      5        \u001b[36m1.1610\u001b[0m       \u001b[32m0.4635\u001b[0m        \u001b[35m1.0810\u001b[0m  0.0518\n",
      "      6        \u001b[36m1.0886\u001b[0m       \u001b[32m0.5069\u001b[0m        \u001b[35m1.0211\u001b[0m  0.0648\n",
      "      7        \u001b[36m1.0441\u001b[0m       \u001b[32m0.5582\u001b[0m        \u001b[35m0.9605\u001b[0m  0.0429\n",
      "      8        \u001b[36m0.9837\u001b[0m       \u001b[32m0.6075\u001b[0m        \u001b[35m0.9058\u001b[0m  0.0539\n",
      "      9        \u001b[36m0.9378\u001b[0m       \u001b[32m0.6292\u001b[0m        \u001b[35m0.8518\u001b[0m  0.0638\n",
      "     10        \u001b[36m0.8995\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m0.8025\u001b[0m  0.0539\n",
      "     11        \u001b[36m0.8648\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m0.7599\u001b[0m  0.0638\n",
      "     12        \u001b[36m0.8477\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m0.7253\u001b[0m  0.0519\n",
      "     13        \u001b[36m0.8072\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.6835\u001b[0m  0.0658\n",
      "     14        \u001b[36m0.7839\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m0.6566\u001b[0m  0.0509\n",
      "     15        \u001b[36m0.7415\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m0.6302\u001b[0m  0.0638\n",
      "     16        \u001b[36m0.7309\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m0.5960\u001b[0m  0.0578\n",
      "     17        \u001b[36m0.7041\u001b[0m       \u001b[32m0.7949\u001b[0m        \u001b[35m0.5692\u001b[0m  0.0618\n",
      "     18        \u001b[36m0.7037\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.5553\u001b[0m  0.0499\n",
      "     19        \u001b[36m0.6766\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.5242\u001b[0m  0.0588\n",
      "     20        0.6810       \u001b[32m0.8363\u001b[0m        \u001b[35m0.5089\u001b[0m  0.0479\n",
      "     21        \u001b[36m0.6282\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.4950\u001b[0m  0.0439\n",
      "     22        0.6315       \u001b[32m0.8481\u001b[0m        \u001b[35m0.4809\u001b[0m  0.0499\n",
      "     23        0.6310       \u001b[32m0.8540\u001b[0m        \u001b[35m0.4578\u001b[0m  0.0529\n",
      "     24        \u001b[36m0.5904\u001b[0m       0.8501        \u001b[35m0.4476\u001b[0m  0.0549\n",
      "     25        0.6144       \u001b[32m0.8600\u001b[0m        \u001b[35m0.4398\u001b[0m  0.0638\n",
      "     26        0.5990       \u001b[32m0.8659\u001b[0m        \u001b[35m0.4281\u001b[0m  0.0638\n",
      "     27        0.5998       \u001b[32m0.8679\u001b[0m        \u001b[35m0.4213\u001b[0m  0.0578\n",
      "     28        \u001b[36m0.5762\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.4046\u001b[0m  0.0519\n",
      "     29        0.5891       0.8757        \u001b[35m0.3938\u001b[0m  0.0539\n",
      "     30        \u001b[36m0.5761\u001b[0m       0.8738        \u001b[35m0.3877\u001b[0m  0.0509\n",
      "     31        \u001b[36m0.5571\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.3691\u001b[0m  0.0658\n",
      "     32        \u001b[36m0.5278\u001b[0m       0.8797        \u001b[35m0.3613\u001b[0m  0.0608\n",
      "     33        0.5455       0.8777        0.3642  0.0608\n",
      "     34        0.5540       0.8836        \u001b[35m0.3492\u001b[0m  0.0519\n",
      "     35        \u001b[36m0.5226\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.3454\u001b[0m  0.0359\n",
      "     36        \u001b[36m0.5148\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.3325\u001b[0m  0.0429\n",
      "     37        0.5276       \u001b[32m0.8895\u001b[0m        \u001b[35m0.3267\u001b[0m  0.0419\n",
      "     38        \u001b[36m0.4950\u001b[0m       0.8876        \u001b[35m0.3225\u001b[0m  0.0359\n",
      "     39        0.5180       \u001b[32m0.8915\u001b[0m        \u001b[35m0.3139\u001b[0m  0.0439\n",
      "     40        0.5200       \u001b[32m0.8955\u001b[0m        \u001b[35m0.3132\u001b[0m  0.0618\n",
      "     41        0.5014       \u001b[32m0.8974\u001b[0m        \u001b[35m0.3053\u001b[0m  0.0568\n",
      "     42        0.5238       0.8955        \u001b[35m0.3043\u001b[0m  0.0628\n",
      "     43        \u001b[36m0.4817\u001b[0m       0.8955        \u001b[35m0.2999\u001b[0m  0.0409\n",
      "     44        0.4871       0.8974        \u001b[35m0.2921\u001b[0m  0.0409\n",
      "     45        0.4871       0.8974        0.2923  0.0409\n",
      "     46        \u001b[36m0.4653\u001b[0m       0.8955        \u001b[35m0.2852\u001b[0m  0.0698\n",
      "     47        \u001b[36m0.4614\u001b[0m       \u001b[32m0.9034\u001b[0m        \u001b[35m0.2717\u001b[0m  0.0568\n",
      "     48        0.4684       0.9014        0.2772  0.0439\n",
      "     49        0.4926       \u001b[32m0.9073\u001b[0m        \u001b[35m0.2705\u001b[0m  0.0509\n",
      "     50        0.4640       0.9014        \u001b[35m0.2688\u001b[0m  0.0499\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.4s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m7.1036\u001b[0m       \u001b[32m0.2781\u001b[0m        \u001b[35m3.7690\u001b[0m  0.0479\n",
      "      2        9.6250       0.2485        \u001b[35m3.7273\u001b[0m  0.0539\n",
      "      3        8.6694       \u001b[32m0.4872\u001b[0m        \u001b[35m1.2402\u001b[0m  0.0618\n",
      "      4        \u001b[36m5.8969\u001b[0m       0.4162        1.3450  0.0539\n",
      "      5        \u001b[36m5.5761\u001b[0m       \u001b[32m0.5957\u001b[0m        \u001b[35m0.8195\u001b[0m  0.0618\n",
      "      6        \u001b[36m4.1251\u001b[0m       0.5168        1.7678  0.0459\n",
      "      7        \u001b[36m3.8955\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.3590\u001b[0m  0.0479\n",
      "      8        \u001b[36m2.5192\u001b[0m       0.6805        1.2486  0.0598\n",
      "      9        3.0062       \u001b[32m0.8856\u001b[0m        0.4234  0.0439\n",
      "     10        \u001b[36m2.0258\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.3150\u001b[0m  0.0479\n",
      "     11        2.0367       0.8028        0.5808  0.0459\n",
      "     12        2.1938       \u001b[32m0.9428\u001b[0m        \u001b[35m0.2637\u001b[0m  0.0499\n",
      "     13        \u001b[36m1.5072\u001b[0m       0.9250        0.2639  0.0628\n",
      "     14        1.5526       0.9389        0.3073  0.0598\n",
      "     15        1.5482       \u001b[32m0.9487\u001b[0m        \u001b[35m0.1915\u001b[0m  0.0638\n",
      "     16        \u001b[36m1.3330\u001b[0m       0.9428        0.2191  0.0509\n",
      "     17        \u001b[36m1.3148\u001b[0m       0.9349        0.3230  0.0519\n",
      "     18        1.4925       \u001b[32m0.9566\u001b[0m        \u001b[35m0.1603\u001b[0m  0.0479\n",
      "     19        \u001b[36m1.2244\u001b[0m       0.9349        0.3476  0.0559\n",
      "     20        1.4869       0.9527        0.1956  0.0678\n",
      "     21        1.2983       0.9467        0.2757  0.0588\n",
      "     22        1.6634       \u001b[32m0.9586\u001b[0m        \u001b[35m0.1319\u001b[0m  0.0509\n",
      "     23        \u001b[36m1.1004\u001b[0m       0.9290        0.3112  0.0588\n",
      "     24        1.4292       0.9546        0.1872  0.0419\n",
      "     25        1.1696       0.9448        0.2205  0.0509\n",
      "     26        1.3968       0.9507        0.1756  0.0598\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.8s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m5.1817\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m8.9647\u001b[0m  0.0479\n",
      "      2       10.7444       0.2505        \u001b[35m5.0269\u001b[0m  0.0579\n",
      "      3        9.3867       \u001b[32m0.4320\u001b[0m        \u001b[35m2.4745\u001b[0m  0.0588\n",
      "      4        6.3726       \u001b[32m0.4576\u001b[0m        2.7456  0.0439\n",
      "      5        5.2129       \u001b[32m0.5720\u001b[0m        \u001b[35m1.0760\u001b[0m  0.0618\n",
      "      6        \u001b[36m4.5546\u001b[0m       0.4911        1.1962  0.0598\n",
      "      7        \u001b[36m4.1566\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m0.7181\u001b[0m  0.0539\n",
      "      8        \u001b[36m3.2631\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.5983\u001b[0m  0.0539\n",
      "      9        3.3047       \u001b[32m0.8718\u001b[0m        \u001b[35m0.4602\u001b[0m  0.0509\n",
      "     10        \u001b[36m2.6687\u001b[0m       0.8402        0.7618  0.0449\n",
      "     11        2.8763       \u001b[32m0.9191\u001b[0m        \u001b[35m0.3532\u001b[0m  0.0539\n",
      "     12        \u001b[36m2.1572\u001b[0m       0.8836        0.4814  0.0608\n",
      "     13        2.7818       0.9073        0.3718  0.0598\n",
      "     14        2.5933       0.9073        \u001b[35m0.3326\u001b[0m  0.0539\n",
      "     15        2.4597       0.9014        0.4416  0.0758\n",
      "     16        2.3565       \u001b[32m0.9250\u001b[0m        0.3709  0.0539\n",
      "     17        \u001b[36m2.0765\u001b[0m       0.9014        0.4209  0.0549\n",
      "     18        2.5948       0.8600        0.8090  0.0479\n",
      "     19        2.6447       \u001b[32m0.9467\u001b[0m        \u001b[35m0.1800\u001b[0m  0.0509\n",
      "     20        \u001b[36m1.6454\u001b[0m       0.7416        0.8725  0.0658\n",
      "     21        2.5287       0.9329        0.2368  0.0588\n",
      "     22        1.7046       0.8974        0.4457  0.0688\n",
      "     23        2.0683       \u001b[32m0.9487\u001b[0m        0.1849  0.0568\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.6s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m3.8579\u001b[0m       \u001b[32m0.2505\u001b[0m       \u001b[35m10.0366\u001b[0m  0.0578\n",
      "      2       11.2971       \u001b[32m0.2584\u001b[0m        \u001b[35m2.5294\u001b[0m  0.0568\n",
      "      3        8.7366       \u001b[32m0.4852\u001b[0m        4.4016  0.0718\n",
      "      4        4.8519       0.3688        2.6816  0.0489\n",
      "      5        6.4277       \u001b[32m0.5878\u001b[0m        \u001b[35m0.8702\u001b[0m  0.0578\n",
      "      6        \u001b[36m3.5024\u001b[0m       \u001b[32m0.5957\u001b[0m        1.5138  0.0519\n",
      "      7        4.1452       \u001b[32m0.9270\u001b[0m        \u001b[35m0.2012\u001b[0m  0.0698\n",
      "      8        \u001b[36m2.5063\u001b[0m       0.9073        0.4798  0.0688\n",
      "      9        \u001b[36m1.9951\u001b[0m       0.9034        0.4058  0.0578\n",
      "     10        2.3865       \u001b[32m0.9586\u001b[0m        \u001b[35m0.1735\u001b[0m  0.0479\n",
      "     11        \u001b[36m1.5305\u001b[0m       0.9073        0.5714  0.0509\n",
      "     12        1.8810       0.9566        \u001b[35m0.1468\u001b[0m  0.0489\n",
      "     13        \u001b[36m1.0838\u001b[0m       0.9369        0.3278  0.0459\n",
      "     14        1.4115       0.9566        0.2181  0.0459\n",
      "     15        \u001b[36m1.0382\u001b[0m       \u001b[32m0.9704\u001b[0m        \u001b[35m0.1370\u001b[0m  0.0618\n",
      "     16        1.2572       0.9408        0.2913  0.0489\n",
      "     17        1.2697       0.9527        0.2205  0.0459\n",
      "     18        1.1281       0.9645        0.1622  0.0529\n",
      "     19        1.0544       0.9369        0.4009  0.0638\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.3s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3621\u001b[0m       \u001b[32m0.4892\u001b[0m        \u001b[35m1.2410\u001b[0m  0.0419\n",
      "      2        \u001b[36m1.2576\u001b[0m       0.4438        \u001b[35m1.1642\u001b[0m  0.0519\n",
      "      3        \u001b[36m1.1815\u001b[0m       \u001b[32m0.4931\u001b[0m        \u001b[35m1.0874\u001b[0m  0.0399\n",
      "      4        \u001b[36m1.0994\u001b[0m       \u001b[32m0.5325\u001b[0m        \u001b[35m1.0095\u001b[0m  0.0618\n",
      "      5        \u001b[36m1.0441\u001b[0m       \u001b[32m0.5819\u001b[0m        \u001b[35m0.9373\u001b[0m  0.0449\n",
      "      6        \u001b[36m0.9505\u001b[0m       \u001b[32m0.6134\u001b[0m        \u001b[35m0.8646\u001b[0m  0.0389\n",
      "      7        \u001b[36m0.8963\u001b[0m       \u001b[32m0.6469\u001b[0m        \u001b[35m0.7977\u001b[0m  0.0509\n",
      "      8        \u001b[36m0.8458\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m0.7478\u001b[0m  0.0469\n",
      "      9        \u001b[36m0.7931\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m0.7031\u001b[0m  0.0409\n",
      "     10        \u001b[36m0.7400\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m0.6582\u001b[0m  0.0499\n",
      "     11        \u001b[36m0.7274\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m0.6310\u001b[0m  0.0499\n",
      "     12        \u001b[36m0.6756\u001b[0m       \u001b[32m0.7594\u001b[0m        \u001b[35m0.5923\u001b[0m  0.0509\n",
      "     13        \u001b[36m0.6625\u001b[0m       \u001b[32m0.7791\u001b[0m        \u001b[35m0.5674\u001b[0m  0.0399\n",
      "     14        \u001b[36m0.6338\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m0.5455\u001b[0m  0.0389\n",
      "     15        \u001b[36m0.6089\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.5102\u001b[0m  0.0558\n",
      "     16        \u001b[36m0.5915\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.4979\u001b[0m  0.0489\n",
      "     17        \u001b[36m0.5821\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.4787\u001b[0m  0.0389\n",
      "     18        \u001b[36m0.5376\u001b[0m       \u001b[32m0.8185\u001b[0m        \u001b[35m0.4660\u001b[0m  0.0419\n",
      "     19        \u001b[36m0.5351\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4432\u001b[0m  0.0379\n",
      "     20        \u001b[36m0.5286\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.4338\u001b[0m  0.0379\n",
      "     21        \u001b[36m0.5120\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.4181\u001b[0m  0.0488\n",
      "     22        \u001b[36m0.5037\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.3981\u001b[0m  0.0479\n",
      "     23        \u001b[36m0.4886\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.3885\u001b[0m  0.0459\n",
      "     24        \u001b[36m0.4762\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3781\u001b[0m  0.0469\n",
      "     25        \u001b[36m0.4534\u001b[0m       0.8580        \u001b[35m0.3693\u001b[0m  0.0399\n",
      "     26        0.4563       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3634\u001b[0m  0.0539\n",
      "     27        \u001b[36m0.4507\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.3495\u001b[0m  0.0479\n",
      "     28        \u001b[36m0.4394\u001b[0m       0.8679        \u001b[35m0.3437\u001b[0m  0.0409\n",
      "     29        0.4517       0.8619        0.3460  0.0399\n",
      "     30        \u001b[36m0.4354\u001b[0m       0.8639        \u001b[35m0.3403\u001b[0m  0.0369\n",
      "     31        \u001b[36m0.4219\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.3191\u001b[0m  0.0439\n",
      "     32        \u001b[36m0.4195\u001b[0m       0.8659        0.3254  0.0459\n",
      "     33        \u001b[36m0.4069\u001b[0m       0.8698        \u001b[35m0.3143\u001b[0m  0.0449\n",
      "     34        0.4128       0.8698        \u001b[35m0.3071\u001b[0m  0.0539\n",
      "     35        \u001b[36m0.3968\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.2983\u001b[0m  0.0578\n",
      "     36        0.4060       0.8738        0.3002  0.0389\n",
      "     37        0.3973       \u001b[32m0.8797\u001b[0m        \u001b[35m0.2903\u001b[0m  0.0529\n",
      "     38        \u001b[36m0.3797\u001b[0m       \u001b[32m0.8817\u001b[0m        0.2911  0.0499\n",
      "     39        \u001b[36m0.3777\u001b[0m       0.8817        \u001b[35m0.2807\u001b[0m  0.0509\n",
      "     40        0.3900       0.8777        0.2815  0.0529\n",
      "     41        \u001b[36m0.3763\u001b[0m       0.8777        0.2847  0.0569\n",
      "     42        \u001b[36m0.3592\u001b[0m       0.8817        \u001b[35m0.2711\u001b[0m  0.0718\n",
      "     43        \u001b[36m0.3516\u001b[0m       0.8817        \u001b[35m0.2655\u001b[0m  0.0668\n",
      "     44        0.3603       0.8817        \u001b[35m0.2636\u001b[0m  0.0668\n",
      "     45        \u001b[36m0.3502\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.2622\u001b[0m  0.0708\n",
      "     46        0.3558       0.8856        \u001b[35m0.2517\u001b[0m  0.0698\n",
      "     47        \u001b[36m0.3370\u001b[0m       0.8817        0.2573  0.0479\n",
      "     48        0.3511       0.8817        0.2593  0.0489\n",
      "     49        0.3515       \u001b[32m0.8876\u001b[0m        \u001b[35m0.2494\u001b[0m  0.0499\n",
      "     50        0.3420       \u001b[32m0.8895\u001b[0m        \u001b[35m0.2389\u001b[0m  0.0618\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.1s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3946\u001b[0m       \u001b[32m0.2959\u001b[0m        \u001b[35m1.2929\u001b[0m  0.0399\n",
      "      2        \u001b[36m1.3195\u001b[0m       \u001b[32m0.3471\u001b[0m        \u001b[35m1.2226\u001b[0m  0.0439\n",
      "      3        \u001b[36m1.2282\u001b[0m       \u001b[32m0.4418\u001b[0m        \u001b[35m1.1413\u001b[0m  0.0648\n",
      "      4        \u001b[36m1.1560\u001b[0m       \u001b[32m0.5049\u001b[0m        \u001b[35m1.0654\u001b[0m  0.0469\n",
      "      5        \u001b[36m1.1031\u001b[0m       \u001b[32m0.5365\u001b[0m        \u001b[35m0.9918\u001b[0m  0.0539\n",
      "      6        \u001b[36m1.0095\u001b[0m       \u001b[32m0.5779\u001b[0m        \u001b[35m0.9217\u001b[0m  0.0598\n",
      "      7        \u001b[36m0.9602\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m0.8546\u001b[0m  0.0439\n",
      "      8        \u001b[36m0.8879\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m0.7917\u001b[0m  0.0588\n",
      "      9        \u001b[36m0.8434\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m0.7431\u001b[0m  0.0628\n",
      "     10        \u001b[36m0.7907\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m0.7046\u001b[0m  0.0618\n",
      "     11        \u001b[36m0.7592\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m0.6694\u001b[0m  0.0409\n",
      "     12        \u001b[36m0.7021\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m0.6297\u001b[0m  0.0449\n",
      "     13        \u001b[36m0.6723\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m0.5989\u001b[0m  0.0479\n",
      "     14        \u001b[36m0.6516\u001b[0m       \u001b[32m0.7613\u001b[0m        \u001b[35m0.5751\u001b[0m  0.0479\n",
      "     15        \u001b[36m0.6261\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.5538\u001b[0m  0.0489\n",
      "     16        \u001b[36m0.6143\u001b[0m       \u001b[32m0.7909\u001b[0m        \u001b[35m0.5264\u001b[0m  0.0618\n",
      "     17        \u001b[36m0.5735\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.5017\u001b[0m  0.0549\n",
      "     18        \u001b[36m0.5626\u001b[0m       0.8028        \u001b[35m0.4944\u001b[0m  0.0588\n",
      "     19        \u001b[36m0.5565\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.4751\u001b[0m  0.0459\n",
      "     20        \u001b[36m0.5273\u001b[0m       \u001b[32m0.8264\u001b[0m        \u001b[35m0.4487\u001b[0m  0.0589\n",
      "     21        \u001b[36m0.5105\u001b[0m       0.8264        \u001b[35m0.4451\u001b[0m  0.0519\n",
      "     22        \u001b[36m0.5008\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.4240\u001b[0m  0.0439\n",
      "     23        \u001b[36m0.4882\u001b[0m       0.8284        \u001b[35m0.4218\u001b[0m  0.0559\n",
      "     24        0.5027       0.8323        \u001b[35m0.4168\u001b[0m  0.0489\n",
      "     25        \u001b[36m0.4760\u001b[0m       \u001b[32m0.8422\u001b[0m        \u001b[35m0.4008\u001b[0m  0.0499\n",
      "     26        \u001b[36m0.4619\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.3934\u001b[0m  0.0559\n",
      "     27        \u001b[36m0.4394\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.3771\u001b[0m  0.0708\n",
      "     28        \u001b[36m0.4364\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.3748\u001b[0m  0.0668\n",
      "     29        0.4449       \u001b[32m0.8580\u001b[0m        \u001b[35m0.3653\u001b[0m  0.0459\n",
      "     30        0.4472       0.8560        \u001b[35m0.3590\u001b[0m  0.0499\n",
      "     31        \u001b[36m0.4163\u001b[0m       0.8580        \u001b[35m0.3514\u001b[0m  0.0658\n",
      "     32        \u001b[36m0.4084\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.3445\u001b[0m  0.0419\n",
      "     33        0.4144       0.8580        0.3501  0.0598\n",
      "     34        0.4168       \u001b[32m0.8659\u001b[0m        \u001b[35m0.3305\u001b[0m  0.0409\n",
      "     35        \u001b[36m0.3964\u001b[0m       0.8659        \u001b[35m0.3246\u001b[0m  0.0449\n",
      "     36        \u001b[36m0.3847\u001b[0m       0.8659        \u001b[35m0.3221\u001b[0m  0.0509\n",
      "     37        0.3925       0.8659        \u001b[35m0.3157\u001b[0m  0.0409\n",
      "     38        \u001b[36m0.3779\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.3105\u001b[0m  0.0608\n",
      "     39        \u001b[36m0.3680\u001b[0m       0.8679        \u001b[35m0.3064\u001b[0m  0.0658\n",
      "     40        \u001b[36m0.3658\u001b[0m       0.8659        \u001b[35m0.3052\u001b[0m  0.0608\n",
      "     41        \u001b[36m0.3617\u001b[0m       0.8679        \u001b[35m0.2980\u001b[0m  0.0578\n",
      "     42        \u001b[36m0.3525\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.2936\u001b[0m  0.0489\n",
      "     43        \u001b[36m0.3499\u001b[0m       0.8698        \u001b[35m0.2915\u001b[0m  0.0369\n",
      "     44        \u001b[36m0.3343\u001b[0m       0.8698        \u001b[35m0.2873\u001b[0m  0.0429\n",
      "     45        \u001b[36m0.3326\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.2805\u001b[0m  0.0499\n",
      "     46        0.3426       0.8738        0.2886  0.0588\n",
      "     47        0.3542       0.8738        \u001b[35m0.2761\u001b[0m  0.0628\n",
      "     48        0.3455       0.8738        \u001b[35m0.2706\u001b[0m  0.0449\n",
      "     49        0.3328       \u001b[32m0.8777\u001b[0m        0.2718  0.0568\n",
      "     50        0.3351       0.8757        \u001b[35m0.2691\u001b[0m  0.0529\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.3s\n",
      "[CV] lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3842\u001b[0m       \u001b[32m0.3294\u001b[0m        \u001b[35m1.3062\u001b[0m  0.0519\n",
      "      2        \u001b[36m1.3050\u001b[0m       \u001b[32m0.4024\u001b[0m        \u001b[35m1.2291\u001b[0m  0.0479\n",
      "      3        \u001b[36m1.2395\u001b[0m       \u001b[32m0.4497\u001b[0m        \u001b[35m1.1497\u001b[0m  0.0429\n",
      "      4        \u001b[36m1.1546\u001b[0m       \u001b[32m0.5108\u001b[0m        \u001b[35m1.0626\u001b[0m  0.0588\n",
      "      5        \u001b[36m1.0771\u001b[0m       \u001b[32m0.5523\u001b[0m        \u001b[35m0.9855\u001b[0m  0.0399\n",
      "      6        \u001b[36m0.9987\u001b[0m       \u001b[32m0.6036\u001b[0m        \u001b[35m0.9086\u001b[0m  0.0389\n",
      "      7        \u001b[36m0.9331\u001b[0m       \u001b[32m0.6272\u001b[0m        \u001b[35m0.8440\u001b[0m  0.0419\n",
      "      8        \u001b[36m0.8668\u001b[0m       \u001b[32m0.6469\u001b[0m        \u001b[35m0.7863\u001b[0m  0.0409\n",
      "      9        \u001b[36m0.8244\u001b[0m       \u001b[32m0.6746\u001b[0m        \u001b[35m0.7327\u001b[0m  0.0588\n",
      "     10        \u001b[36m0.7832\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m0.6896\u001b[0m  0.0429\n",
      "     11        \u001b[36m0.7507\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.6512\u001b[0m  0.0439\n",
      "     12        \u001b[36m0.7016\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m0.6110\u001b[0m  0.0399\n",
      "     13        \u001b[36m0.6899\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m0.5812\u001b[0m  0.0429\n",
      "     14        \u001b[36m0.6362\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m0.5495\u001b[0m  0.0529\n",
      "     15        0.6377       \u001b[32m0.7890\u001b[0m        \u001b[35m0.5235\u001b[0m  0.0419\n",
      "     16        \u001b[36m0.6064\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.5045\u001b[0m  0.0519\n",
      "     17        \u001b[36m0.5857\u001b[0m       \u001b[32m0.8205\u001b[0m        \u001b[35m0.4751\u001b[0m  0.0379\n",
      "     18        \u001b[36m0.5485\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.4631\u001b[0m  0.0618\n",
      "     19        \u001b[36m0.5407\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.4469\u001b[0m  0.0439\n",
      "     20        0.5526       \u001b[32m0.8442\u001b[0m        \u001b[35m0.4340\u001b[0m  0.0658\n",
      "     21        \u001b[36m0.5163\u001b[0m       \u001b[32m0.8521\u001b[0m        \u001b[35m0.4099\u001b[0m  0.0499\n",
      "     22        \u001b[36m0.4978\u001b[0m       0.8521        \u001b[35m0.4000\u001b[0m  0.0479\n",
      "     23        \u001b[36m0.4910\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.3808\u001b[0m  0.0419\n",
      "     24        0.4915       \u001b[32m0.8757\u001b[0m        \u001b[35m0.3655\u001b[0m  0.0519\n",
      "     25        \u001b[36m0.4574\u001b[0m       \u001b[32m0.8797\u001b[0m        \u001b[35m0.3595\u001b[0m  0.0459\n",
      "     26        0.4651       0.8797        \u001b[35m0.3534\u001b[0m  0.0449\n",
      "     27        \u001b[36m0.4489\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.3437\u001b[0m  0.0678\n",
      "     28        \u001b[36m0.4290\u001b[0m       0.8817        \u001b[35m0.3325\u001b[0m  0.0529\n",
      "     29        0.4362       0.8817        \u001b[35m0.3276\u001b[0m  0.0549\n",
      "     30        \u001b[36m0.4290\u001b[0m       0.8817        \u001b[35m0.3199\u001b[0m  0.0529\n",
      "     31        \u001b[36m0.4219\u001b[0m       0.8817        \u001b[35m0.3082\u001b[0m  0.0598\n",
      "     32        \u001b[36m0.4117\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.3000\u001b[0m  0.0499\n",
      "     33        \u001b[36m0.4071\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.2895\u001b[0m  0.0519\n",
      "     34        \u001b[36m0.4055\u001b[0m       0.8895        \u001b[35m0.2877\u001b[0m  0.0409\n",
      "     35        \u001b[36m0.3801\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.2827\u001b[0m  0.0528\n",
      "     36        \u001b[36m0.3776\u001b[0m       0.8895        \u001b[35m0.2826\u001b[0m  0.0588\n",
      "     37        \u001b[36m0.3755\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.2691\u001b[0m  0.0678\n",
      "     38        \u001b[36m0.3719\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.2649\u001b[0m  0.0509\n",
      "     39        0.3796       0.8994        \u001b[35m0.2613\u001b[0m  0.0399\n",
      "     40        \u001b[36m0.3637\u001b[0m       0.9014        \u001b[35m0.2578\u001b[0m  0.0519\n",
      "     41        0.3658       \u001b[32m0.9073\u001b[0m        \u001b[35m0.2486\u001b[0m  0.0598\n",
      "     42        \u001b[36m0.3418\u001b[0m       0.9034        0.2490  0.0409\n",
      "     43        \u001b[36m0.3373\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m0.2419\u001b[0m  0.0469\n",
      "     44        0.3487       0.9053        0.2420  0.0529\n",
      "     45        0.3440       0.9073        \u001b[35m0.2374\u001b[0m  0.0598\n",
      "     46        0.3481       0.9093        \u001b[35m0.2348\u001b[0m  0.0479\n",
      "     47        0.3428       \u001b[32m0.9152\u001b[0m        \u001b[35m0.2332\u001b[0m  0.0539\n",
      "     48        \u001b[36m0.3309\u001b[0m       0.9112        \u001b[35m0.2284\u001b[0m  0.0568\n",
      "     49        0.3314       0.9132        \u001b[35m0.2264\u001b[0m  0.0588\n",
      "     50        0.3386       0.9112        \u001b[35m0.2250\u001b[0m  0.0419\n",
      "[CV]  lr=0.1, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.1s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.6522\u001b[0m       \u001b[32m0.3590\u001b[0m        \u001b[35m1.3421\u001b[0m  0.0439\n",
      "      2        \u001b[36m1.2550\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m1.1610\u001b[0m  0.0608\n",
      "      3        \u001b[36m1.1583\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m1.0100\u001b[0m  0.0628\n",
      "      4        \u001b[36m1.0274\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.8645\u001b[0m  0.0409\n",
      "      5        \u001b[36m0.9000\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.7471\u001b[0m  0.0658\n",
      "      6        \u001b[36m0.8110\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.6456\u001b[0m  0.0459\n",
      "      7        \u001b[36m0.7075\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.5541\u001b[0m  0.0678\n",
      "      8        \u001b[36m0.6400\u001b[0m       \u001b[32m0.9034\u001b[0m        \u001b[35m0.4783\u001b[0m  0.0559\n",
      "      9        \u001b[36m0.5738\u001b[0m       0.8994        \u001b[35m0.4190\u001b[0m  0.0529\n",
      "     10        \u001b[36m0.5359\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.3708\u001b[0m  0.0449\n",
      "     11        \u001b[36m0.4790\u001b[0m       0.9093        \u001b[35m0.3328\u001b[0m  0.0449\n",
      "     12        \u001b[36m0.4580\u001b[0m       0.9152        \u001b[35m0.3010\u001b[0m  0.0638\n",
      "     13        \u001b[36m0.4354\u001b[0m       0.9152        \u001b[35m0.2765\u001b[0m  0.0608\n",
      "     14        \u001b[36m0.4321\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.2589\u001b[0m  0.0499\n",
      "     15        \u001b[36m0.4112\u001b[0m       \u001b[32m0.9369\u001b[0m        \u001b[35m0.2434\u001b[0m  0.0509\n",
      "     16        \u001b[36m0.3746\u001b[0m       0.9369        \u001b[35m0.2283\u001b[0m  0.0559\n",
      "     17        0.3824       \u001b[32m0.9448\u001b[0m        \u001b[35m0.2177\u001b[0m  0.0568\n",
      "     18        \u001b[36m0.3568\u001b[0m       \u001b[32m0.9487\u001b[0m        \u001b[35m0.2070\u001b[0m  0.0668\n",
      "     19        \u001b[36m0.3538\u001b[0m       \u001b[32m0.9527\u001b[0m        \u001b[35m0.1963\u001b[0m  0.0738\n",
      "     20        \u001b[36m0.3398\u001b[0m       \u001b[32m0.9566\u001b[0m        \u001b[35m0.1872\u001b[0m  0.0698\n",
      "     21        0.3577       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1813\u001b[0m  0.0439\n",
      "     22        \u001b[36m0.3196\u001b[0m       0.9625        \u001b[35m0.1742\u001b[0m  0.0558\n",
      "     23        0.3261       0.9606        \u001b[35m0.1681\u001b[0m  0.0529\n",
      "     24        \u001b[36m0.3138\u001b[0m       0.9606        \u001b[35m0.1615\u001b[0m  0.0568\n",
      "     25        \u001b[36m0.2840\u001b[0m       0.9606        \u001b[35m0.1569\u001b[0m  0.0608\n",
      "     26        0.2953       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1497\u001b[0m  0.0479\n",
      "     27        0.2978       \u001b[32m0.9704\u001b[0m        \u001b[35m0.1448\u001b[0m  0.0509\n",
      "     28        0.2888       0.9645        \u001b[35m0.1422\u001b[0m  0.0439\n",
      "     29        0.2852       0.9684        \u001b[35m0.1373\u001b[0m  0.0459\n",
      "     30        \u001b[36m0.2770\u001b[0m       0.9684        \u001b[35m0.1347\u001b[0m  0.0668\n",
      "     31        \u001b[36m0.2768\u001b[0m       0.9704        \u001b[35m0.1316\u001b[0m  0.0608\n",
      "     32        \u001b[36m0.2721\u001b[0m       0.9704        \u001b[35m0.1274\u001b[0m  0.0409\n",
      "     33        \u001b[36m0.2598\u001b[0m       0.9665        \u001b[35m0.1267\u001b[0m  0.0499\n",
      "     34        0.2606       0.9704        \u001b[35m0.1225\u001b[0m  0.0539\n",
      "     35        \u001b[36m0.2410\u001b[0m       0.9665        \u001b[35m0.1187\u001b[0m  0.0439\n",
      "     36        0.2439       0.9684        \u001b[35m0.1172\u001b[0m  0.0628\n",
      "     37        0.2506       0.9665        \u001b[35m0.1153\u001b[0m  0.0469\n",
      "     38        0.2588       \u001b[32m0.9724\u001b[0m        \u001b[35m0.1122\u001b[0m  0.0419\n",
      "     39        0.2614       \u001b[32m0.9744\u001b[0m        \u001b[35m0.1089\u001b[0m  0.0419\n",
      "     40        \u001b[36m0.2308\u001b[0m       0.9744        \u001b[35m0.1056\u001b[0m  0.0489\n",
      "     41        0.2420       0.9744        \u001b[35m0.1037\u001b[0m  0.0479\n",
      "     42        0.2324       0.9744        0.1049  0.0489\n",
      "     43        0.2456       0.9744        \u001b[35m0.1026\u001b[0m  0.0509\n",
      "     44        0.2377       \u001b[32m0.9763\u001b[0m        \u001b[35m0.0997\u001b[0m  0.0409\n",
      "     45        \u001b[36m0.2175\u001b[0m       0.9744        \u001b[35m0.0981\u001b[0m  0.0588\n",
      "     46        0.2350       0.9763        \u001b[35m0.0951\u001b[0m  0.0459\n",
      "     47        0.2363       0.9744        0.0959  0.0469\n",
      "     48        0.2215       0.9763        0.0962  0.0588\n",
      "     49        0.2200       0.9744        0.0969  0.0409\n",
      "     50        0.2255       0.9763        \u001b[35m0.0925\u001b[0m  0.0469\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.6340\u001b[0m       \u001b[32m0.4852\u001b[0m        \u001b[35m1.3436\u001b[0m  0.0479\n",
      "      2        \u001b[36m1.3231\u001b[0m       \u001b[32m0.5345\u001b[0m        \u001b[35m1.2256\u001b[0m  0.0628\n",
      "      3        \u001b[36m1.2199\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.0879\u001b[0m  0.0568\n",
      "      4        \u001b[36m1.0966\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m0.9340\u001b[0m  0.0499\n",
      "      5        \u001b[36m0.9610\u001b[0m       \u001b[32m0.7850\u001b[0m        \u001b[35m0.7909\u001b[0m  0.0489\n",
      "      6        \u001b[36m0.8419\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.6711\u001b[0m  0.0509\n",
      "      7        \u001b[36m0.7366\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.5732\u001b[0m  0.0618\n",
      "      8        \u001b[36m0.6623\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.4939\u001b[0m  0.0549\n",
      "      9        \u001b[36m0.5969\u001b[0m       0.8856        \u001b[35m0.4353\u001b[0m  0.0489\n",
      "     10        \u001b[36m0.5398\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.3904\u001b[0m  0.0529\n",
      "     11        \u001b[36m0.4989\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.3538\u001b[0m  0.0488\n",
      "     12        \u001b[36m0.4674\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.3277\u001b[0m  0.0399\n",
      "     13        \u001b[36m0.4526\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m0.3043\u001b[0m  0.0449\n",
      "     14        \u001b[36m0.4185\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m0.2843\u001b[0m  0.0459\n",
      "     15        \u001b[36m0.3961\u001b[0m       0.9152        \u001b[35m0.2706\u001b[0m  0.0549\n",
      "     16        \u001b[36m0.3949\u001b[0m       \u001b[32m0.9270\u001b[0m        \u001b[35m0.2555\u001b[0m  0.0459\n",
      "     17        \u001b[36m0.3760\u001b[0m       \u001b[32m0.9290\u001b[0m        \u001b[35m0.2430\u001b[0m  0.0529\n",
      "     18        \u001b[36m0.3678\u001b[0m       \u001b[32m0.9349\u001b[0m        \u001b[35m0.2335\u001b[0m  0.0559\n",
      "     19        \u001b[36m0.3538\u001b[0m       \u001b[32m0.9428\u001b[0m        \u001b[35m0.2220\u001b[0m  0.0578\n",
      "     20        \u001b[36m0.3350\u001b[0m       0.9389        \u001b[35m0.2143\u001b[0m  0.0738\n",
      "     21        \u001b[36m0.3209\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.2040\u001b[0m  0.0598\n",
      "     22        0.3332       0.9448        \u001b[35m0.1989\u001b[0m  0.0539\n",
      "     23        \u001b[36m0.3100\u001b[0m       0.9428        \u001b[35m0.1925\u001b[0m  0.0509\n",
      "     24        \u001b[36m0.3048\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m0.1847\u001b[0m  0.0529\n",
      "     25        0.3154       \u001b[32m0.9487\u001b[0m        \u001b[35m0.1800\u001b[0m  0.0489\n",
      "     26        0.3058       \u001b[32m0.9507\u001b[0m        \u001b[35m0.1755\u001b[0m  0.0479\n",
      "     27        \u001b[36m0.2976\u001b[0m       0.9487        \u001b[35m0.1721\u001b[0m  0.0618\n",
      "     28        \u001b[36m0.2933\u001b[0m       0.9487        \u001b[35m0.1715\u001b[0m  0.0698\n",
      "     29        \u001b[36m0.2881\u001b[0m       \u001b[32m0.9586\u001b[0m        \u001b[35m0.1645\u001b[0m  0.0479\n",
      "     30        \u001b[36m0.2790\u001b[0m       0.9586        \u001b[35m0.1611\u001b[0m  0.0758\n",
      "     31        \u001b[36m0.2643\u001b[0m       0.9546        \u001b[35m0.1568\u001b[0m  0.0638\n",
      "     32        \u001b[36m0.2615\u001b[0m       0.9566        \u001b[35m0.1541\u001b[0m  0.0509\n",
      "     33        \u001b[36m0.2602\u001b[0m       0.9566        \u001b[35m0.1522\u001b[0m  0.0509\n",
      "     34        0.2818       \u001b[32m0.9645\u001b[0m        \u001b[35m0.1459\u001b[0m  0.0668\n",
      "     35        \u001b[36m0.2563\u001b[0m       0.9566        0.1472  0.0668\n",
      "     36        \u001b[36m0.2554\u001b[0m       0.9586        \u001b[35m0.1411\u001b[0m  0.0539\n",
      "     37        \u001b[36m0.2455\u001b[0m       0.9586        0.1412  0.0529\n",
      "     38        0.2458       0.9566        \u001b[35m0.1404\u001b[0m  0.0459\n",
      "     39        0.2626       0.9625        \u001b[35m0.1352\u001b[0m  0.0429\n",
      "     40        0.2461       0.9566        0.1407  0.0619\n",
      "     41        \u001b[36m0.2384\u001b[0m       0.9645        \u001b[35m0.1348\u001b[0m  0.0688\n",
      "     42        0.2559       0.9566        \u001b[35m0.1319\u001b[0m  0.0549\n",
      "     43        \u001b[36m0.2289\u001b[0m       0.9606        \u001b[35m0.1299\u001b[0m  0.0419\n",
      "     44        0.2302       0.9606        \u001b[35m0.1268\u001b[0m  0.0608\n",
      "     45        0.2377       0.9625        \u001b[35m0.1225\u001b[0m  0.0568\n",
      "     46        0.2384       \u001b[32m0.9665\u001b[0m        \u001b[35m0.1215\u001b[0m  0.0638\n",
      "     47        \u001b[36m0.2214\u001b[0m       0.9606        \u001b[35m0.1210\u001b[0m  0.0668\n",
      "     48        0.2233       0.9625        \u001b[35m0.1174\u001b[0m  0.0469\n",
      "     49        0.2357       0.9645        \u001b[35m0.1173\u001b[0m  0.0598\n",
      "     50        0.2461       0.9625        0.1191  0.0648\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.4s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.5881\u001b[0m       \u001b[32m0.4694\u001b[0m        \u001b[35m1.2469\u001b[0m  0.0559\n",
      "      2        \u001b[36m1.1783\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.0778\u001b[0m  0.0638\n",
      "      3        \u001b[36m1.0865\u001b[0m       \u001b[32m0.7653\u001b[0m        \u001b[35m0.9300\u001b[0m  0.0758\n",
      "      4        \u001b[36m0.9632\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.8092\u001b[0m  0.0558\n",
      "      5        \u001b[36m0.8522\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.7077\u001b[0m  0.0519\n",
      "      6        \u001b[36m0.7770\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.6204\u001b[0m  0.0688\n",
      "      7        \u001b[36m0.7088\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.5449\u001b[0m  0.0658\n",
      "      8        \u001b[36m0.6495\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.4810\u001b[0m  0.0578\n",
      "      9        \u001b[36m0.5794\u001b[0m       \u001b[32m0.9270\u001b[0m        \u001b[35m0.4294\u001b[0m  0.0588\n",
      "     10        \u001b[36m0.5385\u001b[0m       0.9270        \u001b[35m0.3862\u001b[0m  0.0588\n",
      "     11        \u001b[36m0.5130\u001b[0m       \u001b[32m0.9329\u001b[0m        \u001b[35m0.3496\u001b[0m  0.0678\n",
      "     12        \u001b[36m0.4822\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.3206\u001b[0m  0.0628\n",
      "     13        \u001b[36m0.4579\u001b[0m       0.9349        \u001b[35m0.2970\u001b[0m  0.0549\n",
      "     14        \u001b[36m0.4470\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.2782\u001b[0m  0.0429\n",
      "     15        \u001b[36m0.4083\u001b[0m       0.9448        \u001b[35m0.2620\u001b[0m  0.0539\n",
      "     16        0.4097       \u001b[32m0.9467\u001b[0m        \u001b[35m0.2473\u001b[0m  0.0648\n",
      "     17        \u001b[36m0.3763\u001b[0m       \u001b[32m0.9487\u001b[0m        \u001b[35m0.2345\u001b[0m  0.0578\n",
      "     18        \u001b[36m0.3758\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.2230\u001b[0m  0.0578\n",
      "     19        0.3843       0.9546        \u001b[35m0.2128\u001b[0m  0.0598\n",
      "     20        \u001b[36m0.3645\u001b[0m       \u001b[32m0.9586\u001b[0m        \u001b[35m0.2034\u001b[0m  0.0628\n",
      "     21        \u001b[36m0.3371\u001b[0m       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1957\u001b[0m  0.0429\n",
      "     22        \u001b[36m0.3293\u001b[0m       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1877\u001b[0m  0.0549\n",
      "     23        0.3315       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1804\u001b[0m  0.0558\n",
      "     24        \u001b[36m0.3221\u001b[0m       \u001b[32m0.9744\u001b[0m        \u001b[35m0.1744\u001b[0m  0.0449\n",
      "     25        \u001b[36m0.3080\u001b[0m       0.9665        \u001b[35m0.1682\u001b[0m  0.0609\n",
      "     26        \u001b[36m0.2937\u001b[0m       0.9704        \u001b[35m0.1623\u001b[0m  0.0628\n",
      "     27        \u001b[36m0.2887\u001b[0m       0.9724        \u001b[35m0.1580\u001b[0m  0.0568\n",
      "     28        0.2920       0.9744        \u001b[35m0.1527\u001b[0m  0.0598\n",
      "     29        \u001b[36m0.2808\u001b[0m       0.9704        \u001b[35m0.1474\u001b[0m  0.0569\n",
      "     30        \u001b[36m0.2803\u001b[0m       0.9645        \u001b[35m0.1458\u001b[0m  0.0559\n",
      "     31        0.2816       0.9724        \u001b[35m0.1419\u001b[0m  0.0519\n",
      "     32        \u001b[36m0.2719\u001b[0m       0.9684        \u001b[35m0.1385\u001b[0m  0.0628\n",
      "     33        \u001b[36m0.2499\u001b[0m       0.9744        \u001b[35m0.1336\u001b[0m  0.0609\n",
      "     34        0.2575       0.9744        \u001b[35m0.1309\u001b[0m  0.0668\n",
      "     35        0.2669       0.9744        \u001b[35m0.1289\u001b[0m  0.0539\n",
      "     36        0.2528       0.9744        \u001b[35m0.1265\u001b[0m  0.0489\n",
      "     37        \u001b[36m0.2440\u001b[0m       \u001b[32m0.9763\u001b[0m        \u001b[35m0.1250\u001b[0m  0.0469\n",
      "     38        0.2543       0.9684        \u001b[35m0.1247\u001b[0m  0.0519\n",
      "     39        \u001b[36m0.2369\u001b[0m       0.9744        \u001b[35m0.1227\u001b[0m  0.0628\n",
      "     40        0.2481       0.9665        \u001b[35m0.1222\u001b[0m  0.0578\n",
      "     41        \u001b[36m0.2345\u001b[0m       0.9645        \u001b[35m0.1199\u001b[0m  0.0658\n",
      "     42        \u001b[36m0.2177\u001b[0m       0.9704        \u001b[35m0.1161\u001b[0m  0.0399\n",
      "     43        0.2455       0.9763        \u001b[35m0.1133\u001b[0m  0.0439\n",
      "     44        0.2389       0.9724        \u001b[35m0.1115\u001b[0m  0.0559\n",
      "     45        0.2223       0.9704        \u001b[35m0.1106\u001b[0m  0.0668\n",
      "     46        0.2204       0.9763        \u001b[35m0.1081\u001b[0m  0.0479\n",
      "     47        0.2217       0.9744        \u001b[35m0.1080\u001b[0m  0.0529\n",
      "     48        \u001b[36m0.2151\u001b[0m       0.9744        \u001b[35m0.1059\u001b[0m  0.0648\n",
      "     49        0.2157       0.9763        \u001b[35m0.1031\u001b[0m  0.0529\n",
      "     50        0.2330       0.9645        0.1046  0.0519\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.5s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4074\u001b[0m       \u001b[32m0.2722\u001b[0m        \u001b[35m1.3883\u001b[0m  0.0359\n",
      "      2        \u001b[36m1.3979\u001b[0m       \u001b[32m0.2840\u001b[0m        \u001b[35m1.3805\u001b[0m  0.0539\n",
      "      3        \u001b[36m1.3944\u001b[0m       \u001b[32m0.2998\u001b[0m        \u001b[35m1.3729\u001b[0m  0.0519\n",
      "      4        \u001b[36m1.3891\u001b[0m       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3656\u001b[0m  0.0559\n",
      "      5        \u001b[36m1.3775\u001b[0m       \u001b[32m0.3393\u001b[0m        \u001b[35m1.3585\u001b[0m  0.0499\n",
      "      6        \u001b[36m1.3697\u001b[0m       \u001b[32m0.3550\u001b[0m        \u001b[35m1.3514\u001b[0m  0.0389\n",
      "      7        \u001b[36m1.3616\u001b[0m       \u001b[32m0.3767\u001b[0m        \u001b[35m1.3444\u001b[0m  0.0439\n",
      "      8        \u001b[36m1.3537\u001b[0m       \u001b[32m0.3964\u001b[0m        \u001b[35m1.3375\u001b[0m  0.0399\n",
      "      9        \u001b[36m1.3519\u001b[0m       \u001b[32m0.4221\u001b[0m        \u001b[35m1.3305\u001b[0m  0.0379\n",
      "     10        \u001b[36m1.3470\u001b[0m       \u001b[32m0.4300\u001b[0m        \u001b[35m1.3236\u001b[0m  0.0449\n",
      "     11        \u001b[36m1.3386\u001b[0m       \u001b[32m0.4477\u001b[0m        \u001b[35m1.3165\u001b[0m  0.0459\n",
      "     12        \u001b[36m1.3300\u001b[0m       \u001b[32m0.4596\u001b[0m        \u001b[35m1.3094\u001b[0m  0.0549\n",
      "     13        \u001b[36m1.3204\u001b[0m       \u001b[32m0.4714\u001b[0m        \u001b[35m1.3021\u001b[0m  0.0489\n",
      "     14        \u001b[36m1.3200\u001b[0m       \u001b[32m0.4832\u001b[0m        \u001b[35m1.2949\u001b[0m  0.0508\n",
      "     15        \u001b[36m1.3099\u001b[0m       \u001b[32m0.4970\u001b[0m        \u001b[35m1.2874\u001b[0m  0.0498\n",
      "     16        \u001b[36m1.3011\u001b[0m       \u001b[32m0.5069\u001b[0m        \u001b[35m1.2799\u001b[0m  0.0518\n",
      "     17        \u001b[36m1.2952\u001b[0m       \u001b[32m0.5128\u001b[0m        \u001b[35m1.2722\u001b[0m  0.0569\n",
      "     18        \u001b[36m1.2925\u001b[0m       \u001b[32m0.5187\u001b[0m        \u001b[35m1.2645\u001b[0m  0.0419\n",
      "     19        \u001b[36m1.2805\u001b[0m       \u001b[32m0.5286\u001b[0m        \u001b[35m1.2567\u001b[0m  0.0529\n",
      "     20        \u001b[36m1.2763\u001b[0m       \u001b[32m0.5404\u001b[0m        \u001b[35m1.2487\u001b[0m  0.0439\n",
      "     21        \u001b[36m1.2689\u001b[0m       \u001b[32m0.5523\u001b[0m        \u001b[35m1.2406\u001b[0m  0.0578\n",
      "     22        \u001b[36m1.2609\u001b[0m       \u001b[32m0.5602\u001b[0m        \u001b[35m1.2323\u001b[0m  0.0568\n",
      "     23        \u001b[36m1.2527\u001b[0m       \u001b[32m0.5720\u001b[0m        \u001b[35m1.2239\u001b[0m  0.0628\n",
      "     24        \u001b[36m1.2421\u001b[0m       \u001b[32m0.5799\u001b[0m        \u001b[35m1.2153\u001b[0m  0.0429\n",
      "     25        \u001b[36m1.2378\u001b[0m       \u001b[32m0.5838\u001b[0m        \u001b[35m1.2068\u001b[0m  0.0549\n",
      "     26        \u001b[36m1.2274\u001b[0m       \u001b[32m0.5957\u001b[0m        \u001b[35m1.1978\u001b[0m  0.0429\n",
      "     27        \u001b[36m1.2237\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m1.1888\u001b[0m  0.0578\n",
      "     28        \u001b[36m1.2076\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m1.1797\u001b[0m  0.0419\n",
      "     29        \u001b[36m1.1949\u001b[0m       \u001b[32m0.6193\u001b[0m        \u001b[35m1.1704\u001b[0m  0.0429\n",
      "     30        1.1965       \u001b[32m0.6252\u001b[0m        \u001b[35m1.1610\u001b[0m  0.0529\n",
      "     31        \u001b[36m1.1844\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.1513\u001b[0m  0.0519\n",
      "     32        \u001b[36m1.1774\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m1.1417\u001b[0m  0.0588\n",
      "     33        \u001b[36m1.1653\u001b[0m       \u001b[32m0.6548\u001b[0m        \u001b[35m1.1319\u001b[0m  0.0578\n",
      "     34        \u001b[36m1.1589\u001b[0m       \u001b[32m0.6568\u001b[0m        \u001b[35m1.1221\u001b[0m  0.0439\n",
      "     35        \u001b[36m1.1477\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.1120\u001b[0m  0.0519\n",
      "     36        \u001b[36m1.1342\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m1.1019\u001b[0m  0.0618\n",
      "     37        \u001b[36m1.1293\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.0917\u001b[0m  0.0519\n",
      "     38        \u001b[36m1.1253\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m1.0817\u001b[0m  0.0578\n",
      "     39        \u001b[36m1.1193\u001b[0m       0.6844        \u001b[35m1.0718\u001b[0m  0.0469\n",
      "     40        \u001b[36m1.1057\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m1.0618\u001b[0m  0.0549\n",
      "     41        \u001b[36m1.0939\u001b[0m       0.6884        \u001b[35m1.0517\u001b[0m  0.0439\n",
      "     42        \u001b[36m1.0859\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m1.0417\u001b[0m  0.0608\n",
      "     43        \u001b[36m1.0808\u001b[0m       \u001b[32m0.6963\u001b[0m        \u001b[35m1.0314\u001b[0m  0.0439\n",
      "     44        \u001b[36m1.0672\u001b[0m       0.6963        \u001b[35m1.0214\u001b[0m  0.0539\n",
      "     45        \u001b[36m1.0619\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m1.0114\u001b[0m  0.0539\n",
      "     46        \u001b[36m1.0487\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m1.0015\u001b[0m  0.0598\n",
      "     47        \u001b[36m1.0436\u001b[0m       \u001b[32m0.7041\u001b[0m        \u001b[35m0.9915\u001b[0m  0.0499\n",
      "     48        \u001b[36m1.0294\u001b[0m       0.7022        \u001b[35m0.9817\u001b[0m  0.0489\n",
      "     49        \u001b[36m1.0261\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.9719\u001b[0m  0.0429\n",
      "     50        \u001b[36m1.0145\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.9623\u001b[0m  0.0558\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.2s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4394\u001b[0m       \u001b[32m0.2387\u001b[0m        \u001b[35m1.4125\u001b[0m  0.0568\n",
      "      2        \u001b[36m1.4273\u001b[0m       \u001b[32m0.2525\u001b[0m        \u001b[35m1.4025\u001b[0m  0.0628\n",
      "      3        \u001b[36m1.4136\u001b[0m       \u001b[32m0.2663\u001b[0m        \u001b[35m1.3936\u001b[0m  0.0529\n",
      "      4        \u001b[36m1.4098\u001b[0m       \u001b[32m0.2742\u001b[0m        \u001b[35m1.3852\u001b[0m  0.0608\n",
      "      5        \u001b[36m1.4023\u001b[0m       \u001b[32m0.2821\u001b[0m        \u001b[35m1.3773\u001b[0m  0.0588\n",
      "      6        \u001b[36m1.3949\u001b[0m       \u001b[32m0.2840\u001b[0m        \u001b[35m1.3701\u001b[0m  0.0499\n",
      "      7        \u001b[36m1.3878\u001b[0m       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3631\u001b[0m  0.0479\n",
      "      8        \u001b[36m1.3810\u001b[0m       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3564\u001b[0m  0.0608\n",
      "      9        \u001b[36m1.3761\u001b[0m       \u001b[32m0.3471\u001b[0m        \u001b[35m1.3499\u001b[0m  0.0499\n",
      "     10        \u001b[36m1.3655\u001b[0m       \u001b[32m0.3649\u001b[0m        \u001b[35m1.3436\u001b[0m  0.0539\n",
      "     11        \u001b[36m1.3599\u001b[0m       \u001b[32m0.3787\u001b[0m        \u001b[35m1.3375\u001b[0m  0.0419\n",
      "     12        \u001b[36m1.3536\u001b[0m       \u001b[32m0.4083\u001b[0m        \u001b[35m1.3316\u001b[0m  0.0429\n",
      "     13        \u001b[36m1.3520\u001b[0m       \u001b[32m0.4379\u001b[0m        \u001b[35m1.3257\u001b[0m  0.0519\n",
      "     14        \u001b[36m1.3365\u001b[0m       \u001b[32m0.4556\u001b[0m        \u001b[35m1.3198\u001b[0m  0.0549\n",
      "     15        1.3383       \u001b[32m0.4773\u001b[0m        \u001b[35m1.3138\u001b[0m  0.0429\n",
      "     16        \u001b[36m1.3280\u001b[0m       \u001b[32m0.4990\u001b[0m        \u001b[35m1.3077\u001b[0m  0.0439\n",
      "     17        1.3331       \u001b[32m0.5168\u001b[0m        \u001b[35m1.3018\u001b[0m  0.0399\n",
      "     18        \u001b[36m1.3229\u001b[0m       \u001b[32m0.5247\u001b[0m        \u001b[35m1.2958\u001b[0m  0.0469\n",
      "     19        \u001b[36m1.3191\u001b[0m       \u001b[32m0.5404\u001b[0m        \u001b[35m1.2898\u001b[0m  0.0568\n",
      "     20        \u001b[36m1.3112\u001b[0m       \u001b[32m0.5483\u001b[0m        \u001b[35m1.2837\u001b[0m  0.0489\n",
      "     21        \u001b[36m1.3077\u001b[0m       \u001b[32m0.5542\u001b[0m        \u001b[35m1.2773\u001b[0m  0.0479\n",
      "     22        \u001b[36m1.2984\u001b[0m       \u001b[32m0.5602\u001b[0m        \u001b[35m1.2709\u001b[0m  0.0399\n",
      "     23        \u001b[36m1.2911\u001b[0m       \u001b[32m0.5641\u001b[0m        \u001b[35m1.2642\u001b[0m  0.0539\n",
      "     24        1.2938       0.5582        \u001b[35m1.2577\u001b[0m  0.0409\n",
      "     25        \u001b[36m1.2806\u001b[0m       0.5641        \u001b[35m1.2510\u001b[0m  0.0549\n",
      "     26        1.2807       \u001b[32m0.5720\u001b[0m        \u001b[35m1.2442\u001b[0m  0.0609\n",
      "     27        \u001b[36m1.2652\u001b[0m       \u001b[32m0.5779\u001b[0m        \u001b[35m1.2371\u001b[0m  0.0409\n",
      "     28        \u001b[36m1.2599\u001b[0m       \u001b[32m0.5799\u001b[0m        \u001b[35m1.2299\u001b[0m  0.0399\n",
      "     29        \u001b[36m1.2490\u001b[0m       \u001b[32m0.5858\u001b[0m        \u001b[35m1.2226\u001b[0m  0.0499\n",
      "     30        \u001b[36m1.2487\u001b[0m       0.5858        \u001b[35m1.2151\u001b[0m  0.0519\n",
      "     31        \u001b[36m1.2420\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m1.2075\u001b[0m  0.0578\n",
      "     32        \u001b[36m1.2290\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m1.1999\u001b[0m  0.0489\n",
      "     33        \u001b[36m1.2258\u001b[0m       \u001b[32m0.6075\u001b[0m        \u001b[35m1.1922\u001b[0m  0.0419\n",
      "     34        \u001b[36m1.2177\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m1.1844\u001b[0m  0.0399\n",
      "     35        \u001b[36m1.2154\u001b[0m       \u001b[32m0.6233\u001b[0m        \u001b[35m1.1765\u001b[0m  0.0409\n",
      "     36        \u001b[36m1.2022\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m1.1684\u001b[0m  0.0579\n",
      "     37        \u001b[36m1.1997\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.1603\u001b[0m  0.0519\n",
      "     38        \u001b[36m1.1900\u001b[0m       \u001b[32m0.6509\u001b[0m        \u001b[35m1.1521\u001b[0m  0.0359\n",
      "     39        \u001b[36m1.1866\u001b[0m       \u001b[32m0.6607\u001b[0m        \u001b[35m1.1439\u001b[0m  0.0449\n",
      "     40        \u001b[36m1.1742\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m1.1356\u001b[0m  0.0419\n",
      "     41        \u001b[36m1.1667\u001b[0m       \u001b[32m0.6726\u001b[0m        \u001b[35m1.1272\u001b[0m  0.0588\n",
      "     42        \u001b[36m1.1587\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m1.1187\u001b[0m  0.0489\n",
      "     43        \u001b[36m1.1536\u001b[0m       \u001b[32m0.6785\u001b[0m        \u001b[35m1.1101\u001b[0m  0.0568\n",
      "     44        \u001b[36m1.1506\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m1.1016\u001b[0m  0.0549\n",
      "     45        \u001b[36m1.1303\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m1.0930\u001b[0m  0.0429\n",
      "     46        \u001b[36m1.1274\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m1.0841\u001b[0m  0.0459\n",
      "     47        \u001b[36m1.1221\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m1.0755\u001b[0m  0.0419\n",
      "     48        \u001b[36m1.1066\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m1.0667\u001b[0m  0.0479\n",
      "     49        \u001b[36m1.1065\u001b[0m       \u001b[32m0.7041\u001b[0m        \u001b[35m1.0581\u001b[0m  0.0419\n",
      "     50        \u001b[36m1.0985\u001b[0m       0.7041        \u001b[35m1.0494\u001b[0m  0.0539\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4002\u001b[0m       \u001b[32m0.2682\u001b[0m        \u001b[35m1.3759\u001b[0m  0.0369\n",
      "      2        \u001b[36m1.3951\u001b[0m       \u001b[32m0.2722\u001b[0m        \u001b[35m1.3692\u001b[0m  0.0429\n",
      "      3        \u001b[36m1.3937\u001b[0m       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3627\u001b[0m  0.0459\n",
      "      4        \u001b[36m1.3849\u001b[0m       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3562\u001b[0m  0.0489\n",
      "      5        \u001b[36m1.3788\u001b[0m       \u001b[32m0.3136\u001b[0m        \u001b[35m1.3501\u001b[0m  0.0449\n",
      "      6        \u001b[36m1.3764\u001b[0m       \u001b[32m0.3353\u001b[0m        \u001b[35m1.3438\u001b[0m  0.0509\n",
      "      7        \u001b[36m1.3669\u001b[0m       \u001b[32m0.3609\u001b[0m        \u001b[35m1.3376\u001b[0m  0.0519\n",
      "      8        \u001b[36m1.3552\u001b[0m       \u001b[32m0.4181\u001b[0m        \u001b[35m1.3314\u001b[0m  0.0708\n",
      "      9        1.3561       \u001b[32m0.4576\u001b[0m        \u001b[35m1.3251\u001b[0m  0.0529\n",
      "     10        \u001b[36m1.3383\u001b[0m       \u001b[32m0.4852\u001b[0m        \u001b[35m1.3189\u001b[0m  0.0559\n",
      "     11        1.3463       \u001b[32m0.5227\u001b[0m        \u001b[35m1.3126\u001b[0m  0.0529\n",
      "     12        \u001b[36m1.3331\u001b[0m       \u001b[32m0.5542\u001b[0m        \u001b[35m1.3065\u001b[0m  0.0619\n",
      "     13        \u001b[36m1.3272\u001b[0m       \u001b[32m0.5680\u001b[0m        \u001b[35m1.3001\u001b[0m  0.0429\n",
      "     14        \u001b[36m1.3191\u001b[0m       \u001b[32m0.5897\u001b[0m        \u001b[35m1.2936\u001b[0m  0.0618\n",
      "     15        1.3211       \u001b[32m0.5976\u001b[0m        \u001b[35m1.2870\u001b[0m  0.0509\n",
      "     16        \u001b[36m1.3133\u001b[0m       0.5937        \u001b[35m1.2806\u001b[0m  0.0489\n",
      "     17        \u001b[36m1.3027\u001b[0m       \u001b[32m0.6055\u001b[0m        \u001b[35m1.2738\u001b[0m  0.0489\n",
      "     18        \u001b[36m1.3009\u001b[0m       \u001b[32m0.6174\u001b[0m        \u001b[35m1.2672\u001b[0m  0.0459\n",
      "     19        \u001b[36m1.2895\u001b[0m       0.6174        \u001b[35m1.2602\u001b[0m  0.0499\n",
      "     20        \u001b[36m1.2793\u001b[0m       \u001b[32m0.6292\u001b[0m        \u001b[35m1.2532\u001b[0m  0.0549\n",
      "     21        1.2794       \u001b[32m0.6331\u001b[0m        \u001b[35m1.2461\u001b[0m  0.0499\n",
      "     22        \u001b[36m1.2661\u001b[0m       \u001b[32m0.6371\u001b[0m        \u001b[35m1.2387\u001b[0m  0.0509\n",
      "     23        1.2674       \u001b[32m0.6489\u001b[0m        \u001b[35m1.2312\u001b[0m  0.0529\n",
      "     24        \u001b[36m1.2519\u001b[0m       \u001b[32m0.6568\u001b[0m        \u001b[35m1.2235\u001b[0m  0.0688\n",
      "     25        \u001b[36m1.2429\u001b[0m       \u001b[32m0.6627\u001b[0m        \u001b[35m1.2156\u001b[0m  0.0459\n",
      "     26        \u001b[36m1.2417\u001b[0m       0.6627        \u001b[35m1.2075\u001b[0m  0.0549\n",
      "     27        \u001b[36m1.2302\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.1994\u001b[0m  0.0479\n",
      "     28        \u001b[36m1.2249\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m1.1910\u001b[0m  0.0369\n",
      "     29        \u001b[36m1.2237\u001b[0m       \u001b[32m0.6686\u001b[0m        \u001b[35m1.1827\u001b[0m  0.0529\n",
      "     30        \u001b[36m1.2056\u001b[0m       \u001b[32m0.6746\u001b[0m        \u001b[35m1.1742\u001b[0m  0.0539\n",
      "     31        \u001b[36m1.2001\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m1.1655\u001b[0m  0.0549\n",
      "     32        \u001b[36m1.1949\u001b[0m       \u001b[32m0.6785\u001b[0m        \u001b[35m1.1567\u001b[0m  0.0449\n",
      "     33        \u001b[36m1.1854\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.1478\u001b[0m  0.0539\n",
      "     34        \u001b[36m1.1807\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m1.1389\u001b[0m  0.0559\n",
      "     35        \u001b[36m1.1692\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m1.1294\u001b[0m  0.0439\n",
      "     36        \u001b[36m1.1522\u001b[0m       \u001b[32m0.7041\u001b[0m        \u001b[35m1.1199\u001b[0m  0.0608\n",
      "     37        1.1582       \u001b[32m0.7061\u001b[0m        \u001b[35m1.1105\u001b[0m  0.0608\n",
      "     38        \u001b[36m1.1443\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m1.1010\u001b[0m  0.0479\n",
      "     39        \u001b[36m1.1401\u001b[0m       0.7140        \u001b[35m1.0914\u001b[0m  0.0519\n",
      "     40        \u001b[36m1.1229\u001b[0m       \u001b[32m0.7199\u001b[0m        \u001b[35m1.0818\u001b[0m  0.0499\n",
      "     41        \u001b[36m1.1087\u001b[0m       0.7199        \u001b[35m1.0718\u001b[0m  0.0489\n",
      "     42        \u001b[36m1.1018\u001b[0m       0.7199        \u001b[35m1.0617\u001b[0m  0.0578\n",
      "     43        \u001b[36m1.0991\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m1.0519\u001b[0m  0.0509\n",
      "     44        \u001b[36m1.0920\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m1.0420\u001b[0m  0.0558\n",
      "     45        \u001b[36m1.0837\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m1.0320\u001b[0m  0.0549\n",
      "     46        \u001b[36m1.0721\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m1.0221\u001b[0m  0.0539\n",
      "     47        \u001b[36m1.0687\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m1.0123\u001b[0m  0.0529\n",
      "     48        \u001b[36m1.0529\u001b[0m       0.7357        \u001b[35m1.0021\u001b[0m  0.0399\n",
      "     49        \u001b[36m1.0348\u001b[0m       0.7357        \u001b[35m0.9921\u001b[0m  0.0409\n",
      "     50        \u001b[36m1.0331\u001b[0m       0.7357        \u001b[35m0.9820\u001b[0m  0.0718\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.3s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7009\u001b[0m       \u001b[32m0.3373\u001b[0m        \u001b[35m1.3391\u001b[0m  0.0558\n",
      "      2        \u001b[36m1.2493\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m1.1309\u001b[0m  0.0489\n",
      "      3        \u001b[36m1.1136\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m0.9339\u001b[0m  0.0419\n",
      "      4        \u001b[36m0.9531\u001b[0m       \u001b[32m0.7751\u001b[0m        \u001b[35m0.7621\u001b[0m  0.0549\n",
      "      5        \u001b[36m0.7873\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.6291\u001b[0m  0.0459\n",
      "      6        \u001b[36m0.6937\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.5200\u001b[0m  0.0539\n",
      "      7        \u001b[36m0.5910\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.4344\u001b[0m  0.0439\n",
      "      8        \u001b[36m0.5185\u001b[0m       \u001b[32m0.9112\u001b[0m        \u001b[35m0.3680\u001b[0m  0.0468\n",
      "      9        \u001b[36m0.4668\u001b[0m       0.8994        \u001b[35m0.3260\u001b[0m  0.0449\n",
      "     10        \u001b[36m0.4296\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m0.2889\u001b[0m  0.0449\n",
      "     11        \u001b[36m0.3939\u001b[0m       0.9132        \u001b[35m0.2670\u001b[0m  0.0558\n",
      "     12        \u001b[36m0.3567\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.2433\u001b[0m  0.0439\n",
      "     13        \u001b[36m0.3343\u001b[0m       0.9310        \u001b[35m0.2284\u001b[0m  0.0509\n",
      "     14        \u001b[36m0.3233\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.2109\u001b[0m  0.0439\n",
      "     15        \u001b[36m0.3199\u001b[0m       \u001b[32m0.9507\u001b[0m        \u001b[35m0.1977\u001b[0m  0.0409\n",
      "     16        \u001b[36m0.2901\u001b[0m       \u001b[32m0.9566\u001b[0m        \u001b[35m0.1875\u001b[0m  0.0399\n",
      "     17        \u001b[36m0.2699\u001b[0m       0.9507        \u001b[35m0.1818\u001b[0m  0.0519\n",
      "     18        0.2793       \u001b[32m0.9645\u001b[0m        \u001b[35m0.1679\u001b[0m  0.0658\n",
      "     19        0.2785       0.9586        \u001b[35m0.1653\u001b[0m  0.0638\n",
      "     20        \u001b[36m0.2592\u001b[0m       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1565\u001b[0m  0.0419\n",
      "     21        \u001b[36m0.2362\u001b[0m       0.9566        \u001b[35m0.1553\u001b[0m  0.0399\n",
      "     22        0.2405       0.9684        \u001b[35m0.1452\u001b[0m  0.0519\n",
      "     23        \u001b[36m0.2313\u001b[0m       0.9606        \u001b[35m0.1444\u001b[0m  0.0479\n",
      "     24        0.2342       0.9684        \u001b[35m0.1353\u001b[0m  0.0509\n",
      "     25        \u001b[36m0.2143\u001b[0m       0.9625        \u001b[35m0.1325\u001b[0m  0.0429\n",
      "     26        \u001b[36m0.2135\u001b[0m       \u001b[32m0.9724\u001b[0m        \u001b[35m0.1258\u001b[0m  0.0479\n",
      "     27        \u001b[36m0.2083\u001b[0m       0.9625        0.1259  0.0479\n",
      "     28        \u001b[36m0.2040\u001b[0m       0.9684        \u001b[35m0.1199\u001b[0m  0.0558\n",
      "     29        \u001b[36m0.1935\u001b[0m       0.9684        \u001b[35m0.1198\u001b[0m  0.0469\n",
      "     30        0.2029       0.9704        \u001b[35m0.1146\u001b[0m  0.0459\n",
      "     31        \u001b[36m0.1920\u001b[0m       0.9684        \u001b[35m0.1135\u001b[0m  0.0469\n",
      "     32        0.1936       0.9704        \u001b[35m0.1106\u001b[0m  0.0568\n",
      "     33        \u001b[36m0.1741\u001b[0m       0.9665        0.1151  0.0558\n",
      "     34        0.1939       0.9724        \u001b[35m0.1051\u001b[0m  0.0469\n",
      "     35        0.1780       0.9704        0.1057  0.0588\n",
      "     36        0.1746       \u001b[32m0.9744\u001b[0m        \u001b[35m0.1003\u001b[0m  0.0598\n",
      "     37        0.1844       0.9744        \u001b[35m0.0983\u001b[0m  0.0578\n",
      "     38        \u001b[36m0.1650\u001b[0m       0.9744        \u001b[35m0.0964\u001b[0m  0.0648\n",
      "     39        0.1796       0.9744        \u001b[35m0.0947\u001b[0m  0.0509\n",
      "     40        \u001b[36m0.1592\u001b[0m       \u001b[32m0.9763\u001b[0m        \u001b[35m0.0936\u001b[0m  0.0429\n",
      "     41        \u001b[36m0.1552\u001b[0m       0.9763        \u001b[35m0.0912\u001b[0m  0.0449\n",
      "     42        0.1662       0.9744        \u001b[35m0.0910\u001b[0m  0.0688\n",
      "     43        0.1642       0.9763        \u001b[35m0.0907\u001b[0m  0.0758\n",
      "     44        0.1553       0.9763        \u001b[35m0.0896\u001b[0m  0.0668\n",
      "     45        \u001b[36m0.1412\u001b[0m       0.9744        0.0904  0.0638\n",
      "     46        0.1533       0.9744        \u001b[35m0.0860\u001b[0m  0.0668\n",
      "     47        0.1432       0.9763        \u001b[35m0.0855\u001b[0m  0.0598\n",
      "     48        0.1630       0.9744        \u001b[35m0.0836\u001b[0m  0.0648\n",
      "     49        0.1471       0.9744        \u001b[35m0.0828\u001b[0m  0.0509\n",
      "     50        0.1552       0.9763        \u001b[35m0.0802\u001b[0m  0.0459\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8289\u001b[0m       \u001b[32m0.3412\u001b[0m        \u001b[35m1.3700\u001b[0m  0.0409\n",
      "      2        \u001b[36m1.2280\u001b[0m       \u001b[32m0.6331\u001b[0m        \u001b[35m1.1571\u001b[0m  0.0539\n",
      "      3        \u001b[36m1.1441\u001b[0m       \u001b[32m0.7850\u001b[0m        \u001b[35m0.9646\u001b[0m  0.0459\n",
      "      4        \u001b[36m0.9716\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.7711\u001b[0m  0.0638\n",
      "      5        \u001b[36m0.7889\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.6261\u001b[0m  0.0489\n",
      "      6        \u001b[36m0.6640\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.5141\u001b[0m  0.0479\n",
      "      7        \u001b[36m0.5832\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.4323\u001b[0m  0.0469\n",
      "      8        \u001b[36m0.4950\u001b[0m       0.8935        \u001b[35m0.3765\u001b[0m  0.0618\n",
      "      9        \u001b[36m0.4525\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.3344\u001b[0m  0.0449\n",
      "     10        \u001b[36m0.4000\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.3077\u001b[0m  0.0489\n",
      "     11        \u001b[36m0.3648\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m0.2811\u001b[0m  0.0509\n",
      "     12        \u001b[36m0.3512\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.2628\u001b[0m  0.0578\n",
      "     13        \u001b[36m0.3388\u001b[0m       \u001b[32m0.9270\u001b[0m        \u001b[35m0.2462\u001b[0m  0.0499\n",
      "     14        \u001b[36m0.3190\u001b[0m       \u001b[32m0.9310\u001b[0m        \u001b[35m0.2318\u001b[0m  0.0519\n",
      "     15        \u001b[36m0.2955\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.2208\u001b[0m  0.0549\n",
      "     16        \u001b[36m0.2806\u001b[0m       \u001b[32m0.9408\u001b[0m        \u001b[35m0.2091\u001b[0m  0.0489\n",
      "     17        \u001b[36m0.2727\u001b[0m       0.9389        \u001b[35m0.2009\u001b[0m  0.0429\n",
      "     18        \u001b[36m0.2687\u001b[0m       0.9349        \u001b[35m0.1996\u001b[0m  0.0459\n",
      "     19        \u001b[36m0.2627\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m0.1897\u001b[0m  0.0439\n",
      "     20        0.2665       0.9448        \u001b[35m0.1826\u001b[0m  0.0479\n",
      "     21        \u001b[36m0.2377\u001b[0m       \u001b[32m0.9507\u001b[0m        \u001b[35m0.1765\u001b[0m  0.0399\n",
      "     22        \u001b[36m0.2319\u001b[0m       0.9507        \u001b[35m0.1692\u001b[0m  0.0529\n",
      "     23        \u001b[36m0.2292\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.1629\u001b[0m  0.0469\n",
      "     24        \u001b[36m0.2270\u001b[0m       0.9487        \u001b[35m0.1624\u001b[0m  0.0539\n",
      "     25        \u001b[36m0.2197\u001b[0m       \u001b[32m0.9566\u001b[0m        \u001b[35m0.1551\u001b[0m  0.0658\n",
      "     26        \u001b[36m0.2056\u001b[0m       0.9527        0.1579  0.0708\n",
      "     27        \u001b[36m0.2051\u001b[0m       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1479\u001b[0m  0.0419\n",
      "     28        \u001b[36m0.1917\u001b[0m       0.9606        \u001b[35m0.1458\u001b[0m  0.0409\n",
      "     29        0.1973       0.9606        \u001b[35m0.1418\u001b[0m  0.0419\n",
      "     30        \u001b[36m0.1898\u001b[0m       0.9606        \u001b[35m0.1390\u001b[0m  0.0628\n",
      "     31        \u001b[36m0.1865\u001b[0m       \u001b[32m0.9625\u001b[0m        0.1395  0.0618\n",
      "     32        0.1921       0.9566        \u001b[35m0.1355\u001b[0m  0.0628\n",
      "     33        0.1931       0.9566        0.1365  0.0768\n",
      "     34        \u001b[36m0.1771\u001b[0m       0.9606        \u001b[35m0.1286\u001b[0m  0.0459\n",
      "     35        \u001b[36m0.1765\u001b[0m       \u001b[32m0.9645\u001b[0m        \u001b[35m0.1275\u001b[0m  0.0568\n",
      "     36        0.1782       0.9606        \u001b[35m0.1246\u001b[0m  0.0499\n",
      "     37        \u001b[36m0.1648\u001b[0m       0.9625        0.1248  0.0668\n",
      "     38        0.1788       0.9606        \u001b[35m0.1205\u001b[0m  0.0469\n",
      "     39        0.1678       0.9606        0.1233  0.0429\n",
      "     40        0.1728       0.9586        0.1219  0.0449\n",
      "     41        \u001b[36m0.1584\u001b[0m       0.9606        \u001b[35m0.1164\u001b[0m  0.0479\n",
      "     42        0.1592       0.9606        \u001b[35m0.1149\u001b[0m  0.0519\n",
      "     43        \u001b[36m0.1569\u001b[0m       0.9586        \u001b[35m0.1147\u001b[0m  0.0509\n",
      "     44        \u001b[36m0.1557\u001b[0m       0.9586        \u001b[35m0.1129\u001b[0m  0.0618\n",
      "     45        \u001b[36m0.1541\u001b[0m       0.9586        \u001b[35m0.1114\u001b[0m  0.0668\n",
      "     46        \u001b[36m0.1370\u001b[0m       0.9606        0.1136  0.1037\n",
      "     47        0.1495       0.9625        \u001b[35m0.1112\u001b[0m  0.0718\n",
      "     48        \u001b[36m0.1332\u001b[0m       0.9586        \u001b[35m0.1111\u001b[0m  0.0688\n",
      "     49        0.1470       0.9566        \u001b[35m0.1100\u001b[0m  0.0658\n",
      "     50        0.1468       0.9606        0.1160  0.0648\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7953\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3504\u001b[0m  0.0688\n",
      "      2        \u001b[36m1.2165\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m1.1376\u001b[0m  0.0489\n",
      "      3        \u001b[36m1.1273\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.9450\u001b[0m  0.0688\n",
      "      4        \u001b[36m0.9460\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.7654\u001b[0m  0.0698\n",
      "      5        \u001b[36m0.7791\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.6235\u001b[0m  0.0618\n",
      "      6        \u001b[36m0.6685\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.5111\u001b[0m  0.0658\n",
      "      7        \u001b[36m0.5765\u001b[0m       \u001b[32m0.9191\u001b[0m        \u001b[35m0.4254\u001b[0m  0.0578\n",
      "      8        \u001b[36m0.5001\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.3621\u001b[0m  0.0618\n",
      "      9        \u001b[36m0.4419\u001b[0m       \u001b[32m0.9290\u001b[0m        \u001b[35m0.3157\u001b[0m  0.0628\n",
      "     10        \u001b[36m0.4082\u001b[0m       \u001b[32m0.9369\u001b[0m        \u001b[35m0.2819\u001b[0m  0.0578\n",
      "     11        \u001b[36m0.3875\u001b[0m       \u001b[32m0.9428\u001b[0m        \u001b[35m0.2569\u001b[0m  0.0688\n",
      "     12        \u001b[36m0.3633\u001b[0m       \u001b[32m0.9546\u001b[0m        \u001b[35m0.2370\u001b[0m  0.0509\n",
      "     13        \u001b[36m0.3352\u001b[0m       0.9546        \u001b[35m0.2205\u001b[0m  0.0519\n",
      "     14        \u001b[36m0.3228\u001b[0m       \u001b[32m0.9645\u001b[0m        \u001b[35m0.2062\u001b[0m  0.0499\n",
      "     15        \u001b[36m0.3047\u001b[0m       0.9586        \u001b[35m0.1937\u001b[0m  0.0588\n",
      "     16        \u001b[36m0.2916\u001b[0m       \u001b[32m0.9665\u001b[0m        \u001b[35m0.1841\u001b[0m  0.0588\n",
      "     17        \u001b[36m0.2776\u001b[0m       0.9586        \u001b[35m0.1760\u001b[0m  0.0489\n",
      "     18        \u001b[36m0.2662\u001b[0m       \u001b[32m0.9704\u001b[0m        \u001b[35m0.1666\u001b[0m  0.0439\n",
      "     19        \u001b[36m0.2559\u001b[0m       0.9645        \u001b[35m0.1590\u001b[0m  0.0519\n",
      "     20        \u001b[36m0.2395\u001b[0m       0.9684        \u001b[35m0.1536\u001b[0m  0.0628\n",
      "     21        \u001b[36m0.2261\u001b[0m       0.9645        \u001b[35m0.1479\u001b[0m  0.0519\n",
      "     22        0.2378       0.9665        \u001b[35m0.1425\u001b[0m  0.0549\n",
      "     23        0.2266       0.9684        \u001b[35m0.1396\u001b[0m  0.0658\n",
      "     24        \u001b[36m0.2189\u001b[0m       0.9704        \u001b[35m0.1334\u001b[0m  0.0588\n",
      "     25        0.2196       0.9684        \u001b[35m0.1300\u001b[0m  0.0489\n",
      "     26        \u001b[36m0.2099\u001b[0m       0.9684        \u001b[35m0.1273\u001b[0m  0.0509\n",
      "     27        \u001b[36m0.2007\u001b[0m       0.9704        \u001b[35m0.1244\u001b[0m  0.0608\n",
      "     28        \u001b[36m0.1954\u001b[0m       0.9704        \u001b[35m0.1211\u001b[0m  0.0469\n",
      "     29        0.2014       \u001b[32m0.9744\u001b[0m        \u001b[35m0.1187\u001b[0m  0.0578\n",
      "     30        \u001b[36m0.1851\u001b[0m       0.9704        \u001b[35m0.1162\u001b[0m  0.0469\n",
      "     31        0.1897       0.9704        \u001b[35m0.1151\u001b[0m  0.0439\n",
      "     32        0.1900       0.9684        \u001b[35m0.1140\u001b[0m  0.0578\n",
      "     33        \u001b[36m0.1818\u001b[0m       0.9704        \u001b[35m0.1111\u001b[0m  0.0449\n",
      "     34        \u001b[36m0.1774\u001b[0m       0.9724        \u001b[35m0.1100\u001b[0m  0.0459\n",
      "     35        \u001b[36m0.1767\u001b[0m       0.9724        \u001b[35m0.1087\u001b[0m  0.0618\n",
      "     36        \u001b[36m0.1733\u001b[0m       0.9684        \u001b[35m0.1050\u001b[0m  0.0489\n",
      "     37        \u001b[36m0.1690\u001b[0m       0.9665        \u001b[35m0.1047\u001b[0m  0.0618\n",
      "     38        \u001b[36m0.1678\u001b[0m       0.9665        \u001b[35m0.1025\u001b[0m  0.0588\n",
      "     39        0.1685       0.9744        \u001b[35m0.1011\u001b[0m  0.0509\n",
      "     40        \u001b[36m0.1604\u001b[0m       0.9744        0.1013  0.0608\n",
      "     41        0.1695       0.9645        \u001b[35m0.1009\u001b[0m  0.0549\n",
      "     42        \u001b[36m0.1595\u001b[0m       0.9744        \u001b[35m0.1001\u001b[0m  0.0529\n",
      "     43        0.1600       0.9704        \u001b[35m0.0973\u001b[0m  0.0588\n",
      "     44        \u001b[36m0.1514\u001b[0m       \u001b[32m0.9763\u001b[0m        0.0979  0.0578\n",
      "     45        \u001b[36m0.1489\u001b[0m       0.9724        \u001b[35m0.0943\u001b[0m  0.0489\n",
      "     46        0.1533       0.9763        0.0946  0.0469\n",
      "     47        0.1637       0.9724        \u001b[35m0.0927\u001b[0m  0.0608\n",
      "     48        \u001b[36m0.1379\u001b[0m       0.9744        0.0935  0.0648\n",
      "     49        0.1405       0.9763        0.0928  0.0618\n",
      "     50        0.1454       0.9724        \u001b[35m0.0925\u001b[0m  0.0509\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.4s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4045\u001b[0m       \u001b[32m0.2978\u001b[0m        \u001b[35m1.3863\u001b[0m  0.0549\n",
      "      2        \u001b[36m1.3989\u001b[0m       \u001b[32m0.3176\u001b[0m        \u001b[35m1.3765\u001b[0m  0.0489\n",
      "      3        \u001b[36m1.3925\u001b[0m       \u001b[32m0.3294\u001b[0m        \u001b[35m1.3668\u001b[0m  0.0379\n",
      "      4        \u001b[36m1.3746\u001b[0m       \u001b[32m0.3511\u001b[0m        \u001b[35m1.3574\u001b[0m  0.0598\n",
      "      5        \u001b[36m1.3680\u001b[0m       \u001b[32m0.3787\u001b[0m        \u001b[35m1.3480\u001b[0m  0.0379\n",
      "      6        \u001b[36m1.3566\u001b[0m       \u001b[32m0.3905\u001b[0m        \u001b[35m1.3389\u001b[0m  0.0449\n",
      "      7        \u001b[36m1.3549\u001b[0m       \u001b[32m0.4181\u001b[0m        \u001b[35m1.3301\u001b[0m  0.0379\n",
      "      8        \u001b[36m1.3419\u001b[0m       \u001b[32m0.4438\u001b[0m        \u001b[35m1.3212\u001b[0m  0.0379\n",
      "      9        \u001b[36m1.3373\u001b[0m       \u001b[32m0.4596\u001b[0m        \u001b[35m1.3124\u001b[0m  0.0409\n",
      "     10        \u001b[36m1.3216\u001b[0m       \u001b[32m0.4813\u001b[0m        \u001b[35m1.3035\u001b[0m  0.0549\n",
      "     11        \u001b[36m1.3173\u001b[0m       \u001b[32m0.4970\u001b[0m        \u001b[35m1.2946\u001b[0m  0.0439\n",
      "     12        \u001b[36m1.3057\u001b[0m       \u001b[32m0.5108\u001b[0m        \u001b[35m1.2858\u001b[0m  0.0578\n",
      "     13        \u001b[36m1.2987\u001b[0m       \u001b[32m0.5187\u001b[0m        \u001b[35m1.2769\u001b[0m  0.0499\n",
      "     14        \u001b[36m1.2918\u001b[0m       \u001b[32m0.5385\u001b[0m        \u001b[35m1.2682\u001b[0m  0.0489\n",
      "     15        \u001b[36m1.2774\u001b[0m       \u001b[32m0.5483\u001b[0m        \u001b[35m1.2591\u001b[0m  0.0448\n",
      "     16        \u001b[36m1.2765\u001b[0m       \u001b[32m0.5641\u001b[0m        \u001b[35m1.2501\u001b[0m  0.0559\n",
      "     17        \u001b[36m1.2637\u001b[0m       \u001b[32m0.5700\u001b[0m        \u001b[35m1.2409\u001b[0m  0.0359\n",
      "     18        \u001b[36m1.2579\u001b[0m       \u001b[32m0.5799\u001b[0m        \u001b[35m1.2317\u001b[0m  0.0449\n",
      "     19        \u001b[36m1.2489\u001b[0m       \u001b[32m0.5917\u001b[0m        \u001b[35m1.2223\u001b[0m  0.0519\n",
      "     20        \u001b[36m1.2373\u001b[0m       \u001b[32m0.6055\u001b[0m        \u001b[35m1.2126\u001b[0m  0.0578\n",
      "     21        \u001b[36m1.2258\u001b[0m       \u001b[32m0.6193\u001b[0m        \u001b[35m1.2030\u001b[0m  0.0608\n",
      "     22        \u001b[36m1.2174\u001b[0m       \u001b[32m0.6272\u001b[0m        \u001b[35m1.1933\u001b[0m  0.0429\n",
      "     23        \u001b[36m1.2133\u001b[0m       \u001b[32m0.6292\u001b[0m        \u001b[35m1.1834\u001b[0m  0.0509\n",
      "     24        \u001b[36m1.1978\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.1733\u001b[0m  0.0598\n",
      "     25        \u001b[36m1.1838\u001b[0m       \u001b[32m0.6509\u001b[0m        \u001b[35m1.1628\u001b[0m  0.0578\n",
      "     26        1.1858       \u001b[32m0.6529\u001b[0m        \u001b[35m1.1527\u001b[0m  0.0439\n",
      "     27        \u001b[36m1.1691\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m1.1422\u001b[0m  0.0459\n",
      "     28        \u001b[36m1.1609\u001b[0m       \u001b[32m0.6607\u001b[0m        \u001b[35m1.1317\u001b[0m  0.0479\n",
      "     29        \u001b[36m1.1558\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m1.1212\u001b[0m  0.0379\n",
      "     30        \u001b[36m1.1470\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.1106\u001b[0m  0.0419\n",
      "     31        \u001b[36m1.1338\u001b[0m       \u001b[32m0.6726\u001b[0m        \u001b[35m1.1000\u001b[0m  0.0519\n",
      "     32        \u001b[36m1.1223\u001b[0m       \u001b[32m0.6785\u001b[0m        \u001b[35m1.0891\u001b[0m  0.0409\n",
      "     33        \u001b[36m1.1128\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m1.0783\u001b[0m  0.0379\n",
      "     34        \u001b[36m1.0936\u001b[0m       \u001b[32m0.6963\u001b[0m        \u001b[35m1.0671\u001b[0m  0.0489\n",
      "     35        \u001b[36m1.0921\u001b[0m       0.6943        \u001b[35m1.0563\u001b[0m  0.0559\n",
      "     36        \u001b[36m1.0839\u001b[0m       0.6963        \u001b[35m1.0452\u001b[0m  0.0458\n",
      "     37        \u001b[36m1.0737\u001b[0m       0.6963        \u001b[35m1.0342\u001b[0m  0.0578\n",
      "     38        \u001b[36m1.0521\u001b[0m       0.6903        \u001b[35m1.0233\u001b[0m  0.0668\n",
      "     39        1.0575       \u001b[32m0.6982\u001b[0m        \u001b[35m1.0123\u001b[0m  0.0578\n",
      "     40        \u001b[36m1.0407\u001b[0m       \u001b[32m0.7041\u001b[0m        \u001b[35m1.0014\u001b[0m  0.0519\n",
      "     41        \u001b[36m1.0381\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.9907\u001b[0m  0.0499\n",
      "     42        \u001b[36m1.0205\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m0.9800\u001b[0m  0.0538\n",
      "     43        \u001b[36m1.0102\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m0.9692\u001b[0m  0.0389\n",
      "     44        \u001b[36m0.9905\u001b[0m       0.7219        \u001b[35m0.9584\u001b[0m  0.0459\n",
      "     45        0.9972       \u001b[32m0.7239\u001b[0m        \u001b[35m0.9477\u001b[0m  0.0489\n",
      "     46        \u001b[36m0.9842\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m0.9373\u001b[0m  0.0389\n",
      "     47        \u001b[36m0.9769\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m0.9270\u001b[0m  0.0489\n",
      "     48        \u001b[36m0.9628\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m0.9165\u001b[0m  0.0409\n",
      "     49        \u001b[36m0.9575\u001b[0m       0.7377        \u001b[35m0.9064\u001b[0m  0.0419\n",
      "     50        \u001b[36m0.9503\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.8966\u001b[0m  0.0479\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4320\u001b[0m       \u001b[32m0.2367\u001b[0m        \u001b[35m1.3978\u001b[0m  0.0568\n",
      "      2        \u001b[36m1.4142\u001b[0m       \u001b[32m0.2564\u001b[0m        \u001b[35m1.3864\u001b[0m  0.0449\n",
      "      3        \u001b[36m1.4068\u001b[0m       \u001b[32m0.2682\u001b[0m        \u001b[35m1.3755\u001b[0m  0.0469\n",
      "      4        \u001b[36m1.3987\u001b[0m       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3654\u001b[0m  0.0469\n",
      "      5        \u001b[36m1.3841\u001b[0m       \u001b[32m0.3333\u001b[0m        \u001b[35m1.3555\u001b[0m  0.0449\n",
      "      6        \u001b[36m1.3777\u001b[0m       \u001b[32m0.3688\u001b[0m        \u001b[35m1.3460\u001b[0m  0.0419\n",
      "      7        \u001b[36m1.3685\u001b[0m       \u001b[32m0.3984\u001b[0m        \u001b[35m1.3367\u001b[0m  0.0419\n",
      "      8        \u001b[36m1.3542\u001b[0m       \u001b[32m0.4221\u001b[0m        \u001b[35m1.3278\u001b[0m  0.0429\n",
      "      9        \u001b[36m1.3479\u001b[0m       \u001b[32m0.4536\u001b[0m        \u001b[35m1.3188\u001b[0m  0.0359\n",
      "     10        \u001b[36m1.3383\u001b[0m       \u001b[32m0.4714\u001b[0m        \u001b[35m1.3096\u001b[0m  0.0359\n",
      "     11        \u001b[36m1.3244\u001b[0m       \u001b[32m0.5049\u001b[0m        \u001b[35m1.3007\u001b[0m  0.0429\n",
      "     12        \u001b[36m1.3225\u001b[0m       \u001b[32m0.5345\u001b[0m        \u001b[35m1.2915\u001b[0m  0.0648\n",
      "     13        \u001b[36m1.3067\u001b[0m       \u001b[32m0.5483\u001b[0m        \u001b[35m1.2825\u001b[0m  0.0469\n",
      "     14        \u001b[36m1.3001\u001b[0m       \u001b[32m0.5641\u001b[0m        \u001b[35m1.2735\u001b[0m  0.0519\n",
      "     15        \u001b[36m1.2887\u001b[0m       \u001b[32m0.5799\u001b[0m        \u001b[35m1.2642\u001b[0m  0.0459\n",
      "     16        \u001b[36m1.2852\u001b[0m       \u001b[32m0.5917\u001b[0m        \u001b[35m1.2550\u001b[0m  0.0489\n",
      "     17        \u001b[36m1.2720\u001b[0m       \u001b[32m0.6036\u001b[0m        \u001b[35m1.2456\u001b[0m  0.0519\n",
      "     18        \u001b[36m1.2583\u001b[0m       \u001b[32m0.6154\u001b[0m        \u001b[35m1.2362\u001b[0m  0.0509\n",
      "     19        1.2634       \u001b[32m0.6193\u001b[0m        \u001b[35m1.2266\u001b[0m  0.0419\n",
      "     20        \u001b[36m1.2419\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.2168\u001b[0m  0.0489\n",
      "     21        \u001b[36m1.2370\u001b[0m       \u001b[32m0.6410\u001b[0m        \u001b[35m1.2070\u001b[0m  0.0489\n",
      "     22        \u001b[36m1.2243\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.1971\u001b[0m  0.0509\n",
      "     23        \u001b[36m1.2175\u001b[0m       \u001b[32m0.6489\u001b[0m        \u001b[35m1.1871\u001b[0m  0.0559\n",
      "     24        \u001b[36m1.2067\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.1768\u001b[0m  0.0549\n",
      "     25        \u001b[36m1.1997\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m1.1666\u001b[0m  0.0519\n",
      "     26        \u001b[36m1.1888\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.1562\u001b[0m  0.0618\n",
      "     27        \u001b[36m1.1698\u001b[0m       \u001b[32m0.6686\u001b[0m        \u001b[35m1.1457\u001b[0m  0.0379\n",
      "     28        \u001b[36m1.1651\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.1349\u001b[0m  0.0529\n",
      "     29        \u001b[36m1.1574\u001b[0m       \u001b[32m0.6726\u001b[0m        \u001b[35m1.1243\u001b[0m  0.0629\n",
      "     30        \u001b[36m1.1432\u001b[0m       \u001b[32m0.6746\u001b[0m        \u001b[35m1.1136\u001b[0m  0.0459\n",
      "     31        \u001b[36m1.1406\u001b[0m       \u001b[32m0.6805\u001b[0m        \u001b[35m1.1028\u001b[0m  0.0419\n",
      "     32        \u001b[36m1.1311\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m1.0921\u001b[0m  0.0509\n",
      "     33        \u001b[36m1.1172\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m1.0813\u001b[0m  0.0558\n",
      "     34        \u001b[36m1.1085\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m1.0704\u001b[0m  0.0439\n",
      "     35        \u001b[36m1.0931\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m1.0596\u001b[0m  0.0489\n",
      "     36        \u001b[36m1.0888\u001b[0m       0.6963        \u001b[35m1.0489\u001b[0m  0.0588\n",
      "     37        \u001b[36m1.0841\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m1.0382\u001b[0m  0.0549\n",
      "     38        \u001b[36m1.0735\u001b[0m       \u001b[32m0.7041\u001b[0m        \u001b[35m1.0276\u001b[0m  0.0369\n",
      "     39        \u001b[36m1.0572\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.0168\u001b[0m  0.0459\n",
      "     40        \u001b[36m1.0440\u001b[0m       0.7061        \u001b[35m1.0062\u001b[0m  0.0618\n",
      "     41        \u001b[36m1.0341\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m0.9957\u001b[0m  0.0479\n",
      "     42        \u001b[36m1.0246\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.9851\u001b[0m  0.0499\n",
      "     43        \u001b[36m1.0224\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m0.9746\u001b[0m  0.0379\n",
      "     44        \u001b[36m1.0071\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m0.9642\u001b[0m  0.0379\n",
      "     45        \u001b[36m0.9958\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.9540\u001b[0m  0.0369\n",
      "     46        0.9987       \u001b[32m0.7278\u001b[0m        \u001b[35m0.9439\u001b[0m  0.0399\n",
      "     47        \u001b[36m0.9772\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m0.9338\u001b[0m  0.0489\n",
      "     48        \u001b[36m0.9679\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m0.9237\u001b[0m  0.0369\n",
      "     49        \u001b[36m0.9519\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.9139\u001b[0m  0.0449\n",
      "     50        \u001b[36m0.9495\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m0.9041\u001b[0m  0.0399\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4227\u001b[0m       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3984\u001b[0m  0.0499\n",
      "      2        \u001b[36m1.4056\u001b[0m       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3900\u001b[0m  0.0578\n",
      "      3        \u001b[36m1.3992\u001b[0m       \u001b[32m0.3097\u001b[0m        \u001b[35m1.3816\u001b[0m  0.0519\n",
      "      4        \u001b[36m1.3850\u001b[0m       \u001b[32m0.3235\u001b[0m        \u001b[35m1.3735\u001b[0m  0.0439\n",
      "      5        \u001b[36m1.3831\u001b[0m       \u001b[32m0.3314\u001b[0m        \u001b[35m1.3655\u001b[0m  0.0369\n",
      "      6        \u001b[36m1.3774\u001b[0m       \u001b[32m0.3353\u001b[0m        \u001b[35m1.3578\u001b[0m  0.0359\n",
      "      7        \u001b[36m1.3670\u001b[0m       \u001b[32m0.3471\u001b[0m        \u001b[35m1.3503\u001b[0m  0.0389\n",
      "      8        \u001b[36m1.3621\u001b[0m       \u001b[32m0.3531\u001b[0m        \u001b[35m1.3427\u001b[0m  0.0379\n",
      "      9        \u001b[36m1.3511\u001b[0m       \u001b[32m0.3669\u001b[0m        \u001b[35m1.3352\u001b[0m  0.0439\n",
      "     10        1.3520       \u001b[32m0.3767\u001b[0m        \u001b[35m1.3279\u001b[0m  0.0389\n",
      "     11        \u001b[36m1.3354\u001b[0m       \u001b[32m0.3964\u001b[0m        \u001b[35m1.3205\u001b[0m  0.0598\n",
      "     12        \u001b[36m1.3347\u001b[0m       \u001b[32m0.4122\u001b[0m        \u001b[35m1.3133\u001b[0m  0.0429\n",
      "     13        \u001b[36m1.3207\u001b[0m       \u001b[32m0.4221\u001b[0m        \u001b[35m1.3058\u001b[0m  0.0379\n",
      "     14        \u001b[36m1.3168\u001b[0m       \u001b[32m0.4438\u001b[0m        \u001b[35m1.2983\u001b[0m  0.0558\n",
      "     15        \u001b[36m1.3073\u001b[0m       \u001b[32m0.4477\u001b[0m        \u001b[35m1.2908\u001b[0m  0.0449\n",
      "     16        \u001b[36m1.3002\u001b[0m       \u001b[32m0.4615\u001b[0m        \u001b[35m1.2831\u001b[0m  0.0489\n",
      "     17        \u001b[36m1.2913\u001b[0m       \u001b[32m0.4753\u001b[0m        \u001b[35m1.2755\u001b[0m  0.0419\n",
      "     18        \u001b[36m1.2856\u001b[0m       \u001b[32m0.4892\u001b[0m        \u001b[35m1.2677\u001b[0m  0.0459\n",
      "     19        \u001b[36m1.2810\u001b[0m       \u001b[32m0.5010\u001b[0m        \u001b[35m1.2597\u001b[0m  0.0479\n",
      "     20        \u001b[36m1.2722\u001b[0m       \u001b[32m0.5069\u001b[0m        \u001b[35m1.2517\u001b[0m  0.0549\n",
      "     21        \u001b[36m1.2612\u001b[0m       \u001b[32m0.5207\u001b[0m        \u001b[35m1.2435\u001b[0m  0.0529\n",
      "     22        \u001b[36m1.2563\u001b[0m       \u001b[32m0.5345\u001b[0m        \u001b[35m1.2352\u001b[0m  0.0558\n",
      "     23        \u001b[36m1.2414\u001b[0m       \u001b[32m0.5444\u001b[0m        \u001b[35m1.2267\u001b[0m  0.0459\n",
      "     24        1.2420       \u001b[32m0.5562\u001b[0m        \u001b[35m1.2182\u001b[0m  0.0439\n",
      "     25        \u001b[36m1.2250\u001b[0m       \u001b[32m0.5779\u001b[0m        \u001b[35m1.2095\u001b[0m  0.0748\n",
      "     26        1.2301       \u001b[32m0.5917\u001b[0m        \u001b[35m1.2007\u001b[0m  0.0429\n",
      "     27        \u001b[36m1.2151\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m1.1918\u001b[0m  0.0389\n",
      "     28        \u001b[36m1.2083\u001b[0m       \u001b[32m0.6193\u001b[0m        \u001b[35m1.1828\u001b[0m  0.0539\n",
      "     29        \u001b[36m1.1911\u001b[0m       \u001b[32m0.6312\u001b[0m        \u001b[35m1.1736\u001b[0m  0.0479\n",
      "     30        \u001b[36m1.1910\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.1644\u001b[0m  0.0489\n",
      "     31        \u001b[36m1.1808\u001b[0m       \u001b[32m0.6469\u001b[0m        \u001b[35m1.1551\u001b[0m  0.0578\n",
      "     32        \u001b[36m1.1686\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.1456\u001b[0m  0.0409\n",
      "     33        \u001b[36m1.1617\u001b[0m       \u001b[32m0.6686\u001b[0m        \u001b[35m1.1359\u001b[0m  0.0568\n",
      "     34        \u001b[36m1.1579\u001b[0m       \u001b[32m0.6746\u001b[0m        \u001b[35m1.1262\u001b[0m  0.0559\n",
      "     35        \u001b[36m1.1507\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.1166\u001b[0m  0.0389\n",
      "     36        \u001b[36m1.1395\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m1.1068\u001b[0m  0.0489\n",
      "     37        \u001b[36m1.1343\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m1.0970\u001b[0m  0.0568\n",
      "     38        \u001b[36m1.1159\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m1.0870\u001b[0m  0.0519\n",
      "     39        \u001b[36m1.1107\u001b[0m       \u001b[32m0.7081\u001b[0m        \u001b[35m1.0770\u001b[0m  0.0379\n",
      "     40        \u001b[36m1.1002\u001b[0m       0.7081        \u001b[35m1.0669\u001b[0m  0.0409\n",
      "     41        \u001b[36m1.0875\u001b[0m       0.7081        \u001b[35m1.0568\u001b[0m  0.0409\n",
      "     42        \u001b[36m1.0797\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m1.0466\u001b[0m  0.0429\n",
      "     43        \u001b[36m1.0643\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m1.0364\u001b[0m  0.0379\n",
      "     44        1.0687       0.7101        \u001b[35m1.0263\u001b[0m  0.0369\n",
      "     45        \u001b[36m1.0534\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m1.0162\u001b[0m  0.0499\n",
      "     46        \u001b[36m1.0460\u001b[0m       0.7160        \u001b[35m1.0061\u001b[0m  0.0488\n",
      "     47        \u001b[36m1.0322\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m0.9959\u001b[0m  0.0489\n",
      "     48        \u001b[36m1.0259\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m0.9859\u001b[0m  0.0558\n",
      "     49        \u001b[36m1.0103\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m0.9758\u001b[0m  0.0409\n",
      "     50        \u001b[36m0.9971\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m0.9656\u001b[0m  0.0399\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   2.9s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8544\u001b[0m       \u001b[32m0.2604\u001b[0m        \u001b[35m1.3144\u001b[0m  0.0459\n",
      "      2        \u001b[36m1.2806\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.0805\u001b[0m  0.0588\n",
      "      3        \u001b[36m1.0864\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.8265\u001b[0m  0.0568\n",
      "      4        \u001b[36m0.8347\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.6201\u001b[0m  0.0479\n",
      "      5        \u001b[36m0.6661\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.4720\u001b[0m  0.0438\n",
      "      6        \u001b[36m0.5426\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.3744\u001b[0m  0.0539\n",
      "      7        \u001b[36m0.4615\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.3132\u001b[0m  0.0618\n",
      "      8        \u001b[36m0.4087\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.2764\u001b[0m  0.0568\n",
      "      9        \u001b[36m0.3669\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.2463\u001b[0m  0.0519\n",
      "     10        \u001b[36m0.3318\u001b[0m       0.9191        \u001b[35m0.2295\u001b[0m  0.0469\n",
      "     11        \u001b[36m0.3145\u001b[0m       \u001b[32m0.9310\u001b[0m        \u001b[35m0.2104\u001b[0m  0.0519\n",
      "     12        \u001b[36m0.2883\u001b[0m       \u001b[32m0.9369\u001b[0m        \u001b[35m0.1979\u001b[0m  0.0568\n",
      "     13        \u001b[36m0.2861\u001b[0m       \u001b[32m0.9408\u001b[0m        \u001b[35m0.1864\u001b[0m  0.0529\n",
      "     14        \u001b[36m0.2701\u001b[0m       \u001b[32m0.9527\u001b[0m        \u001b[35m0.1743\u001b[0m  0.0588\n",
      "     15        \u001b[36m0.2645\u001b[0m       0.9428        \u001b[35m0.1700\u001b[0m  0.0678\n",
      "     16        \u001b[36m0.2599\u001b[0m       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1570\u001b[0m  0.0569\n",
      "     17        \u001b[36m0.2319\u001b[0m       0.9546        \u001b[35m0.1545\u001b[0m  0.0529\n",
      "     18        \u001b[36m0.2264\u001b[0m       \u001b[32m0.9645\u001b[0m        \u001b[35m0.1459\u001b[0m  0.0519\n",
      "     19        \u001b[36m0.2239\u001b[0m       0.9566        0.1464  0.0499\n",
      "     20        \u001b[36m0.2138\u001b[0m       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1342\u001b[0m  0.0509\n",
      "     21        \u001b[36m0.1962\u001b[0m       0.9625        \u001b[35m0.1310\u001b[0m  0.0708\n",
      "     22        0.1980       \u001b[32m0.9704\u001b[0m        \u001b[35m0.1243\u001b[0m  0.0628\n",
      "     23        \u001b[36m0.1796\u001b[0m       0.9684        \u001b[35m0.1220\u001b[0m  0.0549\n",
      "     24        0.1898       0.9665        \u001b[35m0.1199\u001b[0m  0.0549\n",
      "     25        0.1807       0.9704        \u001b[35m0.1093\u001b[0m  0.0608\n",
      "     26        \u001b[36m0.1717\u001b[0m       0.9684        0.1127  0.0479\n",
      "     27        0.1753       0.9704        \u001b[35m0.1053\u001b[0m  0.0568\n",
      "     28        \u001b[36m0.1574\u001b[0m       0.9684        0.1058  0.0618\n",
      "     29        0.1721       0.9684        \u001b[35m0.0996\u001b[0m  0.0618\n",
      "     30        0.1635       0.9684        0.1044  0.0678\n",
      "     31        \u001b[36m0.1557\u001b[0m       \u001b[32m0.9724\u001b[0m        \u001b[35m0.0965\u001b[0m  0.0499\n",
      "     32        \u001b[36m0.1462\u001b[0m       0.9704        \u001b[35m0.0963\u001b[0m  0.0598\n",
      "     33        0.1477       0.9724        \u001b[35m0.0916\u001b[0m  0.0708\n",
      "     34        0.1509       0.9704        0.0944  0.0559\n",
      "     35        \u001b[36m0.1443\u001b[0m       \u001b[32m0.9744\u001b[0m        \u001b[35m0.0884\u001b[0m  0.0509\n",
      "     36        \u001b[36m0.1316\u001b[0m       0.9684        0.1030  0.0588\n",
      "     37        0.1538       0.9724        \u001b[35m0.0883\u001b[0m  0.0459\n",
      "     38        0.1338       0.9704        0.1016  0.0449\n",
      "     39        0.1530       0.9684        \u001b[35m0.0868\u001b[0m  0.0429\n",
      "     40        0.1339       0.9625        0.1080  0.0529\n",
      "     41        0.1760       0.9645        0.0924  0.0549\n",
      "     42        0.1322       0.9586        0.1224  0.0678\n",
      "     43        0.1727       0.9546        0.1047  0.0588\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.0s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8571\u001b[0m       \u001b[32m0.3866\u001b[0m        \u001b[35m1.2688\u001b[0m  0.0688\n",
      "      2        \u001b[36m1.1874\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m1.0153\u001b[0m  0.0459\n",
      "      3        \u001b[36m1.0370\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.7873\u001b[0m  0.0529\n",
      "      4        \u001b[36m0.8005\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.6089\u001b[0m  0.0568\n",
      "      5        \u001b[36m0.6362\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.4806\u001b[0m  0.0568\n",
      "      6        \u001b[36m0.5330\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.3944\u001b[0m  0.0648\n",
      "      7        \u001b[36m0.4551\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.3403\u001b[0m  0.0469\n",
      "      8        \u001b[36m0.3984\u001b[0m       0.8935        \u001b[35m0.3078\u001b[0m  0.0559\n",
      "      9        \u001b[36m0.3693\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.2791\u001b[0m  0.0708\n",
      "     10        \u001b[36m0.3329\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m0.2589\u001b[0m  0.0529\n",
      "     11        \u001b[36m0.3115\u001b[0m       \u001b[32m0.9112\u001b[0m        \u001b[35m0.2466\u001b[0m  0.0479\n",
      "     12        \u001b[36m0.3021\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.2227\u001b[0m  0.0648\n",
      "     13        \u001b[36m0.2788\u001b[0m       0.9191        \u001b[35m0.2219\u001b[0m  0.0479\n",
      "     14        \u001b[36m0.2703\u001b[0m       \u001b[32m0.9408\u001b[0m        \u001b[35m0.2009\u001b[0m  0.0588\n",
      "     15        \u001b[36m0.2455\u001b[0m       0.9310        0.2015  0.0568\n",
      "     16        \u001b[36m0.2267\u001b[0m       0.9408        \u001b[35m0.1862\u001b[0m  0.0738\n",
      "     17        \u001b[36m0.2173\u001b[0m       0.9349        \u001b[35m0.1848\u001b[0m  0.0628\n",
      "     18        0.2342       \u001b[32m0.9527\u001b[0m        \u001b[35m0.1723\u001b[0m  0.0708\n",
      "     19        \u001b[36m0.2112\u001b[0m       0.9467        \u001b[35m0.1694\u001b[0m  0.0499\n",
      "     20        \u001b[36m0.1992\u001b[0m       \u001b[32m0.9586\u001b[0m        \u001b[35m0.1606\u001b[0m  0.0459\n",
      "     21        \u001b[36m0.1916\u001b[0m       0.9448        0.1634  0.0508\n",
      "     22        \u001b[36m0.1913\u001b[0m       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1533\u001b[0m  0.0578\n",
      "     23        \u001b[36m0.1862\u001b[0m       0.9527        0.1568  0.0439\n",
      "     24        \u001b[36m0.1843\u001b[0m       0.9586        \u001b[35m0.1465\u001b[0m  0.0529\n",
      "     25        \u001b[36m0.1841\u001b[0m       0.9546        0.1489  0.0439\n",
      "     26        \u001b[36m0.1691\u001b[0m       0.9566        \u001b[35m0.1401\u001b[0m  0.0559\n",
      "     27        \u001b[36m0.1610\u001b[0m       0.9527        0.1466  0.0499\n",
      "     28        0.1725       0.9566        \u001b[35m0.1330\u001b[0m  0.0539\n",
      "     29        \u001b[36m0.1546\u001b[0m       0.9527        0.1493  0.0718\n",
      "     30        0.1669       0.9566        \u001b[35m0.1328\u001b[0m  0.0608\n",
      "     31        \u001b[36m0.1478\u001b[0m       0.9467        0.1597  0.0499\n",
      "     32        0.1801       0.9527        0.1379  0.0489\n",
      "     33        \u001b[36m0.1419\u001b[0m       0.9349        0.1826  0.0489\n",
      "     34        0.1888       0.9448        0.1463  0.0449\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.4s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.9104\u001b[0m       \u001b[32m0.2702\u001b[0m        \u001b[35m1.3084\u001b[0m  0.0489\n",
      "      2        \u001b[36m1.2424\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m1.0422\u001b[0m  0.0499\n",
      "      3        \u001b[36m1.0492\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.8069\u001b[0m  0.0479\n",
      "      4        \u001b[36m0.8102\u001b[0m       \u001b[32m0.8264\u001b[0m        \u001b[35m0.6341\u001b[0m  0.0429\n",
      "      5        \u001b[36m0.6677\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.4999\u001b[0m  0.0449\n",
      "      6        \u001b[36m0.5485\u001b[0m       \u001b[32m0.9112\u001b[0m        \u001b[35m0.3995\u001b[0m  0.0448\n",
      "      7        \u001b[36m0.4709\u001b[0m       \u001b[32m0.9290\u001b[0m        \u001b[35m0.3315\u001b[0m  0.0429\n",
      "      8        \u001b[36m0.4043\u001b[0m       0.9290        \u001b[35m0.2881\u001b[0m  0.0439\n",
      "      9        \u001b[36m0.3845\u001b[0m       \u001b[32m0.9369\u001b[0m        \u001b[35m0.2552\u001b[0m  0.0459\n",
      "     10        \u001b[36m0.3334\u001b[0m       0.9349        \u001b[35m0.2333\u001b[0m  0.0539\n",
      "     11        \u001b[36m0.3140\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m0.2135\u001b[0m  0.0469\n",
      "     12        \u001b[36m0.2886\u001b[0m       0.9467        \u001b[35m0.2006\u001b[0m  0.0469\n",
      "     13        \u001b[36m0.2840\u001b[0m       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1856\u001b[0m  0.0469\n",
      "     14        \u001b[36m0.2550\u001b[0m       0.9546        \u001b[35m0.1780\u001b[0m  0.0529\n",
      "     15        \u001b[36m0.2538\u001b[0m       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1668\u001b[0m  0.0628\n",
      "     16        \u001b[36m0.2270\u001b[0m       0.9527        \u001b[35m0.1666\u001b[0m  0.0578\n",
      "     17        0.2308       0.9606        \u001b[35m0.1551\u001b[0m  0.0419\n",
      "     18        \u001b[36m0.2034\u001b[0m       0.9566        \u001b[35m0.1538\u001b[0m  0.0469\n",
      "     19        0.2168       0.9684        \u001b[35m0.1428\u001b[0m  0.0618\n",
      "     20        \u001b[36m0.2023\u001b[0m       0.9645        \u001b[35m0.1405\u001b[0m  0.0469\n",
      "     21        \u001b[36m0.1905\u001b[0m       0.9684        \u001b[35m0.1350\u001b[0m  0.0618\n",
      "     22        \u001b[36m0.1861\u001b[0m       0.9606        0.1386  0.0529\n",
      "     23        0.1891       0.9625        \u001b[35m0.1289\u001b[0m  0.0509\n",
      "     24        \u001b[36m0.1623\u001b[0m       0.9566        0.1455  0.0449\n",
      "     25        0.2054       0.9586        0.1302  0.0419\n",
      "     26        0.1643       0.9566        0.1499  0.0449\n",
      "     27        0.1876       0.9448        0.1433  0.0559\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.7s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4002\u001b[0m       \u001b[32m0.3097\u001b[0m        \u001b[35m1.3657\u001b[0m  0.0389\n",
      "      2        \u001b[36m1.3844\u001b[0m       \u001b[32m0.3728\u001b[0m        \u001b[35m1.3522\u001b[0m  0.0539\n",
      "      3        \u001b[36m1.3764\u001b[0m       \u001b[32m0.4142\u001b[0m        \u001b[35m1.3393\u001b[0m  0.0539\n",
      "      4        \u001b[36m1.3592\u001b[0m       \u001b[32m0.4438\u001b[0m        \u001b[35m1.3266\u001b[0m  0.0519\n",
      "      5        \u001b[36m1.3448\u001b[0m       \u001b[32m0.4773\u001b[0m        \u001b[35m1.3146\u001b[0m  0.0549\n",
      "      6        \u001b[36m1.3356\u001b[0m       \u001b[32m0.5049\u001b[0m        \u001b[35m1.3031\u001b[0m  0.0469\n",
      "      7        \u001b[36m1.3203\u001b[0m       \u001b[32m0.5089\u001b[0m        \u001b[35m1.2915\u001b[0m  0.0499\n",
      "      8        \u001b[36m1.3102\u001b[0m       \u001b[32m0.5286\u001b[0m        \u001b[35m1.2800\u001b[0m  0.0439\n",
      "      9        \u001b[36m1.3002\u001b[0m       0.5286        \u001b[35m1.2686\u001b[0m  0.0459\n",
      "     10        \u001b[36m1.2895\u001b[0m       \u001b[32m0.5542\u001b[0m        \u001b[35m1.2573\u001b[0m  0.0449\n",
      "     11        \u001b[36m1.2790\u001b[0m       \u001b[32m0.5680\u001b[0m        \u001b[35m1.2455\u001b[0m  0.0539\n",
      "     12        \u001b[36m1.2680\u001b[0m       \u001b[32m0.5819\u001b[0m        \u001b[35m1.2340\u001b[0m  0.0468\n",
      "     13        \u001b[36m1.2525\u001b[0m       \u001b[32m0.5838\u001b[0m        \u001b[35m1.2223\u001b[0m  0.0509\n",
      "     14        \u001b[36m1.2372\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m1.2106\u001b[0m  0.0399\n",
      "     15        \u001b[36m1.2353\u001b[0m       \u001b[32m0.6055\u001b[0m        \u001b[35m1.1988\u001b[0m  0.0539\n",
      "     16        \u001b[36m1.2245\u001b[0m       \u001b[32m0.6095\u001b[0m        \u001b[35m1.1870\u001b[0m  0.0399\n",
      "     17        \u001b[36m1.2041\u001b[0m       \u001b[32m0.6154\u001b[0m        \u001b[35m1.1749\u001b[0m  0.0519\n",
      "     18        \u001b[36m1.2028\u001b[0m       \u001b[32m0.6272\u001b[0m        \u001b[35m1.1630\u001b[0m  0.0449\n",
      "     19        \u001b[36m1.1872\u001b[0m       \u001b[32m0.6331\u001b[0m        \u001b[35m1.1509\u001b[0m  0.0489\n",
      "     20        \u001b[36m1.1720\u001b[0m       \u001b[32m0.6410\u001b[0m        \u001b[35m1.1385\u001b[0m  0.0459\n",
      "     21        \u001b[36m1.1633\u001b[0m       0.6410        \u001b[35m1.1262\u001b[0m  0.0419\n",
      "     22        \u001b[36m1.1490\u001b[0m       \u001b[32m0.6489\u001b[0m        \u001b[35m1.1135\u001b[0m  0.0469\n",
      "     23        1.1515       \u001b[32m0.6548\u001b[0m        \u001b[35m1.1010\u001b[0m  0.0409\n",
      "     24        \u001b[36m1.1328\u001b[0m       \u001b[32m0.6607\u001b[0m        \u001b[35m1.0886\u001b[0m  0.0479\n",
      "     25        \u001b[36m1.1144\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.0760\u001b[0m  0.0439\n",
      "     26        \u001b[36m1.1033\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.0634\u001b[0m  0.0379\n",
      "     27        \u001b[36m1.0919\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m1.0508\u001b[0m  0.0628\n",
      "     28        \u001b[36m1.0805\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m1.0384\u001b[0m  0.0459\n",
      "     29        \u001b[36m1.0695\u001b[0m       \u001b[32m0.7041\u001b[0m        \u001b[35m1.0258\u001b[0m  0.0459\n",
      "     30        \u001b[36m1.0549\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m1.0133\u001b[0m  0.0568\n",
      "     31        \u001b[36m1.0456\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m1.0008\u001b[0m  0.0559\n",
      "     32        \u001b[36m1.0401\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m0.9885\u001b[0m  0.0419\n",
      "     33        \u001b[36m1.0306\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m0.9762\u001b[0m  0.0449\n",
      "     34        \u001b[36m1.0094\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m0.9639\u001b[0m  0.0369\n",
      "     35        \u001b[36m1.0029\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m0.9517\u001b[0m  0.0559\n",
      "     36        \u001b[36m0.9931\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m0.9397\u001b[0m  0.0419\n",
      "     37        \u001b[36m0.9810\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m0.9280\u001b[0m  0.0459\n",
      "     38        \u001b[36m0.9614\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m0.9160\u001b[0m  0.0559\n",
      "     39        \u001b[36m0.9509\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.9044\u001b[0m  0.0389\n",
      "     40        \u001b[36m0.9421\u001b[0m       \u001b[32m0.7416\u001b[0m        \u001b[35m0.8929\u001b[0m  0.0449\n",
      "     41        \u001b[36m0.9344\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m0.8815\u001b[0m  0.0549\n",
      "     42        \u001b[36m0.9211\u001b[0m       \u001b[32m0.7535\u001b[0m        \u001b[35m0.8703\u001b[0m  0.0479\n",
      "     43        \u001b[36m0.9105\u001b[0m       \u001b[32m0.7594\u001b[0m        \u001b[35m0.8592\u001b[0m  0.0419\n",
      "     44        \u001b[36m0.9013\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m0.8485\u001b[0m  0.0389\n",
      "     45        \u001b[36m0.8926\u001b[0m       0.7633        \u001b[35m0.8381\u001b[0m  0.0618\n",
      "     46        \u001b[36m0.8808\u001b[0m       0.7633        \u001b[35m0.8276\u001b[0m  0.0539\n",
      "     47        \u001b[36m0.8691\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.8173\u001b[0m  0.0539\n",
      "     48        \u001b[36m0.8617\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.8073\u001b[0m  0.0479\n",
      "     49        \u001b[36m0.8583\u001b[0m       \u001b[32m0.7850\u001b[0m        \u001b[35m0.7973\u001b[0m  0.0499\n",
      "     50        \u001b[36m0.8489\u001b[0m       0.7850        \u001b[35m0.7877\u001b[0m  0.0529\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3681\u001b[0m       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3391\u001b[0m  0.0499\n",
      "      2        \u001b[36m1.3554\u001b[0m       \u001b[32m0.3669\u001b[0m        \u001b[35m1.3269\u001b[0m  0.0499\n",
      "      3        \u001b[36m1.3405\u001b[0m       \u001b[32m0.4359\u001b[0m        \u001b[35m1.3154\u001b[0m  0.0529\n",
      "      4        \u001b[36m1.3296\u001b[0m       \u001b[32m0.4753\u001b[0m        \u001b[35m1.3044\u001b[0m  0.0519\n",
      "      5        \u001b[36m1.3117\u001b[0m       \u001b[32m0.4970\u001b[0m        \u001b[35m1.2936\u001b[0m  0.0558\n",
      "      6        \u001b[36m1.3058\u001b[0m       \u001b[32m0.5483\u001b[0m        \u001b[35m1.2829\u001b[0m  0.0489\n",
      "      7        \u001b[36m1.2921\u001b[0m       \u001b[32m0.5562\u001b[0m        \u001b[35m1.2720\u001b[0m  0.0409\n",
      "      8        \u001b[36m1.2854\u001b[0m       \u001b[32m0.5621\u001b[0m        \u001b[35m1.2614\u001b[0m  0.0409\n",
      "      9        \u001b[36m1.2730\u001b[0m       \u001b[32m0.5759\u001b[0m        \u001b[35m1.2508\u001b[0m  0.0449\n",
      "     10        \u001b[36m1.2667\u001b[0m       0.5740        \u001b[35m1.2402\u001b[0m  0.0409\n",
      "     11        \u001b[36m1.2519\u001b[0m       0.5680        \u001b[35m1.2295\u001b[0m  0.0369\n",
      "     12        \u001b[36m1.2495\u001b[0m       0.5720        \u001b[35m1.2188\u001b[0m  0.0688\n",
      "     13        \u001b[36m1.2333\u001b[0m       \u001b[32m0.5838\u001b[0m        \u001b[35m1.2082\u001b[0m  0.0439\n",
      "     14        \u001b[36m1.2268\u001b[0m       \u001b[32m0.5917\u001b[0m        \u001b[35m1.1975\u001b[0m  0.0399\n",
      "     15        \u001b[36m1.2172\u001b[0m       \u001b[32m0.6055\u001b[0m        \u001b[35m1.1867\u001b[0m  0.0598\n",
      "     16        \u001b[36m1.2034\u001b[0m       \u001b[32m0.6075\u001b[0m        \u001b[35m1.1758\u001b[0m  0.0469\n",
      "     17        \u001b[36m1.1899\u001b[0m       \u001b[32m0.6095\u001b[0m        \u001b[35m1.1649\u001b[0m  0.0359\n",
      "     18        \u001b[36m1.1836\u001b[0m       \u001b[32m0.6154\u001b[0m        \u001b[35m1.1538\u001b[0m  0.0409\n",
      "     19        \u001b[36m1.1651\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.1428\u001b[0m  0.0409\n",
      "     20        \u001b[36m1.1585\u001b[0m       \u001b[32m0.6312\u001b[0m        \u001b[35m1.1316\u001b[0m  0.0668\n",
      "     21        \u001b[36m1.1555\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m1.1205\u001b[0m  0.0389\n",
      "     22        \u001b[36m1.1490\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m1.1094\u001b[0m  0.0499\n",
      "     23        \u001b[36m1.1351\u001b[0m       \u001b[32m0.6469\u001b[0m        \u001b[35m1.0980\u001b[0m  0.0409\n",
      "     24        \u001b[36m1.1259\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.0868\u001b[0m  0.0379\n",
      "     25        \u001b[36m1.1115\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.0757\u001b[0m  0.0539\n",
      "     26        \u001b[36m1.0992\u001b[0m       0.6647        \u001b[35m1.0644\u001b[0m  0.0409\n",
      "     27        \u001b[36m1.0872\u001b[0m       \u001b[32m0.6726\u001b[0m        \u001b[35m1.0530\u001b[0m  0.0588\n",
      "     28        \u001b[36m1.0773\u001b[0m       \u001b[32m0.6785\u001b[0m        \u001b[35m1.0416\u001b[0m  0.0539\n",
      "     29        \u001b[36m1.0671\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m1.0302\u001b[0m  0.0539\n",
      "     30        \u001b[36m1.0620\u001b[0m       0.6884        \u001b[35m1.0191\u001b[0m  0.0519\n",
      "     31        \u001b[36m1.0495\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m1.0077\u001b[0m  0.0419\n",
      "     32        \u001b[36m1.0386\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m0.9965\u001b[0m  0.0429\n",
      "     33        \u001b[36m1.0267\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m0.9854\u001b[0m  0.0549\n",
      "     34        \u001b[36m1.0122\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m0.9742\u001b[0m  0.0558\n",
      "     35        \u001b[36m1.0055\u001b[0m       \u001b[32m0.7081\u001b[0m        \u001b[35m0.9631\u001b[0m  0.0459\n",
      "     36        \u001b[36m0.9866\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m0.9522\u001b[0m  0.0529\n",
      "     37        \u001b[36m0.9833\u001b[0m       0.7101        \u001b[35m0.9412\u001b[0m  0.0389\n",
      "     38        \u001b[36m0.9749\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.9305\u001b[0m  0.0469\n",
      "     39        \u001b[36m0.9673\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m0.9197\u001b[0m  0.0489\n",
      "     40        \u001b[36m0.9529\u001b[0m       \u001b[32m0.7199\u001b[0m        \u001b[35m0.9092\u001b[0m  0.0399\n",
      "     41        \u001b[36m0.9456\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m0.8988\u001b[0m  0.0499\n",
      "     42        \u001b[36m0.9368\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.8886\u001b[0m  0.0598\n",
      "     43        \u001b[36m0.9292\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m0.8785\u001b[0m  0.0598\n",
      "     44        \u001b[36m0.9100\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m0.8685\u001b[0m  0.0578\n",
      "     45        \u001b[36m0.9069\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m0.8587\u001b[0m  0.0389\n",
      "     46        \u001b[36m0.8996\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m0.8488\u001b[0m  0.0638\n",
      "     47        \u001b[36m0.8971\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.8391\u001b[0m  0.0559\n",
      "     48        \u001b[36m0.8858\u001b[0m       0.7377        \u001b[35m0.8299\u001b[0m  0.0668\n",
      "     49        \u001b[36m0.8713\u001b[0m       0.7396        \u001b[35m0.8206\u001b[0m  0.0499\n",
      "     50        \u001b[36m0.8634\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m0.8113\u001b[0m  0.0568\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.1s\n",
      "[CV] lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4652\u001b[0m       \u001b[32m0.2485\u001b[0m        \u001b[35m1.4160\u001b[0m  0.0379\n",
      "      2        \u001b[36m1.4298\u001b[0m       \u001b[32m0.2702\u001b[0m        \u001b[35m1.3914\u001b[0m  0.0479\n",
      "      3        \u001b[36m1.4022\u001b[0m       \u001b[32m0.3156\u001b[0m        \u001b[35m1.3699\u001b[0m  0.0509\n",
      "      4        \u001b[36m1.3860\u001b[0m       \u001b[32m0.3649\u001b[0m        \u001b[35m1.3496\u001b[0m  0.0439\n",
      "      5        \u001b[36m1.3667\u001b[0m       \u001b[32m0.4063\u001b[0m        \u001b[35m1.3313\u001b[0m  0.0618\n",
      "      6        \u001b[36m1.3479\u001b[0m       \u001b[32m0.4497\u001b[0m        \u001b[35m1.3142\u001b[0m  0.0678\n",
      "      7        \u001b[36m1.3306\u001b[0m       \u001b[32m0.4714\u001b[0m        \u001b[35m1.2979\u001b[0m  0.0519\n",
      "      8        \u001b[36m1.3190\u001b[0m       \u001b[32m0.5030\u001b[0m        \u001b[35m1.2824\u001b[0m  0.0519\n",
      "      9        \u001b[36m1.2990\u001b[0m       \u001b[32m0.5266\u001b[0m        \u001b[35m1.2674\u001b[0m  0.0409\n",
      "     10        \u001b[36m1.2848\u001b[0m       \u001b[32m0.5641\u001b[0m        \u001b[35m1.2528\u001b[0m  0.0389\n",
      "     11        \u001b[36m1.2725\u001b[0m       \u001b[32m0.5858\u001b[0m        \u001b[35m1.2385\u001b[0m  0.0628\n",
      "     12        \u001b[36m1.2590\u001b[0m       0.5858        \u001b[35m1.2243\u001b[0m  0.1267\n",
      "     13        \u001b[36m1.2405\u001b[0m       \u001b[32m0.5878\u001b[0m        \u001b[35m1.2105\u001b[0m  0.0549\n",
      "     14        \u001b[36m1.2284\u001b[0m       \u001b[32m0.5957\u001b[0m        \u001b[35m1.1967\u001b[0m  0.0688\n",
      "     15        \u001b[36m1.2179\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m1.1828\u001b[0m  0.0559\n",
      "     16        \u001b[36m1.1999\u001b[0m       \u001b[32m0.6154\u001b[0m        \u001b[35m1.1692\u001b[0m  0.0549\n",
      "     17        \u001b[36m1.1894\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.1557\u001b[0m  0.0628\n",
      "     18        \u001b[36m1.1776\u001b[0m       \u001b[32m0.6312\u001b[0m        \u001b[35m1.1421\u001b[0m  0.0519\n",
      "     19        \u001b[36m1.1640\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m1.1287\u001b[0m  0.0459\n",
      "     20        \u001b[36m1.1457\u001b[0m       \u001b[32m0.6410\u001b[0m        \u001b[35m1.1153\u001b[0m  0.0529\n",
      "     21        \u001b[36m1.1410\u001b[0m       \u001b[32m0.6509\u001b[0m        \u001b[35m1.1020\u001b[0m  0.0568\n",
      "     22        \u001b[36m1.1264\u001b[0m       \u001b[32m0.6568\u001b[0m        \u001b[35m1.0888\u001b[0m  0.0728\n",
      "     23        \u001b[36m1.1110\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.0756\u001b[0m  0.0549\n",
      "     24        \u001b[36m1.0932\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.0626\u001b[0m  0.0529\n",
      "     25        \u001b[36m1.0861\u001b[0m       0.6824        \u001b[35m1.0498\u001b[0m  0.0449\n",
      "     26        \u001b[36m1.0769\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m1.0371\u001b[0m  0.0598\n",
      "     27        \u001b[36m1.0602\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m1.0242\u001b[0m  0.0539\n",
      "     28        \u001b[36m1.0511\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m1.0118\u001b[0m  0.0549\n",
      "     29        \u001b[36m1.0326\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m0.9993\u001b[0m  0.0459\n",
      "     30        \u001b[36m1.0284\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.9871\u001b[0m  0.0638\n",
      "     31        \u001b[36m1.0162\u001b[0m       0.7120        \u001b[35m0.9751\u001b[0m  0.0399\n",
      "     32        \u001b[36m1.0031\u001b[0m       0.7120        \u001b[35m0.9633\u001b[0m  0.0409\n",
      "     33        \u001b[36m0.9922\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.9514\u001b[0m  0.0489\n",
      "     34        \u001b[36m0.9741\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m0.9396\u001b[0m  0.0618\n",
      "     35        \u001b[36m0.9684\u001b[0m       0.7278        \u001b[35m0.9282\u001b[0m  0.0419\n",
      "     36        \u001b[36m0.9606\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m0.9169\u001b[0m  0.0389\n",
      "     37        \u001b[36m0.9532\u001b[0m       \u001b[32m0.7357\u001b[0m        \u001b[35m0.9059\u001b[0m  0.0459\n",
      "     38        \u001b[36m0.9390\u001b[0m       0.7357        \u001b[35m0.8948\u001b[0m  0.0519\n",
      "     39        \u001b[36m0.9265\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.8840\u001b[0m  0.0489\n",
      "     40        \u001b[36m0.9206\u001b[0m       \u001b[32m0.7416\u001b[0m        \u001b[35m0.8734\u001b[0m  0.0648\n",
      "     41        \u001b[36m0.9043\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m0.8628\u001b[0m  0.0638\n",
      "     42        \u001b[36m0.8952\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m0.8525\u001b[0m  0.0509\n",
      "     43        \u001b[36m0.8867\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m0.8423\u001b[0m  0.0399\n",
      "     44        \u001b[36m0.8711\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m0.8321\u001b[0m  0.0419\n",
      "     45        \u001b[36m0.8633\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.8221\u001b[0m  0.0489\n",
      "     46        \u001b[36m0.8529\u001b[0m       0.7771        \u001b[35m0.8127\u001b[0m  0.0409\n",
      "     47        \u001b[36m0.8455\u001b[0m       0.7771        \u001b[35m0.8031\u001b[0m  0.0399\n",
      "     48        \u001b[36m0.8318\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.7938\u001b[0m  0.0439\n",
      "     49        \u001b[36m0.8200\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m0.7847\u001b[0m  0.0549\n",
      "     50        \u001b[36m0.8192\u001b[0m       \u001b[32m0.7850\u001b[0m        \u001b[35m0.7758\u001b[0m  0.0578\n",
      "[CV]  lr=0.01, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.3s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.6420\u001b[0m       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3610\u001b[0m  0.0529\n",
      "      2        \u001b[36m1.3374\u001b[0m       \u001b[32m0.4694\u001b[0m        \u001b[35m1.2595\u001b[0m  0.0539\n",
      "      3        \u001b[36m1.2619\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m1.1547\u001b[0m  0.0419\n",
      "      4        \u001b[36m1.1902\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m1.0216\u001b[0m  0.0598\n",
      "      5        \u001b[36m1.1009\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m0.8882\u001b[0m  0.0409\n",
      "      6        \u001b[36m1.0521\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.7778\u001b[0m  0.0639\n",
      "      7        \u001b[36m0.9617\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.6837\u001b[0m  0.0588\n",
      "      8        \u001b[36m0.9159\u001b[0m       \u001b[32m0.8797\u001b[0m        \u001b[35m0.6067\u001b[0m  0.0539\n",
      "      9        \u001b[36m0.8845\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.5492\u001b[0m  0.0509\n",
      "     10        \u001b[36m0.8268\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.4981\u001b[0m  0.0479\n",
      "     11        \u001b[36m0.8012\u001b[0m       0.8935        \u001b[35m0.4601\u001b[0m  0.0489\n",
      "     12        \u001b[36m0.7899\u001b[0m       \u001b[32m0.9034\u001b[0m        \u001b[35m0.4317\u001b[0m  0.0519\n",
      "     13        \u001b[36m0.7585\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.4008\u001b[0m  0.0449\n",
      "     14        \u001b[36m0.7573\u001b[0m       0.9132        \u001b[35m0.3870\u001b[0m  0.0618\n",
      "     15        \u001b[36m0.7450\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m0.3645\u001b[0m  0.0578\n",
      "     16        \u001b[36m0.7273\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.3457\u001b[0m  0.0638\n",
      "     17        \u001b[36m0.7156\u001b[0m       \u001b[32m0.9270\u001b[0m        \u001b[35m0.3321\u001b[0m  0.0549\n",
      "     18        0.7177       \u001b[32m0.9290\u001b[0m        \u001b[35m0.3176\u001b[0m  0.0539\n",
      "     19        \u001b[36m0.7135\u001b[0m       \u001b[32m0.9507\u001b[0m        \u001b[35m0.3126\u001b[0m  0.0529\n",
      "     20        \u001b[36m0.6824\u001b[0m       0.9408        \u001b[35m0.2935\u001b[0m  0.0618\n",
      "     21        0.6881       0.9428        0.2938  0.0409\n",
      "     22        0.6888       \u001b[32m0.9527\u001b[0m        \u001b[35m0.2794\u001b[0m  0.0459\n",
      "     23        0.6863       0.9487        0.2794  0.0539\n",
      "     24        \u001b[36m0.6739\u001b[0m       0.9487        \u001b[35m0.2670\u001b[0m  0.0449\n",
      "     25        \u001b[36m0.6581\u001b[0m       0.9487        \u001b[35m0.2605\u001b[0m  0.0509\n",
      "     26        0.6940       \u001b[32m0.9625\u001b[0m        \u001b[35m0.2562\u001b[0m  0.0489\n",
      "     27        \u001b[36m0.6470\u001b[0m       0.9527        \u001b[35m0.2516\u001b[0m  0.0648\n",
      "     28        0.6813       0.9606        \u001b[35m0.2485\u001b[0m  0.0529\n",
      "     29        \u001b[36m0.6349\u001b[0m       0.9527        \u001b[35m0.2427\u001b[0m  0.0469\n",
      "     30        0.6583       0.9606        \u001b[35m0.2345\u001b[0m  0.0559\n",
      "     31        0.6481       0.9546        \u001b[35m0.2330\u001b[0m  0.0539\n",
      "     32        0.6432       0.9546        \u001b[35m0.2227\u001b[0m  0.0509\n",
      "     33        0.6567       0.9606        0.2228  0.0459\n",
      "     34        0.6392       0.9625        \u001b[35m0.2140\u001b[0m  0.0509\n",
      "     35        0.6461       0.9625        0.2157  0.0469\n",
      "     36        \u001b[36m0.6291\u001b[0m       \u001b[32m0.9645\u001b[0m        \u001b[35m0.2105\u001b[0m  0.0429\n",
      "     37        0.6421       0.9606        \u001b[35m0.2066\u001b[0m  0.0499\n",
      "     38        0.6405       0.9586        0.2113  0.0459\n",
      "     39        \u001b[36m0.6279\u001b[0m       0.9606        0.2070  0.0469\n",
      "     40        \u001b[36m0.6172\u001b[0m       0.9606        \u001b[35m0.1993\u001b[0m  0.0628\n",
      "     41        0.6250       0.9645        0.2023  0.0578\n",
      "     42        0.6220       0.9625        \u001b[35m0.1936\u001b[0m  0.0429\n",
      "     43        0.6523       0.9606        0.2059  0.0648\n",
      "     44        \u001b[36m0.6146\u001b[0m       0.9566        0.1941  0.0499\n",
      "     45        0.6195       0.9645        0.1938  0.0489\n",
      "     46        \u001b[36m0.6015\u001b[0m       0.9625        \u001b[35m0.1896\u001b[0m  0.0449\n",
      "     47        0.6092       0.9645        \u001b[35m0.1895\u001b[0m  0.0658\n",
      "     48        0.6384       0.9645        \u001b[35m0.1889\u001b[0m  0.0549\n",
      "     49        0.6300       0.9586        0.1932  0.0419\n",
      "     50        0.6296       0.9645        \u001b[35m0.1812\u001b[0m  0.0479\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.2s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.5937\u001b[0m       \u001b[32m0.3807\u001b[0m        \u001b[35m1.3762\u001b[0m  0.0509\n",
      "      2        \u001b[36m1.3582\u001b[0m       \u001b[32m0.4260\u001b[0m        \u001b[35m1.2899\u001b[0m  0.0529\n",
      "      3        \u001b[36m1.2860\u001b[0m       \u001b[32m0.6469\u001b[0m        \u001b[35m1.1759\u001b[0m  0.0598\n",
      "      4        \u001b[36m1.1951\u001b[0m       \u001b[32m0.6686\u001b[0m        \u001b[35m1.0396\u001b[0m  0.0539\n",
      "      5        \u001b[36m1.1103\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.9079\u001b[0m  0.0578\n",
      "      6        \u001b[36m1.0342\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.7967\u001b[0m  0.0578\n",
      "      7        \u001b[36m0.9729\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.7065\u001b[0m  0.0638\n",
      "      8        \u001b[36m0.9202\u001b[0m       \u001b[32m0.9112\u001b[0m        \u001b[35m0.6351\u001b[0m  0.0469\n",
      "      9        \u001b[36m0.8350\u001b[0m       0.9053        \u001b[35m0.5711\u001b[0m  0.0519\n",
      "     10        0.8361       \u001b[32m0.9132\u001b[0m        \u001b[35m0.5278\u001b[0m  0.0499\n",
      "     11        \u001b[36m0.7838\u001b[0m       0.9034        \u001b[35m0.4874\u001b[0m  0.0439\n",
      "     12        \u001b[36m0.7616\u001b[0m       0.9073        \u001b[35m0.4546\u001b[0m  0.0549\n",
      "     13        \u001b[36m0.7385\u001b[0m       0.9053        \u001b[35m0.4267\u001b[0m  0.0568\n",
      "     14        \u001b[36m0.7293\u001b[0m       0.9073        \u001b[35m0.4040\u001b[0m  0.0529\n",
      "     15        0.7481       0.9034        \u001b[35m0.3932\u001b[0m  0.0509\n",
      "     16        \u001b[36m0.7172\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m0.3715\u001b[0m  0.0618\n",
      "     17        \u001b[36m0.7077\u001b[0m       0.9172        \u001b[35m0.3581\u001b[0m  0.0578\n",
      "     18        \u001b[36m0.7020\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.3454\u001b[0m  0.0529\n",
      "     19        \u001b[36m0.7017\u001b[0m       0.9152        \u001b[35m0.3347\u001b[0m  0.0588\n",
      "     20        0.7084       \u001b[32m0.9290\u001b[0m        \u001b[35m0.3245\u001b[0m  0.0539\n",
      "     21        \u001b[36m0.6814\u001b[0m       0.9231        \u001b[35m0.3201\u001b[0m  0.0519\n",
      "     22        0.6867       \u001b[32m0.9349\u001b[0m        \u001b[35m0.3079\u001b[0m  0.0678\n",
      "     23        0.6919       0.9329        \u001b[35m0.3057\u001b[0m  0.0419\n",
      "     24        0.7041       \u001b[32m0.9369\u001b[0m        \u001b[35m0.2984\u001b[0m  0.0529\n",
      "     25        \u001b[36m0.6568\u001b[0m       0.9349        \u001b[35m0.2843\u001b[0m  0.0698\n",
      "     26        0.6588       0.9310        \u001b[35m0.2800\u001b[0m  0.0479\n",
      "     27        \u001b[36m0.6505\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.2691\u001b[0m  0.0578\n",
      "     28        0.6603       \u001b[32m0.9408\u001b[0m        \u001b[35m0.2642\u001b[0m  0.0489\n",
      "     29        \u001b[36m0.6335\u001b[0m       \u001b[32m0.9428\u001b[0m        \u001b[35m0.2551\u001b[0m  0.0549\n",
      "     30        0.6413       \u001b[32m0.9448\u001b[0m        \u001b[35m0.2503\u001b[0m  0.0688\n",
      "     31        0.6456       0.9448        \u001b[35m0.2475\u001b[0m  0.0588\n",
      "     32        0.6414       \u001b[32m0.9467\u001b[0m        \u001b[35m0.2369\u001b[0m  0.0579\n",
      "     33        \u001b[36m0.6310\u001b[0m       \u001b[32m0.9527\u001b[0m        0.2400  0.0499\n",
      "     34        0.6438       0.9467        \u001b[35m0.2310\u001b[0m  0.0459\n",
      "     35        0.6318       \u001b[32m0.9625\u001b[0m        \u001b[35m0.2279\u001b[0m  0.0568\n",
      "     36        0.6390       0.9566        \u001b[35m0.2229\u001b[0m  0.0449\n",
      "     37        0.6353       \u001b[32m0.9645\u001b[0m        0.2269  0.0429\n",
      "     38        0.6445       0.9546        0.2249  0.0409\n",
      "     39        \u001b[36m0.6248\u001b[0m       0.9546        0.2259  0.0539\n",
      "     40        \u001b[36m0.6196\u001b[0m       0.9546        \u001b[35m0.2187\u001b[0m  0.0409\n",
      "     41        0.6207       0.9606        \u001b[35m0.2144\u001b[0m  0.0628\n",
      "     42        0.6204       0.9546        \u001b[35m0.2105\u001b[0m  0.0698\n",
      "     43        0.6314       0.9566        0.2126  0.0479\n",
      "     44        \u001b[36m0.6097\u001b[0m       0.9586        \u001b[35m0.2054\u001b[0m  0.0419\n",
      "     45        0.6265       0.9507        0.2085  0.0499\n",
      "     46        \u001b[36m0.5933\u001b[0m       0.9566        \u001b[35m0.1977\u001b[0m  0.0479\n",
      "     47        0.6115       0.9586        0.2020  0.0659\n",
      "     48        0.6320       0.9527        \u001b[35m0.1962\u001b[0m  0.0469\n",
      "     49        0.6151       0.9546        0.1973  0.0429\n",
      "     50        0.6220       0.9566        \u001b[35m0.1921\u001b[0m  0.0419\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.6534\u001b[0m       \u001b[32m0.2702\u001b[0m        \u001b[35m1.3961\u001b[0m  0.0489\n",
      "      2        \u001b[36m1.3327\u001b[0m       \u001b[32m0.5168\u001b[0m        \u001b[35m1.2765\u001b[0m  0.0598\n",
      "      3        \u001b[36m1.2783\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m1.1636\u001b[0m  0.0499\n",
      "      4        \u001b[36m1.1859\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m1.0285\u001b[0m  0.0419\n",
      "      5        \u001b[36m1.0893\u001b[0m       0.7692        \u001b[35m0.9026\u001b[0m  0.0519\n",
      "      6        \u001b[36m1.0107\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m0.8043\u001b[0m  0.0528\n",
      "      7        \u001b[36m0.9499\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.7237\u001b[0m  0.0459\n",
      "      8        \u001b[36m0.8828\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.6595\u001b[0m  0.0499\n",
      "      9        \u001b[36m0.8624\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.6029\u001b[0m  0.0439\n",
      "     10        \u001b[36m0.8449\u001b[0m       0.8560        \u001b[35m0.5621\u001b[0m  0.0539\n",
      "     11        \u001b[36m0.8226\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.5253\u001b[0m  0.0419\n",
      "     12        \u001b[36m0.8062\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.4938\u001b[0m  0.0489\n",
      "     13        \u001b[36m0.7814\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.4730\u001b[0m  0.0499\n",
      "     14        \u001b[36m0.7600\u001b[0m       \u001b[32m0.9270\u001b[0m        \u001b[35m0.4362\u001b[0m  0.0529\n",
      "     15        0.7748       0.9132        \u001b[35m0.4316\u001b[0m  0.0539\n",
      "     16        \u001b[36m0.7400\u001b[0m       \u001b[32m0.9369\u001b[0m        \u001b[35m0.3943\u001b[0m  0.0419\n",
      "     17        0.7485       \u001b[32m0.9408\u001b[0m        \u001b[35m0.3901\u001b[0m  0.0419\n",
      "     18        \u001b[36m0.7223\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m0.3711\u001b[0m  0.0409\n",
      "     19        0.7223       0.9389        \u001b[35m0.3672\u001b[0m  0.0539\n",
      "     20        \u001b[36m0.7149\u001b[0m       \u001b[32m0.9566\u001b[0m        \u001b[35m0.3402\u001b[0m  0.0568\n",
      "     21        0.7284       \u001b[32m0.9704\u001b[0m        \u001b[35m0.3318\u001b[0m  0.0489\n",
      "     22        \u001b[36m0.6827\u001b[0m       0.9546        \u001b[35m0.3130\u001b[0m  0.0549\n",
      "     23        0.6891       0.9586        \u001b[35m0.3120\u001b[0m  0.0399\n",
      "     24        0.6940       0.9487        \u001b[35m0.2908\u001b[0m  0.0439\n",
      "     25        \u001b[36m0.6815\u001b[0m       0.9606        0.2913  0.0519\n",
      "     26        \u001b[36m0.6503\u001b[0m       0.9684        \u001b[35m0.2748\u001b[0m  0.0688\n",
      "     27        0.6828       0.9586        \u001b[35m0.2721\u001b[0m  0.0519\n",
      "     28        0.6535       0.9665        \u001b[35m0.2617\u001b[0m  0.0489\n",
      "     29        0.6528       \u001b[32m0.9724\u001b[0m        \u001b[35m0.2585\u001b[0m  0.0659\n",
      "     30        \u001b[36m0.6435\u001b[0m       \u001b[32m0.9744\u001b[0m        \u001b[35m0.2508\u001b[0m  0.0618\n",
      "     31        0.6486       0.9665        0.2544  0.0588\n",
      "     32        \u001b[36m0.6387\u001b[0m       \u001b[32m0.9763\u001b[0m        \u001b[35m0.2385\u001b[0m  0.0618\n",
      "     33        \u001b[36m0.6288\u001b[0m       0.9645        \u001b[35m0.2380\u001b[0m  0.0499\n",
      "     34        0.6573       0.9724        \u001b[35m0.2306\u001b[0m  0.0409\n",
      "     35        \u001b[36m0.6151\u001b[0m       0.9704        \u001b[35m0.2269\u001b[0m  0.0628\n",
      "     36        0.6449       0.9724        \u001b[35m0.2199\u001b[0m  0.0479\n",
      "     37        \u001b[36m0.6108\u001b[0m       0.9704        \u001b[35m0.2140\u001b[0m  0.0479\n",
      "     38        0.6324       0.9645        0.2154  0.0449\n",
      "     39        0.6225       0.9724        \u001b[35m0.2048\u001b[0m  0.0598\n",
      "     40        0.6420       0.9625        0.2146  0.0489\n",
      "     41        0.6119       0.9704        \u001b[35m0.2020\u001b[0m  0.0409\n",
      "     42        0.6248       0.9704        \u001b[35m0.1995\u001b[0m  0.0669\n",
      "     43        0.6424       0.9704        \u001b[35m0.1977\u001b[0m  0.0638\n",
      "     44        0.6328       0.9704        \u001b[35m0.1941\u001b[0m  0.0529\n",
      "     45        0.6442       0.9744        \u001b[35m0.1907\u001b[0m  0.0549\n",
      "     46        0.6275       0.9724        \u001b[35m0.1890\u001b[0m  0.0499\n",
      "     47        \u001b[36m0.6087\u001b[0m       0.9724        0.1897  0.0628\n",
      "     48        0.6242       0.9724        \u001b[35m0.1889\u001b[0m  0.0529\n",
      "     49        \u001b[36m0.6019\u001b[0m       0.9704        \u001b[35m0.1851\u001b[0m  0.0598\n",
      "     50        0.6051       0.9645        0.1897  0.0559\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.2s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4521\u001b[0m       \u001b[32m0.2564\u001b[0m        \u001b[35m1.3904\u001b[0m  0.0608\n",
      "      2        \u001b[36m1.4382\u001b[0m       \u001b[32m0.2623\u001b[0m        \u001b[35m1.3831\u001b[0m  0.0509\n",
      "      3        \u001b[36m1.4136\u001b[0m       \u001b[32m0.2663\u001b[0m        \u001b[35m1.3765\u001b[0m  0.0439\n",
      "      4        \u001b[36m1.4087\u001b[0m       \u001b[32m0.2860\u001b[0m        \u001b[35m1.3701\u001b[0m  0.0539\n",
      "      5        \u001b[36m1.4029\u001b[0m       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3640\u001b[0m  0.0519\n",
      "      6        \u001b[36m1.3976\u001b[0m       \u001b[32m0.3176\u001b[0m        \u001b[35m1.3585\u001b[0m  0.0499\n",
      "      7        \u001b[36m1.3958\u001b[0m       \u001b[32m0.3314\u001b[0m        \u001b[35m1.3528\u001b[0m  0.0359\n",
      "      8        \u001b[36m1.3820\u001b[0m       \u001b[32m0.3531\u001b[0m        \u001b[35m1.3473\u001b[0m  0.0519\n",
      "      9        1.3874       \u001b[32m0.3787\u001b[0m        \u001b[35m1.3423\u001b[0m  0.0549\n",
      "     10        \u001b[36m1.3740\u001b[0m       \u001b[32m0.3886\u001b[0m        \u001b[35m1.3374\u001b[0m  0.0449\n",
      "     11        \u001b[36m1.3693\u001b[0m       \u001b[32m0.4063\u001b[0m        \u001b[35m1.3324\u001b[0m  0.0529\n",
      "     12        1.3747       \u001b[32m0.4359\u001b[0m        \u001b[35m1.3276\u001b[0m  0.0409\n",
      "     13        \u001b[36m1.3654\u001b[0m       \u001b[32m0.4635\u001b[0m        \u001b[35m1.3231\u001b[0m  0.0489\n",
      "     14        \u001b[36m1.3566\u001b[0m       \u001b[32m0.4734\u001b[0m        \u001b[35m1.3188\u001b[0m  0.0429\n",
      "     15        \u001b[36m1.3476\u001b[0m       \u001b[32m0.4970\u001b[0m        \u001b[35m1.3143\u001b[0m  0.0369\n",
      "     16        1.3497       \u001b[32m0.5148\u001b[0m        \u001b[35m1.3097\u001b[0m  0.0459\n",
      "     17        1.3488       \u001b[32m0.5286\u001b[0m        \u001b[35m1.3052\u001b[0m  0.0499\n",
      "     18        \u001b[36m1.3335\u001b[0m       \u001b[32m0.5444\u001b[0m        \u001b[35m1.3004\u001b[0m  0.0608\n",
      "     19        \u001b[36m1.3256\u001b[0m       \u001b[32m0.5582\u001b[0m        \u001b[35m1.2955\u001b[0m  0.0439\n",
      "     20        1.3293       \u001b[32m0.5602\u001b[0m        \u001b[35m1.2907\u001b[0m  0.0429\n",
      "     21        \u001b[36m1.3242\u001b[0m       \u001b[32m0.5641\u001b[0m        \u001b[35m1.2861\u001b[0m  0.0399\n",
      "     22        \u001b[36m1.3202\u001b[0m       \u001b[32m0.5740\u001b[0m        \u001b[35m1.2813\u001b[0m  0.0539\n",
      "     23        1.3208       \u001b[32m0.5779\u001b[0m        \u001b[35m1.2768\u001b[0m  0.0489\n",
      "     24        \u001b[36m1.3100\u001b[0m       \u001b[32m0.5976\u001b[0m        \u001b[35m1.2719\u001b[0m  0.0519\n",
      "     25        1.3236       \u001b[32m0.6055\u001b[0m        \u001b[35m1.2671\u001b[0m  0.0608\n",
      "     26        \u001b[36m1.2956\u001b[0m       \u001b[32m0.6154\u001b[0m        \u001b[35m1.2617\u001b[0m  0.0549\n",
      "     27        1.3086       \u001b[32m0.6213\u001b[0m        \u001b[35m1.2569\u001b[0m  0.0508\n",
      "     28        1.3023       \u001b[32m0.6391\u001b[0m        \u001b[35m1.2517\u001b[0m  0.0509\n",
      "     29        \u001b[36m1.2865\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m1.2462\u001b[0m  0.0549\n",
      "     30        1.2877       \u001b[32m0.6529\u001b[0m        \u001b[35m1.2406\u001b[0m  0.0399\n",
      "     31        \u001b[36m1.2757\u001b[0m       \u001b[32m0.6686\u001b[0m        \u001b[35m1.2349\u001b[0m  0.0489\n",
      "     32        1.2801       \u001b[32m0.6746\u001b[0m        \u001b[35m1.2296\u001b[0m  0.0588\n",
      "     33        1.2822       \u001b[32m0.6824\u001b[0m        \u001b[35m1.2242\u001b[0m  0.0429\n",
      "     34        \u001b[36m1.2745\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m1.2186\u001b[0m  0.0618\n",
      "     35        \u001b[36m1.2715\u001b[0m       0.6923        \u001b[35m1.2131\u001b[0m  0.0529\n",
      "     36        \u001b[36m1.2696\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m1.2074\u001b[0m  0.0449\n",
      "     37        \u001b[36m1.2525\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m1.2013\u001b[0m  0.0469\n",
      "     38        \u001b[36m1.2468\u001b[0m       0.7022        \u001b[35m1.1951\u001b[0m  0.0359\n",
      "     39        1.2577       \u001b[32m0.7160\u001b[0m        \u001b[35m1.1893\u001b[0m  0.0438\n",
      "     40        1.2507       \u001b[32m0.7219\u001b[0m        \u001b[35m1.1834\u001b[0m  0.0449\n",
      "     41        \u001b[36m1.2394\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m1.1772\u001b[0m  0.0479\n",
      "     42        \u001b[36m1.2385\u001b[0m       0.7199        \u001b[35m1.1711\u001b[0m  0.0419\n",
      "     43        \u001b[36m1.2345\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m1.1649\u001b[0m  0.0379\n",
      "     44        1.2362       \u001b[32m0.7337\u001b[0m        \u001b[35m1.1588\u001b[0m  0.0499\n",
      "     45        \u001b[36m1.2123\u001b[0m       \u001b[32m0.7357\u001b[0m        \u001b[35m1.1520\u001b[0m  0.0389\n",
      "     46        1.2146       \u001b[32m0.7396\u001b[0m        \u001b[35m1.1456\u001b[0m  0.0359\n",
      "     47        1.2186       \u001b[32m0.7416\u001b[0m        \u001b[35m1.1391\u001b[0m  0.0369\n",
      "     48        1.2153       \u001b[32m0.7456\u001b[0m        \u001b[35m1.1330\u001b[0m  0.0379\n",
      "     49        \u001b[36m1.2032\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m1.1265\u001b[0m  0.0479\n",
      "     50        \u001b[36m1.2018\u001b[0m       0.7495        \u001b[35m1.1202\u001b[0m  0.0469\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4658\u001b[0m       \u001b[32m0.2209\u001b[0m        \u001b[35m1.4245\u001b[0m  0.0499\n",
      "      2        \u001b[36m1.4579\u001b[0m       0.2209        \u001b[35m1.4169\u001b[0m  0.0638\n",
      "      3        \u001b[36m1.4511\u001b[0m       0.2209        \u001b[35m1.4097\u001b[0m  0.0389\n",
      "      4        \u001b[36m1.4433\u001b[0m       \u001b[32m0.2308\u001b[0m        \u001b[35m1.4030\u001b[0m  0.0469\n",
      "      5        \u001b[36m1.4370\u001b[0m       \u001b[32m0.2387\u001b[0m        \u001b[35m1.3967\u001b[0m  0.0389\n",
      "      6        \u001b[36m1.4156\u001b[0m       \u001b[32m0.2406\u001b[0m        \u001b[35m1.3910\u001b[0m  0.0429\n",
      "      7        1.4271       \u001b[32m0.2485\u001b[0m        \u001b[35m1.3852\u001b[0m  0.0429\n",
      "      8        \u001b[36m1.4030\u001b[0m       \u001b[32m0.2781\u001b[0m        \u001b[35m1.3797\u001b[0m  0.0409\n",
      "      9        1.4070       \u001b[32m0.2978\u001b[0m        \u001b[35m1.3745\u001b[0m  0.0379\n",
      "     10        \u001b[36m1.4005\u001b[0m       \u001b[32m0.3235\u001b[0m        \u001b[35m1.3696\u001b[0m  0.0499\n",
      "     11        \u001b[36m1.3918\u001b[0m       \u001b[32m0.3393\u001b[0m        \u001b[35m1.3643\u001b[0m  0.0379\n",
      "     12        1.3919       \u001b[32m0.3748\u001b[0m        \u001b[35m1.3592\u001b[0m  0.0389\n",
      "     13        \u001b[36m1.3778\u001b[0m       \u001b[32m0.4320\u001b[0m        \u001b[35m1.3541\u001b[0m  0.0379\n",
      "     14        \u001b[36m1.3758\u001b[0m       \u001b[32m0.4576\u001b[0m        \u001b[35m1.3492\u001b[0m  0.0529\n",
      "     15        1.3803       \u001b[32m0.4793\u001b[0m        \u001b[35m1.3441\u001b[0m  0.0449\n",
      "     16        \u001b[36m1.3627\u001b[0m       \u001b[32m0.5010\u001b[0m        \u001b[35m1.3391\u001b[0m  0.0439\n",
      "     17        \u001b[36m1.3603\u001b[0m       \u001b[32m0.5286\u001b[0m        \u001b[35m1.3341\u001b[0m  0.0429\n",
      "     18        \u001b[36m1.3524\u001b[0m       \u001b[32m0.5404\u001b[0m        \u001b[35m1.3289\u001b[0m  0.0399\n",
      "     19        \u001b[36m1.3502\u001b[0m       \u001b[32m0.5542\u001b[0m        \u001b[35m1.3238\u001b[0m  0.0459\n",
      "     20        \u001b[36m1.3426\u001b[0m       \u001b[32m0.5720\u001b[0m        \u001b[35m1.3186\u001b[0m  0.0459\n",
      "     21        1.3506       \u001b[32m0.5779\u001b[0m        \u001b[35m1.3138\u001b[0m  0.0598\n",
      "     22        \u001b[36m1.3379\u001b[0m       \u001b[32m0.5838\u001b[0m        \u001b[35m1.3086\u001b[0m  0.0678\n",
      "     23        \u001b[36m1.3323\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m1.3033\u001b[0m  0.0638\n",
      "     24        \u001b[36m1.3300\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m1.2982\u001b[0m  0.0578\n",
      "     25        \u001b[36m1.3234\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m1.2926\u001b[0m  0.0459\n",
      "     26        \u001b[36m1.3194\u001b[0m       \u001b[32m0.6292\u001b[0m        \u001b[35m1.2873\u001b[0m  0.0389\n",
      "     27        \u001b[36m1.3126\u001b[0m       \u001b[32m0.6331\u001b[0m        \u001b[35m1.2816\u001b[0m  0.0409\n",
      "     28        \u001b[36m1.3044\u001b[0m       0.6331        \u001b[35m1.2757\u001b[0m  0.0399\n",
      "     29        1.3099       \u001b[32m0.6371\u001b[0m        \u001b[35m1.2702\u001b[0m  0.0449\n",
      "     30        \u001b[36m1.2904\u001b[0m       0.6351        \u001b[35m1.2642\u001b[0m  0.0469\n",
      "     31        1.2904       \u001b[32m0.6410\u001b[0m        \u001b[35m1.2581\u001b[0m  0.0518\n",
      "     32        \u001b[36m1.2843\u001b[0m       0.6410        \u001b[35m1.2519\u001b[0m  0.0529\n",
      "     33        \u001b[36m1.2791\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.2456\u001b[0m  0.0429\n",
      "     34        \u001b[36m1.2737\u001b[0m       0.6450        \u001b[35m1.2394\u001b[0m  0.0519\n",
      "     35        \u001b[36m1.2702\u001b[0m       \u001b[32m0.6489\u001b[0m        \u001b[35m1.2329\u001b[0m  0.0578\n",
      "     36        \u001b[36m1.2686\u001b[0m       \u001b[32m0.6509\u001b[0m        \u001b[35m1.2265\u001b[0m  0.0459\n",
      "     37        \u001b[36m1.2619\u001b[0m       0.6489        \u001b[35m1.2200\u001b[0m  0.0459\n",
      "     38        \u001b[36m1.2508\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.2133\u001b[0m  0.0529\n",
      "     39        1.2510       \u001b[32m0.6588\u001b[0m        \u001b[35m1.2066\u001b[0m  0.0489\n",
      "     40        \u001b[36m1.2456\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.1999\u001b[0m  0.0519\n",
      "     41        \u001b[36m1.2447\u001b[0m       \u001b[32m0.6726\u001b[0m        \u001b[35m1.1932\u001b[0m  0.0469\n",
      "     42        \u001b[36m1.2291\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.1863\u001b[0m  0.0459\n",
      "     43        1.2299       \u001b[32m0.6884\u001b[0m        \u001b[35m1.1793\u001b[0m  0.0469\n",
      "     44        \u001b[36m1.2234\u001b[0m       \u001b[32m0.6963\u001b[0m        \u001b[35m1.1722\u001b[0m  0.0459\n",
      "     45        1.2250       0.6943        \u001b[35m1.1654\u001b[0m  0.0539\n",
      "     46        \u001b[36m1.2127\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m1.1583\u001b[0m  0.0519\n",
      "     47        1.2129       \u001b[32m0.7061\u001b[0m        \u001b[35m1.1513\u001b[0m  0.0568\n",
      "     48        \u001b[36m1.2045\u001b[0m       \u001b[32m0.7081\u001b[0m        \u001b[35m1.1442\u001b[0m  0.0479\n",
      "     49        \u001b[36m1.2008\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m1.1372\u001b[0m  0.0538\n",
      "     50        \u001b[36m1.1927\u001b[0m       0.7101        \u001b[35m1.1300\u001b[0m  0.0589\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4359\u001b[0m       \u001b[32m0.2584\u001b[0m        \u001b[35m1.3641\u001b[0m  0.0489\n",
      "      2        \u001b[36m1.4181\u001b[0m       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3548\u001b[0m  0.0499\n",
      "      3        \u001b[36m1.4081\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3459\u001b[0m  0.0539\n",
      "      4        \u001b[36m1.3947\u001b[0m       \u001b[32m0.3708\u001b[0m        \u001b[35m1.3375\u001b[0m  0.0558\n",
      "      5        \u001b[36m1.3936\u001b[0m       \u001b[32m0.4063\u001b[0m        \u001b[35m1.3298\u001b[0m  0.0578\n",
      "      6        \u001b[36m1.3755\u001b[0m       \u001b[32m0.4280\u001b[0m        \u001b[35m1.3224\u001b[0m  0.0439\n",
      "      7        \u001b[36m1.3697\u001b[0m       \u001b[32m0.4556\u001b[0m        \u001b[35m1.3151\u001b[0m  0.0498\n",
      "      8        \u001b[36m1.3540\u001b[0m       \u001b[32m0.4892\u001b[0m        \u001b[35m1.3077\u001b[0m  0.0509\n",
      "      9        \u001b[36m1.3390\u001b[0m       \u001b[32m0.5108\u001b[0m        \u001b[35m1.3007\u001b[0m  0.0459\n",
      "     10        1.3405       \u001b[32m0.5385\u001b[0m        \u001b[35m1.2935\u001b[0m  0.0429\n",
      "     11        \u001b[36m1.3327\u001b[0m       \u001b[32m0.5621\u001b[0m        \u001b[35m1.2866\u001b[0m  0.0568\n",
      "     12        \u001b[36m1.3305\u001b[0m       \u001b[32m0.5799\u001b[0m        \u001b[35m1.2801\u001b[0m  0.0409\n",
      "     13        \u001b[36m1.3121\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m1.2734\u001b[0m  0.0399\n",
      "     14        \u001b[36m1.3027\u001b[0m       \u001b[32m0.6075\u001b[0m        \u001b[35m1.2664\u001b[0m  0.0479\n",
      "     15        \u001b[36m1.3009\u001b[0m       \u001b[32m0.6134\u001b[0m        \u001b[35m1.2595\u001b[0m  0.0429\n",
      "     16        \u001b[36m1.2966\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.2525\u001b[0m  0.0399\n",
      "     17        1.2985       \u001b[32m0.6312\u001b[0m        \u001b[35m1.2461\u001b[0m  0.0509\n",
      "     18        \u001b[36m1.2852\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m1.2391\u001b[0m  0.0489\n",
      "     19        \u001b[36m1.2785\u001b[0m       \u001b[32m0.6410\u001b[0m        \u001b[35m1.2322\u001b[0m  0.0389\n",
      "     20        \u001b[36m1.2732\u001b[0m       0.6391        \u001b[35m1.2252\u001b[0m  0.0389\n",
      "     21        \u001b[36m1.2667\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m1.2183\u001b[0m  0.0379\n",
      "     22        \u001b[36m1.2543\u001b[0m       0.6410        \u001b[35m1.2108\u001b[0m  0.0389\n",
      "     23        \u001b[36m1.2493\u001b[0m       0.6391        \u001b[35m1.2036\u001b[0m  0.0549\n",
      "     24        \u001b[36m1.2482\u001b[0m       0.6430        \u001b[35m1.1967\u001b[0m  0.0529\n",
      "     25        \u001b[36m1.2465\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.1897\u001b[0m  0.0399\n",
      "     26        \u001b[36m1.2316\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.1826\u001b[0m  0.0459\n",
      "     27        \u001b[36m1.2189\u001b[0m       \u001b[32m0.6548\u001b[0m        \u001b[35m1.1749\u001b[0m  0.0499\n",
      "     28        1.2257       \u001b[32m0.6568\u001b[0m        \u001b[35m1.1676\u001b[0m  0.0608\n",
      "     29        \u001b[36m1.2075\u001b[0m       0.6568        \u001b[35m1.1604\u001b[0m  0.0498\n",
      "     30        1.2151       0.6568        \u001b[35m1.1533\u001b[0m  0.0429\n",
      "     31        \u001b[36m1.2073\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m1.1459\u001b[0m  0.0479\n",
      "     32        \u001b[36m1.1941\u001b[0m       \u001b[32m0.6607\u001b[0m        \u001b[35m1.1385\u001b[0m  0.0549\n",
      "     33        \u001b[36m1.1776\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m1.1309\u001b[0m  0.0379\n",
      "     34        1.1877       0.6647        \u001b[35m1.1235\u001b[0m  0.0389\n",
      "     35        1.1885       \u001b[32m0.6686\u001b[0m        \u001b[35m1.1163\u001b[0m  0.0409\n",
      "     36        1.1795       0.6686        \u001b[35m1.1091\u001b[0m  0.0539\n",
      "     37        \u001b[36m1.1610\u001b[0m       \u001b[32m0.6805\u001b[0m        \u001b[35m1.1017\u001b[0m  0.0479\n",
      "     38        \u001b[36m1.1605\u001b[0m       0.6805        \u001b[35m1.0945\u001b[0m  0.0519\n",
      "     39        \u001b[36m1.1573\u001b[0m       0.6805        \u001b[35m1.0873\u001b[0m  0.0439\n",
      "     40        \u001b[36m1.1508\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.0800\u001b[0m  0.0379\n",
      "     41        \u001b[36m1.1428\u001b[0m       0.6824        \u001b[35m1.0729\u001b[0m  0.0578\n",
      "     42        1.1588       0.6824        \u001b[35m1.0661\u001b[0m  0.0379\n",
      "     43        \u001b[36m1.1329\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m1.0590\u001b[0m  0.0389\n",
      "     44        \u001b[36m1.1321\u001b[0m       0.6844        \u001b[35m1.0520\u001b[0m  0.0439\n",
      "     45        \u001b[36m1.1190\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m1.0445\u001b[0m  0.0489\n",
      "     46        1.1242       \u001b[32m0.6903\u001b[0m        \u001b[35m1.0376\u001b[0m  0.0379\n",
      "     47        \u001b[36m1.1174\u001b[0m       0.6903        \u001b[35m1.0307\u001b[0m  0.0658\n",
      "     48        \u001b[36m1.1155\u001b[0m       0.6903        \u001b[35m1.0239\u001b[0m  0.0598\n",
      "     49        \u001b[36m1.1029\u001b[0m       0.6903        \u001b[35m1.0170\u001b[0m  0.0459\n",
      "     50        1.1040       \u001b[32m0.6923\u001b[0m        \u001b[35m1.0102\u001b[0m  0.0409\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7406\u001b[0m       \u001b[32m0.3945\u001b[0m        \u001b[35m1.3437\u001b[0m  0.0459\n",
      "      2        \u001b[36m1.3017\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m1.1522\u001b[0m  0.0559\n",
      "      3        \u001b[36m1.1865\u001b[0m       0.7219        \u001b[35m0.9716\u001b[0m  0.0439\n",
      "      4        \u001b[36m1.0311\u001b[0m       \u001b[32m0.7751\u001b[0m        \u001b[35m0.8089\u001b[0m  0.0568\n",
      "      5        \u001b[36m0.9175\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.6790\u001b[0m  0.0459\n",
      "      6        \u001b[36m0.8424\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.5746\u001b[0m  0.0569\n",
      "      7        \u001b[36m0.7733\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.4997\u001b[0m  0.0638\n",
      "      8        \u001b[36m0.7320\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.4369\u001b[0m  0.0449\n",
      "      9        \u001b[36m0.6537\u001b[0m       0.9053        \u001b[35m0.3890\u001b[0m  0.0519\n",
      "     10        \u001b[36m0.6265\u001b[0m       0.9034        \u001b[35m0.3566\u001b[0m  0.0579\n",
      "     11        \u001b[36m0.6056\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m0.3290\u001b[0m  0.0429\n",
      "     12        \u001b[36m0.5916\u001b[0m       \u001b[32m0.9191\u001b[0m        \u001b[35m0.3039\u001b[0m  0.0469\n",
      "     13        \u001b[36m0.5715\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.2830\u001b[0m  0.0509\n",
      "     14        \u001b[36m0.5511\u001b[0m       \u001b[32m0.9310\u001b[0m        \u001b[35m0.2672\u001b[0m  0.0519\n",
      "     15        \u001b[36m0.5179\u001b[0m       0.9310        \u001b[35m0.2537\u001b[0m  0.0509\n",
      "     16        0.5211       \u001b[32m0.9487\u001b[0m        \u001b[35m0.2384\u001b[0m  0.0568\n",
      "     17        \u001b[36m0.5007\u001b[0m       0.9349        \u001b[35m0.2288\u001b[0m  0.0499\n",
      "     18        \u001b[36m0.4801\u001b[0m       \u001b[32m0.9527\u001b[0m        \u001b[35m0.2142\u001b[0m  0.0568\n",
      "     19        0.4876       0.9428        \u001b[35m0.2079\u001b[0m  0.0638\n",
      "     20        \u001b[36m0.4747\u001b[0m       0.9527        \u001b[35m0.1989\u001b[0m  0.0608\n",
      "     21        0.4895       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1904\u001b[0m  0.0679\n",
      "     22        \u001b[36m0.4687\u001b[0m       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1829\u001b[0m  0.0628\n",
      "     23        0.4690       0.9625        \u001b[35m0.1800\u001b[0m  0.0549\n",
      "     24        \u001b[36m0.4660\u001b[0m       \u001b[32m0.9665\u001b[0m        \u001b[35m0.1735\u001b[0m  0.0668\n",
      "     25        \u001b[36m0.4255\u001b[0m       0.9546        \u001b[35m0.1696\u001b[0m  0.0529\n",
      "     26        0.4533       0.9645        \u001b[35m0.1692\u001b[0m  0.0708\n",
      "     27        0.4365       0.9606        \u001b[35m0.1611\u001b[0m  0.0469\n",
      "     28        0.4322       0.9645        \u001b[35m0.1570\u001b[0m  0.0588\n",
      "     29        0.4296       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1514\u001b[0m  0.0529\n",
      "     30        0.4467       0.9645        \u001b[35m0.1507\u001b[0m  0.0638\n",
      "     31        0.4338       0.9625        \u001b[35m0.1458\u001b[0m  0.0628\n",
      "     32        0.4370       0.9684        \u001b[35m0.1429\u001b[0m  0.0559\n",
      "     33        \u001b[36m0.4153\u001b[0m       0.9684        \u001b[35m0.1402\u001b[0m  0.0559\n",
      "     34        \u001b[36m0.4141\u001b[0m       0.9665        \u001b[35m0.1372\u001b[0m  0.0459\n",
      "     35        \u001b[36m0.4101\u001b[0m       0.9684        \u001b[35m0.1365\u001b[0m  0.0688\n",
      "     36        0.4169       0.9684        \u001b[35m0.1310\u001b[0m  0.0738\n",
      "     37        0.4222       0.9684        \u001b[35m0.1300\u001b[0m  0.0479\n",
      "     38        0.4364       0.9684        \u001b[35m0.1285\u001b[0m  0.0718\n",
      "     39        \u001b[36m0.3946\u001b[0m       \u001b[32m0.9724\u001b[0m        \u001b[35m0.1274\u001b[0m  0.0439\n",
      "     40        0.4096       0.9704        \u001b[35m0.1236\u001b[0m  0.0439\n",
      "     41        0.4001       0.9684        \u001b[35m0.1212\u001b[0m  0.0509\n",
      "     42        \u001b[36m0.3932\u001b[0m       \u001b[32m0.9744\u001b[0m        0.1223  0.0459\n",
      "     43        \u001b[36m0.3859\u001b[0m       0.9724        0.1218  0.0668\n",
      "     44        \u001b[36m0.3831\u001b[0m       0.9724        0.1229  0.0539\n",
      "     45        0.4042       0.9724        \u001b[35m0.1175\u001b[0m  0.0518\n",
      "     46        0.3925       0.9724        0.1200  0.0449\n",
      "     47        0.3886       0.9704        \u001b[35m0.1142\u001b[0m  0.0618\n",
      "     48        0.4216       0.9724        0.1142  0.0509\n",
      "     49        \u001b[36m0.3723\u001b[0m       0.9684        0.1156  0.0688\n",
      "     50        0.4095       0.9744        \u001b[35m0.1130\u001b[0m  0.0688\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.4s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7592\u001b[0m       \u001b[32m0.3531\u001b[0m        \u001b[35m1.3572\u001b[0m  0.0519\n",
      "      2        \u001b[36m1.2782\u001b[0m       \u001b[32m0.5957\u001b[0m        \u001b[35m1.1892\u001b[0m  0.0648\n",
      "      3        \u001b[36m1.2151\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m1.0303\u001b[0m  0.0598\n",
      "      4        \u001b[36m1.0715\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.8633\u001b[0m  0.0529\n",
      "      5        \u001b[36m0.9400\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.7249\u001b[0m  0.0598\n",
      "      6        \u001b[36m0.8471\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.6195\u001b[0m  0.0459\n",
      "      7        \u001b[36m0.7753\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.5314\u001b[0m  0.0459\n",
      "      8        \u001b[36m0.6953\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.4628\u001b[0m  0.0679\n",
      "      9        \u001b[36m0.6892\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.4125\u001b[0m  0.0479\n",
      "     10        \u001b[36m0.6291\u001b[0m       0.9191        \u001b[35m0.3762\u001b[0m  0.0668\n",
      "     11        \u001b[36m0.6069\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.3447\u001b[0m  0.0668\n",
      "     12        \u001b[36m0.5713\u001b[0m       0.9231        \u001b[35m0.3178\u001b[0m  0.0519\n",
      "     13        \u001b[36m0.5576\u001b[0m       \u001b[32m0.9290\u001b[0m        \u001b[35m0.2947\u001b[0m  0.0668\n",
      "     14        \u001b[36m0.5486\u001b[0m       0.9250        \u001b[35m0.2837\u001b[0m  0.0618\n",
      "     15        \u001b[36m0.5183\u001b[0m       0.9231        \u001b[35m0.2707\u001b[0m  0.0509\n",
      "     16        \u001b[36m0.5015\u001b[0m       \u001b[32m0.9349\u001b[0m        \u001b[35m0.2557\u001b[0m  0.0449\n",
      "     17        \u001b[36m0.4888\u001b[0m       0.9329        \u001b[35m0.2411\u001b[0m  0.0439\n",
      "     18        \u001b[36m0.4814\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.2345\u001b[0m  0.0549\n",
      "     19        0.4876       \u001b[32m0.9408\u001b[0m        \u001b[35m0.2264\u001b[0m  0.0618\n",
      "     20        \u001b[36m0.4512\u001b[0m       0.9408        \u001b[35m0.2152\u001b[0m  0.0499\n",
      "     21        0.4522       \u001b[32m0.9467\u001b[0m        \u001b[35m0.2065\u001b[0m  0.0489\n",
      "     22        0.4575       \u001b[32m0.9487\u001b[0m        \u001b[35m0.1990\u001b[0m  0.0618\n",
      "     23        \u001b[36m0.4371\u001b[0m       0.9448        \u001b[35m0.1955\u001b[0m  0.0668\n",
      "     24        0.4401       0.9428        \u001b[35m0.1926\u001b[0m  0.0738\n",
      "     25        0.4443       0.9428        \u001b[35m0.1887\u001b[0m  0.0628\n",
      "     26        0.4377       \u001b[32m0.9546\u001b[0m        \u001b[35m0.1803\u001b[0m  0.0469\n",
      "     27        \u001b[36m0.4225\u001b[0m       0.9507        \u001b[35m0.1801\u001b[0m  0.0449\n",
      "     28        0.4426       \u001b[32m0.9566\u001b[0m        \u001b[35m0.1743\u001b[0m  0.0519\n",
      "     29        \u001b[36m0.4158\u001b[0m       0.9487        0.1767  0.0429\n",
      "     30        0.4250       0.9487        \u001b[35m0.1696\u001b[0m  0.0439\n",
      "     31        \u001b[36m0.4153\u001b[0m       0.9546        \u001b[35m0.1625\u001b[0m  0.0449\n",
      "     32        \u001b[36m0.4054\u001b[0m       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1567\u001b[0m  0.0558\n",
      "     33        \u001b[36m0.3937\u001b[0m       0.9507        0.1603  0.0479\n",
      "     34        \u001b[36m0.3905\u001b[0m       0.9566        \u001b[35m0.1549\u001b[0m  0.0439\n",
      "     35        0.4025       0.9566        \u001b[35m0.1527\u001b[0m  0.0449\n",
      "     36        \u001b[36m0.3844\u001b[0m       0.9606        0.1554  0.0468\n",
      "     37        0.3846       0.9625        \u001b[35m0.1481\u001b[0m  0.0519\n",
      "     38        0.3863       \u001b[32m0.9645\u001b[0m        \u001b[35m0.1454\u001b[0m  0.0459\n",
      "     39        \u001b[36m0.3824\u001b[0m       0.9625        \u001b[35m0.1407\u001b[0m  0.0519\n",
      "     40        \u001b[36m0.3816\u001b[0m       0.9546        0.1411  0.0588\n",
      "     41        0.3904       0.9566        0.1468  0.0628\n",
      "     42        0.4123       0.9586        \u001b[35m0.1403\u001b[0m  0.0489\n",
      "     43        \u001b[36m0.3413\u001b[0m       0.9527        0.1414  0.0439\n",
      "     44        0.3953       0.9527        \u001b[35m0.1385\u001b[0m  0.0459\n",
      "     45        0.3694       0.9606        0.1387  0.0449\n",
      "     46        0.3567       0.9546        \u001b[35m0.1376\u001b[0m  0.0568\n",
      "     47        0.3553       0.9625        \u001b[35m0.1287\u001b[0m  0.0549\n",
      "     48        0.3559       0.9606        0.1336  0.0468\n",
      "     49        0.3712       0.9645        \u001b[35m0.1280\u001b[0m  0.0598\n",
      "     50        0.3604       0.9566        0.1317  0.0608\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7401\u001b[0m       \u001b[32m0.3452\u001b[0m        \u001b[35m1.3640\u001b[0m  0.0539\n",
      "      2        \u001b[36m1.2963\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m1.1888\u001b[0m  0.0618\n",
      "      3        \u001b[36m1.1787\u001b[0m       \u001b[32m0.8422\u001b[0m        \u001b[35m1.0047\u001b[0m  0.0519\n",
      "      4        \u001b[36m1.0522\u001b[0m       0.8323        \u001b[35m0.8312\u001b[0m  0.0449\n",
      "      5        \u001b[36m0.9291\u001b[0m       0.8422        \u001b[35m0.7007\u001b[0m  0.0449\n",
      "      6        \u001b[36m0.8305\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.5985\u001b[0m  0.0688\n",
      "      7        \u001b[36m0.7746\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.5181\u001b[0m  0.0728\n",
      "      8        \u001b[36m0.6967\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m0.4489\u001b[0m  0.0458\n",
      "      9        \u001b[36m0.6664\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.3956\u001b[0m  0.0519\n",
      "     10        \u001b[36m0.6413\u001b[0m       \u001b[32m0.9290\u001b[0m        \u001b[35m0.3582\u001b[0m  0.0698\n",
      "     11        \u001b[36m0.5923\u001b[0m       \u001b[32m0.9369\u001b[0m        \u001b[35m0.3248\u001b[0m  0.0678\n",
      "     12        \u001b[36m0.5818\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.2970\u001b[0m  0.0459\n",
      "     13        \u001b[36m0.5625\u001b[0m       \u001b[32m0.9507\u001b[0m        \u001b[35m0.2790\u001b[0m  0.0549\n",
      "     14        \u001b[36m0.5342\u001b[0m       \u001b[32m0.9586\u001b[0m        \u001b[35m0.2577\u001b[0m  0.0568\n",
      "     15        \u001b[36m0.5006\u001b[0m       0.9546        \u001b[35m0.2418\u001b[0m  0.0598\n",
      "     16        0.5060       \u001b[32m0.9625\u001b[0m        \u001b[35m0.2299\u001b[0m  0.0419\n",
      "     17        0.5105       0.9625        \u001b[35m0.2178\u001b[0m  0.0429\n",
      "     18        0.5044       0.9606        \u001b[35m0.2114\u001b[0m  0.0598\n",
      "     19        \u001b[36m0.4970\u001b[0m       0.9586        \u001b[35m0.2030\u001b[0m  0.0459\n",
      "     20        0.5114       0.9606        0.2036  0.0738\n",
      "     21        \u001b[36m0.4356\u001b[0m       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1890\u001b[0m  0.0628\n",
      "     22        0.4620       \u001b[32m0.9704\u001b[0m        \u001b[35m0.1869\u001b[0m  0.0658\n",
      "     23        \u001b[36m0.4317\u001b[0m       0.9586        \u001b[35m0.1768\u001b[0m  0.0469\n",
      "     24        0.4695       0.9665        \u001b[35m0.1754\u001b[0m  0.0439\n",
      "     25        \u001b[36m0.4252\u001b[0m       0.9645        \u001b[35m0.1635\u001b[0m  0.0469\n",
      "     26        0.4583       0.9625        0.1689  0.0628\n",
      "     27        \u001b[36m0.4049\u001b[0m       0.9684        \u001b[35m0.1549\u001b[0m  0.0519\n",
      "     28        \u001b[36m0.3986\u001b[0m       0.9704        \u001b[35m0.1526\u001b[0m  0.0489\n",
      "     29        0.4277       \u001b[32m0.9744\u001b[0m        \u001b[35m0.1470\u001b[0m  0.0509\n",
      "     30        0.4069       0.9704        \u001b[35m0.1456\u001b[0m  0.0419\n",
      "     31        \u001b[36m0.3900\u001b[0m       0.9704        \u001b[35m0.1426\u001b[0m  0.0539\n",
      "     32        0.3965       0.9724        \u001b[35m0.1379\u001b[0m  0.0549\n",
      "     33        0.4132       0.9744        \u001b[35m0.1370\u001b[0m  0.0618\n",
      "     34        0.3910       0.9704        \u001b[35m0.1356\u001b[0m  0.0569\n",
      "     35        0.4028       0.9744        \u001b[35m0.1335\u001b[0m  0.0518\n",
      "     36        0.4101       0.9645        \u001b[35m0.1331\u001b[0m  0.0489\n",
      "     37        \u001b[36m0.3808\u001b[0m       \u001b[32m0.9783\u001b[0m        \u001b[35m0.1282\u001b[0m  0.0549\n",
      "     38        \u001b[36m0.3735\u001b[0m       0.9704        \u001b[35m0.1268\u001b[0m  0.0588\n",
      "     39        0.3975       0.9724        \u001b[35m0.1250\u001b[0m  0.0489\n",
      "     40        \u001b[36m0.3696\u001b[0m       0.9665        0.1279  0.0618\n",
      "     41        \u001b[36m0.3509\u001b[0m       0.9744        \u001b[35m0.1226\u001b[0m  0.0549\n",
      "     42        0.3922       0.9645        0.1264  0.0489\n",
      "     43        0.3572       0.9724        \u001b[35m0.1186\u001b[0m  0.0489\n",
      "     44        0.3716       \u001b[32m0.9803\u001b[0m        \u001b[35m0.1184\u001b[0m  0.0568\n",
      "     45        0.3807       0.9704        \u001b[35m0.1178\u001b[0m  0.0429\n",
      "     46        0.3611       0.9763        \u001b[35m0.1138\u001b[0m  0.0708\n",
      "     47        0.3632       0.9665        0.1162  0.0539\n",
      "     48        0.3516       0.9783        \u001b[35m0.1119\u001b[0m  0.0628\n",
      "     49        0.3812       0.9665        0.1134  0.0519\n",
      "     50        0.3655       0.9783        0.1120  0.0598\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.4s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4499\u001b[0m       \u001b[32m0.2840\u001b[0m        \u001b[35m1.4065\u001b[0m  0.0588\n",
      "      2        \u001b[36m1.4408\u001b[0m       \u001b[32m0.2880\u001b[0m        \u001b[35m1.3924\u001b[0m  0.0509\n",
      "      3        \u001b[36m1.4303\u001b[0m       0.2860        \u001b[35m1.3796\u001b[0m  0.0469\n",
      "      4        \u001b[36m1.4126\u001b[0m       \u001b[32m0.2899\u001b[0m        \u001b[35m1.3676\u001b[0m  0.0399\n",
      "      5        \u001b[36m1.3922\u001b[0m       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3570\u001b[0m  0.0588\n",
      "      6        \u001b[36m1.3907\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3464\u001b[0m  0.0439\n",
      "      7        \u001b[36m1.3856\u001b[0m       \u001b[32m0.3393\u001b[0m        \u001b[35m1.3371\u001b[0m  0.0598\n",
      "      8        \u001b[36m1.3735\u001b[0m       \u001b[32m0.4103\u001b[0m        \u001b[35m1.3276\u001b[0m  0.0479\n",
      "      9        \u001b[36m1.3568\u001b[0m       \u001b[32m0.4379\u001b[0m        \u001b[35m1.3181\u001b[0m  0.0708\n",
      "     10        \u001b[36m1.3423\u001b[0m       \u001b[32m0.4714\u001b[0m        \u001b[35m1.3090\u001b[0m  0.0628\n",
      "     11        \u001b[36m1.3308\u001b[0m       \u001b[32m0.4872\u001b[0m        \u001b[35m1.3000\u001b[0m  0.0479\n",
      "     12        \u001b[36m1.3285\u001b[0m       \u001b[32m0.5227\u001b[0m        \u001b[35m1.2912\u001b[0m  0.0498\n",
      "     13        \u001b[36m1.3214\u001b[0m       \u001b[32m0.5464\u001b[0m        \u001b[35m1.2828\u001b[0m  0.0539\n",
      "     14        \u001b[36m1.3069\u001b[0m       \u001b[32m0.5838\u001b[0m        \u001b[35m1.2743\u001b[0m  0.0399\n",
      "     15        \u001b[36m1.2967\u001b[0m       \u001b[32m0.5957\u001b[0m        \u001b[35m1.2658\u001b[0m  0.0519\n",
      "     16        \u001b[36m1.2945\u001b[0m       0.5957        \u001b[35m1.2574\u001b[0m  0.0648\n",
      "     17        1.2992       \u001b[32m0.6036\u001b[0m        \u001b[35m1.2487\u001b[0m  0.0399\n",
      "     18        \u001b[36m1.2831\u001b[0m       \u001b[32m0.6154\u001b[0m        \u001b[35m1.2400\u001b[0m  0.0558\n",
      "     19        \u001b[36m1.2800\u001b[0m       \u001b[32m0.6174\u001b[0m        \u001b[35m1.2317\u001b[0m  0.0469\n",
      "     20        \u001b[36m1.2752\u001b[0m       \u001b[32m0.6233\u001b[0m        \u001b[35m1.2233\u001b[0m  0.0598\n",
      "     21        \u001b[36m1.2614\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.2147\u001b[0m  0.0419\n",
      "     22        \u001b[36m1.2585\u001b[0m       \u001b[32m0.6272\u001b[0m        \u001b[35m1.2061\u001b[0m  0.0539\n",
      "     23        1.2597       \u001b[32m0.6312\u001b[0m        \u001b[35m1.1976\u001b[0m  0.0489\n",
      "     24        \u001b[36m1.2502\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.1893\u001b[0m  0.0628\n",
      "     25        \u001b[36m1.2335\u001b[0m       0.6351        \u001b[35m1.1806\u001b[0m  0.0529\n",
      "     26        \u001b[36m1.2314\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m1.1718\u001b[0m  0.0439\n",
      "     27        \u001b[36m1.2132\u001b[0m       \u001b[32m0.6489\u001b[0m        \u001b[35m1.1629\u001b[0m  0.0499\n",
      "     28        1.2162       \u001b[32m0.6568\u001b[0m        \u001b[35m1.1540\u001b[0m  0.0568\n",
      "     29        1.2140       \u001b[32m0.6607\u001b[0m        \u001b[35m1.1453\u001b[0m  0.0519\n",
      "     30        \u001b[36m1.2071\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.1365\u001b[0m  0.0439\n",
      "     31        \u001b[36m1.1864\u001b[0m       \u001b[32m0.6726\u001b[0m        \u001b[35m1.1274\u001b[0m  0.0399\n",
      "     32        \u001b[36m1.1848\u001b[0m       0.6726        \u001b[35m1.1185\u001b[0m  0.0479\n",
      "     33        \u001b[36m1.1663\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m1.1091\u001b[0m  0.0399\n",
      "     34        1.1766       \u001b[32m0.6785\u001b[0m        \u001b[35m1.1003\u001b[0m  0.0399\n",
      "     35        1.1717       \u001b[32m0.6864\u001b[0m        \u001b[35m1.0915\u001b[0m  0.0419\n",
      "     36        \u001b[36m1.1541\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m1.0822\u001b[0m  0.0529\n",
      "     37        \u001b[36m1.1479\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m1.0731\u001b[0m  0.0399\n",
      "     38        \u001b[36m1.1385\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m1.0641\u001b[0m  0.0489\n",
      "     39        \u001b[36m1.1325\u001b[0m       0.6982        \u001b[35m1.0549\u001b[0m  0.0499\n",
      "     40        \u001b[36m1.1234\u001b[0m       0.6963        \u001b[35m1.0459\u001b[0m  0.0529\n",
      "     41        \u001b[36m1.1145\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.0372\u001b[0m  0.0459\n",
      "     42        \u001b[36m1.1135\u001b[0m       0.7061        \u001b[35m1.0285\u001b[0m  0.0399\n",
      "     43        \u001b[36m1.1029\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m1.0197\u001b[0m  0.0439\n",
      "     44        \u001b[36m1.0972\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m1.0110\u001b[0m  0.0499\n",
      "     45        \u001b[36m1.0941\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m1.0023\u001b[0m  0.0519\n",
      "     46        \u001b[36m1.0815\u001b[0m       \u001b[32m0.7199\u001b[0m        \u001b[35m0.9936\u001b[0m  0.0608\n",
      "     47        \u001b[36m1.0774\u001b[0m       0.7199        \u001b[35m0.9847\u001b[0m  0.0409\n",
      "     48        \u001b[36m1.0661\u001b[0m       0.7199        \u001b[35m0.9760\u001b[0m  0.0509\n",
      "     49        1.0772       0.7199        \u001b[35m0.9678\u001b[0m  0.0588\n",
      "     50        \u001b[36m1.0630\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m0.9594\u001b[0m  0.0439\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.1s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4846\u001b[0m       \u001b[32m0.2110\u001b[0m        \u001b[35m1.4302\u001b[0m  0.0549\n",
      "      2        \u001b[36m1.4673\u001b[0m       \u001b[32m0.2387\u001b[0m        \u001b[35m1.4159\u001b[0m  0.0529\n",
      "      3        \u001b[36m1.4515\u001b[0m       \u001b[32m0.2584\u001b[0m        \u001b[35m1.4038\u001b[0m  0.0529\n",
      "      4        \u001b[36m1.4387\u001b[0m       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3929\u001b[0m  0.0578\n",
      "      5        \u001b[36m1.4320\u001b[0m       \u001b[32m0.2978\u001b[0m        \u001b[35m1.3829\u001b[0m  0.0459\n",
      "      6        \u001b[36m1.4154\u001b[0m       \u001b[32m0.3176\u001b[0m        \u001b[35m1.3736\u001b[0m  0.0728\n",
      "      7        \u001b[36m1.4031\u001b[0m       \u001b[32m0.3353\u001b[0m        \u001b[35m1.3648\u001b[0m  0.0568\n",
      "      8        \u001b[36m1.3937\u001b[0m       \u001b[32m0.3609\u001b[0m        \u001b[35m1.3567\u001b[0m  0.0399\n",
      "      9        \u001b[36m1.3906\u001b[0m       \u001b[32m0.3748\u001b[0m        \u001b[35m1.3489\u001b[0m  0.0439\n",
      "     10        \u001b[36m1.3740\u001b[0m       \u001b[32m0.3925\u001b[0m        \u001b[35m1.3416\u001b[0m  0.0409\n",
      "     11        \u001b[36m1.3691\u001b[0m       \u001b[32m0.4004\u001b[0m        \u001b[35m1.3342\u001b[0m  0.0419\n",
      "     12        \u001b[36m1.3554\u001b[0m       \u001b[32m0.4320\u001b[0m        \u001b[35m1.3269\u001b[0m  0.0529\n",
      "     13        \u001b[36m1.3535\u001b[0m       \u001b[32m0.4576\u001b[0m        \u001b[35m1.3196\u001b[0m  0.0578\n",
      "     14        \u001b[36m1.3492\u001b[0m       \u001b[32m0.4734\u001b[0m        \u001b[35m1.3125\u001b[0m  0.0559\n",
      "     15        \u001b[36m1.3467\u001b[0m       \u001b[32m0.4931\u001b[0m        \u001b[35m1.3057\u001b[0m  0.0469\n",
      "     16        \u001b[36m1.3345\u001b[0m       \u001b[32m0.5168\u001b[0m        \u001b[35m1.2988\u001b[0m  0.0419\n",
      "     17        \u001b[36m1.3295\u001b[0m       \u001b[32m0.5207\u001b[0m        \u001b[35m1.2917\u001b[0m  0.0409\n",
      "     18        \u001b[36m1.3245\u001b[0m       \u001b[32m0.5404\u001b[0m        \u001b[35m1.2847\u001b[0m  0.0658\n",
      "     19        \u001b[36m1.3190\u001b[0m       \u001b[32m0.5523\u001b[0m        \u001b[35m1.2778\u001b[0m  0.0499\n",
      "     20        \u001b[36m1.3006\u001b[0m       \u001b[32m0.5621\u001b[0m        \u001b[35m1.2705\u001b[0m  0.0668\n",
      "     21        1.3074       \u001b[32m0.5720\u001b[0m        \u001b[35m1.2631\u001b[0m  0.0688\n",
      "     22        \u001b[36m1.2954\u001b[0m       \u001b[32m0.5799\u001b[0m        \u001b[35m1.2562\u001b[0m  0.0389\n",
      "     23        \u001b[36m1.2884\u001b[0m       0.5799        \u001b[35m1.2489\u001b[0m  0.0608\n",
      "     24        \u001b[36m1.2767\u001b[0m       \u001b[32m0.5917\u001b[0m        \u001b[35m1.2415\u001b[0m  0.0459\n",
      "     25        \u001b[36m1.2730\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m1.2340\u001b[0m  0.0499\n",
      "     26        \u001b[36m1.2664\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m1.2263\u001b[0m  0.0509\n",
      "     27        \u001b[36m1.2574\u001b[0m       \u001b[32m0.6233\u001b[0m        \u001b[35m1.2188\u001b[0m  0.0578\n",
      "     28        \u001b[36m1.2526\u001b[0m       \u001b[32m0.6272\u001b[0m        \u001b[35m1.2109\u001b[0m  0.0439\n",
      "     29        \u001b[36m1.2522\u001b[0m       \u001b[32m0.6371\u001b[0m        \u001b[35m1.2030\u001b[0m  0.0499\n",
      "     30        \u001b[36m1.2425\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.1950\u001b[0m  0.0499\n",
      "     31        \u001b[36m1.2397\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m1.1871\u001b[0m  0.0509\n",
      "     32        \u001b[36m1.2221\u001b[0m       \u001b[32m0.6509\u001b[0m        \u001b[35m1.1789\u001b[0m  0.0499\n",
      "     33        \u001b[36m1.2220\u001b[0m       \u001b[32m0.6568\u001b[0m        \u001b[35m1.1707\u001b[0m  0.0449\n",
      "     34        \u001b[36m1.1998\u001b[0m       0.6568        \u001b[35m1.1621\u001b[0m  0.0558\n",
      "     35        \u001b[36m1.1977\u001b[0m       \u001b[32m0.6607\u001b[0m        \u001b[35m1.1534\u001b[0m  0.0399\n",
      "     36        \u001b[36m1.1902\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m1.1448\u001b[0m  0.0449\n",
      "     37        1.1924       0.6667        \u001b[35m1.1363\u001b[0m  0.0519\n",
      "     38        \u001b[36m1.1797\u001b[0m       0.6667        \u001b[35m1.1276\u001b[0m  0.0549\n",
      "     39        \u001b[36m1.1732\u001b[0m       \u001b[32m0.6746\u001b[0m        \u001b[35m1.1190\u001b[0m  0.0578\n",
      "     40        1.1740       \u001b[32m0.6824\u001b[0m        \u001b[35m1.1105\u001b[0m  0.0499\n",
      "     41        \u001b[36m1.1679\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m1.1020\u001b[0m  0.0529\n",
      "     42        \u001b[36m1.1561\u001b[0m       \u001b[32m0.7041\u001b[0m        \u001b[35m1.0931\u001b[0m  0.0399\n",
      "     43        \u001b[36m1.1444\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.0843\u001b[0m  0.0658\n",
      "     44        \u001b[36m1.1362\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m1.0754\u001b[0m  0.0628\n",
      "     45        \u001b[36m1.1294\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m1.0667\u001b[0m  0.0459\n",
      "     46        \u001b[36m1.1222\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m1.0579\u001b[0m  0.0568\n",
      "     47        \u001b[36m1.1218\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m1.0491\u001b[0m  0.0688\n",
      "     48        \u001b[36m1.1118\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m1.0406\u001b[0m  0.0638\n",
      "     49        \u001b[36m1.1007\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m1.0318\u001b[0m  0.0559\n",
      "     50        \u001b[36m1.1001\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m1.0232\u001b[0m  0.0559\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.3s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4509\u001b[0m       \u001b[32m0.2012\u001b[0m        \u001b[35m1.4104\u001b[0m  0.0489\n",
      "      2        \u001b[36m1.4489\u001b[0m       \u001b[32m0.2249\u001b[0m        \u001b[35m1.4017\u001b[0m  0.0479\n",
      "      3        \u001b[36m1.4309\u001b[0m       \u001b[32m0.2702\u001b[0m        \u001b[35m1.3933\u001b[0m  0.0479\n",
      "      4        \u001b[36m1.4197\u001b[0m       \u001b[32m0.2781\u001b[0m        \u001b[35m1.3852\u001b[0m  0.0399\n",
      "      5        1.4199       \u001b[32m0.2860\u001b[0m        \u001b[35m1.3776\u001b[0m  0.0469\n",
      "      6        \u001b[36m1.4077\u001b[0m       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3702\u001b[0m  0.0429\n",
      "      7        \u001b[36m1.3866\u001b[0m       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3631\u001b[0m  0.0419\n",
      "      8        1.3956       \u001b[32m0.3669\u001b[0m        \u001b[35m1.3561\u001b[0m  0.0439\n",
      "      9        \u001b[36m1.3801\u001b[0m       \u001b[32m0.4063\u001b[0m        \u001b[35m1.3495\u001b[0m  0.0389\n",
      "     10        1.3816       \u001b[32m0.4201\u001b[0m        \u001b[35m1.3433\u001b[0m  0.0409\n",
      "     11        \u001b[36m1.3690\u001b[0m       \u001b[32m0.4379\u001b[0m        \u001b[35m1.3368\u001b[0m  0.0439\n",
      "     12        \u001b[36m1.3598\u001b[0m       \u001b[32m0.4596\u001b[0m        \u001b[35m1.3305\u001b[0m  0.0499\n",
      "     13        \u001b[36m1.3489\u001b[0m       \u001b[32m0.4773\u001b[0m        \u001b[35m1.3241\u001b[0m  0.0499\n",
      "     14        1.3580       \u001b[32m0.4872\u001b[0m        \u001b[35m1.3177\u001b[0m  0.0419\n",
      "     15        1.3496       \u001b[32m0.4990\u001b[0m        \u001b[35m1.3115\u001b[0m  0.0588\n",
      "     16        \u001b[36m1.3329\u001b[0m       \u001b[32m0.5089\u001b[0m        \u001b[35m1.3055\u001b[0m  0.0449\n",
      "     17        \u001b[36m1.3327\u001b[0m       \u001b[32m0.5247\u001b[0m        \u001b[35m1.2987\u001b[0m  0.0489\n",
      "     18        \u001b[36m1.3283\u001b[0m       \u001b[32m0.5385\u001b[0m        \u001b[35m1.2925\u001b[0m  0.0479\n",
      "     19        \u001b[36m1.3237\u001b[0m       \u001b[32m0.5424\u001b[0m        \u001b[35m1.2863\u001b[0m  0.0459\n",
      "     20        \u001b[36m1.3126\u001b[0m       \u001b[32m0.5503\u001b[0m        \u001b[35m1.2799\u001b[0m  0.0389\n",
      "     21        \u001b[36m1.3028\u001b[0m       \u001b[32m0.5621\u001b[0m        \u001b[35m1.2734\u001b[0m  0.0549\n",
      "     22        \u001b[36m1.2985\u001b[0m       \u001b[32m0.5779\u001b[0m        \u001b[35m1.2666\u001b[0m  0.0499\n",
      "     23        1.2993       \u001b[32m0.5838\u001b[0m        \u001b[35m1.2601\u001b[0m  0.0379\n",
      "     24        \u001b[36m1.2820\u001b[0m       \u001b[32m0.5957\u001b[0m        \u001b[35m1.2533\u001b[0m  0.0419\n",
      "     25        1.2929       \u001b[32m0.6075\u001b[0m        \u001b[35m1.2470\u001b[0m  0.0489\n",
      "     26        \u001b[36m1.2757\u001b[0m       \u001b[32m0.6095\u001b[0m        \u001b[35m1.2406\u001b[0m  0.0439\n",
      "     27        \u001b[36m1.2748\u001b[0m       \u001b[32m0.6134\u001b[0m        \u001b[35m1.2339\u001b[0m  0.0489\n",
      "     28        \u001b[36m1.2704\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m1.2270\u001b[0m  0.0588\n",
      "     29        \u001b[36m1.2568\u001b[0m       0.6213        \u001b[35m1.2199\u001b[0m  0.0539\n",
      "     30        \u001b[36m1.2559\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.2127\u001b[0m  0.0479\n",
      "     31        \u001b[36m1.2543\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m1.2056\u001b[0m  0.0439\n",
      "     32        \u001b[36m1.2419\u001b[0m       0.6351        \u001b[35m1.1986\u001b[0m  0.0539\n",
      "     33        1.2497       \u001b[32m0.6410\u001b[0m        \u001b[35m1.1917\u001b[0m  0.0459\n",
      "     34        \u001b[36m1.2409\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.1846\u001b[0m  0.0489\n",
      "     35        \u001b[36m1.2236\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.1770\u001b[0m  0.0459\n",
      "     36        \u001b[36m1.2230\u001b[0m       \u001b[32m0.6607\u001b[0m        \u001b[35m1.1696\u001b[0m  0.0449\n",
      "     37        \u001b[36m1.2178\u001b[0m       \u001b[32m0.6686\u001b[0m        \u001b[35m1.1623\u001b[0m  0.0489\n",
      "     38        \u001b[36m1.2022\u001b[0m       \u001b[32m0.6785\u001b[0m        \u001b[35m1.1546\u001b[0m  0.0399\n",
      "     39        \u001b[36m1.1975\u001b[0m       \u001b[32m0.6805\u001b[0m        \u001b[35m1.1470\u001b[0m  0.0429\n",
      "     40        \u001b[36m1.1954\u001b[0m       0.6805        \u001b[35m1.1392\u001b[0m  0.0399\n",
      "     41        \u001b[36m1.1931\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.1316\u001b[0m  0.0379\n",
      "     42        \u001b[36m1.1803\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m1.1238\u001b[0m  0.0419\n",
      "     43        \u001b[36m1.1669\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m1.1158\u001b[0m  0.0459\n",
      "     44        \u001b[36m1.1604\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m1.1079\u001b[0m  0.0459\n",
      "     45        1.1650       0.6923        \u001b[35m1.1001\u001b[0m  0.0549\n",
      "     46        \u001b[36m1.1577\u001b[0m       0.6923        \u001b[35m1.0922\u001b[0m  0.0529\n",
      "     47        \u001b[36m1.1476\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m1.0842\u001b[0m  0.0509\n",
      "     48        \u001b[36m1.1455\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.0765\u001b[0m  0.0529\n",
      "     49        1.1477       \u001b[32m0.7140\u001b[0m        \u001b[35m1.0689\u001b[0m  0.0409\n",
      "     50        \u001b[36m1.1253\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m1.0611\u001b[0m  0.0389\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   2.9s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8392\u001b[0m       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3016\u001b[0m  0.0429\n",
      "      2        \u001b[36m1.2720\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m1.0517\u001b[0m  0.0568\n",
      "      3        \u001b[36m1.1049\u001b[0m       \u001b[32m0.8166\u001b[0m        \u001b[35m0.8343\u001b[0m  0.0449\n",
      "      4        \u001b[36m0.8822\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.6619\u001b[0m  0.0439\n",
      "      5        \u001b[36m0.7734\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.5314\u001b[0m  0.0429\n",
      "      6        \u001b[36m0.6510\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.4317\u001b[0m  0.0429\n",
      "      7        \u001b[36m0.5988\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.3659\u001b[0m  0.0529\n",
      "      8        \u001b[36m0.5321\u001b[0m       0.9014        \u001b[35m0.3157\u001b[0m  0.0708\n",
      "      9        \u001b[36m0.5114\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.2800\u001b[0m  0.0568\n",
      "     10        \u001b[36m0.4677\u001b[0m       0.9132        \u001b[35m0.2545\u001b[0m  0.0439\n",
      "     11        \u001b[36m0.4527\u001b[0m       \u001b[32m0.9310\u001b[0m        \u001b[35m0.2334\u001b[0m  0.0459\n",
      "     12        \u001b[36m0.4204\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.2176\u001b[0m  0.0439\n",
      "     13        \u001b[36m0.3921\u001b[0m       0.9349        \u001b[35m0.2076\u001b[0m  0.0489\n",
      "     14        \u001b[36m0.3916\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m0.1895\u001b[0m  0.0479\n",
      "     15        \u001b[36m0.3592\u001b[0m       0.9448        \u001b[35m0.1807\u001b[0m  0.0469\n",
      "     16        0.3608       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1707\u001b[0m  0.0499\n",
      "     17        \u001b[36m0.3402\u001b[0m       0.9527        \u001b[35m0.1701\u001b[0m  0.0449\n",
      "     18        \u001b[36m0.3397\u001b[0m       \u001b[32m0.9625\u001b[0m        \u001b[35m0.1595\u001b[0m  0.0489\n",
      "     19        \u001b[36m0.3381\u001b[0m       0.9527        \u001b[35m0.1560\u001b[0m  0.0409\n",
      "     20        \u001b[36m0.3237\u001b[0m       \u001b[32m0.9645\u001b[0m        \u001b[35m0.1488\u001b[0m  0.0459\n",
      "     21        \u001b[36m0.2889\u001b[0m       0.9546        0.1507  0.0549\n",
      "     22        0.3207       \u001b[32m0.9665\u001b[0m        \u001b[35m0.1424\u001b[0m  0.0708\n",
      "     23        0.3105       0.9527        0.1472  0.0519\n",
      "     24        0.2983       0.9546        0.1446  0.0539\n",
      "     25        \u001b[36m0.2858\u001b[0m       0.9527        0.1522  0.0519\n",
      "     26        0.3076       0.9546        0.1464  0.0439\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.6s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7843\u001b[0m       \u001b[32m0.5562\u001b[0m        \u001b[35m1.2130\u001b[0m  0.0429\n",
      "      2        \u001b[36m1.2683\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m1.0357\u001b[0m  0.0578\n",
      "      3        \u001b[36m1.0890\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.8130\u001b[0m  0.0578\n",
      "      4        \u001b[36m0.8836\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.6334\u001b[0m  0.0658\n",
      "      5        \u001b[36m0.7494\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.5073\u001b[0m  0.0618\n",
      "      6        \u001b[36m0.6700\u001b[0m       0.8817        \u001b[35m0.4240\u001b[0m  0.0639\n",
      "      7        \u001b[36m0.5970\u001b[0m       0.8777        \u001b[35m0.3699\u001b[0m  0.0578\n",
      "      8        \u001b[36m0.5006\u001b[0m       0.8777        \u001b[35m0.3381\u001b[0m  0.0469\n",
      "      9        \u001b[36m0.4997\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.2997\u001b[0m  0.0419\n",
      "     10        \u001b[36m0.4590\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.2773\u001b[0m  0.0429\n",
      "     11        \u001b[36m0.4215\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.2664\u001b[0m  0.0509\n",
      "     12        \u001b[36m0.4151\u001b[0m       \u001b[32m0.9349\u001b[0m        \u001b[35m0.2410\u001b[0m  0.0439\n",
      "     13        \u001b[36m0.3894\u001b[0m       0.9132        \u001b[35m0.2381\u001b[0m  0.0458\n",
      "     14        \u001b[36m0.3880\u001b[0m       \u001b[32m0.9369\u001b[0m        \u001b[35m0.2190\u001b[0m  0.0558\n",
      "     15        \u001b[36m0.3817\u001b[0m       0.9270        \u001b[35m0.2162\u001b[0m  0.0519\n",
      "     16        \u001b[36m0.3500\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.1999\u001b[0m  0.0509\n",
      "     17        \u001b[36m0.3426\u001b[0m       \u001b[32m0.9487\u001b[0m        \u001b[35m0.1923\u001b[0m  0.0429\n",
      "     18        \u001b[36m0.3242\u001b[0m       0.9369        \u001b[35m0.1910\u001b[0m  0.0539\n",
      "     19        \u001b[36m0.3203\u001b[0m       \u001b[32m0.9527\u001b[0m        \u001b[35m0.1790\u001b[0m  0.0429\n",
      "     20        \u001b[36m0.2898\u001b[0m       0.9428        0.1829  0.0519\n",
      "     21        0.3222       0.9527        \u001b[35m0.1677\u001b[0m  0.0588\n",
      "     22        \u001b[36m0.2756\u001b[0m       0.9408        0.1795  0.0529\n",
      "     23        0.3096       0.9487        \u001b[35m0.1551\u001b[0m  0.0568\n",
      "     24        \u001b[36m0.2580\u001b[0m       0.9389        0.1779  0.0588\n",
      "     25        0.2924       \u001b[32m0.9546\u001b[0m        \u001b[35m0.1520\u001b[0m  0.0409\n",
      "     26        0.2586       0.9290        0.1851  0.0469\n",
      "     27        0.2945       0.9448        0.1584  0.0559\n",
      "     28        0.2648       0.9270        0.2020  0.0618\n",
      "     29        0.3343       0.9448        0.1597  0.0479\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   1.9s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8350\u001b[0m       \u001b[32m0.3057\u001b[0m        \u001b[35m1.2269\u001b[0m  0.0479\n",
      "      2        \u001b[36m1.2343\u001b[0m       \u001b[32m0.7653\u001b[0m        \u001b[35m1.0176\u001b[0m  0.0449\n",
      "      3        \u001b[36m1.0473\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.7963\u001b[0m  0.0489\n",
      "      4        \u001b[36m0.8480\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.6234\u001b[0m  0.0568\n",
      "      5        \u001b[36m0.7301\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.4944\u001b[0m  0.0549\n",
      "      6        \u001b[36m0.6353\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.3994\u001b[0m  0.0509\n",
      "      7        \u001b[36m0.5703\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.3355\u001b[0m  0.0618\n",
      "      8        \u001b[36m0.5116\u001b[0m       \u001b[32m0.9310\u001b[0m        \u001b[35m0.2937\u001b[0m  0.0559\n",
      "      9        \u001b[36m0.5075\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m0.2652\u001b[0m  0.0598\n",
      "     10        \u001b[36m0.4694\u001b[0m       0.9408        \u001b[35m0.2420\u001b[0m  0.0638\n",
      "     11        \u001b[36m0.4432\u001b[0m       \u001b[32m0.9467\u001b[0m        \u001b[35m0.2231\u001b[0m  0.0509\n",
      "     12        \u001b[36m0.4019\u001b[0m       \u001b[32m0.9487\u001b[0m        \u001b[35m0.2084\u001b[0m  0.0519\n",
      "     13        \u001b[36m0.3861\u001b[0m       \u001b[32m0.9527\u001b[0m        \u001b[35m0.1942\u001b[0m  0.0519\n",
      "     14        0.3906       \u001b[32m0.9586\u001b[0m        \u001b[35m0.1839\u001b[0m  0.0499\n",
      "     15        \u001b[36m0.3534\u001b[0m       \u001b[32m0.9606\u001b[0m        \u001b[35m0.1756\u001b[0m  0.0439\n",
      "     16        0.3600       \u001b[32m0.9645\u001b[0m        \u001b[35m0.1677\u001b[0m  0.0519\n",
      "     17        \u001b[36m0.3477\u001b[0m       \u001b[32m0.9665\u001b[0m        \u001b[35m0.1598\u001b[0m  0.0549\n",
      "     18        \u001b[36m0.3371\u001b[0m       0.9606        \u001b[35m0.1560\u001b[0m  0.0509\n",
      "     19        \u001b[36m0.3176\u001b[0m       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1480\u001b[0m  0.0429\n",
      "     20        \u001b[36m0.3090\u001b[0m       0.9665        \u001b[35m0.1442\u001b[0m  0.0608\n",
      "     21        \u001b[36m0.2832\u001b[0m       0.9684        \u001b[35m0.1385\u001b[0m  0.0649\n",
      "     22        0.3070       0.9625        0.1401  0.0459\n",
      "     23        0.3001       \u001b[32m0.9704\u001b[0m        \u001b[35m0.1302\u001b[0m  0.0499\n",
      "     24        \u001b[36m0.2643\u001b[0m       0.9704        \u001b[35m0.1279\u001b[0m  0.0469\n",
      "     25        0.2779       0.9684        \u001b[35m0.1239\u001b[0m  0.0559\n",
      "     26        \u001b[36m0.2526\u001b[0m       \u001b[32m0.9724\u001b[0m        \u001b[35m0.1225\u001b[0m  0.0449\n",
      "     27        0.2690       0.9704        \u001b[35m0.1184\u001b[0m  0.0459\n",
      "     28        0.2683       0.9704        0.1201  0.0439\n",
      "     29        0.2559       0.9625        \u001b[35m0.1166\u001b[0m  0.0519\n",
      "     30        0.2783       0.9665        0.1237  0.0559\n",
      "     31        \u001b[36m0.2487\u001b[0m       0.9566        0.1169  0.0439\n",
      "     32        \u001b[36m0.2455\u001b[0m       0.9606        0.1359  0.0499\n",
      "     33        0.2721       0.9527        0.1293  0.0588\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   2.1s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4745\u001b[0m       \u001b[32m0.2268\u001b[0m        \u001b[35m1.4125\u001b[0m  0.0379\n",
      "      2        \u001b[36m1.4541\u001b[0m       \u001b[32m0.2564\u001b[0m        \u001b[35m1.3957\u001b[0m  0.0668\n",
      "      3        \u001b[36m1.4362\u001b[0m       \u001b[32m0.2860\u001b[0m        \u001b[35m1.3807\u001b[0m  0.0529\n",
      "      4        \u001b[36m1.4187\u001b[0m       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3670\u001b[0m  0.0439\n",
      "      5        \u001b[36m1.3919\u001b[0m       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3543\u001b[0m  0.0648\n",
      "      6        1.4018       \u001b[32m0.3412\u001b[0m        \u001b[35m1.3420\u001b[0m  0.0478\n",
      "      7        \u001b[36m1.3852\u001b[0m       \u001b[32m0.3669\u001b[0m        \u001b[35m1.3301\u001b[0m  0.0608\n",
      "      8        \u001b[36m1.3737\u001b[0m       \u001b[32m0.4004\u001b[0m        \u001b[35m1.3188\u001b[0m  0.0529\n",
      "      9        \u001b[36m1.3619\u001b[0m       \u001b[32m0.4162\u001b[0m        \u001b[35m1.3080\u001b[0m  0.0529\n",
      "     10        \u001b[36m1.3382\u001b[0m       \u001b[32m0.4359\u001b[0m        \u001b[35m1.2970\u001b[0m  0.0539\n",
      "     11        \u001b[36m1.3344\u001b[0m       \u001b[32m0.4576\u001b[0m        \u001b[35m1.2867\u001b[0m  0.0559\n",
      "     12        \u001b[36m1.3249\u001b[0m       \u001b[32m0.4832\u001b[0m        \u001b[35m1.2761\u001b[0m  0.0429\n",
      "     13        \u001b[36m1.3147\u001b[0m       \u001b[32m0.5030\u001b[0m        \u001b[35m1.2659\u001b[0m  0.0499\n",
      "     14        \u001b[36m1.2995\u001b[0m       \u001b[32m0.5207\u001b[0m        \u001b[35m1.2560\u001b[0m  0.0489\n",
      "     15        \u001b[36m1.2854\u001b[0m       \u001b[32m0.5365\u001b[0m        \u001b[35m1.2455\u001b[0m  0.0608\n",
      "     16        \u001b[36m1.2795\u001b[0m       \u001b[32m0.5641\u001b[0m        \u001b[35m1.2350\u001b[0m  0.0558\n",
      "     17        \u001b[36m1.2743\u001b[0m       \u001b[32m0.5819\u001b[0m        \u001b[35m1.2247\u001b[0m  0.0409\n",
      "     18        \u001b[36m1.2666\u001b[0m       \u001b[32m0.5976\u001b[0m        \u001b[35m1.2148\u001b[0m  0.0639\n",
      "     19        \u001b[36m1.2631\u001b[0m       \u001b[32m0.6095\u001b[0m        \u001b[35m1.2050\u001b[0m  0.0649\n",
      "     20        \u001b[36m1.2454\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m1.1950\u001b[0m  0.0509\n",
      "     21        \u001b[36m1.2411\u001b[0m       \u001b[32m0.6331\u001b[0m        \u001b[35m1.1850\u001b[0m  0.0608\n",
      "     22        \u001b[36m1.2309\u001b[0m       \u001b[32m0.6410\u001b[0m        \u001b[35m1.1747\u001b[0m  0.0409\n",
      "     23        1.2315       \u001b[32m0.6450\u001b[0m        \u001b[35m1.1647\u001b[0m  0.0409\n",
      "     24        \u001b[36m1.2189\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.1548\u001b[0m  0.0529\n",
      "     25        \u001b[36m1.2086\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m1.1450\u001b[0m  0.0499\n",
      "     26        \u001b[36m1.1903\u001b[0m       \u001b[32m0.6627\u001b[0m        \u001b[35m1.1349\u001b[0m  0.0479\n",
      "     27        1.1910       \u001b[32m0.6686\u001b[0m        \u001b[35m1.1249\u001b[0m  0.0489\n",
      "     28        \u001b[36m1.1713\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m1.1148\u001b[0m  0.0449\n",
      "     29        1.1748       \u001b[32m0.6844\u001b[0m        \u001b[35m1.1049\u001b[0m  0.0429\n",
      "     30        \u001b[36m1.1651\u001b[0m       0.6844        \u001b[35m1.0951\u001b[0m  0.0588\n",
      "     31        \u001b[36m1.1503\u001b[0m       \u001b[32m0.6963\u001b[0m        \u001b[35m1.0851\u001b[0m  0.0489\n",
      "     32        \u001b[36m1.1485\u001b[0m       0.6963        \u001b[35m1.0750\u001b[0m  0.0539\n",
      "     33        \u001b[36m1.1366\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m1.0650\u001b[0m  0.0609\n",
      "     34        \u001b[36m1.1300\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.0549\u001b[0m  0.0638\n",
      "     35        \u001b[36m1.1196\u001b[0m       0.7061        \u001b[35m1.0449\u001b[0m  0.0489\n",
      "     36        \u001b[36m1.1127\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m1.0351\u001b[0m  0.0479\n",
      "     37        \u001b[36m1.0919\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m1.0249\u001b[0m  0.0469\n",
      "     38        1.1043       \u001b[32m0.7199\u001b[0m        \u001b[35m1.0149\u001b[0m  0.0519\n",
      "     39        \u001b[36m1.0904\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m1.0050\u001b[0m  0.0489\n",
      "     40        \u001b[36m1.0727\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m0.9952\u001b[0m  0.0598\n",
      "     41        \u001b[36m1.0717\u001b[0m       0.7377        \u001b[35m0.9856\u001b[0m  0.0559\n",
      "     42        \u001b[36m1.0540\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.9756\u001b[0m  0.0459\n",
      "     43        \u001b[36m1.0480\u001b[0m       0.7396        \u001b[35m0.9663\u001b[0m  0.0389\n",
      "     44        1.0528       \u001b[32m0.7456\u001b[0m        \u001b[35m0.9568\u001b[0m  0.0499\n",
      "     45        \u001b[36m1.0472\u001b[0m       0.7456        \u001b[35m0.9475\u001b[0m  0.0399\n",
      "     46        \u001b[36m1.0357\u001b[0m       0.7456        \u001b[35m0.9383\u001b[0m  0.0429\n",
      "     47        \u001b[36m1.0186\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m0.9291\u001b[0m  0.0488\n",
      "     48        \u001b[36m1.0138\u001b[0m       \u001b[32m0.7535\u001b[0m        \u001b[35m0.9199\u001b[0m  0.0618\n",
      "     49        1.0187       \u001b[32m0.7673\u001b[0m        \u001b[35m0.9109\u001b[0m  0.0389\n",
      "     50        \u001b[36m0.9986\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.9018\u001b[0m  0.0389\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.2s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3962\u001b[0m       \u001b[32m0.4024\u001b[0m        \u001b[35m1.3416\u001b[0m  0.0519\n",
      "      2        \u001b[36m1.3814\u001b[0m       \u001b[32m0.4536\u001b[0m        \u001b[35m1.3288\u001b[0m  0.0499\n",
      "      3        \u001b[36m1.3733\u001b[0m       \u001b[32m0.4872\u001b[0m        \u001b[35m1.3170\u001b[0m  0.0449\n",
      "      4        \u001b[36m1.3567\u001b[0m       \u001b[32m0.4970\u001b[0m        \u001b[35m1.3053\u001b[0m  0.0439\n",
      "      5        \u001b[36m1.3486\u001b[0m       \u001b[32m0.5010\u001b[0m        \u001b[35m1.2945\u001b[0m  0.0399\n",
      "      6        \u001b[36m1.3336\u001b[0m       \u001b[32m0.5187\u001b[0m        \u001b[35m1.2841\u001b[0m  0.0459\n",
      "      7        \u001b[36m1.3293\u001b[0m       \u001b[32m0.5385\u001b[0m        \u001b[35m1.2743\u001b[0m  0.0668\n",
      "      8        \u001b[36m1.3280\u001b[0m       \u001b[32m0.5523\u001b[0m        \u001b[35m1.2643\u001b[0m  0.0469\n",
      "      9        \u001b[36m1.3086\u001b[0m       \u001b[32m0.5799\u001b[0m        \u001b[35m1.2542\u001b[0m  0.0389\n",
      "     10        \u001b[36m1.3043\u001b[0m       \u001b[32m0.5838\u001b[0m        \u001b[35m1.2449\u001b[0m  0.0479\n",
      "     11        \u001b[36m1.2945\u001b[0m       \u001b[32m0.5957\u001b[0m        \u001b[35m1.2352\u001b[0m  0.0469\n",
      "     12        \u001b[36m1.2878\u001b[0m       \u001b[32m0.6193\u001b[0m        \u001b[35m1.2258\u001b[0m  0.0439\n",
      "     13        \u001b[36m1.2780\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.2163\u001b[0m  0.0549\n",
      "     14        \u001b[36m1.2645\u001b[0m       \u001b[32m0.6351\u001b[0m        \u001b[35m1.2069\u001b[0m  0.0479\n",
      "     15        \u001b[36m1.2508\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.1972\u001b[0m  0.0429\n",
      "     16        \u001b[36m1.2485\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.1877\u001b[0m  0.0409\n",
      "     17        \u001b[36m1.2388\u001b[0m       0.6529        \u001b[35m1.1783\u001b[0m  0.0389\n",
      "     18        \u001b[36m1.2266\u001b[0m       \u001b[32m0.6548\u001b[0m        \u001b[35m1.1689\u001b[0m  0.0389\n",
      "     19        \u001b[36m1.2189\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.1593\u001b[0m  0.0489\n",
      "     20        \u001b[36m1.2142\u001b[0m       \u001b[32m0.6667\u001b[0m        \u001b[35m1.1498\u001b[0m  0.0449\n",
      "     21        \u001b[36m1.2044\u001b[0m       \u001b[32m0.6726\u001b[0m        \u001b[35m1.1400\u001b[0m  0.0419\n",
      "     22        \u001b[36m1.2025\u001b[0m       \u001b[32m0.6746\u001b[0m        \u001b[35m1.1306\u001b[0m  0.0509\n",
      "     23        \u001b[36m1.1842\u001b[0m       \u001b[32m0.6805\u001b[0m        \u001b[35m1.1208\u001b[0m  0.0529\n",
      "     24        \u001b[36m1.1719\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m1.1108\u001b[0m  0.0598\n",
      "     25        \u001b[36m1.1634\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m1.1008\u001b[0m  0.0419\n",
      "     26        \u001b[36m1.1558\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m1.0910\u001b[0m  0.0409\n",
      "     27        1.1656       \u001b[32m0.7081\u001b[0m        \u001b[35m1.0814\u001b[0m  0.0389\n",
      "     28        \u001b[36m1.1495\u001b[0m       \u001b[32m0.7140\u001b[0m        \u001b[35m1.0715\u001b[0m  0.0449\n",
      "     29        \u001b[36m1.1275\u001b[0m       0.7140        \u001b[35m1.0616\u001b[0m  0.0389\n",
      "     30        1.1276       0.7140        \u001b[35m1.0520\u001b[0m  0.0519\n",
      "     31        \u001b[36m1.1111\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m1.0422\u001b[0m  0.0488\n",
      "     32        \u001b[36m1.0987\u001b[0m       \u001b[32m0.7199\u001b[0m        \u001b[35m1.0324\u001b[0m  0.0539\n",
      "     33        1.1054       \u001b[32m0.7239\u001b[0m        \u001b[35m1.0229\u001b[0m  0.0678\n",
      "     34        \u001b[36m1.0956\u001b[0m       0.7239        \u001b[35m1.0135\u001b[0m  0.0559\n",
      "     35        \u001b[36m1.0953\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m1.0039\u001b[0m  0.0409\n",
      "     36        \u001b[36m1.0836\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m0.9944\u001b[0m  0.0479\n",
      "     37        \u001b[36m1.0790\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m0.9849\u001b[0m  0.0558\n",
      "     38        \u001b[36m1.0620\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m0.9753\u001b[0m  0.0529\n",
      "     39        \u001b[36m1.0534\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.9659\u001b[0m  0.0419\n",
      "     40        \u001b[36m1.0488\u001b[0m       0.7396        \u001b[35m0.9568\u001b[0m  0.0499\n",
      "     41        \u001b[36m1.0333\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.9476\u001b[0m  0.0469\n",
      "     42        1.0424       \u001b[32m0.7495\u001b[0m        \u001b[35m0.9389\u001b[0m  0.0588\n",
      "     43        \u001b[36m1.0243\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m0.9300\u001b[0m  0.0519\n",
      "     44        \u001b[36m1.0078\u001b[0m       \u001b[32m0.7554\u001b[0m        \u001b[35m0.9209\u001b[0m  0.0499\n",
      "     45        \u001b[36m1.0024\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m0.9120\u001b[0m  0.0559\n",
      "     46        1.0114       \u001b[32m0.7633\u001b[0m        \u001b[35m0.9033\u001b[0m  0.0519\n",
      "     47        \u001b[36m0.9972\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m0.8946\u001b[0m  0.0568\n",
      "     48        \u001b[36m0.9812\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m0.8859\u001b[0m  0.0449\n",
      "     49        0.9819       \u001b[32m0.7732\u001b[0m        \u001b[35m0.8779\u001b[0m  0.0559\n",
      "     50        \u001b[36m0.9781\u001b[0m       0.7712        \u001b[35m0.8695\u001b[0m  0.0409\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3758\u001b[0m       \u001b[32m0.4241\u001b[0m        \u001b[35m1.3113\u001b[0m  0.0399\n",
      "      2        \u001b[36m1.3648\u001b[0m       \u001b[32m0.4635\u001b[0m        \u001b[35m1.2954\u001b[0m  0.0588\n",
      "      3        \u001b[36m1.3408\u001b[0m       \u001b[32m0.5089\u001b[0m        \u001b[35m1.2809\u001b[0m  0.0519\n",
      "      4        \u001b[36m1.3263\u001b[0m       \u001b[32m0.5404\u001b[0m        \u001b[35m1.2676\u001b[0m  0.0608\n",
      "      5        \u001b[36m1.3135\u001b[0m       \u001b[32m0.5503\u001b[0m        \u001b[35m1.2543\u001b[0m  0.0568\n",
      "      6        \u001b[36m1.3102\u001b[0m       \u001b[32m0.5759\u001b[0m        \u001b[35m1.2416\u001b[0m  0.0449\n",
      "      7        \u001b[36m1.2809\u001b[0m       \u001b[32m0.5878\u001b[0m        \u001b[35m1.2292\u001b[0m  0.0399\n",
      "      8        \u001b[36m1.2785\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m1.2168\u001b[0m  0.0648\n",
      "      9        \u001b[36m1.2584\u001b[0m       \u001b[32m0.6036\u001b[0m        \u001b[35m1.2050\u001b[0m  0.0638\n",
      "     10        1.2650       \u001b[32m0.6134\u001b[0m        \u001b[35m1.1940\u001b[0m  0.0558\n",
      "     11        \u001b[36m1.2362\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.1829\u001b[0m  0.0389\n",
      "     12        \u001b[36m1.2340\u001b[0m       \u001b[32m0.6292\u001b[0m        \u001b[35m1.1720\u001b[0m  0.0399\n",
      "     13        \u001b[36m1.2279\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.1612\u001b[0m  0.0499\n",
      "     14        \u001b[36m1.2168\u001b[0m       \u001b[32m0.6469\u001b[0m        \u001b[35m1.1506\u001b[0m  0.0568\n",
      "     15        \u001b[36m1.2153\u001b[0m       \u001b[32m0.6548\u001b[0m        \u001b[35m1.1399\u001b[0m  0.0489\n",
      "     16        \u001b[36m1.1895\u001b[0m       \u001b[32m0.6568\u001b[0m        \u001b[35m1.1295\u001b[0m  0.0528\n",
      "     17        \u001b[36m1.1847\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.1191\u001b[0m  0.0589\n",
      "     18        \u001b[36m1.1676\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.1087\u001b[0m  0.0479\n",
      "     19        \u001b[36m1.1656\u001b[0m       \u001b[32m0.6746\u001b[0m        \u001b[35m1.0986\u001b[0m  0.0409\n",
      "     20        \u001b[36m1.1543\u001b[0m       \u001b[32m0.6805\u001b[0m        \u001b[35m1.0885\u001b[0m  0.0449\n",
      "     21        \u001b[36m1.1401\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m1.0782\u001b[0m  0.0578\n",
      "     22        \u001b[36m1.1386\u001b[0m       \u001b[32m0.6903\u001b[0m        \u001b[35m1.0685\u001b[0m  0.0509\n",
      "     23        \u001b[36m1.1095\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m1.0585\u001b[0m  0.0618\n",
      "     24        1.1242       \u001b[32m0.6982\u001b[0m        \u001b[35m1.0489\u001b[0m  0.0499\n",
      "     25        1.1148       \u001b[32m0.7041\u001b[0m        \u001b[35m1.0392\u001b[0m  0.0549\n",
      "     26        \u001b[36m1.0987\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.0296\u001b[0m  0.0449\n",
      "     27        1.1065       \u001b[32m0.7140\u001b[0m        \u001b[35m1.0202\u001b[0m  0.0618\n",
      "     28        \u001b[36m1.0981\u001b[0m       \u001b[32m0.7199\u001b[0m        \u001b[35m1.0111\u001b[0m  0.0389\n",
      "     29        \u001b[36m1.0641\u001b[0m       0.7199        \u001b[35m1.0015\u001b[0m  0.0559\n",
      "     30        1.0648       \u001b[32m0.7258\u001b[0m        \u001b[35m0.9921\u001b[0m  0.0549\n",
      "     31        \u001b[36m1.0629\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m0.9827\u001b[0m  0.0409\n",
      "     32        \u001b[36m1.0621\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m0.9737\u001b[0m  0.0499\n",
      "     33        \u001b[36m1.0492\u001b[0m       \u001b[32m0.7357\u001b[0m        \u001b[35m0.9648\u001b[0m  0.0499\n",
      "     34        \u001b[36m1.0357\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m0.9558\u001b[0m  0.0539\n",
      "     35        \u001b[36m1.0211\u001b[0m       0.7377        \u001b[35m0.9470\u001b[0m  0.0559\n",
      "     36        1.0321       \u001b[32m0.7396\u001b[0m        \u001b[35m0.9382\u001b[0m  0.0608\n",
      "     37        1.0288       \u001b[32m0.7436\u001b[0m        \u001b[35m0.9297\u001b[0m  0.0568\n",
      "     38        \u001b[36m1.0141\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m0.9211\u001b[0m  0.0479\n",
      "     39        \u001b[36m0.9981\u001b[0m       0.7495        \u001b[35m0.9126\u001b[0m  0.0519\n",
      "     40        \u001b[36m0.9910\u001b[0m       \u001b[32m0.7535\u001b[0m        \u001b[35m0.9042\u001b[0m  0.0578\n",
      "     41        0.9920       \u001b[32m0.7594\u001b[0m        \u001b[35m0.8960\u001b[0m  0.0479\n",
      "     42        \u001b[36m0.9900\u001b[0m       \u001b[32m0.7613\u001b[0m        \u001b[35m0.8880\u001b[0m  0.0459\n",
      "     43        \u001b[36m0.9761\u001b[0m       0.7613        \u001b[35m0.8798\u001b[0m  0.0419\n",
      "     44        \u001b[36m0.9477\u001b[0m       \u001b[32m0.7653\u001b[0m        \u001b[35m0.8718\u001b[0m  0.0419\n",
      "     45        0.9591       0.7653        \u001b[35m0.8638\u001b[0m  0.0588\n",
      "     46        \u001b[36m0.9449\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m0.8559\u001b[0m  0.0549\n",
      "     47        0.9573       \u001b[32m0.7732\u001b[0m        \u001b[35m0.8485\u001b[0m  0.0668\n",
      "     48        \u001b[36m0.9376\u001b[0m       \u001b[32m0.7751\u001b[0m        \u001b[35m0.8409\u001b[0m  0.0638\n",
      "     49        \u001b[36m0.9341\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.8334\u001b[0m  0.0389\n",
      "     50        \u001b[36m0.9274\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.8259\u001b[0m  0.0638\n",
      "[CV]  lr=0.01, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.2s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4508\u001b[0m       \u001b[32m0.2110\u001b[0m        \u001b[35m1.4190\u001b[0m  0.0419\n",
      "      2        \u001b[36m1.4228\u001b[0m       \u001b[32m0.2465\u001b[0m        \u001b[35m1.4047\u001b[0m  0.0638\n",
      "      3        \u001b[36m1.4078\u001b[0m       \u001b[32m0.2702\u001b[0m        \u001b[35m1.3910\u001b[0m  0.0578\n",
      "      4        \u001b[36m1.3952\u001b[0m       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3779\u001b[0m  0.0469\n",
      "      5        \u001b[36m1.3825\u001b[0m       \u001b[32m0.3432\u001b[0m        \u001b[35m1.3653\u001b[0m  0.0559\n",
      "      6        \u001b[36m1.3752\u001b[0m       \u001b[32m0.3688\u001b[0m        \u001b[35m1.3529\u001b[0m  0.0748\n",
      "      7        \u001b[36m1.3549\u001b[0m       \u001b[32m0.3964\u001b[0m        \u001b[35m1.3406\u001b[0m  0.0459\n",
      "      8        \u001b[36m1.3513\u001b[0m       \u001b[32m0.4339\u001b[0m        \u001b[35m1.3281\u001b[0m  0.0638\n",
      "      9        \u001b[36m1.3326\u001b[0m       \u001b[32m0.4536\u001b[0m        \u001b[35m1.3154\u001b[0m  0.0578\n",
      "     10        \u001b[36m1.3224\u001b[0m       \u001b[32m0.4931\u001b[0m        \u001b[35m1.3022\u001b[0m  0.0568\n",
      "     11        \u001b[36m1.3123\u001b[0m       \u001b[32m0.5325\u001b[0m        \u001b[35m1.2885\u001b[0m  0.0549\n",
      "     12        \u001b[36m1.2943\u001b[0m       \u001b[32m0.5720\u001b[0m        \u001b[35m1.2742\u001b[0m  0.0659\n",
      "     13        \u001b[36m1.2824\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m1.2594\u001b[0m  0.0539\n",
      "     14        \u001b[36m1.2682\u001b[0m       \u001b[32m0.6292\u001b[0m        \u001b[35m1.2438\u001b[0m  0.0549\n",
      "     15        \u001b[36m1.2549\u001b[0m       \u001b[32m0.6469\u001b[0m        \u001b[35m1.2276\u001b[0m  0.0429\n",
      "     16        \u001b[36m1.2411\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m1.2107\u001b[0m  0.0519\n",
      "     17        \u001b[36m1.2218\u001b[0m       \u001b[32m0.6746\u001b[0m        \u001b[35m1.1930\u001b[0m  0.0499\n",
      "     18        \u001b[36m1.1965\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m1.1747\u001b[0m  0.0708\n",
      "     19        \u001b[36m1.1815\u001b[0m       \u001b[32m0.6963\u001b[0m        \u001b[35m1.1557\u001b[0m  0.0698\n",
      "     20        \u001b[36m1.1721\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m1.1364\u001b[0m  0.0598\n",
      "     21        \u001b[36m1.1544\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.1170\u001b[0m  0.0469\n",
      "     22        \u001b[36m1.1364\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m1.0973\u001b[0m  0.0529\n",
      "     23        \u001b[36m1.1248\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m1.0775\u001b[0m  0.0529\n",
      "     24        \u001b[36m1.0908\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m1.0573\u001b[0m  0.0479\n",
      "     25        \u001b[36m1.0856\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m1.0372\u001b[0m  0.0469\n",
      "     26        \u001b[36m1.0688\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m1.0175\u001b[0m  0.0668\n",
      "     27        \u001b[36m1.0377\u001b[0m       \u001b[32m0.7416\u001b[0m        \u001b[35m0.9974\u001b[0m  0.0598\n",
      "     28        \u001b[36m1.0207\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m0.9775\u001b[0m  0.0628\n",
      "     29        \u001b[36m1.0145\u001b[0m       \u001b[32m0.7535\u001b[0m        \u001b[35m0.9582\u001b[0m  0.0429\n",
      "     30        \u001b[36m0.9950\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m0.9396\u001b[0m  0.0539\n",
      "     31        \u001b[36m0.9792\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m0.9212\u001b[0m  0.0439\n",
      "     32        \u001b[36m0.9680\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m0.9032\u001b[0m  0.0678\n",
      "     33        \u001b[36m0.9494\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m0.8856\u001b[0m  0.0648\n",
      "     34        \u001b[36m0.9366\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.8685\u001b[0m  0.0578\n",
      "     35        \u001b[36m0.9060\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.8515\u001b[0m  0.0519\n",
      "     36        \u001b[36m0.9037\u001b[0m       \u001b[32m0.7909\u001b[0m        \u001b[35m0.8350\u001b[0m  0.0628\n",
      "     37        \u001b[36m0.8708\u001b[0m       \u001b[32m0.7949\u001b[0m        \u001b[35m0.8189\u001b[0m  0.0549\n",
      "     38        0.8755       \u001b[32m0.7988\u001b[0m        \u001b[35m0.8033\u001b[0m  0.0539\n",
      "     39        \u001b[36m0.8567\u001b[0m       \u001b[32m0.8028\u001b[0m        \u001b[35m0.7879\u001b[0m  0.0728\n",
      "     40        \u001b[36m0.8319\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.7732\u001b[0m  0.0509\n",
      "     41        \u001b[36m0.8259\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.7586\u001b[0m  0.0509\n",
      "     42        \u001b[36m0.8146\u001b[0m       \u001b[32m0.8185\u001b[0m        \u001b[35m0.7445\u001b[0m  0.0658\n",
      "     43        0.8196       \u001b[32m0.8264\u001b[0m        \u001b[35m0.7309\u001b[0m  0.0618\n",
      "     44        \u001b[36m0.7891\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.7178\u001b[0m  0.0529\n",
      "     45        \u001b[36m0.7770\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.7050\u001b[0m  0.0469\n",
      "     46        \u001b[36m0.7719\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.6924\u001b[0m  0.0708\n",
      "     47        \u001b[36m0.7584\u001b[0m       \u001b[32m0.8442\u001b[0m        \u001b[35m0.6801\u001b[0m  0.0539\n",
      "     48        \u001b[36m0.7551\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.6681\u001b[0m  0.0648\n",
      "     49        \u001b[36m0.7401\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.6567\u001b[0m  0.0578\n",
      "     50        \u001b[36m0.7377\u001b[0m       0.8501        \u001b[35m0.6454\u001b[0m  0.0499\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.5s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3920\u001b[0m       \u001b[32m0.2821\u001b[0m        \u001b[35m1.3724\u001b[0m  0.0658\n",
      "      2        \u001b[36m1.3621\u001b[0m       \u001b[32m0.3097\u001b[0m        \u001b[35m1.3539\u001b[0m  0.0628\n",
      "      3        \u001b[36m1.3457\u001b[0m       \u001b[32m0.3471\u001b[0m        \u001b[35m1.3344\u001b[0m  0.0549\n",
      "      4        \u001b[36m1.3259\u001b[0m       \u001b[32m0.4142\u001b[0m        \u001b[35m1.3144\u001b[0m  0.0519\n",
      "      5        \u001b[36m1.3140\u001b[0m       \u001b[32m0.4852\u001b[0m        \u001b[35m1.2943\u001b[0m  0.0519\n",
      "      6        \u001b[36m1.2890\u001b[0m       \u001b[32m0.5404\u001b[0m        \u001b[35m1.2734\u001b[0m  0.0648\n",
      "      7        \u001b[36m1.2594\u001b[0m       \u001b[32m0.5700\u001b[0m        \u001b[35m1.2520\u001b[0m  0.0588\n",
      "      8        \u001b[36m1.2515\u001b[0m       \u001b[32m0.5937\u001b[0m        \u001b[35m1.2303\u001b[0m  0.0598\n",
      "      9        \u001b[36m1.2277\u001b[0m       \u001b[32m0.6036\u001b[0m        \u001b[35m1.2082\u001b[0m  0.0578\n",
      "     10        \u001b[36m1.2035\u001b[0m       \u001b[32m0.6134\u001b[0m        \u001b[35m1.1860\u001b[0m  0.0568\n",
      "     11        \u001b[36m1.1783\u001b[0m       \u001b[32m0.6252\u001b[0m        \u001b[35m1.1635\u001b[0m  0.0469\n",
      "     12        \u001b[36m1.1665\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.1408\u001b[0m  0.0499\n",
      "     13        \u001b[36m1.1396\u001b[0m       \u001b[32m0.6529\u001b[0m        \u001b[35m1.1180\u001b[0m  0.0578\n",
      "     14        \u001b[36m1.1252\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m1.0955\u001b[0m  0.0618\n",
      "     15        \u001b[36m1.1015\u001b[0m       \u001b[32m0.6726\u001b[0m        \u001b[35m1.0734\u001b[0m  0.0688\n",
      "     16        \u001b[36m1.0809\u001b[0m       \u001b[32m0.6805\u001b[0m        \u001b[35m1.0512\u001b[0m  0.0489\n",
      "     17        \u001b[36m1.0698\u001b[0m       0.6805        \u001b[35m1.0299\u001b[0m  0.0638\n",
      "     18        \u001b[36m1.0541\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.0091\u001b[0m  0.0549\n",
      "     19        \u001b[36m1.0317\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m0.9888\u001b[0m  0.0598\n",
      "     20        \u001b[36m1.0067\u001b[0m       \u001b[32m0.7120\u001b[0m        \u001b[35m0.9688\u001b[0m  0.0748\n",
      "     21        \u001b[36m0.9856\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m0.9489\u001b[0m  0.0539\n",
      "     22        \u001b[36m0.9714\u001b[0m       \u001b[32m0.7357\u001b[0m        \u001b[35m0.9295\u001b[0m  0.0419\n",
      "     23        \u001b[36m0.9510\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.9110\u001b[0m  0.0429\n",
      "     24        \u001b[36m0.9376\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m0.8930\u001b[0m  0.0419\n",
      "     25        \u001b[36m0.9256\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m0.8756\u001b[0m  0.0519\n",
      "     26        \u001b[36m0.9162\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m0.8586\u001b[0m  0.0489\n",
      "     27        \u001b[36m0.9000\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m0.8423\u001b[0m  0.0479\n",
      "     28        \u001b[36m0.8858\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.8265\u001b[0m  0.0499\n",
      "     29        \u001b[36m0.8603\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m0.8110\u001b[0m  0.0588\n",
      "     30        \u001b[36m0.8525\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.7959\u001b[0m  0.0669\n",
      "     31        \u001b[36m0.8411\u001b[0m       \u001b[32m0.7949\u001b[0m        \u001b[35m0.7813\u001b[0m  0.0518\n",
      "     32        \u001b[36m0.8218\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.7670\u001b[0m  0.0509\n",
      "     33        \u001b[36m0.8168\u001b[0m       0.8008        \u001b[35m0.7532\u001b[0m  0.0429\n",
      "     34        \u001b[36m0.8139\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.7398\u001b[0m  0.0419\n",
      "     35        \u001b[36m0.7845\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.7266\u001b[0m  0.0519\n",
      "     36        \u001b[36m0.7777\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.7138\u001b[0m  0.0589\n",
      "     37        \u001b[36m0.7657\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.7013\u001b[0m  0.0519\n",
      "     38        \u001b[36m0.7404\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.6889\u001b[0m  0.0478\n",
      "     39        \u001b[36m0.7340\u001b[0m       0.8323        \u001b[35m0.6770\u001b[0m  0.0549\n",
      "     40        \u001b[36m0.7332\u001b[0m       0.8323        \u001b[35m0.6657\u001b[0m  0.0489\n",
      "     41        \u001b[36m0.7230\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.6546\u001b[0m  0.0499\n",
      "     42        \u001b[36m0.7095\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.6438\u001b[0m  0.0459\n",
      "     43        \u001b[36m0.7036\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.6332\u001b[0m  0.0608\n",
      "     44        \u001b[36m0.6896\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.6228\u001b[0m  0.0459\n",
      "     45        \u001b[36m0.6876\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.6126\u001b[0m  0.0598\n",
      "     46        \u001b[36m0.6835\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.6030\u001b[0m  0.0678\n",
      "     47        \u001b[36m0.6638\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.5936\u001b[0m  0.0618\n",
      "     48        \u001b[36m0.6606\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.5844\u001b[0m  0.0628\n",
      "     49        \u001b[36m0.6545\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.5756\u001b[0m  0.0708\n",
      "     50        \u001b[36m0.6476\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.5670\u001b[0m  0.0638\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.4s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4428\u001b[0m       \u001b[32m0.2032\u001b[0m        \u001b[35m1.4059\u001b[0m  0.0658\n",
      "      2        \u001b[36m1.4088\u001b[0m       \u001b[32m0.2406\u001b[0m        \u001b[35m1.3912\u001b[0m  0.0638\n",
      "      3        \u001b[36m1.3943\u001b[0m       \u001b[32m0.2643\u001b[0m        \u001b[35m1.3767\u001b[0m  0.0608\n",
      "      4        \u001b[36m1.3790\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3624\u001b[0m  0.0549\n",
      "      5        \u001b[36m1.3662\u001b[0m       \u001b[32m0.3570\u001b[0m        \u001b[35m1.3483\u001b[0m  0.0479\n",
      "      6        \u001b[36m1.3490\u001b[0m       \u001b[32m0.4201\u001b[0m        \u001b[35m1.3341\u001b[0m  0.0668\n",
      "      7        \u001b[36m1.3379\u001b[0m       \u001b[32m0.4596\u001b[0m        \u001b[35m1.3194\u001b[0m  0.0618\n",
      "      8        \u001b[36m1.3226\u001b[0m       \u001b[32m0.4931\u001b[0m        \u001b[35m1.3040\u001b[0m  0.0499\n",
      "      9        \u001b[36m1.3066\u001b[0m       \u001b[32m0.5187\u001b[0m        \u001b[35m1.2879\u001b[0m  0.0529\n",
      "     10        \u001b[36m1.2969\u001b[0m       \u001b[32m0.5582\u001b[0m        \u001b[35m1.2712\u001b[0m  0.0499\n",
      "     11        \u001b[36m1.2718\u001b[0m       \u001b[32m0.5957\u001b[0m        \u001b[35m1.2533\u001b[0m  0.0539\n",
      "     12        \u001b[36m1.2562\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.2347\u001b[0m  0.0658\n",
      "     13        \u001b[36m1.2454\u001b[0m       \u001b[32m0.6607\u001b[0m        \u001b[35m1.2154\u001b[0m  0.0728\n",
      "     14        \u001b[36m1.2189\u001b[0m       \u001b[32m0.6805\u001b[0m        \u001b[35m1.1950\u001b[0m  0.0578\n",
      "     15        \u001b[36m1.2101\u001b[0m       \u001b[32m0.6982\u001b[0m        \u001b[35m1.1739\u001b[0m  0.0568\n",
      "     16        \u001b[36m1.1748\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m1.1519\u001b[0m  0.0568\n",
      "     17        \u001b[36m1.1613\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m1.1293\u001b[0m  0.0529\n",
      "     18        \u001b[36m1.1424\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m1.1067\u001b[0m  0.0578\n",
      "     19        \u001b[36m1.1197\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m1.0837\u001b[0m  0.0628\n",
      "     20        \u001b[36m1.1020\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m1.0606\u001b[0m  0.0519\n",
      "     21        \u001b[36m1.0731\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m1.0376\u001b[0m  0.0568\n",
      "     22        \u001b[36m1.0566\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m1.0150\u001b[0m  0.0588\n",
      "     23        \u001b[36m1.0319\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m0.9926\u001b[0m  0.0499\n",
      "     24        \u001b[36m1.0121\u001b[0m       \u001b[32m0.7554\u001b[0m        \u001b[35m0.9707\u001b[0m  0.0509\n",
      "     25        \u001b[36m0.9936\u001b[0m       \u001b[32m0.7653\u001b[0m        \u001b[35m0.9494\u001b[0m  0.0539\n",
      "     26        \u001b[36m0.9712\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m0.9285\u001b[0m  0.0718\n",
      "     27        \u001b[36m0.9567\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m0.9083\u001b[0m  0.0798\n",
      "     28        \u001b[36m0.9375\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.8888\u001b[0m  0.0708\n",
      "     29        \u001b[36m0.9135\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.8699\u001b[0m  0.0788\n",
      "     30        \u001b[36m0.9039\u001b[0m       0.7929        \u001b[35m0.8517\u001b[0m  0.0758\n",
      "     31        \u001b[36m0.8855\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m0.8342\u001b[0m  0.0628\n",
      "     32        \u001b[36m0.8610\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.8172\u001b[0m  0.0778\n",
      "     33        \u001b[36m0.8604\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.8008\u001b[0m  0.0758\n",
      "     34        \u001b[36m0.8417\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.7855\u001b[0m  0.0768\n",
      "     35        \u001b[36m0.8257\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.7707\u001b[0m  0.0618\n",
      "     36        \u001b[36m0.8174\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.7562\u001b[0m  0.0878\n",
      "     37        \u001b[36m0.8120\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.7422\u001b[0m  0.0888\n",
      "     38        \u001b[36m0.7871\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.7286\u001b[0m  0.0698\n",
      "     39        \u001b[36m0.7733\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.7154\u001b[0m  0.0718\n",
      "     40        \u001b[36m0.7659\u001b[0m       0.8343        \u001b[35m0.7026\u001b[0m  0.0668\n",
      "     41        \u001b[36m0.7530\u001b[0m       0.8343        \u001b[35m0.6899\u001b[0m  0.0568\n",
      "     42        \u001b[36m0.7455\u001b[0m       \u001b[32m0.8422\u001b[0m        \u001b[35m0.6779\u001b[0m  0.0698\n",
      "     43        \u001b[36m0.7309\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.6662\u001b[0m  0.0728\n",
      "     44        \u001b[36m0.7216\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.6548\u001b[0m  0.0648\n",
      "     45        \u001b[36m0.7115\u001b[0m       0.8481        \u001b[35m0.6438\u001b[0m  0.0808\n",
      "     46        \u001b[36m0.6856\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.6329\u001b[0m  0.0678\n",
      "     47        0.6877       0.8501        \u001b[35m0.6224\u001b[0m  0.0688\n",
      "     48        \u001b[36m0.6818\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.6120\u001b[0m  0.0618\n",
      "     49        \u001b[36m0.6666\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.6019\u001b[0m  0.0628\n",
      "     50        \u001b[36m0.6662\u001b[0m       0.8600        \u001b[35m0.5922\u001b[0m  0.0808\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   4.1s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3968\u001b[0m       \u001b[32m0.2406\u001b[0m        \u001b[35m1.3946\u001b[0m  0.0728\n",
      "      2        1.4107       0.2406        \u001b[35m1.3938\u001b[0m  0.0519\n",
      "      3        1.3979       0.2406        \u001b[35m1.3930\u001b[0m  0.0558\n",
      "      4        1.4004       0.2406        \u001b[35m1.3922\u001b[0m  0.0638\n",
      "      5        \u001b[36m1.3944\u001b[0m       0.2406        \u001b[35m1.3915\u001b[0m  0.0429\n",
      "      6        1.3984       0.2406        \u001b[35m1.3907\u001b[0m  0.0529\n",
      "      7        1.3971       0.2406        \u001b[35m1.3899\u001b[0m  0.0419\n",
      "      8        1.3979       0.2406        \u001b[35m1.3891\u001b[0m  0.0459\n",
      "      9        1.4010       \u001b[32m0.2426\u001b[0m        \u001b[35m1.3883\u001b[0m  0.0379\n",
      "     10        1.3978       0.2426        \u001b[35m1.3875\u001b[0m  0.0459\n",
      "     11        1.4014       0.2426        \u001b[35m1.3868\u001b[0m  0.0419\n",
      "     12        1.4009       0.2406        \u001b[35m1.3860\u001b[0m  0.0429\n",
      "     13        1.3946       0.2406        \u001b[35m1.3852\u001b[0m  0.0409\n",
      "     14        \u001b[36m1.3931\u001b[0m       0.2406        \u001b[35m1.3844\u001b[0m  0.0399\n",
      "     15        \u001b[36m1.3917\u001b[0m       0.2406        \u001b[35m1.3837\u001b[0m  0.0588\n",
      "     16        \u001b[36m1.3827\u001b[0m       0.2406        \u001b[35m1.3829\u001b[0m  0.0469\n",
      "     17        1.3932       0.2406        \u001b[35m1.3821\u001b[0m  0.0389\n",
      "     18        1.3895       0.2426        \u001b[35m1.3814\u001b[0m  0.0379\n",
      "     19        1.3842       \u001b[32m0.2485\u001b[0m        \u001b[35m1.3806\u001b[0m  0.0479\n",
      "     20        1.3909       0.2465        \u001b[35m1.3798\u001b[0m  0.0379\n",
      "     21        1.3899       0.2446        \u001b[35m1.3791\u001b[0m  0.0409\n",
      "     22        \u001b[36m1.3819\u001b[0m       0.2465        \u001b[35m1.3783\u001b[0m  0.0429\n",
      "     23        1.3889       0.2485        \u001b[35m1.3776\u001b[0m  0.0578\n",
      "     24        \u001b[36m1.3816\u001b[0m       \u001b[32m0.2525\u001b[0m        \u001b[35m1.3768\u001b[0m  0.0429\n",
      "     25        1.3830       \u001b[32m0.2564\u001b[0m        \u001b[35m1.3760\u001b[0m  0.0469\n",
      "     26        \u001b[36m1.3780\u001b[0m       0.2564        \u001b[35m1.3753\u001b[0m  0.0559\n",
      "     27        1.3892       0.2564        \u001b[35m1.3745\u001b[0m  0.0578\n",
      "     28        1.3911       \u001b[32m0.2584\u001b[0m        \u001b[35m1.3738\u001b[0m  0.0409\n",
      "     29        1.3789       \u001b[32m0.2604\u001b[0m        \u001b[35m1.3731\u001b[0m  0.0519\n",
      "     30        1.3824       \u001b[32m0.2623\u001b[0m        \u001b[35m1.3723\u001b[0m  0.0489\n",
      "     31        1.3936       \u001b[32m0.2643\u001b[0m        \u001b[35m1.3716\u001b[0m  0.0489\n",
      "     32        1.3783       0.2643        \u001b[35m1.3708\u001b[0m  0.0488\n",
      "     33        1.3802       \u001b[32m0.2663\u001b[0m        \u001b[35m1.3701\u001b[0m  0.0479\n",
      "     34        \u001b[36m1.3767\u001b[0m       \u001b[32m0.2742\u001b[0m        \u001b[35m1.3693\u001b[0m  0.0429\n",
      "     35        1.3833       \u001b[32m0.2781\u001b[0m        \u001b[35m1.3686\u001b[0m  0.0479\n",
      "     36        \u001b[36m1.3746\u001b[0m       0.2781        \u001b[35m1.3679\u001b[0m  0.0489\n",
      "     37        \u001b[36m1.3722\u001b[0m       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3671\u001b[0m  0.0399\n",
      "     38        1.3843       \u001b[32m0.2860\u001b[0m        \u001b[35m1.3664\u001b[0m  0.0439\n",
      "     39        1.3753       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3657\u001b[0m  0.0469\n",
      "     40        \u001b[36m1.3711\u001b[0m       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3650\u001b[0m  0.0549\n",
      "     41        \u001b[36m1.3706\u001b[0m       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3642\u001b[0m  0.0419\n",
      "     42        1.3737       0.2959        \u001b[35m1.3635\u001b[0m  0.0519\n",
      "     43        \u001b[36m1.3699\u001b[0m       0.2939        \u001b[35m1.3627\u001b[0m  0.0409\n",
      "     44        1.3714       0.2939        \u001b[35m1.3620\u001b[0m  0.0549\n",
      "     45        \u001b[36m1.3689\u001b[0m       0.2959        \u001b[35m1.3613\u001b[0m  0.0539\n",
      "     46        1.3740       \u001b[32m0.2978\u001b[0m        \u001b[35m1.3605\u001b[0m  0.0589\n",
      "     47        1.3689       \u001b[32m0.2998\u001b[0m        \u001b[35m1.3598\u001b[0m  0.0509\n",
      "     48        1.3692       0.2998        \u001b[35m1.3591\u001b[0m  0.0549\n",
      "     49        \u001b[36m1.3606\u001b[0m       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3584\u001b[0m  0.0578\n",
      "     50        \u001b[36m1.3569\u001b[0m       0.3057        \u001b[35m1.3576\u001b[0m  0.0459\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4240\u001b[0m       \u001b[32m0.1815\u001b[0m        \u001b[35m1.4149\u001b[0m  0.0389\n",
      "      2        \u001b[36m1.4235\u001b[0m       \u001b[32m0.1834\u001b[0m        \u001b[35m1.4140\u001b[0m  0.0489\n",
      "      3        \u001b[36m1.4198\u001b[0m       0.1834        \u001b[35m1.4132\u001b[0m  0.0429\n",
      "      4        1.4214       0.1834        \u001b[35m1.4124\u001b[0m  0.0489\n",
      "      5        \u001b[36m1.4185\u001b[0m       0.1795        \u001b[35m1.4115\u001b[0m  0.0539\n",
      "      6        1.4233       0.1795        \u001b[35m1.4107\u001b[0m  0.0598\n",
      "      7        \u001b[36m1.4170\u001b[0m       0.1755        \u001b[35m1.4099\u001b[0m  0.0469\n",
      "      8        1.4219       0.1755        \u001b[35m1.4091\u001b[0m  0.0389\n",
      "      9        1.4193       0.1755        \u001b[35m1.4083\u001b[0m  0.0409\n",
      "     10        \u001b[36m1.4158\u001b[0m       0.1775        \u001b[35m1.4074\u001b[0m  0.0479\n",
      "     11        \u001b[36m1.4151\u001b[0m       0.1775        \u001b[35m1.4066\u001b[0m  0.0419\n",
      "     12        1.4165       0.1775        \u001b[35m1.4058\u001b[0m  0.0389\n",
      "     13        \u001b[36m1.4091\u001b[0m       0.1795        \u001b[35m1.4051\u001b[0m  0.0559\n",
      "     14        1.4166       0.1815        \u001b[35m1.4043\u001b[0m  0.0499\n",
      "     15        1.4123       0.1815        \u001b[35m1.4035\u001b[0m  0.0389\n",
      "     16        1.4175       0.1815        \u001b[35m1.4027\u001b[0m  0.0479\n",
      "     17        1.4151       \u001b[32m0.1854\u001b[0m        \u001b[35m1.4020\u001b[0m  0.0439\n",
      "     18        1.4114       \u001b[32m0.1913\u001b[0m        \u001b[35m1.4012\u001b[0m  0.0389\n",
      "     19        \u001b[36m1.4075\u001b[0m       0.1893        \u001b[35m1.4004\u001b[0m  0.0439\n",
      "     20        1.4145       0.1913        \u001b[35m1.3997\u001b[0m  0.0369\n",
      "     21        1.4148       \u001b[32m0.1933\u001b[0m        \u001b[35m1.3989\u001b[0m  0.0578\n",
      "     22        \u001b[36m1.4050\u001b[0m       \u001b[32m0.1992\u001b[0m        \u001b[35m1.3982\u001b[0m  0.0459\n",
      "     23        1.4084       0.1992        \u001b[35m1.3974\u001b[0m  0.0678\n",
      "     24        1.4092       \u001b[32m0.2012\u001b[0m        \u001b[35m1.3967\u001b[0m  0.0499\n",
      "     25        1.4133       0.1992        \u001b[35m1.3959\u001b[0m  0.0449\n",
      "     26        1.4083       0.2012        \u001b[35m1.3952\u001b[0m  0.0419\n",
      "     27        \u001b[36m1.3991\u001b[0m       0.1992        \u001b[35m1.3945\u001b[0m  0.0618\n",
      "     28        1.4059       0.2012        \u001b[35m1.3938\u001b[0m  0.0399\n",
      "     29        \u001b[36m1.3975\u001b[0m       0.2012        \u001b[35m1.3931\u001b[0m  0.0459\n",
      "     30        1.4082       0.2012        \u001b[35m1.3924\u001b[0m  0.0479\n",
      "     31        \u001b[36m1.3957\u001b[0m       \u001b[32m0.2051\u001b[0m        \u001b[35m1.3916\u001b[0m  0.0409\n",
      "     32        1.3996       0.2051        \u001b[35m1.3909\u001b[0m  0.0459\n",
      "     33        1.4036       0.2051        \u001b[35m1.3902\u001b[0m  0.0499\n",
      "     34        1.3975       \u001b[32m0.2091\u001b[0m        \u001b[35m1.3895\u001b[0m  0.0648\n",
      "     35        1.3958       \u001b[32m0.2130\u001b[0m        \u001b[35m1.3889\u001b[0m  0.0389\n",
      "     36        \u001b[36m1.3956\u001b[0m       \u001b[32m0.2170\u001b[0m        \u001b[35m1.3882\u001b[0m  0.0429\n",
      "     37        1.3963       0.2170        \u001b[35m1.3875\u001b[0m  0.0419\n",
      "     38        \u001b[36m1.3916\u001b[0m       \u001b[32m0.2189\u001b[0m        \u001b[35m1.3868\u001b[0m  0.0379\n",
      "     39        1.3940       \u001b[32m0.2229\u001b[0m        \u001b[35m1.3861\u001b[0m  0.0468\n",
      "     40        1.3959       \u001b[32m0.2268\u001b[0m        \u001b[35m1.3854\u001b[0m  0.0598\n",
      "     41        \u001b[36m1.3910\u001b[0m       \u001b[32m0.2308\u001b[0m        \u001b[35m1.3848\u001b[0m  0.0439\n",
      "     42        1.3976       0.2308        \u001b[35m1.3841\u001b[0m  0.0389\n",
      "     43        \u001b[36m1.3866\u001b[0m       \u001b[32m0.2347\u001b[0m        \u001b[35m1.3834\u001b[0m  0.0379\n",
      "     44        1.3902       \u001b[32m0.2367\u001b[0m        \u001b[35m1.3828\u001b[0m  0.0419\n",
      "     45        1.3881       0.2367        \u001b[35m1.3821\u001b[0m  0.0369\n",
      "     46        1.3890       \u001b[32m0.2406\u001b[0m        \u001b[35m1.3814\u001b[0m  0.0419\n",
      "     47        1.3911       \u001b[32m0.2465\u001b[0m        \u001b[35m1.3808\u001b[0m  0.0459\n",
      "     48        1.3924       \u001b[32m0.2505\u001b[0m        \u001b[35m1.3801\u001b[0m  0.0598\n",
      "     49        1.3907       \u001b[32m0.2525\u001b[0m        \u001b[35m1.3795\u001b[0m  0.0469\n",
      "     50        1.3885       \u001b[32m0.2564\u001b[0m        \u001b[35m1.3788\u001b[0m  0.0389\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4393\u001b[0m       \u001b[32m0.2702\u001b[0m        \u001b[35m1.4251\u001b[0m  0.0519\n",
      "      2        \u001b[36m1.4356\u001b[0m       \u001b[32m0.2722\u001b[0m        \u001b[35m1.4240\u001b[0m  0.0559\n",
      "      3        \u001b[36m1.4312\u001b[0m       0.2722        \u001b[35m1.4228\u001b[0m  0.0439\n",
      "      4        \u001b[36m1.4309\u001b[0m       \u001b[32m0.2742\u001b[0m        \u001b[35m1.4217\u001b[0m  0.0379\n",
      "      5        \u001b[36m1.4304\u001b[0m       0.2742        \u001b[35m1.4205\u001b[0m  0.0479\n",
      "      6        1.4348       \u001b[32m0.2761\u001b[0m        \u001b[35m1.4194\u001b[0m  0.0598\n",
      "      7        \u001b[36m1.4265\u001b[0m       \u001b[32m0.2801\u001b[0m        \u001b[35m1.4182\u001b[0m  0.0469\n",
      "      8        \u001b[36m1.4225\u001b[0m       \u001b[32m0.2840\u001b[0m        \u001b[35m1.4171\u001b[0m  0.0409\n",
      "      9        1.4248       0.2840        \u001b[35m1.4161\u001b[0m  0.0399\n",
      "     10        1.4304       0.2840        \u001b[35m1.4150\u001b[0m  0.0419\n",
      "     11        1.4255       \u001b[32m0.2860\u001b[0m        \u001b[35m1.4139\u001b[0m  0.0379\n",
      "     12        1.4226       0.2860        \u001b[35m1.4128\u001b[0m  0.0509\n",
      "     13        \u001b[36m1.4218\u001b[0m       \u001b[32m0.2919\u001b[0m        \u001b[35m1.4118\u001b[0m  0.0518\n",
      "     14        \u001b[36m1.4192\u001b[0m       \u001b[32m0.2939\u001b[0m        \u001b[35m1.4107\u001b[0m  0.0379\n",
      "     15        1.4211       \u001b[32m0.2959\u001b[0m        \u001b[35m1.4097\u001b[0m  0.0419\n",
      "     16        \u001b[36m1.4168\u001b[0m       \u001b[32m0.2978\u001b[0m        \u001b[35m1.4086\u001b[0m  0.0428\n",
      "     17        \u001b[36m1.4168\u001b[0m       0.2978        \u001b[35m1.4076\u001b[0m  0.0539\n",
      "     18        1.4176       \u001b[32m0.2998\u001b[0m        \u001b[35m1.4066\u001b[0m  0.0529\n",
      "     19        1.4184       0.2998        \u001b[35m1.4056\u001b[0m  0.0538\n",
      "     20        \u001b[36m1.4124\u001b[0m       0.2998        \u001b[35m1.4046\u001b[0m  0.0449\n",
      "     21        1.4144       0.2998        \u001b[35m1.4036\u001b[0m  0.0409\n",
      "     22        \u001b[36m1.4102\u001b[0m       0.2998        \u001b[35m1.4027\u001b[0m  0.0409\n",
      "     23        1.4126       \u001b[32m0.3018\u001b[0m        \u001b[35m1.4017\u001b[0m  0.0379\n",
      "     24        1.4105       0.3018        \u001b[35m1.4007\u001b[0m  0.0449\n",
      "     25        1.4117       0.3018        \u001b[35m1.3998\u001b[0m  0.0559\n",
      "     26        \u001b[36m1.4073\u001b[0m       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3988\u001b[0m  0.0479\n",
      "     27        1.4089       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3979\u001b[0m  0.0399\n",
      "     28        1.4107       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3969\u001b[0m  0.0499\n",
      "     29        1.4090       \u001b[32m0.3097\u001b[0m        \u001b[35m1.3960\u001b[0m  0.0399\n",
      "     30        \u001b[36m1.4054\u001b[0m       0.3097        \u001b[35m1.3950\u001b[0m  0.0369\n",
      "     31        \u001b[36m1.4042\u001b[0m       0.3097        \u001b[35m1.3941\u001b[0m  0.0379\n",
      "     32        1.4062       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3932\u001b[0m  0.0479\n",
      "     33        1.4088       \u001b[32m0.3156\u001b[0m        \u001b[35m1.3922\u001b[0m  0.0399\n",
      "     34        \u001b[36m1.3992\u001b[0m       \u001b[32m0.3176\u001b[0m        \u001b[35m1.3914\u001b[0m  0.0409\n",
      "     35        1.4069       0.3176        \u001b[35m1.3905\u001b[0m  0.0429\n",
      "     36        1.4031       \u001b[32m0.3195\u001b[0m        \u001b[35m1.3896\u001b[0m  0.0379\n",
      "     37        1.4039       0.3195        \u001b[35m1.3887\u001b[0m  0.0399\n",
      "     38        \u001b[36m1.3985\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3878\u001b[0m  0.0469\n",
      "     39        1.4006       \u001b[32m0.3235\u001b[0m        \u001b[35m1.3869\u001b[0m  0.0539\n",
      "     40        1.3986       0.3215        \u001b[35m1.3860\u001b[0m  0.0479\n",
      "     41        \u001b[36m1.3949\u001b[0m       0.3235        \u001b[35m1.3851\u001b[0m  0.0449\n",
      "     42        \u001b[36m1.3904\u001b[0m       0.3215        \u001b[35m1.3843\u001b[0m  0.0608\n",
      "     43        1.3951       0.3235        \u001b[35m1.3834\u001b[0m  0.0648\n",
      "     44        1.3943       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3826\u001b[0m  0.0539\n",
      "     45        1.3962       \u001b[32m0.3333\u001b[0m        \u001b[35m1.3817\u001b[0m  0.0529\n",
      "     46        1.3952       \u001b[32m0.3353\u001b[0m        \u001b[35m1.3808\u001b[0m  0.0489\n",
      "     47        1.3949       \u001b[32m0.3373\u001b[0m        \u001b[35m1.3800\u001b[0m  0.0499\n",
      "     48        1.3918       \u001b[32m0.3393\u001b[0m        \u001b[35m1.3791\u001b[0m  0.0489\n",
      "     49        \u001b[36m1.3857\u001b[0m       0.3393        \u001b[35m1.3783\u001b[0m  0.0559\n",
      "     50        1.3858       0.3393        \u001b[35m1.3775\u001b[0m  0.0549\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4188\u001b[0m       \u001b[32m0.3412\u001b[0m        \u001b[35m1.3699\u001b[0m  0.0419\n",
      "      2        \u001b[36m1.3721\u001b[0m       \u001b[32m0.3629\u001b[0m        \u001b[35m1.3456\u001b[0m  0.0608\n",
      "      3        \u001b[36m1.3481\u001b[0m       \u001b[32m0.4043\u001b[0m        \u001b[35m1.3212\u001b[0m  0.0479\n",
      "      4        \u001b[36m1.3311\u001b[0m       \u001b[32m0.4694\u001b[0m        \u001b[35m1.2967\u001b[0m  0.0529\n",
      "      5        \u001b[36m1.3056\u001b[0m       \u001b[32m0.5720\u001b[0m        \u001b[35m1.2721\u001b[0m  0.0499\n",
      "      6        \u001b[36m1.2740\u001b[0m       \u001b[32m0.6548\u001b[0m        \u001b[35m1.2470\u001b[0m  0.0439\n",
      "      7        \u001b[36m1.2577\u001b[0m       \u001b[32m0.6884\u001b[0m        \u001b[35m1.2210\u001b[0m  0.0768\n",
      "      8        \u001b[36m1.2303\u001b[0m       \u001b[32m0.7239\u001b[0m        \u001b[35m1.1940\u001b[0m  0.0429\n",
      "      9        \u001b[36m1.2043\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m1.1663\u001b[0m  0.0479\n",
      "     10        \u001b[36m1.1829\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m1.1378\u001b[0m  0.0558\n",
      "     11        \u001b[36m1.1494\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m1.1088\u001b[0m  0.0479\n",
      "     12        \u001b[36m1.1241\u001b[0m       0.7751        \u001b[35m1.0793\u001b[0m  0.0598\n",
      "     13        \u001b[36m1.1035\u001b[0m       \u001b[32m0.7850\u001b[0m        \u001b[35m1.0499\u001b[0m  0.0499\n",
      "     14        \u001b[36m1.0679\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m1.0205\u001b[0m  0.0628\n",
      "     15        \u001b[36m1.0456\u001b[0m       \u001b[32m0.8028\u001b[0m        \u001b[35m0.9912\u001b[0m  0.0539\n",
      "     16        \u001b[36m1.0184\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.9623\u001b[0m  0.0549\n",
      "     17        \u001b[36m0.9965\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.9345\u001b[0m  0.0568\n",
      "     18        \u001b[36m0.9675\u001b[0m       \u001b[32m0.8264\u001b[0m        \u001b[35m0.9073\u001b[0m  0.0499\n",
      "     19        \u001b[36m0.9487\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.8810\u001b[0m  0.0429\n",
      "     20        \u001b[36m0.9162\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.8556\u001b[0m  0.0439\n",
      "     21        \u001b[36m0.8952\u001b[0m       0.8462        \u001b[35m0.8308\u001b[0m  0.0529\n",
      "     22        \u001b[36m0.8766\u001b[0m       0.8481        \u001b[35m0.8073\u001b[0m  0.0549\n",
      "     23        \u001b[36m0.8490\u001b[0m       0.8481        \u001b[35m0.7847\u001b[0m  0.0429\n",
      "     24        \u001b[36m0.8308\u001b[0m       \u001b[32m0.8521\u001b[0m        \u001b[35m0.7631\u001b[0m  0.0499\n",
      "     25        \u001b[36m0.8163\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.7424\u001b[0m  0.0499\n",
      "     26        \u001b[36m0.7960\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.7227\u001b[0m  0.0568\n",
      "     27        \u001b[36m0.7701\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.7037\u001b[0m  0.0598\n",
      "     28        \u001b[36m0.7576\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.6853\u001b[0m  0.0638\n",
      "     29        \u001b[36m0.7373\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.6678\u001b[0m  0.0459\n",
      "     30        \u001b[36m0.7211\u001b[0m       \u001b[32m0.8797\u001b[0m        \u001b[35m0.6509\u001b[0m  0.0459\n",
      "     31        \u001b[36m0.7108\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.6347\u001b[0m  0.0459\n",
      "     32        \u001b[36m0.7020\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.6194\u001b[0m  0.0488\n",
      "     33        \u001b[36m0.6790\u001b[0m       0.8856        \u001b[35m0.6047\u001b[0m  0.0439\n",
      "     34        \u001b[36m0.6767\u001b[0m       0.8856        \u001b[35m0.5907\u001b[0m  0.0808\n",
      "     35        \u001b[36m0.6584\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.5774\u001b[0m  0.0558\n",
      "     36        \u001b[36m0.6421\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.5643\u001b[0m  0.0608\n",
      "     37        \u001b[36m0.6283\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.5517\u001b[0m  0.0609\n",
      "     38        \u001b[36m0.6143\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.5396\u001b[0m  0.0638\n",
      "     39        \u001b[36m0.6074\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.5279\u001b[0m  0.0439\n",
      "     40        \u001b[36m0.5867\u001b[0m       0.9014        \u001b[35m0.5167\u001b[0m  0.0519\n",
      "     41        0.5935       \u001b[32m0.9034\u001b[0m        \u001b[35m0.5063\u001b[0m  0.0578\n",
      "     42        \u001b[36m0.5810\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.4963\u001b[0m  0.0449\n",
      "     43        \u001b[36m0.5676\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m0.4866\u001b[0m  0.0689\n",
      "     44        \u001b[36m0.5597\u001b[0m       0.9014        \u001b[35m0.4771\u001b[0m  0.0419\n",
      "     45        \u001b[36m0.5509\u001b[0m       0.9034        \u001b[35m0.4679\u001b[0m  0.0499\n",
      "     46        0.5567       0.9014        \u001b[35m0.4594\u001b[0m  0.0469\n",
      "     47        \u001b[36m0.5391\u001b[0m       0.9034        \u001b[35m0.4512\u001b[0m  0.0429\n",
      "     48        \u001b[36m0.5205\u001b[0m       0.9034        \u001b[35m0.4430\u001b[0m  0.0519\n",
      "     49        \u001b[36m0.5151\u001b[0m       0.9053        \u001b[35m0.4352\u001b[0m  0.0509\n",
      "     50        \u001b[36m0.5036\u001b[0m       0.9034        \u001b[35m0.4276\u001b[0m  0.0549\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4363\u001b[0m       \u001b[32m0.2663\u001b[0m        \u001b[35m1.3826\u001b[0m  0.0549\n",
      "      2        \u001b[36m1.3869\u001b[0m       \u001b[32m0.3136\u001b[0m        \u001b[35m1.3593\u001b[0m  0.0499\n",
      "      3        \u001b[36m1.3628\u001b[0m       \u001b[32m0.3471\u001b[0m        \u001b[35m1.3365\u001b[0m  0.0439\n",
      "      4        \u001b[36m1.3487\u001b[0m       \u001b[32m0.4300\u001b[0m        \u001b[35m1.3143\u001b[0m  0.0519\n",
      "      5        \u001b[36m1.3215\u001b[0m       \u001b[32m0.5286\u001b[0m        \u001b[35m1.2923\u001b[0m  0.0449\n",
      "      6        \u001b[36m1.2995\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m1.2704\u001b[0m  0.0449\n",
      "      7        \u001b[36m1.2790\u001b[0m       \u001b[32m0.6607\u001b[0m        \u001b[35m1.2484\u001b[0m  0.0728\n",
      "      8        \u001b[36m1.2536\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m1.2254\u001b[0m  0.0529\n",
      "      9        \u001b[36m1.2351\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m1.2018\u001b[0m  0.0449\n",
      "     10        \u001b[36m1.2138\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m1.1778\u001b[0m  0.0439\n",
      "     11        \u001b[36m1.1915\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m1.1534\u001b[0m  0.0439\n",
      "     12        \u001b[36m1.1618\u001b[0m       \u001b[32m0.7613\u001b[0m        \u001b[35m1.1282\u001b[0m  0.0609\n",
      "     13        \u001b[36m1.1436\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m1.1026\u001b[0m  0.0429\n",
      "     14        \u001b[36m1.1167\u001b[0m       0.7673        \u001b[35m1.0768\u001b[0m  0.0499\n",
      "     15        \u001b[36m1.0931\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m1.0508\u001b[0m  0.0608\n",
      "     16        \u001b[36m1.0703\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m1.0249\u001b[0m  0.0509\n",
      "     17        \u001b[36m1.0466\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m0.9992\u001b[0m  0.0688\n",
      "     18        \u001b[36m1.0150\u001b[0m       \u001b[32m0.7850\u001b[0m        \u001b[35m0.9737\u001b[0m  0.0439\n",
      "     19        \u001b[36m0.9916\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.9485\u001b[0m  0.0449\n",
      "     20        \u001b[36m0.9736\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m0.9239\u001b[0m  0.0578\n",
      "     21        \u001b[36m0.9599\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m0.8998\u001b[0m  0.0648\n",
      "     22        \u001b[36m0.9350\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.8762\u001b[0m  0.0489\n",
      "     23        \u001b[36m0.9032\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.8533\u001b[0m  0.0509\n",
      "     24        \u001b[36m0.8826\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.8310\u001b[0m  0.0489\n",
      "     25        \u001b[36m0.8575\u001b[0m       \u001b[32m0.8166\u001b[0m        \u001b[35m0.8094\u001b[0m  0.0459\n",
      "     26        \u001b[36m0.8389\u001b[0m       \u001b[32m0.8264\u001b[0m        \u001b[35m0.7884\u001b[0m  0.0668\n",
      "     27        \u001b[36m0.8259\u001b[0m       \u001b[32m0.8284\u001b[0m        \u001b[35m0.7683\u001b[0m  0.0479\n",
      "     28        \u001b[36m0.8124\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.7490\u001b[0m  0.0569\n",
      "     29        \u001b[36m0.7800\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.7306\u001b[0m  0.0469\n",
      "     30        \u001b[36m0.7666\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.7127\u001b[0m  0.0509\n",
      "     31        \u001b[36m0.7493\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.6953\u001b[0m  0.0489\n",
      "     32        \u001b[36m0.7351\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.6784\u001b[0m  0.0559\n",
      "     33        \u001b[36m0.7108\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.6621\u001b[0m  0.0518\n",
      "     34        \u001b[36m0.7051\u001b[0m       0.8718        \u001b[35m0.6465\u001b[0m  0.0509\n",
      "     35        \u001b[36m0.6953\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.6317\u001b[0m  0.0579\n",
      "     36        \u001b[36m0.6696\u001b[0m       0.8757        \u001b[35m0.6174\u001b[0m  0.0608\n",
      "     37        \u001b[36m0.6612\u001b[0m       0.8757        \u001b[35m0.6036\u001b[0m  0.0519\n",
      "     38        \u001b[36m0.6547\u001b[0m       0.8797        \u001b[35m0.5904\u001b[0m  0.0578\n",
      "     39        \u001b[36m0.6281\u001b[0m       0.8777        \u001b[35m0.5777\u001b[0m  0.0499\n",
      "     40        \u001b[36m0.6204\u001b[0m       0.8757        \u001b[35m0.5654\u001b[0m  0.0698\n",
      "     41        \u001b[36m0.6128\u001b[0m       0.8777        \u001b[35m0.5537\u001b[0m  0.0728\n",
      "     42        \u001b[36m0.5916\u001b[0m       0.8797        \u001b[35m0.5421\u001b[0m  0.0568\n",
      "     43        \u001b[36m0.5865\u001b[0m       0.8817        \u001b[35m0.5311\u001b[0m  0.0479\n",
      "     44        \u001b[36m0.5795\u001b[0m       0.8817        \u001b[35m0.5204\u001b[0m  0.0429\n",
      "     45        \u001b[36m0.5630\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.5099\u001b[0m  0.0499\n",
      "     46        \u001b[36m0.5518\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.5000\u001b[0m  0.0578\n",
      "     47        \u001b[36m0.5483\u001b[0m       0.8895        \u001b[35m0.4905\u001b[0m  0.0469\n",
      "     48        \u001b[36m0.5365\u001b[0m       0.8876        \u001b[35m0.4814\u001b[0m  0.0539\n",
      "     49        0.5382       0.8876        \u001b[35m0.4726\u001b[0m  0.0568\n",
      "     50        \u001b[36m0.5215\u001b[0m       0.8895        \u001b[35m0.4641\u001b[0m  0.0598\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.2s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4126\u001b[0m       \u001b[32m0.2998\u001b[0m        \u001b[35m1.3595\u001b[0m  0.0599\n",
      "      2        \u001b[36m1.3587\u001b[0m       \u001b[32m0.3471\u001b[0m        \u001b[35m1.3329\u001b[0m  0.0559\n",
      "      3        \u001b[36m1.3385\u001b[0m       \u001b[32m0.3787\u001b[0m        \u001b[35m1.3069\u001b[0m  0.0499\n",
      "      4        \u001b[36m1.3080\u001b[0m       \u001b[32m0.4359\u001b[0m        \u001b[35m1.2820\u001b[0m  0.0588\n",
      "      5        \u001b[36m1.2842\u001b[0m       \u001b[32m0.4753\u001b[0m        \u001b[35m1.2575\u001b[0m  0.0409\n",
      "      6        \u001b[36m1.2610\u001b[0m       \u001b[32m0.5424\u001b[0m        \u001b[35m1.2329\u001b[0m  0.0529\n",
      "      7        \u001b[36m1.2436\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m1.2086\u001b[0m  0.0519\n",
      "      8        \u001b[36m1.2163\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.1843\u001b[0m  0.0539\n",
      "      9        \u001b[36m1.1899\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m1.1595\u001b[0m  0.0469\n",
      "     10        \u001b[36m1.1670\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m1.1344\u001b[0m  0.0598\n",
      "     11        \u001b[36m1.1438\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m1.1092\u001b[0m  0.0429\n",
      "     12        \u001b[36m1.1216\u001b[0m       \u001b[32m0.7909\u001b[0m        \u001b[35m1.0839\u001b[0m  0.0489\n",
      "     13        \u001b[36m1.0904\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m1.0584\u001b[0m  0.0499\n",
      "     14        \u001b[36m1.0693\u001b[0m       \u001b[32m0.8166\u001b[0m        \u001b[35m1.0329\u001b[0m  0.0509\n",
      "     15        \u001b[36m1.0510\u001b[0m       0.8166        \u001b[35m1.0079\u001b[0m  0.0598\n",
      "     16        \u001b[36m1.0236\u001b[0m       0.8146        \u001b[35m0.9832\u001b[0m  0.0469\n",
      "     17        \u001b[36m1.0011\u001b[0m       0.7988        \u001b[35m0.9590\u001b[0m  0.0568\n",
      "     18        \u001b[36m0.9749\u001b[0m       0.7949        \u001b[35m0.9352\u001b[0m  0.0558\n",
      "     19        \u001b[36m0.9514\u001b[0m       0.8008        \u001b[35m0.9119\u001b[0m  0.0698\n",
      "     20        \u001b[36m0.9325\u001b[0m       0.8047        \u001b[35m0.8891\u001b[0m  0.0519\n",
      "     21        \u001b[36m0.8988\u001b[0m       0.8047        \u001b[35m0.8670\u001b[0m  0.0469\n",
      "     22        \u001b[36m0.8890\u001b[0m       0.8087        \u001b[35m0.8454\u001b[0m  0.0718\n",
      "     23        \u001b[36m0.8687\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.8244\u001b[0m  0.0748\n",
      "     24        \u001b[36m0.8474\u001b[0m       \u001b[32m0.8284\u001b[0m        \u001b[35m0.8041\u001b[0m  0.0519\n",
      "     25        \u001b[36m0.8319\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.7845\u001b[0m  0.0539\n",
      "     26        \u001b[36m0.8164\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.7654\u001b[0m  0.0469\n",
      "     27        \u001b[36m0.7959\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.7469\u001b[0m  0.0429\n",
      "     28        \u001b[36m0.7775\u001b[0m       \u001b[32m0.8521\u001b[0m        \u001b[35m0.7289\u001b[0m  0.0419\n",
      "     29        \u001b[36m0.7584\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.7113\u001b[0m  0.0529\n",
      "     30        \u001b[36m0.7493\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.6945\u001b[0m  0.0519\n",
      "     31        \u001b[36m0.7294\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.6779\u001b[0m  0.0519\n",
      "     32        \u001b[36m0.7154\u001b[0m       0.8659        \u001b[35m0.6619\u001b[0m  0.0489\n",
      "     33        \u001b[36m0.6900\u001b[0m       0.8659        \u001b[35m0.6461\u001b[0m  0.0628\n",
      "     34        \u001b[36m0.6848\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.6308\u001b[0m  0.0459\n",
      "     35        \u001b[36m0.6603\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.6156\u001b[0m  0.0519\n",
      "     36        \u001b[36m0.6601\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.6012\u001b[0m  0.0429\n",
      "     37        \u001b[36m0.6341\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.5870\u001b[0m  0.0419\n",
      "     38        0.6355       \u001b[32m0.8915\u001b[0m        \u001b[35m0.5733\u001b[0m  0.0559\n",
      "     39        \u001b[36m0.6117\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.5600\u001b[0m  0.0479\n",
      "     40        \u001b[36m0.6019\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.5472\u001b[0m  0.0469\n",
      "     41        \u001b[36m0.5865\u001b[0m       \u001b[32m0.9034\u001b[0m        \u001b[35m0.5349\u001b[0m  0.0509\n",
      "     42        \u001b[36m0.5764\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.5229\u001b[0m  0.0429\n",
      "     43        \u001b[36m0.5694\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m0.5113\u001b[0m  0.0429\n",
      "     44        \u001b[36m0.5545\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m0.5002\u001b[0m  0.0578\n",
      "     45        \u001b[36m0.5386\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.4892\u001b[0m  0.0468\n",
      "     46        \u001b[36m0.5370\u001b[0m       0.9152        \u001b[35m0.4786\u001b[0m  0.0479\n",
      "     47        \u001b[36m0.5297\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.4687\u001b[0m  0.0559\n",
      "     48        \u001b[36m0.5201\u001b[0m       \u001b[32m0.9270\u001b[0m        \u001b[35m0.4591\u001b[0m  0.0608\n",
      "     49        \u001b[36m0.5107\u001b[0m       0.9270        \u001b[35m0.4497\u001b[0m  0.0439\n",
      "     50        \u001b[36m0.4994\u001b[0m       \u001b[32m0.9290\u001b[0m        \u001b[35m0.4406\u001b[0m  0.0489\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.2s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4100\u001b[0m       \u001b[32m0.2308\u001b[0m        \u001b[35m1.4032\u001b[0m  0.0459\n",
      "      2        1.4115       0.2288        \u001b[35m1.4024\u001b[0m  0.0479\n",
      "      3        1.4102       0.2308        \u001b[35m1.4015\u001b[0m  0.0459\n",
      "      4        1.4184       0.2308        \u001b[35m1.4007\u001b[0m  0.0479\n",
      "      5        \u001b[36m1.4051\u001b[0m       0.2308        \u001b[35m1.3999\u001b[0m  0.0409\n",
      "      6        1.4118       \u001b[32m0.2327\u001b[0m        \u001b[35m1.3991\u001b[0m  0.0519\n",
      "      7        \u001b[36m1.4026\u001b[0m       \u001b[32m0.2347\u001b[0m        \u001b[35m1.3983\u001b[0m  0.0549\n",
      "      8        1.4072       0.2347        \u001b[35m1.3974\u001b[0m  0.0409\n",
      "      9        1.4075       \u001b[32m0.2387\u001b[0m        \u001b[35m1.3967\u001b[0m  0.0499\n",
      "     10        1.4031       \u001b[32m0.2426\u001b[0m        \u001b[35m1.3959\u001b[0m  0.0529\n",
      "     11        1.4049       0.2426        \u001b[35m1.3951\u001b[0m  0.0439\n",
      "     12        \u001b[36m1.4026\u001b[0m       0.2406        \u001b[35m1.3943\u001b[0m  0.0409\n",
      "     13        \u001b[36m1.4017\u001b[0m       0.2387        \u001b[35m1.3935\u001b[0m  0.0448\n",
      "     14        \u001b[36m1.3990\u001b[0m       0.2426        \u001b[35m1.3927\u001b[0m  0.0449\n",
      "     15        1.4038       \u001b[32m0.2485\u001b[0m        \u001b[35m1.3920\u001b[0m  0.0409\n",
      "     16        1.3995       0.2465        \u001b[35m1.3912\u001b[0m  0.0479\n",
      "     17        1.4009       0.2485        \u001b[35m1.3905\u001b[0m  0.0419\n",
      "     18        1.4019       \u001b[32m0.2525\u001b[0m        \u001b[35m1.3897\u001b[0m  0.0449\n",
      "     19        \u001b[36m1.3989\u001b[0m       0.2525        \u001b[35m1.3890\u001b[0m  0.0539\n",
      "     20        \u001b[36m1.3953\u001b[0m       0.2485        \u001b[35m1.3882\u001b[0m  0.0439\n",
      "     21        1.3954       0.2525        \u001b[35m1.3874\u001b[0m  0.0628\n",
      "     22        1.3983       0.2525        \u001b[35m1.3867\u001b[0m  0.0519\n",
      "     23        \u001b[36m1.3922\u001b[0m       \u001b[32m0.2604\u001b[0m        \u001b[35m1.3860\u001b[0m  0.0419\n",
      "     24        \u001b[36m1.3897\u001b[0m       \u001b[32m0.2643\u001b[0m        \u001b[35m1.3852\u001b[0m  0.0439\n",
      "     25        1.3912       \u001b[32m0.2702\u001b[0m        \u001b[35m1.3845\u001b[0m  0.0509\n",
      "     26        1.3939       0.2682        \u001b[35m1.3837\u001b[0m  0.0658\n",
      "     27        1.3934       0.2682        \u001b[35m1.3830\u001b[0m  0.0549\n",
      "     28        1.3932       0.2682        \u001b[35m1.3823\u001b[0m  0.0489\n",
      "     29        1.3929       0.2682        \u001b[35m1.3816\u001b[0m  0.0559\n",
      "     30        \u001b[36m1.3884\u001b[0m       \u001b[32m0.2761\u001b[0m        \u001b[35m1.3808\u001b[0m  0.0519\n",
      "     31        1.3894       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3801\u001b[0m  0.0519\n",
      "     32        1.3890       \u001b[32m0.2821\u001b[0m        \u001b[35m1.3794\u001b[0m  0.0499\n",
      "     33        \u001b[36m1.3878\u001b[0m       0.2801        \u001b[35m1.3787\u001b[0m  0.0389\n",
      "     34        \u001b[36m1.3845\u001b[0m       0.2821        \u001b[35m1.3779\u001b[0m  0.0409\n",
      "     35        \u001b[36m1.3833\u001b[0m       0.2821        \u001b[35m1.3772\u001b[0m  0.0469\n",
      "     36        1.3863       \u001b[32m0.2840\u001b[0m        \u001b[35m1.3765\u001b[0m  0.0429\n",
      "     37        \u001b[36m1.3816\u001b[0m       \u001b[32m0.2860\u001b[0m        \u001b[35m1.3758\u001b[0m  0.0459\n",
      "     38        1.3885       0.2860        \u001b[35m1.3751\u001b[0m  0.0698\n",
      "     39        1.3852       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3744\u001b[0m  0.0568\n",
      "     40        \u001b[36m1.3802\u001b[0m       0.2919        \u001b[35m1.3737\u001b[0m  0.0559\n",
      "     41        1.3811       0.2919        \u001b[35m1.3729\u001b[0m  0.0519\n",
      "     42        1.3837       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3722\u001b[0m  0.0429\n",
      "     43        \u001b[36m1.3737\u001b[0m       \u001b[32m0.2978\u001b[0m        \u001b[35m1.3715\u001b[0m  0.0409\n",
      "     44        1.3797       \u001b[32m0.3018\u001b[0m        \u001b[35m1.3708\u001b[0m  0.0668\n",
      "     45        1.3826       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3701\u001b[0m  0.0469\n",
      "     46        1.3801       0.3037        \u001b[35m1.3694\u001b[0m  0.0578\n",
      "     47        1.3778       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3688\u001b[0m  0.0489\n",
      "     48        \u001b[36m1.3721\u001b[0m       0.3037        \u001b[35m1.3681\u001b[0m  0.0559\n",
      "     49        1.3742       0.3057        \u001b[35m1.3674\u001b[0m  0.0369\n",
      "     50        1.3780       0.3037        \u001b[35m1.3667\u001b[0m  0.0419\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4491\u001b[0m       \u001b[32m0.1736\u001b[0m        \u001b[35m1.4332\u001b[0m  0.0399\n",
      "      2        \u001b[36m1.4476\u001b[0m       \u001b[32m0.1755\u001b[0m        \u001b[35m1.4318\u001b[0m  0.0518\n",
      "      3        1.4574       0.1755        \u001b[35m1.4303\u001b[0m  0.0549\n",
      "      4        1.4488       \u001b[32m0.1775\u001b[0m        \u001b[35m1.4290\u001b[0m  0.0559\n",
      "      5        1.4479       \u001b[32m0.1795\u001b[0m        \u001b[35m1.4276\u001b[0m  0.0509\n",
      "      6        \u001b[36m1.4433\u001b[0m       \u001b[32m0.1815\u001b[0m        \u001b[35m1.4263\u001b[0m  0.0529\n",
      "      7        1.4441       0.1815        \u001b[35m1.4250\u001b[0m  0.0648\n",
      "      8        1.4484       \u001b[32m0.1834\u001b[0m        \u001b[35m1.4236\u001b[0m  0.0549\n",
      "      9        1.4462       0.1834        \u001b[35m1.4223\u001b[0m  0.0568\n",
      "     10        \u001b[36m1.4404\u001b[0m       0.1834        \u001b[35m1.4209\u001b[0m  0.0429\n",
      "     11        1.4420       \u001b[32m0.1893\u001b[0m        \u001b[35m1.4196\u001b[0m  0.0479\n",
      "     12        \u001b[36m1.4330\u001b[0m       \u001b[32m0.1913\u001b[0m        \u001b[35m1.4183\u001b[0m  0.0628\n",
      "     13        1.4362       0.1913        \u001b[35m1.4170\u001b[0m  0.0578\n",
      "     14        1.4393       0.1913        \u001b[35m1.4157\u001b[0m  0.0658\n",
      "     15        1.4343       0.1913        \u001b[35m1.4144\u001b[0m  0.0459\n",
      "     16        \u001b[36m1.4327\u001b[0m       0.1913        \u001b[35m1.4131\u001b[0m  0.0568\n",
      "     17        \u001b[36m1.4292\u001b[0m       \u001b[32m0.1953\u001b[0m        \u001b[35m1.4119\u001b[0m  0.0419\n",
      "     18        \u001b[36m1.4286\u001b[0m       \u001b[32m0.1972\u001b[0m        \u001b[35m1.4107\u001b[0m  0.0539\n",
      "     19        \u001b[36m1.4281\u001b[0m       0.1953        \u001b[35m1.4094\u001b[0m  0.0479\n",
      "     20        \u001b[36m1.4267\u001b[0m       0.1972        \u001b[35m1.4082\u001b[0m  0.0498\n",
      "     21        \u001b[36m1.4235\u001b[0m       0.1972        \u001b[35m1.4070\u001b[0m  0.0419\n",
      "     22        \u001b[36m1.4217\u001b[0m       \u001b[32m0.2012\u001b[0m        \u001b[35m1.4058\u001b[0m  0.0638\n",
      "     23        \u001b[36m1.4211\u001b[0m       0.2012        \u001b[35m1.4045\u001b[0m  0.0638\n",
      "     24        \u001b[36m1.4201\u001b[0m       \u001b[32m0.2032\u001b[0m        \u001b[35m1.4033\u001b[0m  0.0509\n",
      "     25        1.4216       \u001b[32m0.2051\u001b[0m        \u001b[35m1.4022\u001b[0m  0.0409\n",
      "     26        \u001b[36m1.4105\u001b[0m       \u001b[32m0.2071\u001b[0m        \u001b[35m1.4010\u001b[0m  0.0479\n",
      "     27        1.4155       \u001b[32m0.2091\u001b[0m        \u001b[35m1.3998\u001b[0m  0.0529\n",
      "     28        1.4171       0.2091        \u001b[35m1.3986\u001b[0m  0.0379\n",
      "     29        1.4217       \u001b[32m0.2130\u001b[0m        \u001b[35m1.3975\u001b[0m  0.0479\n",
      "     30        1.4119       \u001b[32m0.2150\u001b[0m        \u001b[35m1.3963\u001b[0m  0.0379\n",
      "     31        1.4209       \u001b[32m0.2189\u001b[0m        \u001b[35m1.3951\u001b[0m  0.0469\n",
      "     32        1.4144       \u001b[32m0.2209\u001b[0m        \u001b[35m1.3939\u001b[0m  0.0449\n",
      "     33        1.4114       \u001b[32m0.2249\u001b[0m        \u001b[35m1.3928\u001b[0m  0.0588\n",
      "     34        \u001b[36m1.4093\u001b[0m       0.2249        \u001b[35m1.3916\u001b[0m  0.0449\n",
      "     35        1.4104       0.2249        \u001b[35m1.3905\u001b[0m  0.0519\n",
      "     36        \u001b[36m1.4067\u001b[0m       \u001b[32m0.2288\u001b[0m        \u001b[35m1.3894\u001b[0m  0.0389\n",
      "     37        1.4107       \u001b[32m0.2308\u001b[0m        \u001b[35m1.3883\u001b[0m  0.0509\n",
      "     38        \u001b[36m1.4061\u001b[0m       \u001b[32m0.2327\u001b[0m        \u001b[35m1.3871\u001b[0m  0.0529\n",
      "     39        \u001b[36m1.4056\u001b[0m       0.2327        \u001b[35m1.3861\u001b[0m  0.0379\n",
      "     40        \u001b[36m1.4038\u001b[0m       0.2327        \u001b[35m1.3850\u001b[0m  0.0409\n",
      "     41        1.4042       0.2308        \u001b[35m1.3839\u001b[0m  0.0459\n",
      "     42        \u001b[36m1.4037\u001b[0m       \u001b[32m0.2387\u001b[0m        \u001b[35m1.3828\u001b[0m  0.0419\n",
      "     43        \u001b[36m1.3968\u001b[0m       \u001b[32m0.2426\u001b[0m        \u001b[35m1.3817\u001b[0m  0.0529\n",
      "     44        1.4015       \u001b[32m0.2446\u001b[0m        \u001b[35m1.3806\u001b[0m  0.0459\n",
      "     45        1.3996       0.2446        \u001b[35m1.3795\u001b[0m  0.0529\n",
      "     46        1.4008       0.2446        \u001b[35m1.3784\u001b[0m  0.0459\n",
      "     47        \u001b[36m1.3945\u001b[0m       \u001b[32m0.2485\u001b[0m        \u001b[35m1.3773\u001b[0m  0.0439\n",
      "     48        1.3978       0.2485        \u001b[35m1.3763\u001b[0m  0.0499\n",
      "     49        1.3974       \u001b[32m0.2525\u001b[0m        \u001b[35m1.3752\u001b[0m  0.0389\n",
      "     50        1.3961       \u001b[32m0.2544\u001b[0m        \u001b[35m1.3741\u001b[0m  0.0389\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.1s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4296\u001b[0m       \u001b[32m0.1755\u001b[0m        \u001b[35m1.4183\u001b[0m  0.0628\n",
      "      2        1.4297       \u001b[32m0.1775\u001b[0m        \u001b[35m1.4173\u001b[0m  0.0539\n",
      "      3        \u001b[36m1.4268\u001b[0m       \u001b[32m0.1795\u001b[0m        \u001b[35m1.4163\u001b[0m  0.0459\n",
      "      4        \u001b[36m1.4142\u001b[0m       \u001b[32m0.1815\u001b[0m        \u001b[35m1.4154\u001b[0m  0.0379\n",
      "      5        1.4212       0.1795        \u001b[35m1.4144\u001b[0m  0.0449\n",
      "      6        1.4188       \u001b[32m0.1854\u001b[0m        \u001b[35m1.4134\u001b[0m  0.0459\n",
      "      7        1.4282       \u001b[32m0.1913\u001b[0m        \u001b[35m1.4124\u001b[0m  0.0519\n",
      "      8        1.4233       0.1893        \u001b[35m1.4115\u001b[0m  0.0448\n",
      "      9        1.4184       0.1913        \u001b[35m1.4105\u001b[0m  0.0479\n",
      "     10        1.4177       0.1913        \u001b[35m1.4095\u001b[0m  0.0419\n",
      "     11        1.4215       \u001b[32m0.1953\u001b[0m        \u001b[35m1.4086\u001b[0m  0.0439\n",
      "     12        1.4167       0.1953        \u001b[35m1.4076\u001b[0m  0.0578\n",
      "     13        1.4199       0.1933        \u001b[35m1.4067\u001b[0m  0.0409\n",
      "     14        \u001b[36m1.4124\u001b[0m       \u001b[32m0.1972\u001b[0m        \u001b[35m1.4057\u001b[0m  0.0469\n",
      "     15        1.4141       \u001b[32m0.2012\u001b[0m        \u001b[35m1.4048\u001b[0m  0.0419\n",
      "     16        1.4136       \u001b[32m0.2032\u001b[0m        \u001b[35m1.4038\u001b[0m  0.0399\n",
      "     17        1.4129       0.2032        \u001b[35m1.4029\u001b[0m  0.0479\n",
      "     18        1.4146       \u001b[32m0.2071\u001b[0m        \u001b[35m1.4020\u001b[0m  0.0598\n",
      "     19        \u001b[36m1.4100\u001b[0m       \u001b[32m0.2091\u001b[0m        \u001b[35m1.4010\u001b[0m  0.0508\n",
      "     20        \u001b[36m1.4075\u001b[0m       \u001b[32m0.2130\u001b[0m        \u001b[35m1.4001\u001b[0m  0.0469\n",
      "     21        \u001b[36m1.4035\u001b[0m       0.2130        \u001b[35m1.3992\u001b[0m  0.0459\n",
      "     22        1.4104       0.2130        \u001b[35m1.3983\u001b[0m  0.0588\n",
      "     23        1.4062       0.2110        \u001b[35m1.3974\u001b[0m  0.0509\n",
      "     24        1.4105       \u001b[32m0.2150\u001b[0m        \u001b[35m1.3964\u001b[0m  0.0399\n",
      "     25        1.4062       0.2150        \u001b[35m1.3955\u001b[0m  0.0399\n",
      "     26        1.4055       \u001b[32m0.2170\u001b[0m        \u001b[35m1.3946\u001b[0m  0.0678\n",
      "     27        \u001b[36m1.4007\u001b[0m       \u001b[32m0.2189\u001b[0m        \u001b[35m1.3937\u001b[0m  0.0668\n",
      "     28        1.4031       0.2189        \u001b[35m1.3928\u001b[0m  0.0658\n",
      "     29        1.4016       \u001b[32m0.2268\u001b[0m        \u001b[35m1.3919\u001b[0m  0.0509\n",
      "     30        \u001b[36m1.3997\u001b[0m       0.2268        \u001b[35m1.3911\u001b[0m  0.0539\n",
      "     31        1.4018       0.2268        \u001b[35m1.3902\u001b[0m  0.0499\n",
      "     32        1.4030       0.2268        \u001b[35m1.3893\u001b[0m  0.0419\n",
      "     33        \u001b[36m1.3939\u001b[0m       \u001b[32m0.2288\u001b[0m        \u001b[35m1.3884\u001b[0m  0.0588\n",
      "     34        1.3948       0.2288        \u001b[35m1.3875\u001b[0m  0.0429\n",
      "     35        1.3942       0.2288        \u001b[35m1.3866\u001b[0m  0.0678\n",
      "     36        1.4007       \u001b[32m0.2308\u001b[0m        \u001b[35m1.3857\u001b[0m  0.0618\n",
      "     37        1.3966       \u001b[32m0.2327\u001b[0m        \u001b[35m1.3849\u001b[0m  0.0628\n",
      "     38        \u001b[36m1.3891\u001b[0m       \u001b[32m0.2347\u001b[0m        \u001b[35m1.3840\u001b[0m  0.0568\n",
      "     39        1.3899       0.2347        \u001b[35m1.3832\u001b[0m  0.0439\n",
      "     40        \u001b[36m1.3872\u001b[0m       \u001b[32m0.2367\u001b[0m        \u001b[35m1.3823\u001b[0m  0.0559\n",
      "     41        1.3922       0.2367        \u001b[35m1.3814\u001b[0m  0.0478\n",
      "     42        1.3908       0.2367        \u001b[35m1.3806\u001b[0m  0.0519\n",
      "     43        1.3905       0.2367        \u001b[35m1.3797\u001b[0m  0.0678\n",
      "     44        1.3939       0.2367        \u001b[35m1.3788\u001b[0m  0.0459\n",
      "     45        1.3884       \u001b[32m0.2387\u001b[0m        \u001b[35m1.3780\u001b[0m  0.0519\n",
      "     46        1.3875       \u001b[32m0.2426\u001b[0m        \u001b[35m1.3771\u001b[0m  0.0489\n",
      "     47        \u001b[36m1.3823\u001b[0m       \u001b[32m0.2465\u001b[0m        \u001b[35m1.3763\u001b[0m  0.0479\n",
      "     48        1.3839       0.2465        \u001b[35m1.3754\u001b[0m  0.0429\n",
      "     49        1.3860       \u001b[32m0.2505\u001b[0m        \u001b[35m1.3746\u001b[0m  0.0479\n",
      "     50        1.3840       \u001b[32m0.2525\u001b[0m        \u001b[35m1.3737\u001b[0m  0.0509\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.2s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4566\u001b[0m       \u001b[32m0.2268\u001b[0m        \u001b[35m1.3756\u001b[0m  0.0519\n",
      "      2        \u001b[36m1.3812\u001b[0m       \u001b[32m0.3767\u001b[0m        \u001b[35m1.3407\u001b[0m  0.0489\n",
      "      3        \u001b[36m1.3389\u001b[0m       \u001b[32m0.5306\u001b[0m        \u001b[35m1.3064\u001b[0m  0.0529\n",
      "      4        \u001b[36m1.3109\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m1.2718\u001b[0m  0.0738\n",
      "      5        \u001b[36m1.2778\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.2362\u001b[0m  0.0578\n",
      "      6        \u001b[36m1.2417\u001b[0m       \u001b[32m0.7081\u001b[0m        \u001b[35m1.1999\u001b[0m  0.0608\n",
      "      7        \u001b[36m1.2001\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m1.1622\u001b[0m  0.0489\n",
      "      8        \u001b[36m1.1651\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m1.1230\u001b[0m  0.0608\n",
      "      9        \u001b[36m1.1307\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m1.0831\u001b[0m  0.0419\n",
      "     10        \u001b[36m1.0963\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m1.0429\u001b[0m  0.0588\n",
      "     11        \u001b[36m1.0492\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m1.0025\u001b[0m  0.0549\n",
      "     12        \u001b[36m1.0099\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.9628\u001b[0m  0.0638\n",
      "     13        \u001b[36m0.9729\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.9243\u001b[0m  0.0618\n",
      "     14        \u001b[36m0.9448\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.8871\u001b[0m  0.0598\n",
      "     15        \u001b[36m0.9048\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.8513\u001b[0m  0.0519\n",
      "     16        \u001b[36m0.8765\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.8174\u001b[0m  0.0568\n",
      "     17        \u001b[36m0.8467\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.7853\u001b[0m  0.0489\n",
      "     18        \u001b[36m0.8184\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.7551\u001b[0m  0.0509\n",
      "     19        \u001b[36m0.7859\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.7264\u001b[0m  0.0598\n",
      "     20        \u001b[36m0.7562\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.6994\u001b[0m  0.0489\n",
      "     21        \u001b[36m0.7237\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.6737\u001b[0m  0.0489\n",
      "     22        \u001b[36m0.7016\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.6495\u001b[0m  0.0668\n",
      "     23        \u001b[36m0.6967\u001b[0m       \u001b[32m0.8797\u001b[0m        \u001b[35m0.6266\u001b[0m  0.0608\n",
      "     24        \u001b[36m0.6636\u001b[0m       0.8797        \u001b[35m0.6051\u001b[0m  0.0459\n",
      "     25        \u001b[36m0.6418\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.5848\u001b[0m  0.0449\n",
      "     26        \u001b[36m0.6171\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.5656\u001b[0m  0.0638\n",
      "     27        \u001b[36m0.6111\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.5473\u001b[0m  0.0449\n",
      "     28        \u001b[36m0.5959\u001b[0m       0.8895        \u001b[35m0.5302\u001b[0m  0.0519\n",
      "     29        \u001b[36m0.5757\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.5141\u001b[0m  0.0688\n",
      "     30        \u001b[36m0.5594\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.4987\u001b[0m  0.0559\n",
      "     31        \u001b[36m0.5457\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.4840\u001b[0m  0.0459\n",
      "     32        \u001b[36m0.5292\u001b[0m       0.9014        \u001b[35m0.4701\u001b[0m  0.0458\n",
      "     33        \u001b[36m0.5161\u001b[0m       0.9014        \u001b[35m0.4570\u001b[0m  0.0568\n",
      "     34        \u001b[36m0.4989\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m0.4446\u001b[0m  0.0479\n",
      "     35        \u001b[36m0.4919\u001b[0m       0.9073        \u001b[35m0.4329\u001b[0m  0.0479\n",
      "     36        \u001b[36m0.4867\u001b[0m       0.9073        \u001b[35m0.4218\u001b[0m  0.0469\n",
      "     37        \u001b[36m0.4721\u001b[0m       0.9073        \u001b[35m0.4112\u001b[0m  0.0439\n",
      "     38        \u001b[36m0.4642\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m0.4013\u001b[0m  0.0638\n",
      "     39        \u001b[36m0.4508\u001b[0m       0.9093        \u001b[35m0.3918\u001b[0m  0.0588\n",
      "     40        \u001b[36m0.4466\u001b[0m       \u001b[32m0.9112\u001b[0m        \u001b[35m0.3828\u001b[0m  0.0559\n",
      "     41        \u001b[36m0.4345\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m0.3744\u001b[0m  0.0439\n",
      "     42        \u001b[36m0.4287\u001b[0m       \u001b[32m0.9191\u001b[0m        \u001b[35m0.3665\u001b[0m  0.0549\n",
      "     43        \u001b[36m0.4226\u001b[0m       0.9191        \u001b[35m0.3587\u001b[0m  0.0598\n",
      "     44        \u001b[36m0.4193\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.3515\u001b[0m  0.0439\n",
      "     45        \u001b[36m0.4118\u001b[0m       0.9211        \u001b[35m0.3447\u001b[0m  0.0688\n",
      "     46        \u001b[36m0.3972\u001b[0m       0.9211        \u001b[35m0.3384\u001b[0m  0.0578\n",
      "     47        \u001b[36m0.3897\u001b[0m       0.9211        \u001b[35m0.3323\u001b[0m  0.0598\n",
      "     48        \u001b[36m0.3836\u001b[0m       0.9211        \u001b[35m0.3263\u001b[0m  0.0549\n",
      "     49        \u001b[36m0.3730\u001b[0m       0.9211        \u001b[35m0.3204\u001b[0m  0.0568\n",
      "     50        \u001b[36m0.3666\u001b[0m       0.9211        \u001b[35m0.3147\u001b[0m  0.0559\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.4s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4551\u001b[0m       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3767\u001b[0m  0.0449\n",
      "      2        \u001b[36m1.3830\u001b[0m       \u001b[32m0.4024\u001b[0m        \u001b[35m1.3382\u001b[0m  0.0628\n",
      "      3        \u001b[36m1.3407\u001b[0m       \u001b[32m0.5069\u001b[0m        \u001b[35m1.3002\u001b[0m  0.0489\n",
      "      4        \u001b[36m1.3085\u001b[0m       \u001b[32m0.6114\u001b[0m        \u001b[35m1.2632\u001b[0m  0.0489\n",
      "      5        \u001b[36m1.2725\u001b[0m       \u001b[32m0.6963\u001b[0m        \u001b[35m1.2264\u001b[0m  0.0459\n",
      "      6        \u001b[36m1.2315\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m1.1891\u001b[0m  0.0608\n",
      "      7        \u001b[36m1.2025\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m1.1512\u001b[0m  0.0688\n",
      "      8        \u001b[36m1.1646\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m1.1127\u001b[0m  0.0578\n",
      "      9        \u001b[36m1.1272\u001b[0m       \u001b[32m0.7751\u001b[0m        \u001b[35m1.0739\u001b[0m  0.0638\n",
      "     10        \u001b[36m1.0862\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m1.0348\u001b[0m  0.0618\n",
      "     11        \u001b[36m1.0521\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.9964\u001b[0m  0.0509\n",
      "     12        \u001b[36m1.0132\u001b[0m       0.8047        \u001b[35m0.9583\u001b[0m  0.0459\n",
      "     13        \u001b[36m0.9806\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.9217\u001b[0m  0.0628\n",
      "     14        \u001b[36m0.9403\u001b[0m       \u001b[32m0.8185\u001b[0m        \u001b[35m0.8865\u001b[0m  0.0598\n",
      "     15        \u001b[36m0.9118\u001b[0m       \u001b[32m0.8264\u001b[0m        \u001b[35m0.8529\u001b[0m  0.0668\n",
      "     16        \u001b[36m0.8823\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.8207\u001b[0m  0.0499\n",
      "     17        \u001b[36m0.8465\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.7903\u001b[0m  0.0449\n",
      "     18        \u001b[36m0.8197\u001b[0m       \u001b[32m0.8442\u001b[0m        \u001b[35m0.7615\u001b[0m  0.0479\n",
      "     19        \u001b[36m0.7927\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.7343\u001b[0m  0.0559\n",
      "     20        \u001b[36m0.7678\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.7087\u001b[0m  0.0628\n",
      "     21        \u001b[36m0.7434\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.6842\u001b[0m  0.0698\n",
      "     22        \u001b[36m0.7093\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.6611\u001b[0m  0.0598\n",
      "     23        \u001b[36m0.6967\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.6393\u001b[0m  0.0519\n",
      "     24        \u001b[36m0.6769\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.6188\u001b[0m  0.0489\n",
      "     25        \u001b[36m0.6597\u001b[0m       0.8777        \u001b[35m0.5996\u001b[0m  0.0529\n",
      "     26        \u001b[36m0.6298\u001b[0m       0.8777        \u001b[35m0.5814\u001b[0m  0.0439\n",
      "     27        \u001b[36m0.6182\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.5645\u001b[0m  0.0559\n",
      "     28        \u001b[36m0.5978\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.5483\u001b[0m  0.0758\n",
      "     29        \u001b[36m0.5870\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.5328\u001b[0m  0.0658\n",
      "     30        \u001b[36m0.5744\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.5180\u001b[0m  0.0688\n",
      "     31        \u001b[36m0.5537\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.5040\u001b[0m  0.0559\n",
      "     32        \u001b[36m0.5373\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.4909\u001b[0m  0.0688\n",
      "     33        \u001b[36m0.5212\u001b[0m       0.8935        \u001b[35m0.4787\u001b[0m  0.0669\n",
      "     34        \u001b[36m0.5069\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.4669\u001b[0m  0.0609\n",
      "     35        \u001b[36m0.4992\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.4558\u001b[0m  0.0569\n",
      "     36        \u001b[36m0.4947\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.4455\u001b[0m  0.0519\n",
      "     37        \u001b[36m0.4699\u001b[0m       0.9014        \u001b[35m0.4357\u001b[0m  0.0539\n",
      "     38        \u001b[36m0.4669\u001b[0m       0.8994        \u001b[35m0.4261\u001b[0m  0.0638\n",
      "     39        \u001b[36m0.4587\u001b[0m       0.8955        \u001b[35m0.4173\u001b[0m  0.0598\n",
      "     40        \u001b[36m0.4416\u001b[0m       0.8955        \u001b[35m0.4090\u001b[0m  0.0688\n",
      "     41        \u001b[36m0.4392\u001b[0m       0.8974        \u001b[35m0.4009\u001b[0m  0.0588\n",
      "     42        \u001b[36m0.4302\u001b[0m       0.8955        \u001b[35m0.3932\u001b[0m  0.0509\n",
      "     43        0.4319       0.8935        \u001b[35m0.3861\u001b[0m  0.0549\n",
      "     44        \u001b[36m0.4170\u001b[0m       0.8955        \u001b[35m0.3792\u001b[0m  0.0529\n",
      "     45        \u001b[36m0.4060\u001b[0m       0.8955        \u001b[35m0.3725\u001b[0m  0.0459\n",
      "     46        0.4069       0.8955        \u001b[35m0.3661\u001b[0m  0.0549\n",
      "     47        \u001b[36m0.3934\u001b[0m       0.8974        \u001b[35m0.3601\u001b[0m  0.0539\n",
      "     48        \u001b[36m0.3857\u001b[0m       0.9014        \u001b[35m0.3541\u001b[0m  0.0469\n",
      "     49        \u001b[36m0.3819\u001b[0m       \u001b[32m0.9034\u001b[0m        \u001b[35m0.3484\u001b[0m  0.0539\n",
      "     50        \u001b[36m0.3757\u001b[0m       0.9034        \u001b[35m0.3432\u001b[0m  0.0578\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.5s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4511\u001b[0m       \u001b[32m0.2623\u001b[0m        \u001b[35m1.3826\u001b[0m  0.0529\n",
      "      2        \u001b[36m1.3766\u001b[0m       \u001b[32m0.3609\u001b[0m        \u001b[35m1.3416\u001b[0m  0.0618\n",
      "      3        \u001b[36m1.3300\u001b[0m       \u001b[32m0.4951\u001b[0m        \u001b[35m1.3013\u001b[0m  0.0578\n",
      "      4        \u001b[36m1.2947\u001b[0m       \u001b[32m0.6154\u001b[0m        \u001b[35m1.2626\u001b[0m  0.0708\n",
      "      5        \u001b[36m1.2585\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.2243\u001b[0m  0.0668\n",
      "      6        \u001b[36m1.2225\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m1.1857\u001b[0m  0.0568\n",
      "      7        \u001b[36m1.1856\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m1.1467\u001b[0m  0.0469\n",
      "      8        \u001b[36m1.1523\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m1.1070\u001b[0m  0.0489\n",
      "      9        \u001b[36m1.1103\u001b[0m       \u001b[32m0.7456\u001b[0m        \u001b[35m1.0669\u001b[0m  0.0748\n",
      "     10        \u001b[36m1.0720\u001b[0m       \u001b[32m0.7535\u001b[0m        \u001b[35m1.0264\u001b[0m  0.0618\n",
      "     11        \u001b[36m1.0329\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m0.9863\u001b[0m  0.0598\n",
      "     12        \u001b[36m0.9976\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.9469\u001b[0m  0.0509\n",
      "     13        \u001b[36m0.9616\u001b[0m       \u001b[32m0.7850\u001b[0m        \u001b[35m0.9085\u001b[0m  0.0638\n",
      "     14        \u001b[36m0.9216\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.8714\u001b[0m  0.0578\n",
      "     15        \u001b[36m0.8935\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m0.8361\u001b[0m  0.0519\n",
      "     16        \u001b[36m0.8575\u001b[0m       \u001b[32m0.8126\u001b[0m        \u001b[35m0.8025\u001b[0m  0.0499\n",
      "     17        \u001b[36m0.8268\u001b[0m       \u001b[32m0.8205\u001b[0m        \u001b[35m0.7707\u001b[0m  0.0459\n",
      "     18        \u001b[36m0.7913\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.7408\u001b[0m  0.0568\n",
      "     19        \u001b[36m0.7677\u001b[0m       \u001b[32m0.8422\u001b[0m        \u001b[35m0.7125\u001b[0m  0.0578\n",
      "     20        \u001b[36m0.7359\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.6857\u001b[0m  0.0688\n",
      "     21        \u001b[36m0.7108\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.6603\u001b[0m  0.0479\n",
      "     22        \u001b[36m0.6895\u001b[0m       \u001b[32m0.8856\u001b[0m        \u001b[35m0.6362\u001b[0m  0.0578\n",
      "     23        \u001b[36m0.6631\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.6136\u001b[0m  0.0528\n",
      "     24        \u001b[36m0.6535\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.5922\u001b[0m  0.0479\n",
      "     25        \u001b[36m0.6310\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.5721\u001b[0m  0.0509\n",
      "     26        \u001b[36m0.6068\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.5530\u001b[0m  0.0489\n",
      "     27        \u001b[36m0.5870\u001b[0m       \u001b[32m0.9112\u001b[0m        \u001b[35m0.5350\u001b[0m  0.0588\n",
      "     28        \u001b[36m0.5769\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m0.5181\u001b[0m  0.0479\n",
      "     29        \u001b[36m0.5594\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m0.5023\u001b[0m  0.0679\n",
      "     30        \u001b[36m0.5440\u001b[0m       0.9172        \u001b[35m0.4874\u001b[0m  0.0579\n",
      "     31        \u001b[36m0.5281\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.4731\u001b[0m  0.0499\n",
      "     32        \u001b[36m0.5209\u001b[0m       0.9211        \u001b[35m0.4598\u001b[0m  0.0598\n",
      "     33        \u001b[36m0.4994\u001b[0m       0.9191        \u001b[35m0.4470\u001b[0m  0.0539\n",
      "     34        \u001b[36m0.4977\u001b[0m       0.9191        \u001b[35m0.4351\u001b[0m  0.0529\n",
      "     35        \u001b[36m0.4749\u001b[0m       0.9191        \u001b[35m0.4240\u001b[0m  0.0568\n",
      "     36        \u001b[36m0.4634\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.4133\u001b[0m  0.0499\n",
      "     37        \u001b[36m0.4551\u001b[0m       0.9231        \u001b[35m0.4031\u001b[0m  0.0529\n",
      "     38        \u001b[36m0.4465\u001b[0m       0.9231        \u001b[35m0.3934\u001b[0m  0.0568\n",
      "     39        0.4474       0.9231        \u001b[35m0.3846\u001b[0m  0.0718\n",
      "     40        \u001b[36m0.4312\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.3760\u001b[0m  0.0608\n",
      "     41        \u001b[36m0.4255\u001b[0m       0.9250        \u001b[35m0.3679\u001b[0m  0.0598\n",
      "     42        \u001b[36m0.4097\u001b[0m       0.9250        \u001b[35m0.3597\u001b[0m  0.0568\n",
      "     43        0.4111       0.9231        \u001b[35m0.3521\u001b[0m  0.0549\n",
      "     44        \u001b[36m0.4028\u001b[0m       0.9231        \u001b[35m0.3450\u001b[0m  0.0539\n",
      "     45        \u001b[36m0.3998\u001b[0m       0.9231        \u001b[35m0.3383\u001b[0m  0.0449\n",
      "     46        \u001b[36m0.3894\u001b[0m       0.9250        \u001b[35m0.3316\u001b[0m  0.0618\n",
      "     47        \u001b[36m0.3821\u001b[0m       \u001b[32m0.9270\u001b[0m        \u001b[35m0.3254\u001b[0m  0.0429\n",
      "     48        \u001b[36m0.3706\u001b[0m       0.9270        \u001b[35m0.3196\u001b[0m  0.0439\n",
      "     49        \u001b[36m0.3625\u001b[0m       \u001b[32m0.9349\u001b[0m        \u001b[35m0.3144\u001b[0m  0.0618\n",
      "     50        \u001b[36m0.3604\u001b[0m       \u001b[32m0.9389\u001b[0m        \u001b[35m0.3090\u001b[0m  0.0628\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.5s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4369\u001b[0m       \u001b[32m0.1716\u001b[0m        \u001b[35m1.4262\u001b[0m  0.0618\n",
      "      2        1.4372       0.1716        \u001b[35m1.4249\u001b[0m  0.0479\n",
      "      3        1.4409       0.1716        \u001b[35m1.4235\u001b[0m  0.0549\n",
      "      4        1.4381       0.1716        \u001b[35m1.4221\u001b[0m  0.0429\n",
      "      5        \u001b[36m1.4330\u001b[0m       0.1716        \u001b[35m1.4208\u001b[0m  0.0539\n",
      "      6        \u001b[36m1.4310\u001b[0m       0.1716        \u001b[35m1.4194\u001b[0m  0.0598\n",
      "      7        1.4379       \u001b[32m0.1736\u001b[0m        \u001b[35m1.4180\u001b[0m  0.0638\n",
      "      8        1.4326       \u001b[32m0.1775\u001b[0m        \u001b[35m1.4167\u001b[0m  0.0628\n",
      "      9        \u001b[36m1.4242\u001b[0m       0.1775        \u001b[35m1.4154\u001b[0m  0.0708\n",
      "     10        1.4280       \u001b[32m0.1834\u001b[0m        \u001b[35m1.4140\u001b[0m  0.0578\n",
      "     11        1.4263       \u001b[32m0.1854\u001b[0m        \u001b[35m1.4127\u001b[0m  0.0648\n",
      "     12        \u001b[36m1.4153\u001b[0m       \u001b[32m0.1913\u001b[0m        \u001b[35m1.4114\u001b[0m  0.0668\n",
      "     13        1.4236       \u001b[32m0.1933\u001b[0m        \u001b[35m1.4101\u001b[0m  0.0539\n",
      "     14        1.4157       0.1933        \u001b[35m1.4088\u001b[0m  0.0549\n",
      "     15        1.4157       \u001b[32m0.1972\u001b[0m        \u001b[35m1.4075\u001b[0m  0.0568\n",
      "     16        1.4179       \u001b[32m0.2051\u001b[0m        \u001b[35m1.4062\u001b[0m  0.0598\n",
      "     17        1.4195       \u001b[32m0.2150\u001b[0m        \u001b[35m1.4049\u001b[0m  0.0668\n",
      "     18        1.4160       \u001b[32m0.2170\u001b[0m        \u001b[35m1.4037\u001b[0m  0.0539\n",
      "     19        1.4165       \u001b[32m0.2229\u001b[0m        \u001b[35m1.4024\u001b[0m  0.0568\n",
      "     20        \u001b[36m1.4122\u001b[0m       \u001b[32m0.2268\u001b[0m        \u001b[35m1.4011\u001b[0m  0.0539\n",
      "     21        \u001b[36m1.4084\u001b[0m       \u001b[32m0.2288\u001b[0m        \u001b[35m1.3998\u001b[0m  0.0678\n",
      "     22        1.4148       0.2288        \u001b[35m1.3986\u001b[0m  0.0479\n",
      "     23        1.4090       \u001b[32m0.2308\u001b[0m        \u001b[35m1.3973\u001b[0m  0.0429\n",
      "     24        \u001b[36m1.4027\u001b[0m       \u001b[32m0.2347\u001b[0m        \u001b[35m1.3961\u001b[0m  0.0568\n",
      "     25        1.4067       0.2347        \u001b[35m1.3949\u001b[0m  0.0578\n",
      "     26        1.4028       \u001b[32m0.2367\u001b[0m        \u001b[35m1.3936\u001b[0m  0.0638\n",
      "     27        \u001b[36m1.4010\u001b[0m       \u001b[32m0.2387\u001b[0m        \u001b[35m1.3924\u001b[0m  0.0549\n",
      "     28        1.4050       \u001b[32m0.2426\u001b[0m        \u001b[35m1.3911\u001b[0m  0.0688\n",
      "     29        1.4020       \u001b[32m0.2446\u001b[0m        \u001b[35m1.3899\u001b[0m  0.0648\n",
      "     30        \u001b[36m1.3923\u001b[0m       \u001b[32m0.2465\u001b[0m        \u001b[35m1.3887\u001b[0m  0.0549\n",
      "     31        1.4022       \u001b[32m0.2544\u001b[0m        \u001b[35m1.3874\u001b[0m  0.0648\n",
      "     32        1.3991       \u001b[32m0.2623\u001b[0m        \u001b[35m1.3862\u001b[0m  0.0668\n",
      "     33        1.4013       \u001b[32m0.2643\u001b[0m        \u001b[35m1.3850\u001b[0m  0.0708\n",
      "     34        1.3959       \u001b[32m0.2682\u001b[0m        \u001b[35m1.3838\u001b[0m  0.0728\n",
      "     35        1.3980       \u001b[32m0.2742\u001b[0m        \u001b[35m1.3825\u001b[0m  0.0828\n",
      "     36        1.3944       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3813\u001b[0m  0.0628\n",
      "     37        \u001b[36m1.3891\u001b[0m       \u001b[32m0.2860\u001b[0m        \u001b[35m1.3801\u001b[0m  0.0898\n",
      "     38        \u001b[36m1.3864\u001b[0m       \u001b[32m0.2880\u001b[0m        \u001b[35m1.3789\u001b[0m  0.0818\n",
      "     39        1.3877       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3777\u001b[0m  0.0588\n",
      "     40        1.3929       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3765\u001b[0m  0.0658\n",
      "     41        \u001b[36m1.3786\u001b[0m       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3753\u001b[0m  0.0529\n",
      "     42        1.3874       \u001b[32m0.2978\u001b[0m        \u001b[35m1.3742\u001b[0m  0.0489\n",
      "     43        1.3851       0.2978        \u001b[35m1.3730\u001b[0m  0.0519\n",
      "     44        1.3873       \u001b[32m0.2998\u001b[0m        \u001b[35m1.3718\u001b[0m  0.0529\n",
      "     45        1.3792       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3706\u001b[0m  0.0429\n",
      "     46        1.3874       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3694\u001b[0m  0.0598\n",
      "     47        1.3863       0.3077        \u001b[35m1.3682\u001b[0m  0.0539\n",
      "     48        1.3813       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3671\u001b[0m  0.0469\n",
      "     49        \u001b[36m1.3785\u001b[0m       \u001b[32m0.3156\u001b[0m        \u001b[35m1.3659\u001b[0m  0.0438\n",
      "     50        \u001b[36m1.3776\u001b[0m       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3647\u001b[0m  0.0568\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.8s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3749\u001b[0m       \u001b[32m0.3767\u001b[0m        \u001b[35m1.3701\u001b[0m  0.0608\n",
      "      2        1.3802       0.3767        \u001b[35m1.3686\u001b[0m  0.0419\n",
      "      3        1.3777       0.3767        \u001b[35m1.3670\u001b[0m  0.0549\n",
      "      4        \u001b[36m1.3733\u001b[0m       \u001b[32m0.3787\u001b[0m        \u001b[35m1.3654\u001b[0m  0.0409\n",
      "      5        1.3798       \u001b[32m0.3826\u001b[0m        \u001b[35m1.3639\u001b[0m  0.0489\n",
      "      6        1.3802       \u001b[32m0.3846\u001b[0m        \u001b[35m1.3623\u001b[0m  0.0439\n",
      "      7        1.3796       \u001b[32m0.3886\u001b[0m        \u001b[35m1.3608\u001b[0m  0.0459\n",
      "      8        \u001b[36m1.3719\u001b[0m       \u001b[32m0.3905\u001b[0m        \u001b[35m1.3593\u001b[0m  0.0519\n",
      "      9        1.3726       0.3905        \u001b[35m1.3578\u001b[0m  0.0539\n",
      "     10        \u001b[36m1.3683\u001b[0m       \u001b[32m0.3984\u001b[0m        \u001b[35m1.3563\u001b[0m  0.0409\n",
      "     11        \u001b[36m1.3603\u001b[0m       0.3984        \u001b[35m1.3548\u001b[0m  0.0399\n",
      "     12        1.3710       \u001b[32m0.4004\u001b[0m        \u001b[35m1.3533\u001b[0m  0.0449\n",
      "     13        1.3610       0.4004        \u001b[35m1.3519\u001b[0m  0.0648\n",
      "     14        1.3630       \u001b[32m0.4024\u001b[0m        \u001b[35m1.3504\u001b[0m  0.0588\n",
      "     15        1.3630       0.4024        \u001b[35m1.3490\u001b[0m  0.0568\n",
      "     16        1.3628       0.4024        \u001b[35m1.3476\u001b[0m  0.0409\n",
      "     17        1.3611       0.4004        \u001b[35m1.3461\u001b[0m  0.0409\n",
      "     18        \u001b[36m1.3590\u001b[0m       \u001b[32m0.4043\u001b[0m        \u001b[35m1.3447\u001b[0m  0.0409\n",
      "     19        \u001b[36m1.3556\u001b[0m       \u001b[32m0.4083\u001b[0m        \u001b[35m1.3433\u001b[0m  0.0469\n",
      "     20        1.3593       0.4063        \u001b[35m1.3419\u001b[0m  0.0399\n",
      "     21        \u001b[36m1.3535\u001b[0m       0.4063        \u001b[35m1.3405\u001b[0m  0.0399\n",
      "     22        \u001b[36m1.3506\u001b[0m       0.4024        \u001b[35m1.3390\u001b[0m  0.0489\n",
      "     23        1.3556       0.4083        \u001b[35m1.3376\u001b[0m  0.0379\n",
      "     24        \u001b[36m1.3476\u001b[0m       0.4083        \u001b[35m1.3362\u001b[0m  0.0519\n",
      "     25        \u001b[36m1.3465\u001b[0m       \u001b[32m0.4162\u001b[0m        \u001b[35m1.3349\u001b[0m  0.0409\n",
      "     26        1.3480       \u001b[32m0.4181\u001b[0m        \u001b[35m1.3335\u001b[0m  0.0589\n",
      "     27        1.3467       \u001b[32m0.4221\u001b[0m        \u001b[35m1.3321\u001b[0m  0.0628\n",
      "     28        \u001b[36m1.3455\u001b[0m       \u001b[32m0.4300\u001b[0m        \u001b[35m1.3308\u001b[0m  0.0479\n",
      "     29        \u001b[36m1.3413\u001b[0m       \u001b[32m0.4339\u001b[0m        \u001b[35m1.3294\u001b[0m  0.0459\n",
      "     30        1.3429       0.4339        \u001b[35m1.3281\u001b[0m  0.0399\n",
      "     31        \u001b[36m1.3360\u001b[0m       0.4339        \u001b[35m1.3267\u001b[0m  0.0409\n",
      "     32        \u001b[36m1.3338\u001b[0m       \u001b[32m0.4359\u001b[0m        \u001b[35m1.3254\u001b[0m  0.0399\n",
      "     33        1.3360       0.4359        \u001b[35m1.3241\u001b[0m  0.0489\n",
      "     34        \u001b[36m1.3335\u001b[0m       \u001b[32m0.4379\u001b[0m        \u001b[35m1.3227\u001b[0m  0.0459\n",
      "     35        \u001b[36m1.3310\u001b[0m       \u001b[32m0.4458\u001b[0m        \u001b[35m1.3214\u001b[0m  0.0539\n",
      "     36        1.3312       \u001b[32m0.4517\u001b[0m        \u001b[35m1.3201\u001b[0m  0.0628\n",
      "     37        \u001b[36m1.3287\u001b[0m       \u001b[32m0.4615\u001b[0m        \u001b[35m1.3187\u001b[0m  0.0459\n",
      "     38        1.3339       \u001b[32m0.4675\u001b[0m        \u001b[35m1.3174\u001b[0m  0.0648\n",
      "     39        \u001b[36m1.3268\u001b[0m       \u001b[32m0.4734\u001b[0m        \u001b[35m1.3161\u001b[0m  0.0509\n",
      "     40        1.3283       \u001b[32m0.4753\u001b[0m        \u001b[35m1.3148\u001b[0m  0.0479\n",
      "     41        1.3308       \u001b[32m0.4773\u001b[0m        \u001b[35m1.3135\u001b[0m  0.0678\n",
      "     42        1.3299       0.4773        \u001b[35m1.3122\u001b[0m  0.0549\n",
      "     43        \u001b[36m1.3206\u001b[0m       0.4753        \u001b[35m1.3109\u001b[0m  0.0509\n",
      "     44        1.3271       0.4714        \u001b[35m1.3095\u001b[0m  0.0429\n",
      "     45        1.3214       0.4734        \u001b[35m1.3082\u001b[0m  0.0648\n",
      "     46        \u001b[36m1.3168\u001b[0m       0.4753        \u001b[35m1.3070\u001b[0m  0.0529\n",
      "     47        1.3172       \u001b[32m0.4793\u001b[0m        \u001b[35m1.3057\u001b[0m  0.0469\n",
      "     48        1.3225       \u001b[32m0.4872\u001b[0m        \u001b[35m1.3044\u001b[0m  0.0578\n",
      "     49        1.3208       0.4872        \u001b[35m1.3031\u001b[0m  0.0558\n",
      "     50        1.3169       \u001b[32m0.4892\u001b[0m        \u001b[35m1.3018\u001b[0m  0.0559\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.1s\n",
      "[CV] lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3969\u001b[0m       \u001b[32m0.2761\u001b[0m        \u001b[35m1.3834\u001b[0m  0.0509\n",
      "      2        1.4015       \u001b[32m0.2781\u001b[0m        \u001b[35m1.3821\u001b[0m  0.0419\n",
      "      3        \u001b[36m1.3969\u001b[0m       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3808\u001b[0m  0.0608\n",
      "      4        \u001b[36m1.3935\u001b[0m       \u001b[32m0.2821\u001b[0m        \u001b[35m1.3795\u001b[0m  0.0568\n",
      "      5        \u001b[36m1.3856\u001b[0m       0.2821        \u001b[35m1.3783\u001b[0m  0.0399\n",
      "      6        1.3926       \u001b[32m0.2880\u001b[0m        \u001b[35m1.3770\u001b[0m  0.0399\n",
      "      7        1.3880       0.2880        \u001b[35m1.3757\u001b[0m  0.0449\n",
      "      8        1.3892       0.2860        \u001b[35m1.3745\u001b[0m  0.0389\n",
      "      9        \u001b[36m1.3807\u001b[0m       0.2880        \u001b[35m1.3732\u001b[0m  0.0469\n",
      "     10        1.3812       0.2880        \u001b[35m1.3720\u001b[0m  0.0618\n",
      "     11        1.3847       0.2880        \u001b[35m1.3707\u001b[0m  0.0559\n",
      "     12        1.3843       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3695\u001b[0m  0.0409\n",
      "     13        1.3865       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3682\u001b[0m  0.0468\n",
      "     14        1.3821       \u001b[32m0.2998\u001b[0m        \u001b[35m1.3670\u001b[0m  0.0549\n",
      "     15        1.3818       0.2998        \u001b[35m1.3658\u001b[0m  0.0529\n",
      "     16        \u001b[36m1.3715\u001b[0m       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3645\u001b[0m  0.0519\n",
      "     17        1.3821       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3633\u001b[0m  0.0449\n",
      "     18        1.3725       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3621\u001b[0m  0.0389\n",
      "     19        1.3718       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3608\u001b[0m  0.0459\n",
      "     20        1.3721       \u001b[32m0.3156\u001b[0m        \u001b[35m1.3596\u001b[0m  0.0489\n",
      "     21        1.3742       \u001b[32m0.3176\u001b[0m        \u001b[35m1.3584\u001b[0m  0.0479\n",
      "     22        \u001b[36m1.3685\u001b[0m       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3572\u001b[0m  0.0499\n",
      "     23        1.3705       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3560\u001b[0m  0.0419\n",
      "     24        1.3693       \u001b[32m0.3314\u001b[0m        \u001b[35m1.3548\u001b[0m  0.0459\n",
      "     25        \u001b[36m1.3610\u001b[0m       0.3314        \u001b[35m1.3536\u001b[0m  0.0479\n",
      "     26        1.3663       \u001b[32m0.3333\u001b[0m        \u001b[35m1.3524\u001b[0m  0.0549\n",
      "     27        1.3635       \u001b[32m0.3373\u001b[0m        \u001b[35m1.3512\u001b[0m  0.0499\n",
      "     28        1.3640       0.3373        \u001b[35m1.3500\u001b[0m  0.0499\n",
      "     29        1.3636       \u001b[32m0.3412\u001b[0m        \u001b[35m1.3488\u001b[0m  0.0608\n",
      "     30        \u001b[36m1.3599\u001b[0m       \u001b[32m0.3471\u001b[0m        \u001b[35m1.3476\u001b[0m  0.0419\n",
      "     31        1.3606       0.3452        \u001b[35m1.3465\u001b[0m  0.0489\n",
      "     32        \u001b[36m1.3533\u001b[0m       \u001b[32m0.3491\u001b[0m        \u001b[35m1.3453\u001b[0m  0.0489\n",
      "     33        1.3587       \u001b[32m0.3511\u001b[0m        \u001b[35m1.3441\u001b[0m  0.0499\n",
      "     34        1.3604       \u001b[32m0.3609\u001b[0m        \u001b[35m1.3429\u001b[0m  0.0399\n",
      "     35        \u001b[36m1.3438\u001b[0m       \u001b[32m0.3649\u001b[0m        \u001b[35m1.3418\u001b[0m  0.0419\n",
      "     36        1.3566       \u001b[32m0.3767\u001b[0m        \u001b[35m1.3406\u001b[0m  0.0449\n",
      "     37        1.3535       0.3767        \u001b[35m1.3394\u001b[0m  0.0429\n",
      "     38        1.3566       \u001b[32m0.3886\u001b[0m        \u001b[35m1.3382\u001b[0m  0.0459\n",
      "     39        1.3484       0.3866        \u001b[35m1.3371\u001b[0m  0.0399\n",
      "     40        1.3522       0.3866        \u001b[35m1.3359\u001b[0m  0.0618\n",
      "     41        1.3500       0.3886        \u001b[35m1.3348\u001b[0m  0.0559\n",
      "     42        1.3459       \u001b[32m0.3925\u001b[0m        \u001b[35m1.3336\u001b[0m  0.0409\n",
      "     43        1.3494       \u001b[32m0.3945\u001b[0m        \u001b[35m1.3324\u001b[0m  0.0499\n",
      "     44        1.3471       \u001b[32m0.4004\u001b[0m        \u001b[35m1.3313\u001b[0m  0.0519\n",
      "     45        \u001b[36m1.3397\u001b[0m       \u001b[32m0.4024\u001b[0m        \u001b[35m1.3301\u001b[0m  0.0509\n",
      "     46        1.3418       \u001b[32m0.4103\u001b[0m        \u001b[35m1.3290\u001b[0m  0.0399\n",
      "     47        \u001b[36m1.3388\u001b[0m       \u001b[32m0.4162\u001b[0m        \u001b[35m1.3278\u001b[0m  0.0618\n",
      "     48        1.3413       0.4162        \u001b[35m1.3267\u001b[0m  0.0389\n",
      "     49        \u001b[36m1.3382\u001b[0m       \u001b[32m0.4221\u001b[0m        \u001b[35m1.3255\u001b[0m  0.0479\n",
      "     50        1.3416       \u001b[32m0.4280\u001b[0m        \u001b[35m1.3244\u001b[0m  0.0409\n",
      "[CV]  lr=0.001, module__dropout=0.5, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4670\u001b[0m       \u001b[32m0.2209\u001b[0m        \u001b[35m1.4081\u001b[0m  0.0489\n",
      "      2        \u001b[36m1.4392\u001b[0m       \u001b[32m0.2544\u001b[0m        \u001b[35m1.3849\u001b[0m  0.0588\n",
      "      3        \u001b[36m1.4059\u001b[0m       \u001b[32m0.2899\u001b[0m        \u001b[35m1.3629\u001b[0m  0.0429\n",
      "      4        \u001b[36m1.3775\u001b[0m       \u001b[32m0.3373\u001b[0m        \u001b[35m1.3429\u001b[0m  0.0489\n",
      "      5        \u001b[36m1.3673\u001b[0m       \u001b[32m0.3846\u001b[0m        \u001b[35m1.3240\u001b[0m  0.0529\n",
      "      6        \u001b[36m1.3500\u001b[0m       \u001b[32m0.4122\u001b[0m        \u001b[35m1.3059\u001b[0m  0.0479\n",
      "      7        \u001b[36m1.3382\u001b[0m       \u001b[32m0.4438\u001b[0m        \u001b[35m1.2881\u001b[0m  0.0559\n",
      "      8        \u001b[36m1.3228\u001b[0m       \u001b[32m0.4714\u001b[0m        \u001b[35m1.2710\u001b[0m  0.0598\n",
      "      9        \u001b[36m1.2999\u001b[0m       \u001b[32m0.4892\u001b[0m        \u001b[35m1.2540\u001b[0m  0.0449\n",
      "     10        \u001b[36m1.2853\u001b[0m       \u001b[32m0.5049\u001b[0m        \u001b[35m1.2371\u001b[0m  0.0429\n",
      "     11        \u001b[36m1.2773\u001b[0m       \u001b[32m0.5227\u001b[0m        \u001b[35m1.2203\u001b[0m  0.0499\n",
      "     12        \u001b[36m1.2537\u001b[0m       \u001b[32m0.5424\u001b[0m        \u001b[35m1.2031\u001b[0m  0.0479\n",
      "     13        \u001b[36m1.2485\u001b[0m       \u001b[32m0.5779\u001b[0m        \u001b[35m1.1857\u001b[0m  0.0549\n",
      "     14        \u001b[36m1.2427\u001b[0m       \u001b[32m0.5897\u001b[0m        \u001b[35m1.1687\u001b[0m  0.0429\n",
      "     15        \u001b[36m1.2233\u001b[0m       \u001b[32m0.6055\u001b[0m        \u001b[35m1.1518\u001b[0m  0.0499\n",
      "     16        \u001b[36m1.2078\u001b[0m       \u001b[32m0.6331\u001b[0m        \u001b[35m1.1346\u001b[0m  0.0419\n",
      "     17        \u001b[36m1.1984\u001b[0m       \u001b[32m0.6568\u001b[0m        \u001b[35m1.1175\u001b[0m  0.0419\n",
      "     18        \u001b[36m1.1747\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.1004\u001b[0m  0.0459\n",
      "     19        \u001b[36m1.1713\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m1.0834\u001b[0m  0.0588\n",
      "     20        \u001b[36m1.1507\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m1.0666\u001b[0m  0.0439\n",
      "     21        \u001b[36m1.1377\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m1.0494\u001b[0m  0.0499\n",
      "     22        \u001b[36m1.1258\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m1.0330\u001b[0m  0.0429\n",
      "     23        \u001b[36m1.1117\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m1.0164\u001b[0m  0.0509\n",
      "     24        \u001b[36m1.1036\u001b[0m       \u001b[32m0.7377\u001b[0m        \u001b[35m0.9999\u001b[0m  0.0459\n",
      "     25        \u001b[36m1.0991\u001b[0m       0.7377        \u001b[35m0.9847\u001b[0m  0.0618\n",
      "     26        \u001b[36m1.0774\u001b[0m       \u001b[32m0.7436\u001b[0m        \u001b[35m0.9695\u001b[0m  0.0608\n",
      "     27        \u001b[36m1.0622\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m0.9544\u001b[0m  0.0648\n",
      "     28        \u001b[36m1.0597\u001b[0m       0.7475        \u001b[35m0.9399\u001b[0m  0.0628\n",
      "     29        \u001b[36m1.0399\u001b[0m       \u001b[32m0.7535\u001b[0m        \u001b[35m0.9254\u001b[0m  0.0628\n",
      "     30        \u001b[36m1.0229\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m0.9108\u001b[0m  0.0608\n",
      "     31        \u001b[36m1.0185\u001b[0m       \u001b[32m0.7613\u001b[0m        \u001b[35m0.8966\u001b[0m  0.0499\n",
      "     32        \u001b[36m1.0111\u001b[0m       \u001b[32m0.7791\u001b[0m        \u001b[35m0.8828\u001b[0m  0.0519\n",
      "     33        \u001b[36m1.0100\u001b[0m       \u001b[32m0.7830\u001b[0m        \u001b[35m0.8697\u001b[0m  0.0429\n",
      "     34        \u001b[36m0.9985\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.8568\u001b[0m  0.0479\n",
      "     35        \u001b[36m0.9786\u001b[0m       \u001b[32m0.7890\u001b[0m        \u001b[35m0.8443\u001b[0m  0.0469\n",
      "     36        \u001b[36m0.9709\u001b[0m       \u001b[32m0.7909\u001b[0m        \u001b[35m0.8322\u001b[0m  0.0598\n",
      "     37        \u001b[36m0.9619\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.8202\u001b[0m  0.0459\n",
      "     38        0.9628       \u001b[32m0.7988\u001b[0m        \u001b[35m0.8087\u001b[0m  0.0419\n",
      "     39        \u001b[36m0.9601\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m0.7978\u001b[0m  0.0469\n",
      "     40        \u001b[36m0.9386\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.7872\u001b[0m  0.0499\n",
      "     41        \u001b[36m0.9112\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.7766\u001b[0m  0.0429\n",
      "     42        0.9238       \u001b[32m0.8166\u001b[0m        \u001b[35m0.7662\u001b[0m  0.0559\n",
      "     43        0.9210       \u001b[32m0.8205\u001b[0m        \u001b[35m0.7559\u001b[0m  0.0499\n",
      "     44        0.9231       0.8185        \u001b[35m0.7464\u001b[0m  0.0489\n",
      "     45        \u001b[36m0.9097\u001b[0m       0.8205        \u001b[35m0.7370\u001b[0m  0.0469\n",
      "     46        \u001b[36m0.8874\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.7272\u001b[0m  0.0438\n",
      "     47        0.9009       \u001b[32m0.8323\u001b[0m        \u001b[35m0.7179\u001b[0m  0.0419\n",
      "     48        0.8966       \u001b[32m0.8383\u001b[0m        \u001b[35m0.7090\u001b[0m  0.0419\n",
      "     49        \u001b[36m0.8756\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.7002\u001b[0m  0.0539\n",
      "     50        0.8784       \u001b[32m0.8481\u001b[0m        \u001b[35m0.6921\u001b[0m  0.0539\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.1s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4790\u001b[0m       \u001b[32m0.2564\u001b[0m        \u001b[35m1.4218\u001b[0m  0.0399\n",
      "      2        \u001b[36m1.4450\u001b[0m       0.2564        \u001b[35m1.4070\u001b[0m  0.0449\n",
      "      3        \u001b[36m1.4342\u001b[0m       \u001b[32m0.2623\u001b[0m        \u001b[35m1.3927\u001b[0m  0.0539\n",
      "      4        \u001b[36m1.4211\u001b[0m       \u001b[32m0.2761\u001b[0m        \u001b[35m1.3789\u001b[0m  0.0698\n",
      "      5        \u001b[36m1.4007\u001b[0m       \u001b[32m0.2880\u001b[0m        \u001b[35m1.3662\u001b[0m  0.0429\n",
      "      6        \u001b[36m1.3899\u001b[0m       \u001b[32m0.3471\u001b[0m        \u001b[35m1.3538\u001b[0m  0.0439\n",
      "      7        \u001b[36m1.3727\u001b[0m       \u001b[32m0.4024\u001b[0m        \u001b[35m1.3416\u001b[0m  0.0549\n",
      "      8        \u001b[36m1.3622\u001b[0m       \u001b[32m0.4773\u001b[0m        \u001b[35m1.3294\u001b[0m  0.0519\n",
      "      9        \u001b[36m1.3536\u001b[0m       \u001b[32m0.5503\u001b[0m        \u001b[35m1.3172\u001b[0m  0.0518\n",
      "     10        \u001b[36m1.3376\u001b[0m       \u001b[32m0.6016\u001b[0m        \u001b[35m1.3047\u001b[0m  0.0439\n",
      "     11        \u001b[36m1.3258\u001b[0m       \u001b[32m0.6312\u001b[0m        \u001b[35m1.2924\u001b[0m  0.0419\n",
      "     12        \u001b[36m1.3156\u001b[0m       \u001b[32m0.6805\u001b[0m        \u001b[35m1.2799\u001b[0m  0.0459\n",
      "     13        \u001b[36m1.3020\u001b[0m       \u001b[32m0.7081\u001b[0m        \u001b[35m1.2661\u001b[0m  0.0578\n",
      "     14        \u001b[36m1.2808\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m1.2515\u001b[0m  0.0419\n",
      "     15        \u001b[36m1.2721\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m1.2365\u001b[0m  0.0708\n",
      "     16        \u001b[36m1.2636\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m1.2210\u001b[0m  0.0678\n",
      "     17        \u001b[36m1.2436\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m1.2049\u001b[0m  0.0459\n",
      "     18        \u001b[36m1.2301\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m1.1881\u001b[0m  0.0519\n",
      "     19        \u001b[36m1.2235\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m1.1707\u001b[0m  0.0449\n",
      "     20        \u001b[36m1.2057\u001b[0m       \u001b[32m0.7909\u001b[0m        \u001b[35m1.1534\u001b[0m  0.0568\n",
      "     21        \u001b[36m1.1883\u001b[0m       0.7870        \u001b[35m1.1355\u001b[0m  0.0419\n",
      "     22        \u001b[36m1.1857\u001b[0m       0.7850        \u001b[35m1.1180\u001b[0m  0.0628\n",
      "     23        \u001b[36m1.1596\u001b[0m       0.7870        \u001b[35m1.1001\u001b[0m  0.0409\n",
      "     24        1.1632       \u001b[32m0.7949\u001b[0m        \u001b[35m1.0824\u001b[0m  0.0499\n",
      "     25        \u001b[36m1.1410\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m1.0646\u001b[0m  0.0648\n",
      "     26        \u001b[36m1.1180\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m1.0472\u001b[0m  0.0429\n",
      "     27        \u001b[36m1.1095\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m1.0294\u001b[0m  0.0519\n",
      "     28        \u001b[36m1.0949\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m1.0119\u001b[0m  0.0529\n",
      "     29        \u001b[36m1.0858\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.9948\u001b[0m  0.0509\n",
      "     30        \u001b[36m1.0745\u001b[0m       0.8225        \u001b[35m0.9779\u001b[0m  0.0589\n",
      "     31        \u001b[36m1.0671\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.9617\u001b[0m  0.0598\n",
      "     32        \u001b[36m1.0584\u001b[0m       \u001b[32m0.8264\u001b[0m        \u001b[35m0.9460\u001b[0m  0.0748\n",
      "     33        \u001b[36m1.0315\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.9305\u001b[0m  0.0489\n",
      "     34        \u001b[36m1.0262\u001b[0m       0.8343        \u001b[35m0.9155\u001b[0m  0.0618\n",
      "     35        \u001b[36m1.0092\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.9007\u001b[0m  0.0539\n",
      "     36        \u001b[36m0.9968\u001b[0m       \u001b[32m0.8442\u001b[0m        \u001b[35m0.8857\u001b[0m  0.0519\n",
      "     37        \u001b[36m0.9820\u001b[0m       0.8442        \u001b[35m0.8711\u001b[0m  0.0688\n",
      "     38        0.9925       0.8402        \u001b[35m0.8578\u001b[0m  0.0568\n",
      "     39        \u001b[36m0.9757\u001b[0m       0.8402        \u001b[35m0.8447\u001b[0m  0.0459\n",
      "     40        \u001b[36m0.9638\u001b[0m       \u001b[32m0.8501\u001b[0m        \u001b[35m0.8316\u001b[0m  0.0509\n",
      "     41        \u001b[36m0.9591\u001b[0m       \u001b[32m0.8521\u001b[0m        \u001b[35m0.8189\u001b[0m  0.0429\n",
      "     42        \u001b[36m0.9423\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.8066\u001b[0m  0.0439\n",
      "     43        \u001b[36m0.9376\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.7950\u001b[0m  0.0618\n",
      "     44        \u001b[36m0.9310\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.7842\u001b[0m  0.0648\n",
      "     45        \u001b[36m0.9180\u001b[0m       0.8659        \u001b[35m0.7734\u001b[0m  0.0529\n",
      "     46        \u001b[36m0.9126\u001b[0m       0.8659        \u001b[35m0.7628\u001b[0m  0.0449\n",
      "     47        \u001b[36m0.9094\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.7523\u001b[0m  0.0519\n",
      "     48        0.9099       \u001b[32m0.8738\u001b[0m        \u001b[35m0.7430\u001b[0m  0.0549\n",
      "     49        \u001b[36m0.8828\u001b[0m       0.8659        \u001b[35m0.7338\u001b[0m  0.0489\n",
      "     50        0.8883       \u001b[32m0.8797\u001b[0m        \u001b[35m0.7239\u001b[0m  0.0519\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.2s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.5155\u001b[0m       \u001b[32m0.2288\u001b[0m        \u001b[35m1.4513\u001b[0m  0.0409\n",
      "      2        \u001b[36m1.4811\u001b[0m       \u001b[32m0.2387\u001b[0m        \u001b[35m1.4292\u001b[0m  0.0419\n",
      "      3        \u001b[36m1.4544\u001b[0m       \u001b[32m0.2406\u001b[0m        \u001b[35m1.4096\u001b[0m  0.0489\n",
      "      4        \u001b[36m1.4379\u001b[0m       \u001b[32m0.2465\u001b[0m        \u001b[35m1.3917\u001b[0m  0.0489\n",
      "      5        \u001b[36m1.4062\u001b[0m       \u001b[32m0.2584\u001b[0m        \u001b[35m1.3749\u001b[0m  0.0429\n",
      "      6        \u001b[36m1.3942\u001b[0m       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3593\u001b[0m  0.0469\n",
      "      7        \u001b[36m1.3723\u001b[0m       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3444\u001b[0m  0.0459\n",
      "      8        \u001b[36m1.3627\u001b[0m       \u001b[32m0.3452\u001b[0m        \u001b[35m1.3302\u001b[0m  0.0559\n",
      "      9        \u001b[36m1.3453\u001b[0m       \u001b[32m0.3767\u001b[0m        \u001b[35m1.3164\u001b[0m  0.0489\n",
      "     10        \u001b[36m1.3389\u001b[0m       \u001b[32m0.4201\u001b[0m        \u001b[35m1.3026\u001b[0m  0.0468\n",
      "     11        \u001b[36m1.3235\u001b[0m       \u001b[32m0.4596\u001b[0m        \u001b[35m1.2891\u001b[0m  0.0429\n",
      "     12        \u001b[36m1.3098\u001b[0m       \u001b[32m0.4852\u001b[0m        \u001b[35m1.2753\u001b[0m  0.0449\n",
      "     13        \u001b[36m1.2947\u001b[0m       \u001b[32m0.5247\u001b[0m        \u001b[35m1.2614\u001b[0m  0.0539\n",
      "     14        \u001b[36m1.2853\u001b[0m       \u001b[32m0.5858\u001b[0m        \u001b[35m1.2470\u001b[0m  0.0409\n",
      "     15        \u001b[36m1.2622\u001b[0m       \u001b[32m0.6075\u001b[0m        \u001b[35m1.2322\u001b[0m  0.0419\n",
      "     16        \u001b[36m1.2556\u001b[0m       \u001b[32m0.6272\u001b[0m        \u001b[35m1.2167\u001b[0m  0.0419\n",
      "     17        \u001b[36m1.2450\u001b[0m       \u001b[32m0.6568\u001b[0m        \u001b[35m1.2012\u001b[0m  0.0429\n",
      "     18        \u001b[36m1.2370\u001b[0m       \u001b[32m0.6785\u001b[0m        \u001b[35m1.1856\u001b[0m  0.0678\n",
      "     19        \u001b[36m1.2249\u001b[0m       \u001b[32m0.6864\u001b[0m        \u001b[35m1.1695\u001b[0m  0.0538\n",
      "     20        \u001b[36m1.2084\u001b[0m       \u001b[32m0.6943\u001b[0m        \u001b[35m1.1534\u001b[0m  0.0539\n",
      "     21        \u001b[36m1.1794\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m1.1369\u001b[0m  0.0439\n",
      "     22        \u001b[36m1.1752\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.1201\u001b[0m  0.0409\n",
      "     23        \u001b[36m1.1696\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m1.1041\u001b[0m  0.0499\n",
      "     24        \u001b[36m1.1577\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m1.0874\u001b[0m  0.0479\n",
      "     25        \u001b[36m1.1364\u001b[0m       \u001b[32m0.7258\u001b[0m        \u001b[35m1.0707\u001b[0m  0.0529\n",
      "     26        \u001b[36m1.1196\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m1.0539\u001b[0m  0.0489\n",
      "     27        1.1259       0.7278        \u001b[35m1.0382\u001b[0m  0.0508\n",
      "     28        \u001b[36m1.1087\u001b[0m       0.7298        \u001b[35m1.0231\u001b[0m  0.0578\n",
      "     29        \u001b[36m1.1015\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m1.0080\u001b[0m  0.0718\n",
      "     30        \u001b[36m1.0783\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m0.9929\u001b[0m  0.0628\n",
      "     31        \u001b[36m1.0711\u001b[0m       \u001b[32m0.7416\u001b[0m        \u001b[35m0.9778\u001b[0m  0.0549\n",
      "     32        \u001b[36m1.0522\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m0.9629\u001b[0m  0.0559\n",
      "     33        1.0581       0.7475        \u001b[35m0.9490\u001b[0m  0.0568\n",
      "     34        \u001b[36m1.0402\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m0.9353\u001b[0m  0.0598\n",
      "     35        \u001b[36m1.0251\u001b[0m       0.7495        \u001b[35m0.9217\u001b[0m  0.0449\n",
      "     36        \u001b[36m1.0231\u001b[0m       0.7515        \u001b[35m0.9087\u001b[0m  0.0499\n",
      "     37        \u001b[36m1.0105\u001b[0m       \u001b[32m0.7554\u001b[0m        \u001b[35m0.8960\u001b[0m  0.0539\n",
      "     38        \u001b[36m1.0044\u001b[0m       \u001b[32m0.7594\u001b[0m        \u001b[35m0.8836\u001b[0m  0.0748\n",
      "     39        1.0052       \u001b[32m0.7633\u001b[0m        \u001b[35m0.8720\u001b[0m  0.0599\n",
      "     40        \u001b[36m0.9839\u001b[0m       0.7633        \u001b[35m0.8607\u001b[0m  0.0539\n",
      "     41        \u001b[36m0.9752\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.8497\u001b[0m  0.0419\n",
      "     42        \u001b[36m0.9500\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.8382\u001b[0m  0.0469\n",
      "     43        0.9587       \u001b[32m0.7850\u001b[0m        \u001b[35m0.8272\u001b[0m  0.0479\n",
      "     44        0.9540       \u001b[32m0.7870\u001b[0m        \u001b[35m0.8166\u001b[0m  0.0499\n",
      "     45        0.9577       \u001b[32m0.7949\u001b[0m        \u001b[35m0.8071\u001b[0m  0.0449\n",
      "     46        \u001b[36m0.9457\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.7973\u001b[0m  0.0449\n",
      "     47        \u001b[36m0.9411\u001b[0m       0.7968        \u001b[35m0.7877\u001b[0m  0.0509\n",
      "     48        \u001b[36m0.9177\u001b[0m       0.7968        \u001b[35m0.7782\u001b[0m  0.0698\n",
      "     49        \u001b[36m0.9144\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.7691\u001b[0m  0.0479\n",
      "     50        \u001b[36m0.9128\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.7600\u001b[0m  0.0578\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.2s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4797\u001b[0m       \u001b[32m0.2209\u001b[0m        \u001b[35m1.3953\u001b[0m  0.0369\n",
      "      2        \u001b[36m1.4706\u001b[0m       0.2209        \u001b[35m1.3945\u001b[0m  0.0509\n",
      "      3        1.4745       \u001b[32m0.2268\u001b[0m        \u001b[35m1.3937\u001b[0m  0.0608\n",
      "      4        \u001b[36m1.4624\u001b[0m       \u001b[32m0.2308\u001b[0m        \u001b[35m1.3929\u001b[0m  0.0598\n",
      "      5        1.4800       \u001b[32m0.2347\u001b[0m        \u001b[35m1.3921\u001b[0m  0.0499\n",
      "      6        1.4773       \u001b[32m0.2367\u001b[0m        \u001b[35m1.3914\u001b[0m  0.0578\n",
      "      7        1.4779       \u001b[32m0.2387\u001b[0m        \u001b[35m1.3906\u001b[0m  0.0399\n",
      "      8        1.4824       \u001b[32m0.2426\u001b[0m        \u001b[35m1.3899\u001b[0m  0.0439\n",
      "      9        \u001b[36m1.4576\u001b[0m       0.2426        \u001b[35m1.3891\u001b[0m  0.0439\n",
      "     10        1.4851       \u001b[32m0.2446\u001b[0m        \u001b[35m1.3884\u001b[0m  0.0399\n",
      "     11        1.4613       0.2446        \u001b[35m1.3876\u001b[0m  0.0618\n",
      "     12        \u001b[36m1.4484\u001b[0m       \u001b[32m0.2465\u001b[0m        \u001b[35m1.3870\u001b[0m  0.0568\n",
      "     13        1.4538       0.2465        \u001b[35m1.3862\u001b[0m  0.0419\n",
      "     14        1.4745       0.2465        \u001b[35m1.3855\u001b[0m  0.0539\n",
      "     15        \u001b[36m1.4392\u001b[0m       \u001b[32m0.2485\u001b[0m        \u001b[35m1.3848\u001b[0m  0.0539\n",
      "     16        1.4549       \u001b[32m0.2525\u001b[0m        \u001b[35m1.3840\u001b[0m  0.0499\n",
      "     17        1.4503       \u001b[32m0.2564\u001b[0m        \u001b[35m1.3833\u001b[0m  0.0568\n",
      "     18        1.4455       0.2544        \u001b[35m1.3826\u001b[0m  0.0389\n",
      "     19        1.4479       \u001b[32m0.2584\u001b[0m        \u001b[35m1.3820\u001b[0m  0.0549\n",
      "     20        1.4442       \u001b[32m0.2623\u001b[0m        \u001b[35m1.3813\u001b[0m  0.0519\n",
      "     21        1.4492       \u001b[32m0.2682\u001b[0m        \u001b[35m1.3806\u001b[0m  0.0608\n",
      "     22        1.4397       \u001b[32m0.2702\u001b[0m        \u001b[35m1.3799\u001b[0m  0.0638\n",
      "     23        1.4398       \u001b[32m0.2722\u001b[0m        \u001b[35m1.3792\u001b[0m  0.0429\n",
      "     24        1.4410       \u001b[32m0.2742\u001b[0m        \u001b[35m1.3786\u001b[0m  0.0409\n",
      "     25        \u001b[36m1.4325\u001b[0m       \u001b[32m0.2821\u001b[0m        \u001b[35m1.3779\u001b[0m  0.0539\n",
      "     26        \u001b[36m1.4322\u001b[0m       0.2821        \u001b[35m1.3773\u001b[0m  0.0459\n",
      "     27        1.4392       \u001b[32m0.2860\u001b[0m        \u001b[35m1.3766\u001b[0m  0.0539\n",
      "     28        \u001b[36m1.4256\u001b[0m       0.2860        \u001b[35m1.3759\u001b[0m  0.0559\n",
      "     29        1.4292       \u001b[32m0.2899\u001b[0m        \u001b[35m1.3753\u001b[0m  0.0678\n",
      "     30        \u001b[36m1.4211\u001b[0m       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3746\u001b[0m  0.0568\n",
      "     31        1.4375       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3740\u001b[0m  0.0539\n",
      "     32        1.4410       \u001b[32m0.2978\u001b[0m        \u001b[35m1.3734\u001b[0m  0.0499\n",
      "     33        1.4330       0.2978        \u001b[35m1.3728\u001b[0m  0.0479\n",
      "     34        1.4404       0.2978        \u001b[35m1.3722\u001b[0m  0.0519\n",
      "     35        1.4357       \u001b[32m0.2998\u001b[0m        \u001b[35m1.3716\u001b[0m  0.0608\n",
      "     36        \u001b[36m1.4104\u001b[0m       0.2959        \u001b[35m1.3710\u001b[0m  0.0509\n",
      "     37        1.4346       0.2978        \u001b[35m1.3704\u001b[0m  0.0399\n",
      "     38        1.4343       0.2978        \u001b[35m1.3698\u001b[0m  0.0389\n",
      "     39        1.4320       0.2978        \u001b[35m1.3692\u001b[0m  0.0419\n",
      "     40        1.4211       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3686\u001b[0m  0.0429\n",
      "     41        1.4256       0.3057        \u001b[35m1.3679\u001b[0m  0.0529\n",
      "     42        1.4168       \u001b[32m0.3136\u001b[0m        \u001b[35m1.3673\u001b[0m  0.0519\n",
      "     43        1.4257       \u001b[32m0.3176\u001b[0m        \u001b[35m1.3667\u001b[0m  0.0499\n",
      "     44        1.4214       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3661\u001b[0m  0.0479\n",
      "     45        1.4125       \u001b[32m0.3314\u001b[0m        \u001b[35m1.3655\u001b[0m  0.0529\n",
      "     46        \u001b[36m1.4091\u001b[0m       \u001b[32m0.3373\u001b[0m        \u001b[35m1.3649\u001b[0m  0.0668\n",
      "     47        1.4229       \u001b[32m0.3412\u001b[0m        \u001b[35m1.3643\u001b[0m  0.0638\n",
      "     48        1.4091       0.3412        \u001b[35m1.3637\u001b[0m  0.0459\n",
      "     49        \u001b[36m1.4088\u001b[0m       \u001b[32m0.3432\u001b[0m        \u001b[35m1.3632\u001b[0m  0.0379\n",
      "     50        1.4191       \u001b[32m0.3452\u001b[0m        \u001b[35m1.3626\u001b[0m  0.0489\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.2s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4121\u001b[0m       \u001b[32m0.2012\u001b[0m        \u001b[35m1.3916\u001b[0m  0.0389\n",
      "      2        1.4258       0.2012        \u001b[35m1.3911\u001b[0m  0.0519\n",
      "      3        1.4125       0.2012        \u001b[35m1.3906\u001b[0m  0.0419\n",
      "      4        1.4121       0.2012        \u001b[35m1.3901\u001b[0m  0.0449\n",
      "      5        1.4173       0.2012        \u001b[35m1.3896\u001b[0m  0.0389\n",
      "      6        \u001b[36m1.4081\u001b[0m       0.2012        \u001b[35m1.3891\u001b[0m  0.0389\n",
      "      7        \u001b[36m1.4078\u001b[0m       0.2012        \u001b[35m1.3886\u001b[0m  0.0409\n",
      "      8        1.4136       0.2012        \u001b[35m1.3881\u001b[0m  0.0559\n",
      "      9        1.4204       0.2012        \u001b[35m1.3876\u001b[0m  0.0439\n",
      "     10        \u001b[36m1.4072\u001b[0m       0.2012        \u001b[35m1.3872\u001b[0m  0.0379\n",
      "     11        1.4107       0.2012        \u001b[35m1.3867\u001b[0m  0.0599\n",
      "     12        1.4101       0.2012        \u001b[35m1.3862\u001b[0m  0.0509\n",
      "     13        1.4077       0.2012        \u001b[35m1.3857\u001b[0m  0.0549\n",
      "     14        1.4088       0.2012        \u001b[35m1.3852\u001b[0m  0.0399\n",
      "     15        \u001b[36m1.4049\u001b[0m       0.2012        \u001b[35m1.3847\u001b[0m  0.0519\n",
      "     16        \u001b[36m1.3997\u001b[0m       0.2012        \u001b[35m1.3842\u001b[0m  0.0499\n",
      "     17        1.4042       0.2012        \u001b[35m1.3837\u001b[0m  0.0578\n",
      "     18        1.4076       0.2012        \u001b[35m1.3832\u001b[0m  0.0519\n",
      "     19        1.4036       0.2012        \u001b[35m1.3828\u001b[0m  0.0578\n",
      "     20        1.4020       0.2012        \u001b[35m1.3823\u001b[0m  0.0439\n",
      "     21        1.4037       0.1992        \u001b[35m1.3818\u001b[0m  0.0399\n",
      "     22        1.4024       0.1972        \u001b[35m1.3813\u001b[0m  0.0429\n",
      "     23        1.4026       0.1972        \u001b[35m1.3808\u001b[0m  0.0399\n",
      "     24        1.4041       0.1972        \u001b[35m1.3804\u001b[0m  0.0409\n",
      "     25        1.4041       0.1972        \u001b[35m1.3799\u001b[0m  0.0389\n",
      "     26        1.4042       0.1972        \u001b[35m1.3794\u001b[0m  0.0369\n",
      "     27        \u001b[36m1.3968\u001b[0m       0.1953        \u001b[35m1.3789\u001b[0m  0.0469\n",
      "     28        \u001b[36m1.3959\u001b[0m       0.1953        \u001b[35m1.3785\u001b[0m  0.0658\n",
      "     29        \u001b[36m1.3934\u001b[0m       0.1953        \u001b[35m1.3780\u001b[0m  0.0678\n",
      "     30        1.3973       0.1972        \u001b[35m1.3775\u001b[0m  0.0568\n",
      "     31        1.3949       0.1972        \u001b[35m1.3771\u001b[0m  0.0439\n",
      "     32        1.4068       0.1972        \u001b[35m1.3766\u001b[0m  0.0489\n",
      "     33        1.3991       \u001b[32m0.2032\u001b[0m        \u001b[35m1.3762\u001b[0m  0.0429\n",
      "     34        1.3953       0.2032        \u001b[35m1.3758\u001b[0m  0.0599\n",
      "     35        1.4025       0.2032        \u001b[35m1.3754\u001b[0m  0.0519\n",
      "     36        1.3961       \u001b[32m0.2071\u001b[0m        \u001b[35m1.3749\u001b[0m  0.0419\n",
      "     37        1.4010       0.2071        \u001b[35m1.3745\u001b[0m  0.0399\n",
      "     38        \u001b[36m1.3901\u001b[0m       \u001b[32m0.2091\u001b[0m        \u001b[35m1.3740\u001b[0m  0.0459\n",
      "     39        \u001b[36m1.3865\u001b[0m       \u001b[32m0.2150\u001b[0m        \u001b[35m1.3736\u001b[0m  0.0509\n",
      "     40        1.3951       \u001b[32m0.2170\u001b[0m        \u001b[35m1.3731\u001b[0m  0.0429\n",
      "     41        1.3904       \u001b[32m0.2189\u001b[0m        \u001b[35m1.3727\u001b[0m  0.0519\n",
      "     42        1.3915       \u001b[32m0.2229\u001b[0m        \u001b[35m1.3722\u001b[0m  0.0489\n",
      "     43        1.3941       0.2229        \u001b[35m1.3718\u001b[0m  0.0459\n",
      "     44        1.3904       \u001b[32m0.2249\u001b[0m        \u001b[35m1.3714\u001b[0m  0.0559\n",
      "     45        1.3987       \u001b[32m0.2268\u001b[0m        \u001b[35m1.3709\u001b[0m  0.0389\n",
      "     46        1.3932       0.2249        \u001b[35m1.3705\u001b[0m  0.0479\n",
      "     47        1.3884       0.2268        \u001b[35m1.3701\u001b[0m  0.0409\n",
      "     48        1.3916       \u001b[32m0.2288\u001b[0m        \u001b[35m1.3696\u001b[0m  0.0459\n",
      "     49        1.3892       \u001b[32m0.2327\u001b[0m        \u001b[35m1.3692\u001b[0m  0.0399\n",
      "     50        1.3942       0.2327        \u001b[35m1.3688\u001b[0m  0.0419\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4474\u001b[0m       \u001b[32m0.2840\u001b[0m        \u001b[35m1.4062\u001b[0m  0.0518\n",
      "      2        1.4513       0.2840        \u001b[35m1.4050\u001b[0m  0.0399\n",
      "      3        1.4528       \u001b[32m0.2860\u001b[0m        \u001b[35m1.4039\u001b[0m  0.0469\n",
      "      4        \u001b[36m1.4415\u001b[0m       \u001b[32m0.2880\u001b[0m        \u001b[35m1.4028\u001b[0m  0.0519\n",
      "      5        \u001b[36m1.4357\u001b[0m       \u001b[32m0.2899\u001b[0m        \u001b[35m1.4017\u001b[0m  0.0509\n",
      "      6        1.4428       \u001b[32m0.2919\u001b[0m        \u001b[35m1.4006\u001b[0m  0.0429\n",
      "      7        \u001b[36m1.4353\u001b[0m       \u001b[32m0.2978\u001b[0m        \u001b[35m1.3995\u001b[0m  0.0559\n",
      "      8        1.4387       \u001b[32m0.3018\u001b[0m        \u001b[35m1.3985\u001b[0m  0.0439\n",
      "      9        \u001b[36m1.4340\u001b[0m       0.3018        \u001b[35m1.3975\u001b[0m  0.0459\n",
      "     10        \u001b[36m1.4285\u001b[0m       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3964\u001b[0m  0.0479\n",
      "     11        1.4350       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3954\u001b[0m  0.0399\n",
      "     12        1.4407       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3944\u001b[0m  0.0648\n",
      "     13        \u001b[36m1.4260\u001b[0m       0.3077        \u001b[35m1.3934\u001b[0m  0.0658\n",
      "     14        \u001b[36m1.4234\u001b[0m       0.3077        \u001b[35m1.3924\u001b[0m  0.0389\n",
      "     15        1.4294       \u001b[32m0.3097\u001b[0m        \u001b[35m1.3914\u001b[0m  0.0399\n",
      "     16        1.4296       0.3097        \u001b[35m1.3904\u001b[0m  0.0459\n",
      "     17        1.4439       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3894\u001b[0m  0.0639\n",
      "     18        1.4337       0.3116        \u001b[35m1.3884\u001b[0m  0.0419\n",
      "     19        1.4284       \u001b[32m0.3136\u001b[0m        \u001b[35m1.3875\u001b[0m  0.0519\n",
      "     20        1.4260       0.3136        \u001b[35m1.3865\u001b[0m  0.0379\n",
      "     21        1.4268       \u001b[32m0.3176\u001b[0m        \u001b[35m1.3856\u001b[0m  0.0449\n",
      "     22        \u001b[36m1.4195\u001b[0m       0.3176        \u001b[35m1.3847\u001b[0m  0.0588\n",
      "     23        \u001b[36m1.4189\u001b[0m       0.3176        \u001b[35m1.3837\u001b[0m  0.0389\n",
      "     24        1.4329       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3828\u001b[0m  0.0469\n",
      "     25        1.4263       0.3215        \u001b[35m1.3818\u001b[0m  0.0409\n",
      "     26        1.4227       0.3215        \u001b[35m1.3810\u001b[0m  0.0389\n",
      "     27        \u001b[36m1.4106\u001b[0m       \u001b[32m0.3235\u001b[0m        \u001b[35m1.3801\u001b[0m  0.0618\n",
      "     28        1.4172       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3792\u001b[0m  0.0659\n",
      "     29        1.4178       0.3254        \u001b[35m1.3783\u001b[0m  0.0499\n",
      "     30        1.4181       0.3254        \u001b[35m1.3775\u001b[0m  0.0509\n",
      "     31        1.4171       0.3235        \u001b[35m1.3766\u001b[0m  0.0459\n",
      "     32        1.4111       0.3254        \u001b[35m1.3757\u001b[0m  0.0489\n",
      "     33        1.4138       0.3254        \u001b[35m1.3749\u001b[0m  0.0469\n",
      "     34        1.4256       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3740\u001b[0m  0.0409\n",
      "     35        \u001b[36m1.4071\u001b[0m       0.3274        \u001b[35m1.3732\u001b[0m  0.0509\n",
      "     36        1.4201       \u001b[32m0.3294\u001b[0m        \u001b[35m1.3723\u001b[0m  0.0389\n",
      "     37        1.4082       \u001b[32m0.3353\u001b[0m        \u001b[35m1.3715\u001b[0m  0.0379\n",
      "     38        \u001b[36m1.4045\u001b[0m       0.3353        \u001b[35m1.3707\u001b[0m  0.0419\n",
      "     39        1.4138       \u001b[32m0.3373\u001b[0m        \u001b[35m1.3698\u001b[0m  0.0449\n",
      "     40        \u001b[36m1.4009\u001b[0m       \u001b[32m0.3393\u001b[0m        \u001b[35m1.3690\u001b[0m  0.0419\n",
      "     41        1.4132       0.3393        \u001b[35m1.3682\u001b[0m  0.0429\n",
      "     42        1.4182       0.3393        \u001b[35m1.3674\u001b[0m  0.0479\n",
      "     43        1.4065       \u001b[32m0.3412\u001b[0m        \u001b[35m1.3666\u001b[0m  0.0439\n",
      "     44        1.4065       \u001b[32m0.3432\u001b[0m        \u001b[35m1.3659\u001b[0m  0.0419\n",
      "     45        1.4030       0.3432        \u001b[35m1.3651\u001b[0m  0.0499\n",
      "     46        1.4128       0.3412        \u001b[35m1.3643\u001b[0m  0.0459\n",
      "     47        \u001b[36m1.3973\u001b[0m       \u001b[32m0.3452\u001b[0m        \u001b[35m1.3636\u001b[0m  0.0668\n",
      "     48        1.3998       \u001b[32m0.3471\u001b[0m        \u001b[35m1.3628\u001b[0m  0.0618\n",
      "     49        1.4032       \u001b[32m0.3491\u001b[0m        \u001b[35m1.3621\u001b[0m  0.0419\n",
      "     50        \u001b[36m1.3964\u001b[0m       \u001b[32m0.3511\u001b[0m        \u001b[35m1.3613\u001b[0m  0.0439\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=11, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4966\u001b[0m       \u001b[32m0.2544\u001b[0m        \u001b[35m1.4139\u001b[0m  0.0469\n",
      "      2        \u001b[36m1.4464\u001b[0m       0.2544        \u001b[35m1.3878\u001b[0m  0.0669\n",
      "      3        \u001b[36m1.4166\u001b[0m       \u001b[32m0.2781\u001b[0m        \u001b[35m1.3635\u001b[0m  0.0628\n",
      "      4        \u001b[36m1.3907\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3409\u001b[0m  0.0579\n",
      "      5        \u001b[36m1.3636\u001b[0m       \u001b[32m0.3767\u001b[0m        \u001b[35m1.3188\u001b[0m  0.0539\n",
      "      6        \u001b[36m1.3427\u001b[0m       \u001b[32m0.4379\u001b[0m        \u001b[35m1.2975\u001b[0m  0.0429\n",
      "      7        \u001b[36m1.3240\u001b[0m       \u001b[32m0.4931\u001b[0m        \u001b[35m1.2759\u001b[0m  0.0489\n",
      "      8        \u001b[36m1.3112\u001b[0m       \u001b[32m0.5976\u001b[0m        \u001b[35m1.2544\u001b[0m  0.0419\n",
      "      9        \u001b[36m1.2817\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.2319\u001b[0m  0.0509\n",
      "     10        \u001b[36m1.2728\u001b[0m       \u001b[32m0.6706\u001b[0m        \u001b[35m1.2087\u001b[0m  0.0539\n",
      "     11        \u001b[36m1.2480\u001b[0m       \u001b[32m0.7002\u001b[0m        \u001b[35m1.1853\u001b[0m  0.0459\n",
      "     12        \u001b[36m1.2210\u001b[0m       \u001b[32m0.7160\u001b[0m        \u001b[35m1.1607\u001b[0m  0.0448\n",
      "     13        \u001b[36m1.2029\u001b[0m       \u001b[32m0.7199\u001b[0m        \u001b[35m1.1358\u001b[0m  0.0389\n",
      "     14        \u001b[36m1.1832\u001b[0m       \u001b[32m0.7318\u001b[0m        \u001b[35m1.1106\u001b[0m  0.0419\n",
      "     15        \u001b[36m1.1673\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m1.0854\u001b[0m  0.0459\n",
      "     16        \u001b[36m1.1440\u001b[0m       \u001b[32m0.7456\u001b[0m        \u001b[35m1.0609\u001b[0m  0.0638\n",
      "     17        \u001b[36m1.1130\u001b[0m       \u001b[32m0.7475\u001b[0m        \u001b[35m1.0365\u001b[0m  0.0449\n",
      "     18        \u001b[36m1.0897\u001b[0m       \u001b[32m0.7594\u001b[0m        \u001b[35m1.0126\u001b[0m  0.0529\n",
      "     19        \u001b[36m1.0698\u001b[0m       0.7594        \u001b[35m0.9891\u001b[0m  0.0479\n",
      "     20        \u001b[36m1.0565\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m0.9665\u001b[0m  0.0469\n",
      "     21        \u001b[36m1.0356\u001b[0m       \u001b[32m0.7653\u001b[0m        \u001b[35m0.9449\u001b[0m  0.0489\n",
      "     22        \u001b[36m1.0246\u001b[0m       0.7653        \u001b[35m0.9244\u001b[0m  0.0429\n",
      "     23        \u001b[36m1.0000\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m0.9044\u001b[0m  0.0429\n",
      "     24        \u001b[36m0.9871\u001b[0m       \u001b[32m0.7791\u001b[0m        \u001b[35m0.8852\u001b[0m  0.0468\n",
      "     25        \u001b[36m0.9554\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.8666\u001b[0m  0.0469\n",
      "     26        \u001b[36m0.9482\u001b[0m       \u001b[32m0.7909\u001b[0m        \u001b[35m0.8485\u001b[0m  0.0459\n",
      "     27        \u001b[36m0.9379\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.8314\u001b[0m  0.0608\n",
      "     28        \u001b[36m0.9257\u001b[0m       0.7968        \u001b[35m0.8154\u001b[0m  0.0529\n",
      "     29        \u001b[36m0.9149\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.8002\u001b[0m  0.0429\n",
      "     30        \u001b[36m0.9032\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.7855\u001b[0m  0.0598\n",
      "     31        \u001b[36m0.8956\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.7715\u001b[0m  0.0629\n",
      "     32        \u001b[36m0.8854\u001b[0m       0.8146        \u001b[35m0.7577\u001b[0m  0.0538\n",
      "     33        \u001b[36m0.8627\u001b[0m       \u001b[32m0.8185\u001b[0m        \u001b[35m0.7441\u001b[0m  0.0459\n",
      "     34        \u001b[36m0.8353\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.7303\u001b[0m  0.0439\n",
      "     35        0.8399       0.8245        \u001b[35m0.7169\u001b[0m  0.0449\n",
      "     36        \u001b[36m0.8342\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.7041\u001b[0m  0.0578\n",
      "     37        \u001b[36m0.8221\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.6919\u001b[0m  0.0618\n",
      "     38        \u001b[36m0.8121\u001b[0m       \u001b[32m0.8422\u001b[0m        \u001b[35m0.6803\u001b[0m  0.0429\n",
      "     39        \u001b[36m0.8015\u001b[0m       0.8422        \u001b[35m0.6688\u001b[0m  0.0668\n",
      "     40        \u001b[36m0.7935\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.6573\u001b[0m  0.0549\n",
      "     41        \u001b[36m0.7709\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.6456\u001b[0m  0.0489\n",
      "     42        0.7763       0.8580        \u001b[35m0.6348\u001b[0m  0.0608\n",
      "     43        \u001b[36m0.7698\u001b[0m       0.8580        \u001b[35m0.6243\u001b[0m  0.0788\n",
      "     44        \u001b[36m0.7452\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.6136\u001b[0m  0.0509\n",
      "     45        \u001b[36m0.7408\u001b[0m       0.8659        \u001b[35m0.6034\u001b[0m  0.0618\n",
      "     46        0.7618       0.8659        \u001b[35m0.5939\u001b[0m  0.0489\n",
      "     47        0.7425       \u001b[32m0.8698\u001b[0m        \u001b[35m0.5843\u001b[0m  0.0479\n",
      "     48        \u001b[36m0.7213\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.5746\u001b[0m  0.0499\n",
      "     49        \u001b[36m0.7188\u001b[0m       0.8738        \u001b[35m0.5647\u001b[0m  0.0628\n",
      "     50        \u001b[36m0.7097\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.5551\u001b[0m  0.0598\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.2s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4522\u001b[0m       \u001b[32m0.2209\u001b[0m        \u001b[35m1.3718\u001b[0m  0.0578\n",
      "      2        \u001b[36m1.3990\u001b[0m       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3487\u001b[0m  0.0459\n",
      "      3        \u001b[36m1.3760\u001b[0m       \u001b[32m0.3669\u001b[0m        \u001b[35m1.3263\u001b[0m  0.0469\n",
      "      4        \u001b[36m1.3527\u001b[0m       \u001b[32m0.4280\u001b[0m        \u001b[35m1.3042\u001b[0m  0.0529\n",
      "      5        \u001b[36m1.3348\u001b[0m       \u001b[32m0.5089\u001b[0m        \u001b[35m1.2823\u001b[0m  0.0529\n",
      "      6        \u001b[36m1.3100\u001b[0m       \u001b[32m0.5740\u001b[0m        \u001b[35m1.2601\u001b[0m  0.0678\n",
      "      7        \u001b[36m1.2834\u001b[0m       \u001b[32m0.6391\u001b[0m        \u001b[35m1.2380\u001b[0m  0.0539\n",
      "      8        \u001b[36m1.2636\u001b[0m       \u001b[32m0.6824\u001b[0m        \u001b[35m1.2163\u001b[0m  0.0438\n",
      "      9        \u001b[36m1.2603\u001b[0m       \u001b[32m0.7179\u001b[0m        \u001b[35m1.1943\u001b[0m  0.0678\n",
      "     10        \u001b[36m1.2226\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m1.1719\u001b[0m  0.0489\n",
      "     11        \u001b[36m1.2109\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m1.1493\u001b[0m  0.0479\n",
      "     12        \u001b[36m1.1835\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m1.1263\u001b[0m  0.0529\n",
      "     13        \u001b[36m1.1638\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m1.1031\u001b[0m  0.0738\n",
      "     14        \u001b[36m1.1479\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m1.0795\u001b[0m  0.0559\n",
      "     15        \u001b[36m1.1198\u001b[0m       \u001b[32m0.8166\u001b[0m        \u001b[35m1.0557\u001b[0m  0.0618\n",
      "     16        \u001b[36m1.1110\u001b[0m       0.8146        \u001b[35m1.0321\u001b[0m  0.0489\n",
      "     17        \u001b[36m1.0891\u001b[0m       \u001b[32m0.8205\u001b[0m        \u001b[35m1.0089\u001b[0m  0.0599\n",
      "     18        \u001b[36m1.0768\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.9866\u001b[0m  0.0449\n",
      "     19        \u001b[36m1.0487\u001b[0m       0.8225        \u001b[35m0.9637\u001b[0m  0.0628\n",
      "     20        \u001b[36m1.0161\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.9412\u001b[0m  0.0568\n",
      "     21        1.0168       \u001b[32m0.8343\u001b[0m        \u001b[35m0.9192\u001b[0m  0.0559\n",
      "     22        \u001b[36m0.9841\u001b[0m       \u001b[32m0.8422\u001b[0m        \u001b[35m0.8980\u001b[0m  0.0499\n",
      "     23        \u001b[36m0.9821\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.8776\u001b[0m  0.0419\n",
      "     24        \u001b[36m0.9565\u001b[0m       0.8422        \u001b[35m0.8576\u001b[0m  0.0608\n",
      "     25        \u001b[36m0.9495\u001b[0m       0.8422        \u001b[35m0.8384\u001b[0m  0.0469\n",
      "     26        \u001b[36m0.9205\u001b[0m       0.8462        \u001b[35m0.8194\u001b[0m  0.0648\n",
      "     27        0.9235       \u001b[32m0.8521\u001b[0m        \u001b[35m0.8013\u001b[0m  0.0459\n",
      "     28        \u001b[36m0.9003\u001b[0m       \u001b[32m0.8540\u001b[0m        \u001b[35m0.7837\u001b[0m  0.0499\n",
      "     29        \u001b[36m0.8848\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.7668\u001b[0m  0.0578\n",
      "     30        \u001b[36m0.8684\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.7500\u001b[0m  0.0429\n",
      "     31        \u001b[36m0.8494\u001b[0m       \u001b[32m0.8698\u001b[0m        \u001b[35m0.7337\u001b[0m  0.0429\n",
      "     32        \u001b[36m0.8416\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.7184\u001b[0m  0.0419\n",
      "     33        \u001b[36m0.8279\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.7036\u001b[0m  0.0568\n",
      "     34        0.8384       \u001b[32m0.8777\u001b[0m        \u001b[35m0.6894\u001b[0m  0.0559\n",
      "     35        \u001b[36m0.8072\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.6755\u001b[0m  0.0439\n",
      "     36        \u001b[36m0.7809\u001b[0m       0.8836        \u001b[35m0.6618\u001b[0m  0.0628\n",
      "     37        \u001b[36m0.7800\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.6482\u001b[0m  0.0539\n",
      "     38        \u001b[36m0.7691\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.6355\u001b[0m  0.0449\n",
      "     39        0.7727       \u001b[32m0.8974\u001b[0m        \u001b[35m0.6235\u001b[0m  0.0678\n",
      "     40        \u001b[36m0.7688\u001b[0m       0.8974        \u001b[35m0.6118\u001b[0m  0.0509\n",
      "     41        \u001b[36m0.7489\u001b[0m       0.8955        \u001b[35m0.6006\u001b[0m  0.0718\n",
      "     42        \u001b[36m0.7347\u001b[0m       0.8974        \u001b[35m0.5898\u001b[0m  0.0588\n",
      "     43        \u001b[36m0.7254\u001b[0m       0.8974        \u001b[35m0.5797\u001b[0m  0.0499\n",
      "     44        0.7332       0.8955        \u001b[35m0.5703\u001b[0m  0.0588\n",
      "     45        \u001b[36m0.7121\u001b[0m       0.8974        \u001b[35m0.5605\u001b[0m  0.0568\n",
      "     46        \u001b[36m0.6937\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.5509\u001b[0m  0.0618\n",
      "     47        0.7060       \u001b[32m0.9034\u001b[0m        \u001b[35m0.5419\u001b[0m  0.0539\n",
      "     48        \u001b[36m0.6883\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.5329\u001b[0m  0.0499\n",
      "     49        \u001b[36m0.6870\u001b[0m       0.9053        \u001b[35m0.5244\u001b[0m  0.0418\n",
      "     50        \u001b[36m0.6775\u001b[0m       0.9034        \u001b[35m0.5158\u001b[0m  0.0469\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.5274\u001b[0m       \u001b[32m0.2051\u001b[0m        \u001b[35m1.4187\u001b[0m  0.0509\n",
      "      2        \u001b[36m1.4810\u001b[0m       \u001b[32m0.2781\u001b[0m        \u001b[35m1.3905\u001b[0m  0.0489\n",
      "      3        \u001b[36m1.4238\u001b[0m       \u001b[32m0.3629\u001b[0m        \u001b[35m1.3640\u001b[0m  0.0518\n",
      "      4        \u001b[36m1.4112\u001b[0m       \u001b[32m0.3846\u001b[0m        \u001b[35m1.3393\u001b[0m  0.0429\n",
      "      5        \u001b[36m1.3896\u001b[0m       \u001b[32m0.4122\u001b[0m        \u001b[35m1.3157\u001b[0m  0.0509\n",
      "      6        \u001b[36m1.3583\u001b[0m       \u001b[32m0.4773\u001b[0m        \u001b[35m1.2930\u001b[0m  0.0549\n",
      "      7        \u001b[36m1.3277\u001b[0m       \u001b[32m0.5089\u001b[0m        \u001b[35m1.2702\u001b[0m  0.0578\n",
      "      8        \u001b[36m1.3043\u001b[0m       \u001b[32m0.5621\u001b[0m        \u001b[35m1.2469\u001b[0m  0.0718\n",
      "      9        \u001b[36m1.2898\u001b[0m       \u001b[32m0.5996\u001b[0m        \u001b[35m1.2236\u001b[0m  0.0638\n",
      "     10        \u001b[36m1.2765\u001b[0m       \u001b[32m0.6134\u001b[0m        \u001b[35m1.2001\u001b[0m  0.0439\n",
      "     11        \u001b[36m1.2620\u001b[0m       \u001b[32m0.6272\u001b[0m        \u001b[35m1.1770\u001b[0m  0.0628\n",
      "     12        \u001b[36m1.2264\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m1.1536\u001b[0m  0.0519\n",
      "     13        \u001b[36m1.2000\u001b[0m       \u001b[32m0.6647\u001b[0m        \u001b[35m1.1301\u001b[0m  0.0648\n",
      "     14        \u001b[36m1.1748\u001b[0m       \u001b[32m0.6844\u001b[0m        \u001b[35m1.1063\u001b[0m  0.0439\n",
      "     15        \u001b[36m1.1613\u001b[0m       \u001b[32m0.7101\u001b[0m        \u001b[35m1.0823\u001b[0m  0.0439\n",
      "     16        \u001b[36m1.1368\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m1.0587\u001b[0m  0.0499\n",
      "     17        \u001b[36m1.1187\u001b[0m       \u001b[32m0.7396\u001b[0m        \u001b[35m1.0353\u001b[0m  0.0628\n",
      "     18        \u001b[36m1.0981\u001b[0m       \u001b[32m0.7495\u001b[0m        \u001b[35m1.0123\u001b[0m  0.0539\n",
      "     19        \u001b[36m1.0865\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m0.9900\u001b[0m  0.0628\n",
      "     20        \u001b[36m1.0826\u001b[0m       \u001b[32m0.7633\u001b[0m        \u001b[35m0.9683\u001b[0m  0.0479\n",
      "     21        \u001b[36m1.0426\u001b[0m       \u001b[32m0.7692\u001b[0m        \u001b[35m0.9470\u001b[0m  0.0549\n",
      "     22        \u001b[36m1.0233\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m0.9259\u001b[0m  0.0669\n",
      "     23        \u001b[36m1.0091\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.9057\u001b[0m  0.0549\n",
      "     24        \u001b[36m0.9861\u001b[0m       \u001b[32m0.7988\u001b[0m        \u001b[35m0.8855\u001b[0m  0.0519\n",
      "     25        \u001b[36m0.9732\u001b[0m       \u001b[32m0.8008\u001b[0m        \u001b[35m0.8662\u001b[0m  0.0439\n",
      "     26        \u001b[36m0.9525\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.8478\u001b[0m  0.0559\n",
      "     27        0.9545       \u001b[32m0.8126\u001b[0m        \u001b[35m0.8298\u001b[0m  0.0559\n",
      "     28        \u001b[36m0.9162\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.8115\u001b[0m  0.0479\n",
      "     29        \u001b[36m0.9160\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.7941\u001b[0m  0.0439\n",
      "     30        \u001b[36m0.9014\u001b[0m       \u001b[32m0.8323\u001b[0m        \u001b[35m0.7775\u001b[0m  0.0628\n",
      "     31        \u001b[36m0.8904\u001b[0m       \u001b[32m0.8383\u001b[0m        \u001b[35m0.7614\u001b[0m  0.0588\n",
      "     32        \u001b[36m0.8802\u001b[0m       0.8383        \u001b[35m0.7460\u001b[0m  0.0499\n",
      "     33        \u001b[36m0.8514\u001b[0m       0.8383        \u001b[35m0.7302\u001b[0m  0.0509\n",
      "     34        \u001b[36m0.8491\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.7153\u001b[0m  0.0499\n",
      "     35        \u001b[36m0.8480\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.7012\u001b[0m  0.0559\n",
      "     36        \u001b[36m0.8337\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.6874\u001b[0m  0.0459\n",
      "     37        \u001b[36m0.8159\u001b[0m       0.8560        \u001b[35m0.6740\u001b[0m  0.0469\n",
      "     38        \u001b[36m0.8031\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.6607\u001b[0m  0.0578\n",
      "     39        \u001b[36m0.7964\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.6486\u001b[0m  0.0588\n",
      "     40        \u001b[36m0.7780\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.6359\u001b[0m  0.0608\n",
      "     41        0.7814       \u001b[32m0.8698\u001b[0m        \u001b[35m0.6241\u001b[0m  0.0628\n",
      "     42        0.7785       \u001b[32m0.8738\u001b[0m        \u001b[35m0.6132\u001b[0m  0.0668\n",
      "     43        \u001b[36m0.7510\u001b[0m       \u001b[32m0.8757\u001b[0m        \u001b[35m0.6025\u001b[0m  0.0469\n",
      "     44        \u001b[36m0.7387\u001b[0m       \u001b[32m0.8836\u001b[0m        \u001b[35m0.5918\u001b[0m  0.0549\n",
      "     45        0.7437       \u001b[32m0.8895\u001b[0m        \u001b[35m0.5814\u001b[0m  0.0529\n",
      "     46        \u001b[36m0.7249\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.5710\u001b[0m  0.0489\n",
      "     47        0.7291       \u001b[32m0.8955\u001b[0m        \u001b[35m0.5614\u001b[0m  0.0519\n",
      "     48        \u001b[36m0.7224\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.5522\u001b[0m  0.0568\n",
      "     49        \u001b[36m0.7102\u001b[0m       \u001b[32m0.9034\u001b[0m        \u001b[35m0.5426\u001b[0m  0.0588\n",
      "     50        \u001b[36m0.6966\u001b[0m       0.9034        \u001b[35m0.5335\u001b[0m  0.0509\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4604\u001b[0m       \u001b[32m0.1617\u001b[0m        \u001b[35m1.4072\u001b[0m  0.0389\n",
      "      2        1.4673       0.1617        \u001b[35m1.4057\u001b[0m  0.0519\n",
      "      3        1.4618       \u001b[32m0.1716\u001b[0m        \u001b[35m1.4042\u001b[0m  0.0469\n",
      "      4        \u001b[36m1.4537\u001b[0m       0.1716        \u001b[35m1.4028\u001b[0m  0.0479\n",
      "      5        1.4562       \u001b[32m0.1755\u001b[0m        \u001b[35m1.4014\u001b[0m  0.0549\n",
      "      6        1.4585       \u001b[32m0.1795\u001b[0m        \u001b[35m1.3999\u001b[0m  0.0509\n",
      "      7        \u001b[36m1.4519\u001b[0m       \u001b[32m0.1874\u001b[0m        \u001b[35m1.3985\u001b[0m  0.0668\n",
      "      8        \u001b[36m1.4503\u001b[0m       0.1874        \u001b[35m1.3972\u001b[0m  0.0469\n",
      "      9        \u001b[36m1.4403\u001b[0m       \u001b[32m0.1913\u001b[0m        \u001b[35m1.3959\u001b[0m  0.0738\n",
      "     10        1.4415       \u001b[32m0.1933\u001b[0m        \u001b[35m1.3946\u001b[0m  0.0529\n",
      "     11        1.4449       \u001b[32m0.1953\u001b[0m        \u001b[35m1.3933\u001b[0m  0.0489\n",
      "     12        1.4575       \u001b[32m0.2032\u001b[0m        \u001b[35m1.3919\u001b[0m  0.0578\n",
      "     13        1.4433       \u001b[32m0.2051\u001b[0m        \u001b[35m1.3906\u001b[0m  0.0469\n",
      "     14        \u001b[36m1.4322\u001b[0m       \u001b[32m0.2071\u001b[0m        \u001b[35m1.3894\u001b[0m  0.0379\n",
      "     15        1.4376       0.2071        \u001b[35m1.3881\u001b[0m  0.0379\n",
      "     16        \u001b[36m1.4286\u001b[0m       \u001b[32m0.2170\u001b[0m        \u001b[35m1.3868\u001b[0m  0.0439\n",
      "     17        1.4348       \u001b[32m0.2209\u001b[0m        \u001b[35m1.3856\u001b[0m  0.0519\n",
      "     18        1.4517       \u001b[32m0.2249\u001b[0m        \u001b[35m1.3843\u001b[0m  0.0389\n",
      "     19        1.4317       \u001b[32m0.2268\u001b[0m        \u001b[35m1.3831\u001b[0m  0.0608\n",
      "     20        1.4305       \u001b[32m0.2308\u001b[0m        \u001b[35m1.3819\u001b[0m  0.0549\n",
      "     21        1.4311       \u001b[32m0.2347\u001b[0m        \u001b[35m1.3806\u001b[0m  0.0479\n",
      "     22        1.4293       0.2347        \u001b[35m1.3794\u001b[0m  0.0389\n",
      "     23        \u001b[36m1.4239\u001b[0m       \u001b[32m0.2387\u001b[0m        \u001b[35m1.3782\u001b[0m  0.0389\n",
      "     24        1.4261       \u001b[32m0.2426\u001b[0m        \u001b[35m1.3770\u001b[0m  0.0598\n",
      "     25        1.4386       \u001b[32m0.2446\u001b[0m        \u001b[35m1.3758\u001b[0m  0.0389\n",
      "     26        1.4287       0.2446        \u001b[35m1.3746\u001b[0m  0.0409\n",
      "     27        \u001b[36m1.4172\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m1.3735\u001b[0m  0.0389\n",
      "     28        1.4230       \u001b[32m0.2544\u001b[0m        \u001b[35m1.3723\u001b[0m  0.0489\n",
      "     29        1.4245       \u001b[32m0.2604\u001b[0m        \u001b[35m1.3711\u001b[0m  0.0389\n",
      "     30        1.4247       0.2604        \u001b[35m1.3700\u001b[0m  0.0429\n",
      "     31        \u001b[36m1.4165\u001b[0m       \u001b[32m0.2722\u001b[0m        \u001b[35m1.3689\u001b[0m  0.0469\n",
      "     32        1.4181       \u001b[32m0.2742\u001b[0m        \u001b[35m1.3677\u001b[0m  0.0389\n",
      "     33        \u001b[36m1.4077\u001b[0m       \u001b[32m0.2761\u001b[0m        \u001b[35m1.3667\u001b[0m  0.0429\n",
      "     34        1.4241       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3656\u001b[0m  0.0399\n",
      "     35        1.4192       \u001b[32m0.2840\u001b[0m        \u001b[35m1.3645\u001b[0m  0.0399\n",
      "     36        1.4133       0.2840        \u001b[35m1.3634\u001b[0m  0.0409\n",
      "     37        1.4124       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3623\u001b[0m  0.0598\n",
      "     38        \u001b[36m1.4069\u001b[0m       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3612\u001b[0m  0.0459\n",
      "     39        1.4130       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3601\u001b[0m  0.0568\n",
      "     40        1.4099       0.3057        \u001b[35m1.3590\u001b[0m  0.0389\n",
      "     41        \u001b[36m1.4027\u001b[0m       \u001b[32m0.3097\u001b[0m        \u001b[35m1.3579\u001b[0m  0.0618\n",
      "     42        \u001b[36m1.4019\u001b[0m       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3568\u001b[0m  0.0618\n",
      "     43        \u001b[36m1.3969\u001b[0m       \u001b[32m0.3136\u001b[0m        \u001b[35m1.3558\u001b[0m  0.0509\n",
      "     44        \u001b[36m1.3940\u001b[0m       \u001b[32m0.3156\u001b[0m        \u001b[35m1.3547\u001b[0m  0.0379\n",
      "     45        1.4020       \u001b[32m0.3195\u001b[0m        \u001b[35m1.3537\u001b[0m  0.0389\n",
      "     46        1.3980       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3527\u001b[0m  0.0509\n",
      "     47        \u001b[36m1.3935\u001b[0m       \u001b[32m0.3333\u001b[0m        \u001b[35m1.3516\u001b[0m  0.0459\n",
      "     48        1.4060       \u001b[32m0.3393\u001b[0m        \u001b[35m1.3506\u001b[0m  0.0389\n",
      "     49        1.4026       \u001b[32m0.3452\u001b[0m        \u001b[35m1.3496\u001b[0m  0.0399\n",
      "     50        1.3942       \u001b[32m0.3491\u001b[0m        \u001b[35m1.3486\u001b[0m  0.0529\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4590\u001b[0m       \u001b[32m0.2604\u001b[0m        \u001b[35m1.4030\u001b[0m  0.0389\n",
      "      2        1.4593       \u001b[32m0.2643\u001b[0m        \u001b[35m1.4015\u001b[0m  0.0638\n",
      "      3        \u001b[36m1.4503\u001b[0m       0.2643        \u001b[35m1.4001\u001b[0m  0.0598\n",
      "      4        \u001b[36m1.4500\u001b[0m       0.2643        \u001b[35m1.3987\u001b[0m  0.0429\n",
      "      5        \u001b[36m1.4489\u001b[0m       0.2643        \u001b[35m1.3972\u001b[0m  0.0459\n",
      "      6        \u001b[36m1.4460\u001b[0m       \u001b[32m0.2702\u001b[0m        \u001b[35m1.3958\u001b[0m  0.0588\n",
      "      7        1.4464       0.2702        \u001b[35m1.3944\u001b[0m  0.0509\n",
      "      8        \u001b[36m1.4242\u001b[0m       \u001b[32m0.2742\u001b[0m        \u001b[35m1.3931\u001b[0m  0.0399\n",
      "      9        1.4465       0.2742        \u001b[35m1.3917\u001b[0m  0.0588\n",
      "     10        1.4332       \u001b[32m0.2761\u001b[0m        \u001b[35m1.3903\u001b[0m  0.0578\n",
      "     11        1.4434       0.2742        \u001b[35m1.3890\u001b[0m  0.0469\n",
      "     12        1.4474       \u001b[32m0.2781\u001b[0m        \u001b[35m1.3877\u001b[0m  0.0588\n",
      "     13        1.4264       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3864\u001b[0m  0.0469\n",
      "     14        1.4400       \u001b[32m0.2860\u001b[0m        \u001b[35m1.3851\u001b[0m  0.0479\n",
      "     15        1.4382       0.2860        \u001b[35m1.3839\u001b[0m  0.0419\n",
      "     16        1.4363       0.2860        \u001b[35m1.3827\u001b[0m  0.0588\n",
      "     17        \u001b[36m1.4193\u001b[0m       \u001b[32m0.2939\u001b[0m        \u001b[35m1.3815\u001b[0m  0.0549\n",
      "     18        1.4358       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3802\u001b[0m  0.0459\n",
      "     19        1.4212       0.2939        \u001b[35m1.3790\u001b[0m  0.0429\n",
      "     20        1.4204       0.2939        \u001b[35m1.3779\u001b[0m  0.0688\n",
      "     21        1.4246       \u001b[32m0.2978\u001b[0m        \u001b[35m1.3767\u001b[0m  0.0549\n",
      "     22        \u001b[36m1.4151\u001b[0m       \u001b[32m0.3018\u001b[0m        \u001b[35m1.3756\u001b[0m  0.0389\n",
      "     23        \u001b[36m1.4122\u001b[0m       0.3018        \u001b[35m1.3744\u001b[0m  0.0419\n",
      "     24        \u001b[36m1.4063\u001b[0m       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3733\u001b[0m  0.0529\n",
      "     25        1.4071       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3722\u001b[0m  0.0588\n",
      "     26        1.4313       \u001b[32m0.3097\u001b[0m        \u001b[35m1.3711\u001b[0m  0.0529\n",
      "     27        1.4172       0.3057        \u001b[35m1.3700\u001b[0m  0.0549\n",
      "     28        1.4170       0.3077        \u001b[35m1.3690\u001b[0m  0.0519\n",
      "     29        1.4184       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3679\u001b[0m  0.0568\n",
      "     30        1.4169       \u001b[32m0.3156\u001b[0m        \u001b[35m1.3669\u001b[0m  0.0638\n",
      "     31        1.4126       0.3156        \u001b[35m1.3658\u001b[0m  0.0638\n",
      "     32        1.4083       0.3156        \u001b[35m1.3648\u001b[0m  0.0439\n",
      "     33        1.4072       0.3136        \u001b[35m1.3638\u001b[0m  0.0509\n",
      "     34        1.4066       \u001b[32m0.3176\u001b[0m        \u001b[35m1.3627\u001b[0m  0.0618\n",
      "     35        \u001b[36m1.4046\u001b[0m       \u001b[32m0.3195\u001b[0m        \u001b[35m1.3617\u001b[0m  0.0379\n",
      "     36        \u001b[36m1.3958\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3607\u001b[0m  0.0459\n",
      "     37        1.4129       0.3215        \u001b[35m1.3597\u001b[0m  0.0539\n",
      "     38        1.4064       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3587\u001b[0m  0.0459\n",
      "     39        1.4050       0.3254        \u001b[35m1.3578\u001b[0m  0.0628\n",
      "     40        1.4079       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3568\u001b[0m  0.0529\n",
      "     41        \u001b[36m1.3951\u001b[0m       0.3254        \u001b[35m1.3559\u001b[0m  0.0459\n",
      "     42        1.3952       0.3274        \u001b[35m1.3550\u001b[0m  0.0559\n",
      "     43        \u001b[36m1.3925\u001b[0m       \u001b[32m0.3294\u001b[0m        \u001b[35m1.3540\u001b[0m  0.0539\n",
      "     44        1.3979       0.3294        \u001b[35m1.3530\u001b[0m  0.0578\n",
      "     45        \u001b[36m1.3862\u001b[0m       0.3294        \u001b[35m1.3521\u001b[0m  0.0608\n",
      "     46        1.3963       0.3294        \u001b[35m1.3511\u001b[0m  0.0469\n",
      "     47        1.3888       0.3294        \u001b[35m1.3502\u001b[0m  0.0559\n",
      "     48        1.3974       \u001b[32m0.3314\u001b[0m        \u001b[35m1.3492\u001b[0m  0.0678\n",
      "     49        \u001b[36m1.3841\u001b[0m       \u001b[32m0.3333\u001b[0m        \u001b[35m1.3483\u001b[0m  0.0519\n",
      "     50        1.3890       0.3333        \u001b[35m1.3474\u001b[0m  0.0588\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.3s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4445\u001b[0m       \u001b[32m0.2998\u001b[0m        \u001b[35m1.4079\u001b[0m  0.0578\n",
      "      2        1.4449       0.2998        \u001b[35m1.4061\u001b[0m  0.0459\n",
      "      3        \u001b[36m1.4400\u001b[0m       0.2998        \u001b[35m1.4043\u001b[0m  0.0499\n",
      "      4        1.4530       0.2998        \u001b[35m1.4026\u001b[0m  0.0568\n",
      "      5        1.4479       0.2998        \u001b[35m1.4010\u001b[0m  0.0369\n",
      "      6        1.4429       0.2998        \u001b[35m1.3992\u001b[0m  0.0439\n",
      "      7        1.4449       0.2998        \u001b[35m1.3976\u001b[0m  0.0409\n",
      "      8        \u001b[36m1.4336\u001b[0m       \u001b[32m0.3018\u001b[0m        \u001b[35m1.3959\u001b[0m  0.0429\n",
      "      9        \u001b[36m1.4293\u001b[0m       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3942\u001b[0m  0.0618\n",
      "     10        \u001b[36m1.4270\u001b[0m       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3927\u001b[0m  0.0459\n",
      "     11        1.4355       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3911\u001b[0m  0.0379\n",
      "     12        \u001b[36m1.4230\u001b[0m       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3895\u001b[0m  0.0578\n",
      "     13        1.4275       0.3116        \u001b[35m1.3880\u001b[0m  0.0539\n",
      "     14        1.4351       \u001b[32m0.3136\u001b[0m        \u001b[35m1.3864\u001b[0m  0.0399\n",
      "     15        1.4248       \u001b[32m0.3156\u001b[0m        \u001b[35m1.3849\u001b[0m  0.0429\n",
      "     16        \u001b[36m1.4199\u001b[0m       \u001b[32m0.3176\u001b[0m        \u001b[35m1.3833\u001b[0m  0.0519\n",
      "     17        \u001b[36m1.4153\u001b[0m       0.3176        \u001b[35m1.3818\u001b[0m  0.0578\n",
      "     18        1.4182       0.3176        \u001b[35m1.3803\u001b[0m  0.0509\n",
      "     19        1.4228       0.3176        \u001b[35m1.3788\u001b[0m  0.0459\n",
      "     20        \u001b[36m1.4093\u001b[0m       0.3176        \u001b[35m1.3774\u001b[0m  0.0429\n",
      "     21        \u001b[36m1.3929\u001b[0m       0.3176        \u001b[35m1.3760\u001b[0m  0.0379\n",
      "     22        1.4143       0.3176        \u001b[35m1.3746\u001b[0m  0.0489\n",
      "     23        1.4152       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3731\u001b[0m  0.0648\n",
      "     24        1.4059       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3717\u001b[0m  0.0578\n",
      "     25        1.4153       0.3254        \u001b[35m1.3703\u001b[0m  0.0449\n",
      "     26        1.4062       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3690\u001b[0m  0.0529\n",
      "     27        1.3981       \u001b[32m0.3314\u001b[0m        \u001b[35m1.3676\u001b[0m  0.0419\n",
      "     28        1.3960       0.3314        \u001b[35m1.3663\u001b[0m  0.0389\n",
      "     29        1.4101       \u001b[32m0.3353\u001b[0m        \u001b[35m1.3649\u001b[0m  0.0449\n",
      "     30        \u001b[36m1.3929\u001b[0m       \u001b[32m0.3432\u001b[0m        \u001b[35m1.3635\u001b[0m  0.0598\n",
      "     31        1.3955       0.3432        \u001b[35m1.3622\u001b[0m  0.0459\n",
      "     32        \u001b[36m1.3920\u001b[0m       \u001b[32m0.3452\u001b[0m        \u001b[35m1.3608\u001b[0m  0.0419\n",
      "     33        1.3961       0.3452        \u001b[35m1.3596\u001b[0m  0.0389\n",
      "     34        1.3976       0.3452        \u001b[35m1.3583\u001b[0m  0.0539\n",
      "     35        1.3955       \u001b[32m0.3491\u001b[0m        \u001b[35m1.3569\u001b[0m  0.0519\n",
      "     36        1.4075       \u001b[32m0.3531\u001b[0m        \u001b[35m1.3556\u001b[0m  0.0469\n",
      "     37        \u001b[36m1.3886\u001b[0m       \u001b[32m0.3550\u001b[0m        \u001b[35m1.3544\u001b[0m  0.0559\n",
      "     38        1.3969       0.3550        \u001b[35m1.3531\u001b[0m  0.0608\n",
      "     39        \u001b[36m1.3885\u001b[0m       0.3550        \u001b[35m1.3518\u001b[0m  0.0588\n",
      "     40        \u001b[36m1.3821\u001b[0m       \u001b[32m0.3570\u001b[0m        \u001b[35m1.3506\u001b[0m  0.0459\n",
      "     41        1.3894       \u001b[32m0.3609\u001b[0m        \u001b[35m1.3493\u001b[0m  0.0489\n",
      "     42        \u001b[36m1.3788\u001b[0m       0.3609        \u001b[35m1.3481\u001b[0m  0.0439\n",
      "     43        1.3825       0.3609        \u001b[35m1.3468\u001b[0m  0.0519\n",
      "     44        \u001b[36m1.3724\u001b[0m       \u001b[32m0.3669\u001b[0m        \u001b[35m1.3456\u001b[0m  0.0568\n",
      "     45        1.3850       0.3669        \u001b[35m1.3443\u001b[0m  0.0509\n",
      "     46        1.3731       0.3669        \u001b[35m1.3432\u001b[0m  0.0459\n",
      "     47        1.3839       0.3669        \u001b[35m1.3420\u001b[0m  0.0429\n",
      "     48        \u001b[36m1.3680\u001b[0m       \u001b[32m0.3688\u001b[0m        \u001b[35m1.3408\u001b[0m  0.0449\n",
      "     49        1.3811       0.3688        \u001b[35m1.3397\u001b[0m  0.0379\n",
      "     50        1.3784       0.3688        \u001b[35m1.3385\u001b[0m  0.0568\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=21, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.1s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4484\u001b[0m       \u001b[32m0.3333\u001b[0m        \u001b[35m1.3582\u001b[0m  0.0509\n",
      "      2        \u001b[36m1.3955\u001b[0m       \u001b[32m0.3984\u001b[0m        \u001b[35m1.3282\u001b[0m  0.0678\n",
      "      3        \u001b[36m1.3549\u001b[0m       \u001b[32m0.4872\u001b[0m        \u001b[35m1.2987\u001b[0m  0.0489\n",
      "      4        \u001b[36m1.3269\u001b[0m       \u001b[32m0.5503\u001b[0m        \u001b[35m1.2695\u001b[0m  0.0758\n",
      "      5        \u001b[36m1.3074\u001b[0m       \u001b[32m0.6193\u001b[0m        \u001b[35m1.2404\u001b[0m  0.0489\n",
      "      6        \u001b[36m1.2791\u001b[0m       \u001b[32m0.6430\u001b[0m        \u001b[35m1.2109\u001b[0m  0.0439\n",
      "      7        \u001b[36m1.2516\u001b[0m       \u001b[32m0.6765\u001b[0m        \u001b[35m1.1803\u001b[0m  0.0509\n",
      "      8        \u001b[36m1.2212\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.1487\u001b[0m  0.0429\n",
      "      9        \u001b[36m1.1907\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m1.1162\u001b[0m  0.0559\n",
      "     10        \u001b[36m1.1596\u001b[0m       \u001b[32m0.7337\u001b[0m        \u001b[35m1.0822\u001b[0m  0.0459\n",
      "     11        \u001b[36m1.1309\u001b[0m       \u001b[32m0.7515\u001b[0m        \u001b[35m1.0483\u001b[0m  0.0439\n",
      "     12        \u001b[36m1.0933\u001b[0m       \u001b[32m0.7673\u001b[0m        \u001b[35m1.0139\u001b[0m  0.0559\n",
      "     13        \u001b[36m1.0666\u001b[0m       \u001b[32m0.7732\u001b[0m        \u001b[35m0.9796\u001b[0m  0.0578\n",
      "     14        \u001b[36m1.0279\u001b[0m       \u001b[32m0.7771\u001b[0m        \u001b[35m0.9463\u001b[0m  0.0558\n",
      "     15        \u001b[36m1.0124\u001b[0m       \u001b[32m0.7791\u001b[0m        \u001b[35m0.9141\u001b[0m  0.0499\n",
      "     16        \u001b[36m0.9838\u001b[0m       \u001b[32m0.7870\u001b[0m        \u001b[35m0.8831\u001b[0m  0.0718\n",
      "     17        \u001b[36m0.9465\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.8533\u001b[0m  0.0539\n",
      "     18        \u001b[36m0.9288\u001b[0m       \u001b[32m0.8107\u001b[0m        \u001b[35m0.8251\u001b[0m  0.0559\n",
      "     19        \u001b[36m0.9078\u001b[0m       \u001b[32m0.8225\u001b[0m        \u001b[35m0.7976\u001b[0m  0.0568\n",
      "     20        \u001b[36m0.8769\u001b[0m       \u001b[32m0.8343\u001b[0m        \u001b[35m0.7717\u001b[0m  0.0559\n",
      "     21        \u001b[36m0.8474\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.7468\u001b[0m  0.0449\n",
      "     22        \u001b[36m0.8417\u001b[0m       0.8383        \u001b[35m0.7231\u001b[0m  0.0688\n",
      "     23        \u001b[36m0.8201\u001b[0m       \u001b[32m0.8442\u001b[0m        \u001b[35m0.7006\u001b[0m  0.0449\n",
      "     24        \u001b[36m0.7970\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.6793\u001b[0m  0.0489\n",
      "     25        \u001b[36m0.7950\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.6593\u001b[0m  0.0588\n",
      "     26        \u001b[36m0.7687\u001b[0m       \u001b[32m0.8659\u001b[0m        \u001b[35m0.6406\u001b[0m  0.0618\n",
      "     27        \u001b[36m0.7470\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.6223\u001b[0m  0.0519\n",
      "     28        \u001b[36m0.7286\u001b[0m       \u001b[32m0.8797\u001b[0m        \u001b[35m0.6047\u001b[0m  0.0588\n",
      "     29        \u001b[36m0.6941\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.5873\u001b[0m  0.0549\n",
      "     30        0.7100       \u001b[32m0.8895\u001b[0m        \u001b[35m0.5710\u001b[0m  0.0499\n",
      "     31        \u001b[36m0.6810\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.5554\u001b[0m  0.0489\n",
      "     32        \u001b[36m0.6726\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.5404\u001b[0m  0.0659\n",
      "     33        \u001b[36m0.6540\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.5265\u001b[0m  0.0469\n",
      "     34        \u001b[36m0.6421\u001b[0m       0.8974        \u001b[35m0.5134\u001b[0m  0.0559\n",
      "     35        \u001b[36m0.6395\u001b[0m       \u001b[32m0.8994\u001b[0m        \u001b[35m0.5006\u001b[0m  0.0529\n",
      "     36        \u001b[36m0.6157\u001b[0m       0.8935        \u001b[35m0.4883\u001b[0m  0.0688\n",
      "     37        \u001b[36m0.6106\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.4765\u001b[0m  0.0688\n",
      "     38        \u001b[36m0.5992\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.4655\u001b[0m  0.0539\n",
      "     39        \u001b[36m0.5891\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m0.4551\u001b[0m  0.0578\n",
      "     40        0.5936       \u001b[32m0.9112\u001b[0m        \u001b[35m0.4451\u001b[0m  0.0758\n",
      "     41        \u001b[36m0.5832\u001b[0m       0.9112        \u001b[35m0.4363\u001b[0m  0.0708\n",
      "     42        \u001b[36m0.5672\u001b[0m       0.9073        \u001b[35m0.4273\u001b[0m  0.0648\n",
      "     43        \u001b[36m0.5582\u001b[0m       0.9112        \u001b[35m0.4185\u001b[0m  0.0608\n",
      "     44        \u001b[36m0.5478\u001b[0m       0.9112        \u001b[35m0.4101\u001b[0m  0.0678\n",
      "     45        \u001b[36m0.5376\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m0.4019\u001b[0m  0.0459\n",
      "     46        \u001b[36m0.5375\u001b[0m       0.9112        \u001b[35m0.3944\u001b[0m  0.0469\n",
      "     47        \u001b[36m0.5293\u001b[0m       0.9112        \u001b[35m0.3872\u001b[0m  0.0608\n",
      "     48        \u001b[36m0.5283\u001b[0m       0.9132        \u001b[35m0.3808\u001b[0m  0.0539\n",
      "     49        0.5295       \u001b[32m0.9152\u001b[0m        \u001b[35m0.3741\u001b[0m  0.0688\n",
      "     50        \u001b[36m0.5153\u001b[0m       \u001b[32m0.9172\u001b[0m        \u001b[35m0.3675\u001b[0m  0.0539\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.5s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4876\u001b[0m       \u001b[32m0.3767\u001b[0m        \u001b[35m1.3888\u001b[0m  0.0618\n",
      "      2        \u001b[36m1.4209\u001b[0m       \u001b[32m0.4359\u001b[0m        \u001b[35m1.3534\u001b[0m  0.0479\n",
      "      3        \u001b[36m1.3787\u001b[0m       \u001b[32m0.4832\u001b[0m        \u001b[35m1.3195\u001b[0m  0.0499\n",
      "      4        \u001b[36m1.3475\u001b[0m       \u001b[32m0.5128\u001b[0m        \u001b[35m1.2882\u001b[0m  0.0568\n",
      "      5        \u001b[36m1.2992\u001b[0m       \u001b[32m0.5602\u001b[0m        \u001b[35m1.2572\u001b[0m  0.0768\n",
      "      6        \u001b[36m1.2868\u001b[0m       \u001b[32m0.6213\u001b[0m        \u001b[35m1.2271\u001b[0m  0.0638\n",
      "      7        \u001b[36m1.2684\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m1.1975\u001b[0m  0.0529\n",
      "      8        \u001b[36m1.2454\u001b[0m       \u001b[32m0.7061\u001b[0m        \u001b[35m1.1676\u001b[0m  0.0439\n",
      "      9        \u001b[36m1.2129\u001b[0m       \u001b[32m0.7219\u001b[0m        \u001b[35m1.1375\u001b[0m  0.0449\n",
      "     10        \u001b[36m1.1697\u001b[0m       \u001b[32m0.7298\u001b[0m        \u001b[35m1.1065\u001b[0m  0.0669\n",
      "     11        \u001b[36m1.1512\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m1.0753\u001b[0m  0.0608\n",
      "     12        \u001b[36m1.1286\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m1.0442\u001b[0m  0.0549\n",
      "     13        \u001b[36m1.0983\u001b[0m       \u001b[32m0.7811\u001b[0m        \u001b[35m1.0131\u001b[0m  0.0718\n",
      "     14        \u001b[36m1.0741\u001b[0m       \u001b[32m0.7909\u001b[0m        \u001b[35m0.9825\u001b[0m  0.0439\n",
      "     15        \u001b[36m1.0381\u001b[0m       \u001b[32m0.7968\u001b[0m        \u001b[35m0.9522\u001b[0m  0.0609\n",
      "     16        \u001b[36m1.0086\u001b[0m       \u001b[32m0.8047\u001b[0m        \u001b[35m0.9223\u001b[0m  0.0538\n",
      "     17        \u001b[36m0.9687\u001b[0m       0.8047        \u001b[35m0.8929\u001b[0m  0.0559\n",
      "     18        \u001b[36m0.9613\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.8647\u001b[0m  0.0439\n",
      "     19        \u001b[36m0.9293\u001b[0m       \u001b[32m0.8245\u001b[0m        \u001b[35m0.8379\u001b[0m  0.0459\n",
      "     20        \u001b[36m0.9080\u001b[0m       \u001b[32m0.8284\u001b[0m        \u001b[35m0.8119\u001b[0m  0.0449\n",
      "     21        \u001b[36m0.8685\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.7871\u001b[0m  0.0738\n",
      "     22        0.8760       \u001b[32m0.8383\u001b[0m        \u001b[35m0.7630\u001b[0m  0.0558\n",
      "     23        \u001b[36m0.8387\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.7402\u001b[0m  0.0568\n",
      "     24        \u001b[36m0.8191\u001b[0m       \u001b[32m0.8560\u001b[0m        \u001b[35m0.7186\u001b[0m  0.0439\n",
      "     25        \u001b[36m0.8019\u001b[0m       \u001b[32m0.8619\u001b[0m        \u001b[35m0.6982\u001b[0m  0.0459\n",
      "     26        \u001b[36m0.7879\u001b[0m       \u001b[32m0.8679\u001b[0m        \u001b[35m0.6782\u001b[0m  0.0568\n",
      "     27        \u001b[36m0.7638\u001b[0m       \u001b[32m0.8738\u001b[0m        \u001b[35m0.6589\u001b[0m  0.0489\n",
      "     28        \u001b[36m0.7537\u001b[0m       \u001b[32m0.8817\u001b[0m        \u001b[35m0.6410\u001b[0m  0.0559\n",
      "     29        \u001b[36m0.7405\u001b[0m       0.8817        \u001b[35m0.6238\u001b[0m  0.0668\n",
      "     30        \u001b[36m0.7160\u001b[0m       \u001b[32m0.8876\u001b[0m        \u001b[35m0.6073\u001b[0m  0.0509\n",
      "     31        \u001b[36m0.7066\u001b[0m       0.8856        \u001b[35m0.5920\u001b[0m  0.0499\n",
      "     32        \u001b[36m0.6871\u001b[0m       0.8817        \u001b[35m0.5771\u001b[0m  0.0519\n",
      "     33        \u001b[36m0.6586\u001b[0m       0.8777        \u001b[35m0.5627\u001b[0m  0.0449\n",
      "     34        \u001b[36m0.6510\u001b[0m       0.8757        \u001b[35m0.5489\u001b[0m  0.0549\n",
      "     35        \u001b[36m0.6427\u001b[0m       0.8817        \u001b[35m0.5359\u001b[0m  0.0439\n",
      "     36        \u001b[36m0.6334\u001b[0m       \u001b[32m0.8915\u001b[0m        \u001b[35m0.5236\u001b[0m  0.0549\n",
      "     37        \u001b[36m0.6199\u001b[0m       0.8915        \u001b[35m0.5116\u001b[0m  0.0419\n",
      "     38        \u001b[36m0.6082\u001b[0m       \u001b[32m0.8935\u001b[0m        \u001b[35m0.5005\u001b[0m  0.0549\n",
      "     39        \u001b[36m0.6029\u001b[0m       0.8915        \u001b[35m0.4898\u001b[0m  0.0598\n",
      "     40        \u001b[36m0.5881\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.4798\u001b[0m  0.0469\n",
      "     41        \u001b[36m0.5785\u001b[0m       0.8974        \u001b[35m0.4701\u001b[0m  0.0718\n",
      "     42        \u001b[36m0.5716\u001b[0m       0.8974        \u001b[35m0.4607\u001b[0m  0.0539\n",
      "     43        \u001b[36m0.5539\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.4515\u001b[0m  0.0509\n",
      "     44        0.5675       0.8974        \u001b[35m0.4431\u001b[0m  0.0549\n",
      "     45        \u001b[36m0.5520\u001b[0m       0.8974        \u001b[35m0.4348\u001b[0m  0.0459\n",
      "     46        0.5584       0.8994        \u001b[35m0.4272\u001b[0m  0.0638\n",
      "     47        \u001b[36m0.5336\u001b[0m       0.8994        \u001b[35m0.4197\u001b[0m  0.0459\n",
      "     48        \u001b[36m0.5160\u001b[0m       0.8994        \u001b[35m0.4123\u001b[0m  0.0598\n",
      "     49        \u001b[36m0.5095\u001b[0m       0.8994        \u001b[35m0.4056\u001b[0m  0.0419\n",
      "     50        0.5217       0.9014        \u001b[35m0.3990\u001b[0m  0.0479\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4984\u001b[0m       \u001b[32m0.1815\u001b[0m        \u001b[35m1.4027\u001b[0m  0.0608\n",
      "      2        \u001b[36m1.4364\u001b[0m       \u001b[32m0.2387\u001b[0m        \u001b[35m1.3714\u001b[0m  0.0618\n",
      "      3        \u001b[36m1.3984\u001b[0m       \u001b[32m0.3353\u001b[0m        \u001b[35m1.3409\u001b[0m  0.0568\n",
      "      4        \u001b[36m1.3759\u001b[0m       \u001b[32m0.4872\u001b[0m        \u001b[35m1.3111\u001b[0m  0.0449\n",
      "      5        \u001b[36m1.3495\u001b[0m       \u001b[32m0.5957\u001b[0m        \u001b[35m1.2815\u001b[0m  0.0449\n",
      "      6        \u001b[36m1.3106\u001b[0m       \u001b[32m0.6588\u001b[0m        \u001b[35m1.2510\u001b[0m  0.0568\n",
      "      7        \u001b[36m1.2880\u001b[0m       \u001b[32m0.7022\u001b[0m        \u001b[35m1.2199\u001b[0m  0.0479\n",
      "      8        \u001b[36m1.2524\u001b[0m       \u001b[32m0.7278\u001b[0m        \u001b[35m1.1863\u001b[0m  0.0429\n",
      "      9        \u001b[36m1.2216\u001b[0m       \u001b[32m0.7535\u001b[0m        \u001b[35m1.1506\u001b[0m  0.0499\n",
      "     10        \u001b[36m1.1875\u001b[0m       \u001b[32m0.7712\u001b[0m        \u001b[35m1.1128\u001b[0m  0.0618\n",
      "     11        \u001b[36m1.1424\u001b[0m       \u001b[32m0.7909\u001b[0m        \u001b[35m1.0742\u001b[0m  0.0519\n",
      "     12        \u001b[36m1.1266\u001b[0m       \u001b[32m0.8067\u001b[0m        \u001b[35m1.0354\u001b[0m  0.0549\n",
      "     13        \u001b[36m1.0881\u001b[0m       \u001b[32m0.8087\u001b[0m        \u001b[35m0.9969\u001b[0m  0.0509\n",
      "     14        \u001b[36m1.0450\u001b[0m       \u001b[32m0.8146\u001b[0m        \u001b[35m0.9586\u001b[0m  0.0529\n",
      "     15        \u001b[36m1.0121\u001b[0m       \u001b[32m0.8185\u001b[0m        \u001b[35m0.9213\u001b[0m  0.0638\n",
      "     16        \u001b[36m0.9825\u001b[0m       0.8185        \u001b[35m0.8858\u001b[0m  0.0568\n",
      "     17        \u001b[36m0.9464\u001b[0m       \u001b[32m0.8264\u001b[0m        \u001b[35m0.8516\u001b[0m  0.0439\n",
      "     18        \u001b[36m0.9245\u001b[0m       \u001b[32m0.8304\u001b[0m        \u001b[35m0.8199\u001b[0m  0.0469\n",
      "     19        \u001b[36m0.8948\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.7900\u001b[0m  0.0469\n",
      "     20        \u001b[36m0.8732\u001b[0m       \u001b[32m0.8402\u001b[0m        \u001b[35m0.7618\u001b[0m  0.0489\n",
      "     21        \u001b[36m0.8419\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.7353\u001b[0m  0.0549\n",
      "     22        \u001b[36m0.8155\u001b[0m       \u001b[32m0.8521\u001b[0m        \u001b[35m0.7101\u001b[0m  0.0479\n",
      "     23        \u001b[36m0.7933\u001b[0m       \u001b[32m0.8580\u001b[0m        \u001b[35m0.6861\u001b[0m  0.0489\n",
      "     24        \u001b[36m0.7774\u001b[0m       0.8560        \u001b[35m0.6635\u001b[0m  0.0549\n",
      "     25        \u001b[36m0.7553\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.6418\u001b[0m  0.0658\n",
      "     26        \u001b[36m0.7359\u001b[0m       \u001b[32m0.8639\u001b[0m        \u001b[35m0.6217\u001b[0m  0.0439\n",
      "     27        \u001b[36m0.7194\u001b[0m       \u001b[32m0.8718\u001b[0m        \u001b[35m0.6029\u001b[0m  0.0568\n",
      "     28        \u001b[36m0.7012\u001b[0m       \u001b[32m0.8777\u001b[0m        \u001b[35m0.5849\u001b[0m  0.0549\n",
      "     29        \u001b[36m0.6969\u001b[0m       \u001b[32m0.8895\u001b[0m        \u001b[35m0.5682\u001b[0m  0.0648\n",
      "     30        \u001b[36m0.6686\u001b[0m       \u001b[32m0.8974\u001b[0m        \u001b[35m0.5521\u001b[0m  0.0509\n",
      "     31        \u001b[36m0.6590\u001b[0m       \u001b[32m0.9014\u001b[0m        \u001b[35m0.5370\u001b[0m  0.0549\n",
      "     32        \u001b[36m0.6454\u001b[0m       0.9014        \u001b[35m0.5222\u001b[0m  0.0678\n",
      "     33        \u001b[36m0.6386\u001b[0m       \u001b[32m0.9073\u001b[0m        \u001b[35m0.5086\u001b[0m  0.0688\n",
      "     34        \u001b[36m0.6209\u001b[0m       \u001b[32m0.9093\u001b[0m        \u001b[35m0.4959\u001b[0m  0.0638\n",
      "     35        \u001b[36m0.6142\u001b[0m       \u001b[32m0.9132\u001b[0m        \u001b[35m0.4836\u001b[0m  0.0519\n",
      "     36        0.6161       0.9132        \u001b[35m0.4720\u001b[0m  0.0628\n",
      "     37        \u001b[36m0.5960\u001b[0m       0.9112        \u001b[35m0.4614\u001b[0m  0.0439\n",
      "     38        \u001b[36m0.5797\u001b[0m       \u001b[32m0.9152\u001b[0m        \u001b[35m0.4509\u001b[0m  0.0549\n",
      "     39        \u001b[36m0.5790\u001b[0m       0.9152        \u001b[35m0.4410\u001b[0m  0.0429\n",
      "     40        0.5803       \u001b[32m0.9172\u001b[0m        \u001b[35m0.4314\u001b[0m  0.0469\n",
      "     41        \u001b[36m0.5614\u001b[0m       0.9172        \u001b[35m0.4221\u001b[0m  0.0509\n",
      "     42        \u001b[36m0.5429\u001b[0m       0.9172        \u001b[35m0.4135\u001b[0m  0.0529\n",
      "     43        \u001b[36m0.5335\u001b[0m       \u001b[32m0.9191\u001b[0m        \u001b[35m0.4049\u001b[0m  0.0568\n",
      "     44        0.5400       \u001b[32m0.9231\u001b[0m        \u001b[35m0.3968\u001b[0m  0.0459\n",
      "     45        \u001b[36m0.5085\u001b[0m       \u001b[32m0.9250\u001b[0m        \u001b[35m0.3884\u001b[0m  0.0598\n",
      "     46        0.5193       \u001b[32m0.9270\u001b[0m        \u001b[35m0.3801\u001b[0m  0.0509\n",
      "     47        0.5148       \u001b[32m0.9310\u001b[0m        \u001b[35m0.3733\u001b[0m  0.0498\n",
      "     48        \u001b[36m0.5082\u001b[0m       \u001b[32m0.9329\u001b[0m        \u001b[35m0.3670\u001b[0m  0.0659\n",
      "     49        \u001b[36m0.4936\u001b[0m       0.9329        \u001b[35m0.3607\u001b[0m  0.0628\n",
      "     50        \u001b[36m0.4899\u001b[0m       0.9329        \u001b[35m0.3541\u001b[0m  0.0509\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.adam.Adam'>, total=   3.3s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4447\u001b[0m       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3767\u001b[0m  0.0568\n",
      "      2        \u001b[36m1.4336\u001b[0m       \u001b[32m0.2998\u001b[0m        \u001b[35m1.3751\u001b[0m  0.0569\n",
      "      3        \u001b[36m1.4252\u001b[0m       \u001b[32m0.3037\u001b[0m        \u001b[35m1.3736\u001b[0m  0.0539\n",
      "      4        1.4340       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3721\u001b[0m  0.0628\n",
      "      5        1.4393       \u001b[32m0.3097\u001b[0m        \u001b[35m1.3705\u001b[0m  0.0419\n",
      "      6        1.4426       \u001b[32m0.3136\u001b[0m        \u001b[35m1.3689\u001b[0m  0.0598\n",
      "      7        1.4262       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3674\u001b[0m  0.0559\n",
      "      8        1.4395       \u001b[32m0.3314\u001b[0m        \u001b[35m1.3658\u001b[0m  0.0658\n",
      "      9        1.4399       \u001b[32m0.3353\u001b[0m        \u001b[35m1.3643\u001b[0m  0.0489\n",
      "     10        1.4261       \u001b[32m0.3373\u001b[0m        \u001b[35m1.3629\u001b[0m  0.0499\n",
      "     11        1.4285       0.3353        \u001b[35m1.3615\u001b[0m  0.0618\n",
      "     12        1.4329       0.3353        \u001b[35m1.3600\u001b[0m  0.0559\n",
      "     13        \u001b[36m1.4084\u001b[0m       0.3353        \u001b[35m1.3586\u001b[0m  0.0539\n",
      "     14        1.4241       0.3373        \u001b[35m1.3571\u001b[0m  0.0539\n",
      "     15        1.4174       \u001b[32m0.3531\u001b[0m        \u001b[35m1.3557\u001b[0m  0.0479\n",
      "     16        1.4266       \u001b[32m0.3570\u001b[0m        \u001b[35m1.3542\u001b[0m  0.0509\n",
      "     17        \u001b[36m1.4081\u001b[0m       \u001b[32m0.3590\u001b[0m        \u001b[35m1.3529\u001b[0m  0.0559\n",
      "     18        1.4131       \u001b[32m0.3629\u001b[0m        \u001b[35m1.3515\u001b[0m  0.0509\n",
      "     19        1.4131       \u001b[32m0.3669\u001b[0m        \u001b[35m1.3501\u001b[0m  0.0499\n",
      "     20        \u001b[36m1.4013\u001b[0m       \u001b[32m0.3708\u001b[0m        \u001b[35m1.3487\u001b[0m  0.0489\n",
      "     21        1.4187       \u001b[32m0.3748\u001b[0m        \u001b[35m1.3473\u001b[0m  0.0439\n",
      "     22        \u001b[36m1.3965\u001b[0m       \u001b[32m0.3807\u001b[0m        \u001b[35m1.3460\u001b[0m  0.0409\n",
      "     23        1.4173       \u001b[32m0.3826\u001b[0m        \u001b[35m1.3446\u001b[0m  0.0539\n",
      "     24        1.4057       \u001b[32m0.3866\u001b[0m        \u001b[35m1.3433\u001b[0m  0.0648\n",
      "     25        1.4036       0.3866        \u001b[35m1.3419\u001b[0m  0.0568\n",
      "     26        1.3978       \u001b[32m0.3925\u001b[0m        \u001b[35m1.3406\u001b[0m  0.0518\n",
      "     27        1.4047       0.3925        \u001b[35m1.3392\u001b[0m  0.0479\n",
      "     28        1.4088       \u001b[32m0.3945\u001b[0m        \u001b[35m1.3379\u001b[0m  0.0519\n",
      "     29        1.3969       \u001b[32m0.3964\u001b[0m        \u001b[35m1.3366\u001b[0m  0.0618\n",
      "     30        1.4009       \u001b[32m0.4004\u001b[0m        \u001b[35m1.3352\u001b[0m  0.0589\n",
      "     31        \u001b[36m1.3951\u001b[0m       0.4004        \u001b[35m1.3339\u001b[0m  0.0458\n",
      "     32        \u001b[36m1.3788\u001b[0m       \u001b[32m0.4024\u001b[0m        \u001b[35m1.3326\u001b[0m  0.0449\n",
      "     33        1.3923       \u001b[32m0.4063\u001b[0m        \u001b[35m1.3313\u001b[0m  0.0539\n",
      "     34        1.3926       \u001b[32m0.4083\u001b[0m        \u001b[35m1.3301\u001b[0m  0.0509\n",
      "     35        1.3957       \u001b[32m0.4142\u001b[0m        \u001b[35m1.3288\u001b[0m  0.0718\n",
      "     36        1.3862       \u001b[32m0.4162\u001b[0m        \u001b[35m1.3276\u001b[0m  0.0499\n",
      "     37        1.3809       \u001b[32m0.4181\u001b[0m        \u001b[35m1.3263\u001b[0m  0.0459\n",
      "     38        \u001b[36m1.3772\u001b[0m       \u001b[32m0.4260\u001b[0m        \u001b[35m1.3250\u001b[0m  0.0399\n",
      "     39        \u001b[36m1.3767\u001b[0m       \u001b[32m0.4280\u001b[0m        \u001b[35m1.3239\u001b[0m  0.0419\n",
      "     40        1.3812       \u001b[32m0.4320\u001b[0m        \u001b[35m1.3226\u001b[0m  0.0439\n",
      "     41        \u001b[36m1.3748\u001b[0m       0.4320        \u001b[35m1.3214\u001b[0m  0.0399\n",
      "     42        1.3802       \u001b[32m0.4339\u001b[0m        \u001b[35m1.3202\u001b[0m  0.0479\n",
      "     43        1.3869       \u001b[32m0.4379\u001b[0m        \u001b[35m1.3189\u001b[0m  0.0439\n",
      "     44        1.3889       \u001b[32m0.4418\u001b[0m        \u001b[35m1.3177\u001b[0m  0.0588\n",
      "     45        \u001b[36m1.3669\u001b[0m       0.4418        \u001b[35m1.3165\u001b[0m  0.0409\n",
      "     46        1.3695       0.4418        \u001b[35m1.3153\u001b[0m  0.0469\n",
      "     47        1.3751       \u001b[32m0.4438\u001b[0m        \u001b[35m1.3141\u001b[0m  0.0459\n",
      "     48        1.3701       \u001b[32m0.4477\u001b[0m        \u001b[35m1.3129\u001b[0m  0.0429\n",
      "     49        \u001b[36m1.3645\u001b[0m       \u001b[32m0.4517\u001b[0m        \u001b[35m1.3117\u001b[0m  0.0598\n",
      "     50        1.3750       \u001b[32m0.4556\u001b[0m        \u001b[35m1.3105\u001b[0m  0.0498\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.2s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.5012\u001b[0m       \u001b[32m0.2071\u001b[0m        \u001b[35m1.4420\u001b[0m  0.0539\n",
      "      2        \u001b[36m1.5001\u001b[0m       0.2071        \u001b[35m1.4405\u001b[0m  0.0489\n",
      "      3        \u001b[36m1.4927\u001b[0m       \u001b[32m0.2091\u001b[0m        \u001b[35m1.4389\u001b[0m  0.0459\n",
      "      4        1.4931       0.2091        \u001b[35m1.4373\u001b[0m  0.0598\n",
      "      5        1.4985       0.2091        \u001b[35m1.4358\u001b[0m  0.0389\n",
      "      6        \u001b[36m1.4908\u001b[0m       \u001b[32m0.2110\u001b[0m        \u001b[35m1.4343\u001b[0m  0.0449\n",
      "      7        1.4949       0.2110        \u001b[35m1.4327\u001b[0m  0.0409\n",
      "      8        \u001b[36m1.4861\u001b[0m       0.2110        \u001b[35m1.4312\u001b[0m  0.0489\n",
      "      9        \u001b[36m1.4839\u001b[0m       \u001b[32m0.2130\u001b[0m        \u001b[35m1.4297\u001b[0m  0.0479\n",
      "     10        \u001b[36m1.4802\u001b[0m       0.2130        \u001b[35m1.4283\u001b[0m  0.0409\n",
      "     11        1.4886       \u001b[32m0.2150\u001b[0m        \u001b[35m1.4267\u001b[0m  0.0389\n",
      "     12        \u001b[36m1.4727\u001b[0m       0.2150        \u001b[35m1.4253\u001b[0m  0.0479\n",
      "     13        1.4790       \u001b[32m0.2170\u001b[0m        \u001b[35m1.4239\u001b[0m  0.0389\n",
      "     14        \u001b[36m1.4694\u001b[0m       0.2170        \u001b[35m1.4225\u001b[0m  0.0519\n",
      "     15        1.4741       \u001b[32m0.2209\u001b[0m        \u001b[35m1.4211\u001b[0m  0.0529\n",
      "     16        1.4698       \u001b[32m0.2249\u001b[0m        \u001b[35m1.4197\u001b[0m  0.0509\n",
      "     17        1.4734       \u001b[32m0.2288\u001b[0m        \u001b[35m1.4183\u001b[0m  0.0549\n",
      "     18        1.4799       0.2288        \u001b[35m1.4169\u001b[0m  0.0369\n",
      "     19        1.4736       0.2288        \u001b[35m1.4155\u001b[0m  0.0399\n",
      "     20        \u001b[36m1.4630\u001b[0m       0.2288        \u001b[35m1.4141\u001b[0m  0.0469\n",
      "     21        1.4632       \u001b[32m0.2308\u001b[0m        \u001b[35m1.4128\u001b[0m  0.0499\n",
      "     22        \u001b[36m1.4573\u001b[0m       \u001b[32m0.2367\u001b[0m        \u001b[35m1.4115\u001b[0m  0.0389\n",
      "     23        1.4650       \u001b[32m0.2387\u001b[0m        \u001b[35m1.4101\u001b[0m  0.0459\n",
      "     24        \u001b[36m1.4493\u001b[0m       \u001b[32m0.2406\u001b[0m        \u001b[35m1.4088\u001b[0m  0.0608\n",
      "     25        1.4674       \u001b[32m0.2465\u001b[0m        \u001b[35m1.4075\u001b[0m  0.0569\n",
      "     26        1.4551       \u001b[32m0.2505\u001b[0m        \u001b[35m1.4061\u001b[0m  0.0429\n",
      "     27        1.4603       \u001b[32m0.2623\u001b[0m        \u001b[35m1.4048\u001b[0m  0.0588\n",
      "     28        \u001b[36m1.4480\u001b[0m       \u001b[32m0.2663\u001b[0m        \u001b[35m1.4035\u001b[0m  0.0419\n",
      "     29        \u001b[36m1.4472\u001b[0m       \u001b[32m0.2682\u001b[0m        \u001b[35m1.4022\u001b[0m  0.0529\n",
      "     30        1.4539       0.2682        \u001b[35m1.4009\u001b[0m  0.0469\n",
      "     31        1.4533       0.2663        \u001b[35m1.3997\u001b[0m  0.0539\n",
      "     32        \u001b[36m1.4387\u001b[0m       0.2663        \u001b[35m1.3985\u001b[0m  0.0429\n",
      "     33        1.4390       0.2682        \u001b[35m1.3972\u001b[0m  0.0399\n",
      "     34        \u001b[36m1.4353\u001b[0m       \u001b[32m0.2722\u001b[0m        \u001b[35m1.3960\u001b[0m  0.0499\n",
      "     35        1.4425       0.2722        \u001b[35m1.3948\u001b[0m  0.0698\n",
      "     36        1.4565       \u001b[32m0.2781\u001b[0m        \u001b[35m1.3935\u001b[0m  0.0628\n",
      "     37        1.4373       \u001b[32m0.2801\u001b[0m        \u001b[35m1.3923\u001b[0m  0.0509\n",
      "     38        1.4381       \u001b[32m0.2840\u001b[0m        \u001b[35m1.3911\u001b[0m  0.0499\n",
      "     39        1.4372       0.2840        \u001b[35m1.3900\u001b[0m  0.0389\n",
      "     40        \u001b[36m1.4301\u001b[0m       0.2840        \u001b[35m1.3888\u001b[0m  0.0389\n",
      "     41        1.4314       \u001b[32m0.2880\u001b[0m        \u001b[35m1.3876\u001b[0m  0.0409\n",
      "     42        1.4353       \u001b[32m0.2899\u001b[0m        \u001b[35m1.3864\u001b[0m  0.0539\n",
      "     43        \u001b[36m1.4209\u001b[0m       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3852\u001b[0m  0.0519\n",
      "     44        1.4468       \u001b[32m0.3018\u001b[0m        \u001b[35m1.3841\u001b[0m  0.0439\n",
      "     45        \u001b[36m1.4201\u001b[0m       \u001b[32m0.3077\u001b[0m        \u001b[35m1.3829\u001b[0m  0.0459\n",
      "     46        \u001b[36m1.4117\u001b[0m       \u001b[32m0.3116\u001b[0m        \u001b[35m1.3817\u001b[0m  0.0429\n",
      "     47        1.4294       \u001b[32m0.3195\u001b[0m        \u001b[35m1.3806\u001b[0m  0.0489\n",
      "     48        1.4222       \u001b[32m0.3235\u001b[0m        \u001b[35m1.3794\u001b[0m  0.0638\n",
      "     49        1.4294       \u001b[32m0.3254\u001b[0m        \u001b[35m1.3783\u001b[0m  0.0549\n",
      "     50        1.4197       \u001b[32m0.3294\u001b[0m        \u001b[35m1.3771\u001b[0m  0.0419\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.0s\n",
      "[CV] lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'> \n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.4624\u001b[0m       \u001b[32m0.2249\u001b[0m        \u001b[35m1.4155\u001b[0m  0.0529\n",
      "      2        1.4680       0.2249        \u001b[35m1.4135\u001b[0m  0.0618\n",
      "      3        \u001b[36m1.4551\u001b[0m       0.2229        \u001b[35m1.4115\u001b[0m  0.0459\n",
      "      4        1.4689       0.2229        \u001b[35m1.4096\u001b[0m  0.0449\n",
      "      5        1.4633       0.2229        \u001b[35m1.4077\u001b[0m  0.0419\n",
      "      6        1.4588       0.2229        \u001b[35m1.4058\u001b[0m  0.0499\n",
      "      7        \u001b[36m1.4505\u001b[0m       0.2229        \u001b[35m1.4038\u001b[0m  0.0429\n",
      "      8        \u001b[36m1.4379\u001b[0m       \u001b[32m0.2268\u001b[0m        \u001b[35m1.4021\u001b[0m  0.0409\n",
      "      9        1.4500       0.2268        \u001b[35m1.4002\u001b[0m  0.0449\n",
      "     10        1.4492       \u001b[32m0.2308\u001b[0m        \u001b[35m1.3985\u001b[0m  0.0578\n",
      "     11        1.4618       \u001b[32m0.2327\u001b[0m        \u001b[35m1.3966\u001b[0m  0.0429\n",
      "     12        1.4469       \u001b[32m0.2347\u001b[0m        \u001b[35m1.3949\u001b[0m  0.0668\n",
      "     13        1.4386       \u001b[32m0.2367\u001b[0m        \u001b[35m1.3932\u001b[0m  0.0459\n",
      "     14        \u001b[36m1.4290\u001b[0m       0.2308        \u001b[35m1.3915\u001b[0m  0.0409\n",
      "     15        1.4337       0.2308        \u001b[35m1.3899\u001b[0m  0.0459\n",
      "     16        1.4300       0.2327        \u001b[35m1.3883\u001b[0m  0.0479\n",
      "     17        1.4500       0.2347        \u001b[35m1.3867\u001b[0m  0.0449\n",
      "     18        \u001b[36m1.4188\u001b[0m       \u001b[32m0.2426\u001b[0m        \u001b[35m1.3851\u001b[0m  0.0409\n",
      "     19        1.4315       \u001b[32m0.2465\u001b[0m        \u001b[35m1.3836\u001b[0m  0.0409\n",
      "     20        1.4209       \u001b[32m0.2485\u001b[0m        \u001b[35m1.3820\u001b[0m  0.0459\n",
      "     21        \u001b[36m1.4153\u001b[0m       \u001b[32m0.2505\u001b[0m        \u001b[35m1.3806\u001b[0m  0.0549\n",
      "     22        1.4235       \u001b[32m0.2544\u001b[0m        \u001b[35m1.3791\u001b[0m  0.0519\n",
      "     23        1.4264       0.2544        \u001b[35m1.3776\u001b[0m  0.0469\n",
      "     24        \u001b[36m1.4128\u001b[0m       \u001b[32m0.2564\u001b[0m        \u001b[35m1.3762\u001b[0m  0.0598\n",
      "     25        1.4246       \u001b[32m0.2643\u001b[0m        \u001b[35m1.3747\u001b[0m  0.0409\n",
      "     26        1.4242       \u001b[32m0.2742\u001b[0m        \u001b[35m1.3733\u001b[0m  0.0588\n",
      "     27        \u001b[36m1.4116\u001b[0m       \u001b[32m0.2840\u001b[0m        \u001b[35m1.3718\u001b[0m  0.0578\n",
      "     28        1.4123       0.2840        \u001b[35m1.3704\u001b[0m  0.0389\n",
      "     29        1.4164       \u001b[32m0.2860\u001b[0m        \u001b[35m1.3689\u001b[0m  0.0539\n",
      "     30        1.4136       \u001b[32m0.2919\u001b[0m        \u001b[35m1.3675\u001b[0m  0.0479\n",
      "     31        \u001b[36m1.4009\u001b[0m       \u001b[32m0.2959\u001b[0m        \u001b[35m1.3661\u001b[0m  0.0439\n",
      "     32        1.4127       \u001b[32m0.3057\u001b[0m        \u001b[35m1.3648\u001b[0m  0.0529\n",
      "     33        1.4047       0.3037        \u001b[35m1.3634\u001b[0m  0.0568\n",
      "     34        1.4078       0.3057        \u001b[35m1.3620\u001b[0m  0.0588\n",
      "     35        1.4141       0.3018        \u001b[35m1.3607\u001b[0m  0.0449\n",
      "     36        1.4019       0.3057        \u001b[35m1.3594\u001b[0m  0.0399\n",
      "     37        1.4039       \u001b[32m0.3097\u001b[0m        \u001b[35m1.3581\u001b[0m  0.0549\n",
      "     38        \u001b[36m1.3952\u001b[0m       \u001b[32m0.3136\u001b[0m        \u001b[35m1.3569\u001b[0m  0.0638\n",
      "     39        \u001b[36m1.3907\u001b[0m       \u001b[32m0.3156\u001b[0m        \u001b[35m1.3556\u001b[0m  0.0529\n",
      "     40        \u001b[36m1.3859\u001b[0m       \u001b[32m0.3215\u001b[0m        \u001b[35m1.3544\u001b[0m  0.0578\n",
      "     41        1.3989       0.3156        \u001b[35m1.3531\u001b[0m  0.0568\n",
      "     42        1.3957       0.3136        \u001b[35m1.3519\u001b[0m  0.0439\n",
      "     43        1.4043       0.3215        \u001b[35m1.3507\u001b[0m  0.0419\n",
      "     44        1.4029       \u001b[32m0.3274\u001b[0m        \u001b[35m1.3494\u001b[0m  0.0429\n",
      "     45        1.3922       \u001b[32m0.3314\u001b[0m        \u001b[35m1.3482\u001b[0m  0.0519\n",
      "     46        1.3905       \u001b[32m0.3393\u001b[0m        \u001b[35m1.3470\u001b[0m  0.0429\n",
      "     47        1.3875       \u001b[32m0.3432\u001b[0m        \u001b[35m1.3458\u001b[0m  0.0668\n",
      "     48        \u001b[36m1.3845\u001b[0m       \u001b[32m0.3531\u001b[0m        \u001b[35m1.3445\u001b[0m  0.0489\n",
      "     49        1.3914       \u001b[32m0.3570\u001b[0m        \u001b[35m1.3433\u001b[0m  0.0499\n",
      "     50        1.3867       \u001b[32m0.3590\u001b[0m        \u001b[35m1.3421\u001b[0m  0.0529\n",
      "[CV]  lr=0.001, module__dropout=0.8, module__hidden_dim=42, optimizer=<class 'torch.optim.sgd.SGD'>, total=   3.1s\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "Re-initializing module because the following parameters were re-set: dropout, hidden_dim.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.5317\u001b[0m       \u001b[32m0.5184\u001b[0m        \u001b[35m1.1645\u001b[0m  0.0658\n",
      "      2        \u001b[36m1.2742\u001b[0m       \u001b[32m0.6974\u001b[0m        \u001b[35m0.9965\u001b[0m  0.0698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m1.0234\u001b[0m       \u001b[32m0.7184\u001b[0m        \u001b[35m0.8256\u001b[0m  0.0868\n",
      "      4        \u001b[36m0.9051\u001b[0m       \u001b[32m0.7711\u001b[0m        \u001b[35m0.6897\u001b[0m  0.0768\n",
      "      5        \u001b[36m0.7808\u001b[0m       \u001b[32m0.8132\u001b[0m        \u001b[35m0.5833\u001b[0m  0.0798\n",
      "      6        \u001b[36m0.7063\u001b[0m       \u001b[32m0.8711\u001b[0m        \u001b[35m0.4946\u001b[0m  0.0638\n",
      "      7        \u001b[36m0.6345\u001b[0m       \u001b[32m0.8908\u001b[0m        \u001b[35m0.4191\u001b[0m  0.0808\n",
      "      8        \u001b[36m0.5722\u001b[0m       \u001b[32m0.9013\u001b[0m        \u001b[35m0.3590\u001b[0m  0.0748\n",
      "      9        \u001b[36m0.5232\u001b[0m       \u001b[32m0.9053\u001b[0m        \u001b[35m0.3171\u001b[0m  0.0698\n",
      "     10        \u001b[36m0.4942\u001b[0m       \u001b[32m0.9224\u001b[0m        \u001b[35m0.2815\u001b[0m  0.0977\n",
      "     11        \u001b[36m0.4596\u001b[0m       \u001b[32m0.9355\u001b[0m        \u001b[35m0.2544\u001b[0m  0.0808\n",
      "     12        \u001b[36m0.4253\u001b[0m       0.9329        \u001b[35m0.2380\u001b[0m  0.0888\n",
      "     13        \u001b[36m0.4128\u001b[0m       \u001b[32m0.9474\u001b[0m        \u001b[35m0.2151\u001b[0m  0.0808\n",
      "     14        \u001b[36m0.3991\u001b[0m       0.9395        \u001b[35m0.2110\u001b[0m  0.0608\n",
      "     15        \u001b[36m0.3897\u001b[0m       \u001b[32m0.9526\u001b[0m        \u001b[35m0.1914\u001b[0m  0.0858\n",
      "     16        \u001b[36m0.3526\u001b[0m       0.9526        \u001b[35m0.1850\u001b[0m  0.0848\n",
      "     17        \u001b[36m0.3504\u001b[0m       \u001b[32m0.9579\u001b[0m        \u001b[35m0.1733\u001b[0m  0.0818\n",
      "     18        \u001b[36m0.3370\u001b[0m       0.9539        \u001b[35m0.1693\u001b[0m  0.0918\n",
      "     19        \u001b[36m0.3324\u001b[0m       \u001b[32m0.9618\u001b[0m        \u001b[35m0.1577\u001b[0m  0.0868\n",
      "     20        \u001b[36m0.2986\u001b[0m       0.9539        0.1579  0.0618\n",
      "     21        0.3146       0.9618        \u001b[35m0.1483\u001b[0m  0.0768\n",
      "     22        0.3006       0.9553        0.1524  0.0668\n",
      "     23        0.3173       0.9618        \u001b[35m0.1396\u001b[0m  0.0658\n",
      "     24        \u001b[36m0.2951\u001b[0m       0.9592        0.1397  0.0688\n",
      "     25        \u001b[36m0.2949\u001b[0m       0.9618        \u001b[35m0.1373\u001b[0m  0.0838\n",
      "     26        \u001b[36m0.2821\u001b[0m       \u001b[32m0.9658\u001b[0m        \u001b[35m0.1271\u001b[0m  0.0678\n",
      "     27        \u001b[36m0.2673\u001b[0m       0.9632        0.1374  0.0868\n",
      "     28        0.2873       \u001b[32m0.9671\u001b[0m        \u001b[35m0.1234\u001b[0m  0.0738\n",
      "     29        0.2763       0.9632        0.1305  0.1027\n",
      "     30        0.2733       \u001b[32m0.9684\u001b[0m        \u001b[35m0.1179\u001b[0m  0.0858\n",
      "     31        \u001b[36m0.2653\u001b[0m       \u001b[32m0.9697\u001b[0m        0.1217  0.0698\n",
      "     32        0.2729       \u001b[32m0.9711\u001b[0m        \u001b[35m0.1140\u001b[0m  0.0698\n",
      "     33        0.2712       0.9711        0.1142  0.1057\n",
      "     34        \u001b[36m0.2600\u001b[0m       \u001b[32m0.9737\u001b[0m        \u001b[35m0.1140\u001b[0m  0.0768\n",
      "     35        \u001b[36m0.2536\u001b[0m       0.9711        \u001b[35m0.1112\u001b[0m  0.0708\n",
      "     36        \u001b[36m0.2532\u001b[0m       0.9724        \u001b[35m0.1108\u001b[0m  0.0728\n",
      "     37        0.2562       0.9684        \u001b[35m0.1091\u001b[0m  0.0818\n",
      "     38        \u001b[36m0.2502\u001b[0m       0.9697        0.1097  0.0698\n",
      "     39        \u001b[36m0.2501\u001b[0m       0.9711        \u001b[35m0.1080\u001b[0m  0.0768\n",
      "     40        0.2555       0.9737        \u001b[35m0.1040\u001b[0m  0.0848\n",
      "     41        \u001b[36m0.2419\u001b[0m       0.9737        0.1070  0.0728\n",
      "     42        0.2453       0.9697        \u001b[35m0.1006\u001b[0m  0.0738\n",
      "     43        \u001b[36m0.2395\u001b[0m       0.9737        0.1039  0.0878\n",
      "     44        0.2407       0.9724        \u001b[35m0.0986\u001b[0m  0.1028\n",
      "     45        0.2421       0.9724        0.1063  0.0668\n",
      "     46        0.2429       0.9724        \u001b[35m0.0962\u001b[0m  0.1037\n",
      "     47        \u001b[36m0.2220\u001b[0m       0.9737        0.1049  0.0758\n",
      "     48        0.2440       0.9724        0.0995  0.0888\n",
      "     49        0.2234       \u001b[32m0.9750\u001b[0m        0.0965  0.1017\n",
      "     50        0.2301       0.9750        0.0971  0.0808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=1, shuffle=True),\n",
       "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=CarClassificationNN(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (hidden): Linear(in_features=21, out_features=21, bias=True)\n",
       "    (output): Linear(in_features=21, out_features=4, bias=True)\n",
       "  ),\n",
       "),\n",
       "             param_grid={'lr': [0.1, 0.01, 0.001],\n",
       "                         'module__dropout': [0.5, 0.8],\n",
       "                         'module__hidden_dim': [11, 21, 42],\n",
       "                         'optimizer': [<class 'torch.optim.adam.Adam'>,\n",
       "                                       <class 'torch.optim.sgd.SGD'>]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'lr': [0.1, 0.01, 0.001],\n",
    "    'module__hidden_dim':[11,21,42],\n",
    "    'module__dropout':[0.5,0.8],\n",
    "    'optimizer':[torch.optim.Adam, torch.optim.SGD],    \n",
    "}\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "gs = GridSearchCV(net, params, refit=True, cv=kfold, scoring='accuracy', verbose=2)\n",
    "gs.fit(X_train_torch, y_train_torch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training vs Validation Loss Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to grid search, I choose best estimator combination based on best parameters which are detected automatically by grid search. This is training vs validation loss curves with given epoch loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c9d172f850>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6bklEQVR4nO3dd3xVVdb4/89KDzUhJKF3iAIJLVSlCVIsYIEBxu44inV4rON8x9HR8ec4OKOOdaw4jsrjAzZQREQRFRwp0nsnUhJCgAAhdf3+2DcQQxKSkHtvkrver9d5nXNPXSfoXXfvfc7eoqoYY4wJXEH+DsAYY4x/WSIwxpgAZ4nAGGMCnCUCY4wJcJYIjDEmwFkiMMaYAGeJwFR7IjJHRK6r6n2NMY7YewTGG0TkaJGPdYBsIN/z+RZVfcf3UVWeiAwB/qOqLfxwbQHuBG4G2gIZwGLgUVVd7et4TO0T4u8ATO2kqvUKl0VkB3CTqn5ZfD8RCVHVPF/GVgM9C1wM/Bb4HggGLvesq1AisL+3KYlVDRmfEpEhIpIiIg+IyD7gTRGJFpHZIpImIhme5RZFjlkgIjd5lq8Xke9E5CnPvttFZHQl920rIgtFJFNEvhSRF0TkP5W4p3M91z0kImtFZEyRbReJyDrPNX4WkXs96xt77vOQiBwUkW9F5LT/H0WkI3A7MElVv1LVbFU9rqrvqOpfi99z0fsu8llF5HYR2QxsFpGXReSpYtf5WETu9iw3E5GZnn+P7SJyV5H9+ojIUhE5IiL7ReQfFf17merHEoHxhyZAI6A1rrojCHjT87kVkAU8X8bxfYGNQGPgb8DrnuqTiu77LvAjEAM8AlxT0RsRkVBgFvAFEIerwnlHRBI8u7yOqwqrD3QFvvKsvwdIAWKBeOAPQEn1tMOAFFX9saKxFXMZ7m/RGXffEwr/DiISDYwApnuS0SxgJdDcc/0pIjLSc55ngWdVtQHQHnj/LOMy1YAlAuMPBcDDnl+3WaqarqozPb90M4HHgcFlHL9TVV9V1XzgLaAp7su03PuKSCugN/AnVc1R1e+ATypxL/2AesBfPef5CpgNTPJszwU6i0gDVc1Q1eVF1jcFWqtqrqp+qyU32MUAeysRV3FPqOpBVc0CvsUlnYGebeOAxaq6B/c3iVXVRz33sw14FZhYJO4OItJYVY+q6g9VEJvxM0sExh/SVPVE4QcRqSMi/xKRnSJyBFgIRIlIcCnH7ytcUNXjnsV6Fdy3GXCwyDqA3RW8Dzzn2a2qBUXW7cT9mga4ErgI2Cki34hIf8/6qcAW4AsR2SYivy/l/Om4hHG2Tt6bJ+FM51Sy+jVQ2HjfGmjmqbI6JCKHcKWVwkT7G6ATsEFElojIJVUQm/EzSwTGH4r/8r0HSAD6eqocBnnWl1bdUxX2Ao1EpE6RdS0rcZ49QMti9futgJ8BVHWJqo7FVRt9hKcqRVUzVfUeVW0HXArcLSLDSjj/fKCFiCSXEcMx3JNZhZqUsE/xv/l7wDgRaY2rMprpWb8b2K6qUUWm+qp6kSfuzao6yXM/TwIzRKRuGbGZGsASgakO6uPaBQ6JSCPgYW9fUFV3AkuBR0QkzPNL/dIzHSciEUUnXBvDMeB+EQn1PGZ6Ka6+PUxErhKRhqqaCxzB8witiFwiIh089fSF6/OLX09VNwMvAu95GtrDPNeeWKQUsQK4wlOy6oD71X6m+/8JSANeA+aq6iHPph+BI+Ia8yNFJFhEuopIb0/cV4tIrKcEVHjMaXGbmsUSgakOngEigQPAD8DnPrruVUB/XPXLX4D/xb3vUJrmuIRVdGoJjAFG4+J/EbhWVTd4jrkG2OGp8poMXO1Z3xH4EjiKeyfgRVVdUMp178I1nr+A+/Ldint8dJZn+9NADrAf1w5S3nc03gOG4xqPAfC0pVwKdAe2e+7pNaChZ5dRwFpx74k8C0wsWs1naiZ7ocwYDxH5X2CDqnq9RGJMdWIlAhOwRKS3iLQXkSARGQWMxdXjGxNQ7M1iE8iaAB/gHtFMAW711J0bE1C8VjUkIm8AlwCpqtq1lH2G4OqHQ4EDqlrWs+PGGGO8wJuJYBCuIezfJSUCEYkCFgGjVHWXiMSpaqpXgjHGGFMqr1UNqepCEWlTxi6/Bj5Q1V2e/cuVBBo3bqxt2pR1WmOMMcUtW7bsgKrGlrTNn20EnYBQEVmAe478WVX9d0k7isjNuD5paNWqFUuXLvVZkMYYUxuIyM7StvnzqaEQoBeuK92RwEMi0qmkHVX1FVVNVtXk2NgSE5oxxphK8meJIAXXQHwMOCYiC4FuwCY/xmSMMQHHnyWCj4GBIhLi6e+lL7Dej/EYY0xA8lqJQETeA4YAjUUkBdd/TCiAqr6squtF5HNgFa5b4tdUdY234jHGVD+5ubmkpKRw4oT1UlFVIiIiaNGiBaGhoeU+xptPDU0qxz5Tcd3xGmMCUEpKCvXr16dNmzaUPraQKS9VJT09nZSUFNq2bVvu46yLCWOM35w4cYKYmBhLAlVERIiJialwCcsSgTHGrywJVK3K/D0DJhGs3r+aB+Y9wJHsI/4OxRhjqpWASQQ7Du3gb4v+xtrUtf4OxRhTTaSnp9O9e3e6d+9OkyZNaN68+cnPOTk5ZR67dOlS7rrrLh9F6l0B0/toYnwiAKtTV9O/Zf8z7G2MCQQxMTGsWLECgEceeYR69epx7733ntyel5dHSEjJX5PJyckkJ5c1gmjNETAlgtYNW1MvrB6r96/2dyjGmGrs+uuv5+6772bo0KE88MAD/PjjjwwYMIAePXowYMAANm7cCMCCBQu45JJLAJdEbrzxRoYMGUK7du345z//6c9bqLCAKRGICF3jurI61RKBMdXRlM+nsGLfiio9Z/cm3Xlm1DMVPm7Tpk18+eWXBAcHc+TIERYuXEhISAhffvklf/jDH5g5c+Zpx2zYsIGvv/6azMxMEhISuPXWWyv0LL8/BUwiAEiMS2Tm+pmoqj2pYIwp1fjx4wkODgbg8OHDXHfddWzevBkRITc3t8RjLr74YsLDwwkPDycuLo79+/fTokULX4ZdaQGXCF5d/ir7ju6jaf2m/g7HGFNEZX65e0vdunVPLj/00EMMHTqUDz/8kB07djBkyJASjwkPDz+5HBwcTF5enrfDrDIB00YAv2wwNsaY8jh8+DDNmzcHYNq0af4NxksCKxHEeRKBNRgbY8rp/vvv58EHH+S8884jPz/f3+F4hdeGqvSW5ORkPZuBaZr9vRkj2o9g2mXTqi4oY0ylrF+/nnPPPdffYdQ6Jf1dRWSZqpb4vGtAlQgAe3LIGGOKCbhEkBiXyLq0deQX1M4injHGVFTgJYL4RE7knWBrxlZ/h2KMMdVC4CUCazA2xphfCLhE0Dm2M4JYO4ExxngEXCKIDI2kQ6MOlgiMMcbDa4lARN4QkVQRKXMcYhHpLSL5IjLOW7EUlxifaFVDxhiGDBnC3Llzf7HumWee4bbbbit1/8LH1y+66CIOHTp02j6PPPIITz31VJnX/eijj1i3bt3Jz3/605/48ssvKxh91fFmiWAaMKqsHUQkGHgSmFvWflUtMS6RLQe3cDz3uC8va4ypZiZNmsT06dN/sW769OlMmnTGIdf57LPPiIqKqtR1iyeCRx99lOHDh1fqXFXBa4lAVRcCB8+w253ATCDVW3GUJDEuEUVZn7bel5c1xlQz48aNY/bs2WRnZwOwY8cO9uzZw7vvvktycjJdunTh4YcfLvHYNm3acODAAQAef/xxEhISGD58+MluqgFeffVVevfuTbdu3bjyyis5fvw4ixYt4pNPPuG+++6je/fubN26leuvv54ZM2YAMH/+fHr06EFiYiI33njjydjatGnDww8/TM+ePUlMTGTDhg1V9nfwW6dzItIcuBy4AOh9hn1vBm4GaNWq1Vlfu2ifQ72a9Trr8xljqsCUKeAZJKbKdO8OzzxT6uaYmBj69OnD559/ztixY5k+fToTJkzgwQcfpFGjRuTn5zNs2DBWrVpFUlJSiedYtmwZ06dP56effiIvL4+ePXvSq5f7Xrniiiv47W9/C8Af//hHXn/9de68807GjBnDJZdcwrhxv6wRP3HiBNdffz3z58+nU6dOXHvttbz00ktMmTIFgMaNG7N8+XJefPFFnnrqKV577bWz/hOBfxuLnwEeUNUzvtmlqq+oarKqJsfGxp71hdtHtyciJMLaCYwxv6geKqwWev/99+nZsyc9evRg7dq1v6jGKe7bb7/l8ssvp06dOjRo0IAxY8ac3LZmzRoGDhxIYmIi77zzDmvXlj1U7saNG2nbti2dOnUC4LrrrmPhwoUnt19xxRUA9OrVix07dlT2lk/jz26ok4HpnnEBGgMXiUieqn7k7QsHBwXTObazPTlkTHVSxi93b7rsssu4++67Wb58OVlZWURHR/PUU0+xZMkSoqOjuf766zlx4kSZ5yhtfJPrr7+ejz76iG7dujFt2jQWLFhQ5nnO1PdbYVfXVd3Ntd9KBKraVlXbqGobYAZwmy+SQKHEuERLBMYY6tWrx5AhQ7jxxhuZNGkSR44coW7dujRs2JD9+/czZ86cMo8fNGgQH374IVlZWWRmZjJr1qyT2zIzM2natCm5ubm88847J9fXr1+fzMzM0851zjnnsGPHDrZs2QLA22+/zeDBg6voTkvnzcdH3wMWAwkikiIivxGRySIy2VvXrIjEuET2Hd3HgeMH/B2KMcbPJk2axMqVK5k4cSLdunWjR48edOnShRtvvJHzzjuvzGN79uzJhAkT6N69O1deeSUDBw48ue2xxx6jb9++XHjhhZxzzjkn10+cOJGpU6fSo0cPtm491d1NREQEb775JuPHjycxMZGgoCAmT/b+V2bAdUNd6IutXzDyPyP5+rqvGdJmyNkHZoypMOuG2jusG+pysj6HjDHGCdhE0KReExpFNrJ2AmNMwAvYRCAi1mBsTDVQ06qnq7vK/D0DNhGAqx5ak7qGAi3wdyjGBKSIiAjS09MtGVQRVSU9PZ2IiIgKHefP9wj8LjE+kaM5R9l1eBdtotr4OxxjAk6LFi1ISUkhLS3N36HUGhEREbRo0aJCxwR2IijSYGyJwBjfCw0NpW3btv4OI+AFdNVQl7guANZOYIwJaAGdCBqEN6B1w9aWCIwxAS2gEwHYIDXGGGOJIC6RjekbycnP8XcoxhjjF5YI4hLJK8hj44GNZ97ZGGNqIUsEnkFqVu1f5edIjDHGPwI+ESTEJBAaFGoNxsaYgBXwiSA0OJTOsZ2tRGCMCVgBnwgAkuKTLBEYYwKWJQJcIvg582fSj6f7OxRjjPE5SwS4RAD2hrExJjBZIuBUIrDqIWNMILJEAMTXjSe2TqwlAmNMQPLm4PVviEiqiKwpZftVIrLKMy0SkW7eiuVMRMQajI0xAcubJYJpwKgytm8HBqtqEvAY8IoXYzmjpPgk1qSuIb8g359hGGOMz3ktEajqQuBgGdsXqWqG5+MPQMVGUqhiSfFJZOVlsTVjqz/DMMYYn6subQS/AeaUtlFEbhaRpSKy1FsjGVmDsTEmUPk9EYjIUFwieKC0fVT1FVVNVtXk2NhYr8TRObYzQRLEyn0rvXJ+Y4yprvw6VKWIJAGvAaNV1a9vc0WERJAQk8CqVCsRGGMCi99KBCLSCvgAuEZVN/nkorm5ZW62J4eMMYHIm4+PvgcsBhJEJEVEfiMik0VksmeXPwExwIsiskJElnorFgBmzoToaEhJKXWXpPgkdhzaweETh70aijHGVCdeqxpS1Uln2H4TcJO3rn+ajh3h2DGYNw9uuKHEXQobjNekruG8Vuf5LDRjjPEnvzcW+0xiIsTHw5dflrpLt3j3TptVDxljAkngJAIRGD7cJYKCghJ3adGgBVERUZYIjDEBJXASAbhEkJoKq0vuZfRkVxP25JAxJoAEViK48EI3nzev1F2S4pJYvX81BVpyqcEYY2qbwEoEzZvDueeW2U6QFJ9EZk4mOw/t9GFgxhjjP4GVCMCVChYuhBMnStxsXU0YYwJN4CWC4cMhKwsWLSpxc5e4LghiicAYEzACLxEMGQIhIaW2E9QLq0f7Ru2twdgYEzACLxHUrw/9+p2xncBKBMaYQBF4iQBcO8GyZZBecj93SXFJbE7fzPHc4z4OzBhjfC8wE8Hw4aAKX31V4uak+CQUZW3qWh8HZowxvheYiaBPH2jQoNR2gsInh1but7EJjDG1X2AmgpAQGDq01HaCttFtqRta19oJjDEBITATAbh2gu3bYevpYxQHSRCJ8YmWCIwxASFwE8Hw4W5eWvVQnHtySFV9GJQxxvhe4CaCTp2gZctSq4eS4pPIOJHBz5k/+zgwY4zxrcBNBCKueuirryA//7TN1tWEMSZQBG4iAJcIMjLcOwXFJMYnApYIjDG1nzfHLH5DRFJFZE0p20VE/ikiW0RklYj09FYspbrgAjcvoZ0gKiKKhJgE5m6d6+OgjDHGt7xZIpgGjCpj+2igo2e6GXjJi7GULC4OuncvtZ3gmqRrWLBjAdsytvk2LmOM8SGvJQJVXQgcLGOXscC/1fkBiBKRpt6Kp1QXXgjff+8Gti/m2m7XIghvrXjL52EZY4yv+LONoDmwu8jnFM+604jIzSKyVESWpqWlVW0UF14IublujIJiWjZsyYj2I5i2cpqNWGaMqbX8mQikhHUlPrSvqq+oarKqJsfGxlZtFOefD+HhpVYP3dD9BnYd3sVX20vul8gYY2o6fyaCFKBlkc8tgD0+jyIyEs47D+bPL3Hz2HPGEh0RzRs/veHjwIwxxjf8mQg+Aa71PD3UDzisqnv9EsmwYbByJaSmnrYpIiSCqxKv4oP1H5CRleGH4IwxxrvKnQhEpG5FTiwi7wGLgQQRSRGR34jIZBGZ7NnlM2AbsAV4FbitIuevUoXdTXz9dYmbb+hxA9n52UxfM92HQRljjG/ImfrSEZEBwGtAPVVtJSLdgFtU1S9f3MnJybp06dKqPWl+PsTEwPjx8Oqrp21WVXr8qwehwaEs+e2Sqr22Mcb4gIgsU9XkkraVp0TwNDASSAdQ1ZXAoKoLrxoIDnbdUpfSTiAi3ND9BpbuWcrq/at9HJwxxnhXuaqGVHV3sVWnd85T0w0f7rql3lbyy2NXJV1FaFAob65408eBGWOMd5UnEez2VA+piISJyL3Aei/H5XvDhrl5KY+RNq7TmLHnjOU/q/5DTn6ODwMzxhjvKk8imAzcjnvZKwXojj8bdr0lIQGaNy+1egjcOwVpx9P4dNOnPgzMGGO8qzyJIEFVr1LVeFWNU9WrgXO9HZjPibhSwfz5UFDyW8Qj2o+gWf1mVj1kjKlVypMInivnuppv+HBIT4dVJXc9HRIUwrVJ1/LZ5s/Ym+mfVx6MMaaqlZoIRKS/iNwDxIrI3UWmR4Bgn0XoS2doJwD3TkG+5vP2qrd9FJQxxnhXWSWCMKAeEALULzIdAcZ5PzQ/aNYMzj23zHaCTjGdOL/V+UxbMc3GMzbG1AohpW1Q1W+Ab0Rkmqru9GFM/jV8OLz+OmRnu87oSnBt0rXcPPtmlu9dTq9mvXwcoDHGVK3ytBEcF5GpIvKZiHxVOHk9Mn8ZNgyOH4cffih1l/FdxhMWHGbVQ8aYWqE8ieAdYAPQFvgzsAOovf0sDBkCQUFlVg9FRURxaadLeW/Ne+QV5PkuNmOM8YLyJIIYVX0dyFXVb1T1RqCfl+Pyn4YNoXfvMhuMwQ1jmXoslS+2fuGjwIwxxjvKkwhyPfO9InKxiPTAjR1Qew0fDj/+CEeOlLrL6I6jiYmMseohY0yNV55E8BcRaQjcA9yL64n0f7walb8NG+Z6JP3mm1J3CQsOY0KXCXy04SOOZJeeMIwxprorMxGISDDQUVUPq+oaVR2qqr1U9RMfxecf/fu7kcvOVD3U7RpO5J1g5rqZPgrMGGOqXpmJQFXzgTE+iqX6iIiAgQPLbDAG6Nu8Lx0adbDqIWNMjVaeqqFFIvK8iAwUkZ6Fk9cj87dhw2DtWthbelcSIsLViVezYMcCdh8u3lO3McbUDOVJBAOALsCjwN8901PeDKpaKBy+8quyX5m4OulqFOWd1e/4IChjjKl6Z0wEnnaB4tMFvgjOr7p3d8NXzplT5m7tG7VnQMsBvL3qbetywhhTI5V78PrKEJFRIrJRRLaIyO9L2N5QRGaJyEoRWSsiN3gzngoJCoKxY2HWLNfdRBmuSbqGdWnrWLFvhW9iM8aYKuS1ROB54ugFYDTQGZgkIp2L7XY7sE5VuwFDgL+LSJi3Yqqw8ePduwRflP3S2K+6/Mq6nDDG1Fhnenw0yDNMZWX0Abao6jZVzQGmA2OL7aNAfRERXE+nB4Hq02fDsGEQHQ3/939l7tYoshEXd7yYd1e/a11OGGNqnDM9PlqAaxyujOZA0UdpUjzrinoeN9rZHmA18DvPNX9BRG4WkaUisjQtLa2S4VRCaChcdhl8/PEZq4euTrqa/cf28+W2st89MMaY6qY8VUNfiMiVnl/tFVHS/sVbU0cCK4BmuLGQnxeRBqcdpPqKqiaranJsbGwFwzhLhdVD8+aVudvFHS8mOiLaqoeMMTVOeRLB3cD/ATkickREMkWkPH0qpAAti3xugfvlX9QNwAfqbAG2A+eU49y+M2wYREWdsXooPCScX3X5FR+u/5Cfj/zsm9iMMaYKlOfx0fqqGqSqoarawPP5tF/tJVgCdBSRtp4G4IlA8a4pdgHDAEQkHkgAtlXsFrwsLMw9PVSO6qH7BtxHgRZwzxf3+Cg4Y4w5e+V6akhExojIU57pkvIco6p5wB3AXGA98L6qrhWRySIy2bPbY8AAEVkNzAceUNUDFb8NLxs/Hg4fPmPfQ+0btef35/+e/137v8zfVnb3FMYYU13ImV6CEpG/Ar1xA9QATAKWqepp7wX4QnJysi5dutS3F83Jgbg413A8bVqZu2blZtH1pa6EBYexcvJKwoKrz9OwxpjAJSLLVDW5pG3lKRFcBFyoqm+o6hvAKM+6wFG0eignp8xdI0MjeW70c2w4sIF/LP6HjwI0xpjKK+8LZVFFlht6IY7qb/x4OHTojNVDABd1vIjLzrmMxxY+xq7Du7wfmzHGnIXyJIL/D/hJRKaJyFvAMs+6wHLhhdCgAcyYUa7dnxn5DKrKlM+neDcuY4w5S2d8sxgowI1R/IFn6q+q030QW/USHu6qhz76CHJzz7h766jWPDToIT7c8CFzNpfdcZ0xxvhTed4svkNV96rqJ6r6saru81Fs1c/48ZCRccYBawrdM+AeEmISuHPOnZzIO+Hl4IwxpnLKUzU0T0TuFZGWItKocPJ6ZNXRiBGueugML5cVCgsO44WLXmBrxlae/O5JLwdnjDGVU55EcCOul9CFuPaBZYCPn9+sJsLDYcyYclcPAQxrN4wJXSbwxHdPsOXgFu/GZ4wxlVCeNoLfq2rbYlM7H8VX/YwfDwcPnnHksqL+MfIfhAWHceunt9rgNcaYaqc8bQS3+yiWmmHECKhfv9zVQwDN6jfjiWFP8OW2L21IS2NMtWNtBBUVEQFXXAHvvw+ZmeU+bHLyZPo278v/zP0f0o+nezFAY4ypGGsjqIzbbnNJ4N//LvchwUHBvHLpKxw6cYj75t3nxeCMMaZiytP7aPH2gcBuIwDo0wd694bnn4cK1PknxSdxT/97eHPFmyzYscB78RljTAWUmghE5P4iy+OLbQu8N4uLu/NO2LCh3O8UFPrT4D/RNqott8y+xd4tMMZUC2WVCCYWWX6w2LZRXoilZvnVryA2Fp57rkKH1Qmtw8uXvMym9E088e0TXgrOGGPKr6xEIKUsl/Q58ISHw803w6xZsGNHhQ4d0X4Ev078NU989wTr09Z7Jz5jjCmnshKBlrJc0ufANHkyBAXBiy9W+NCnRz5NvbB63DL7Fgq0wAvBGWNM+ZSVCLoVjlEMJHmWCz8n+ii+6q1FC7j8cnjtNTh+vEKHxtWN46kRT/Htrm/519J/eSlAY4w5s1ITgaoGFxmjOMSzXPg51JdBVmt33OE6onvvvQofekP3GxjRfgT3fHEP69LWeSE4Y4w5s/IOTFMpIjJKRDaKyBYRKXFoSxEZIiIrRGStiHzjzXi8YtAgSEx0jcYV7D5CRHjrsreoH16fiTMm2lNExhi/8FoiEJFg4AVgNNAZmCQinYvtEwW8CIxR1S7A+OLnqfZEXKlg5Ur4/vsKH96kXhOmjZ3G6tTV3D/v/jMfYIwxVcybJYI+wBZV3aaqOcB0YGyxfX4NfKCquwBUNdWL8XjPVVdBVFSFHyUtNLrjaKb0ncJzPz7HrI2zqjY2Y4w5A28mgubA7iKfUzzriuoERIvIAhFZJiLXejEe76lbF37zG5g5E37+uVKn+Ovwv9K9SXdu+PgG9mTuqeIAjTGmdN5MBCW9a1C8Ej0E6AVcDIwEHhKRTqedSORmEVkqIkvT0tKqPtKqcNttUFAA/6rcE0DhIeFMv3I6WXlZXPvhtfZIqTHGZ7yZCFKAlkU+twCK/9RNAT5X1WOqegDXsV234idS1VdUNVlVk2NjY70W8Flp1w4uvtglgqysSp0ioXEC/xz1T+Zvn8/U76dWcYDGGFMybyaCJUBHEWkrImG4Lis+KbbPx8BAEQkRkTpAX6Dmvmp7772QmlrpUgHAjT1uZHzn8fzx6z/y488/VmFwxhhTMq8lAlXNA+4A5uK+3N9X1bUiMllEJnv2WQ98DqwCfgReU9U13orJ6wYPhgsugCeegGPHKnUKEeGVS1+hef3mjJ0+lm0Z26o4SGOM+SWpaUMnJicn69Kl1Xg4hO++g4ED4W9/g/sqP+7AurR1DHxzINER0Xx343c0qdekCoM0xgQaEVmmqsklbfPqC2UB6fzz3XCWTz5ZoRHMiusc25lPf/0pe4/uZdR/RnHoxKGqi9EYY4qwROANjz4K6elu4Jqz0K9FPz741QesS1vHmPfGkJVbuUZoY4wpiyUCb+jb1z1BNHUqHDlyVqca2WEkb1/+Nt/t+o4JMyaQV5BXRUEaY4xjicBb/vxn1xnds8+e9akmdJ3ACxe9wKxNs7jpk5vsHQNjTJWyROAtvXrB2LHw97/DoUNnfbpbe9/Ko0Me5a2Vb3H7p7dbB3XGmCpjicCb/vxnOHwY/vGPKjndHwf9kXv738vLy16m+8vd+Xbnt1VyXmNMYLNE4E3dusG4cfDMM67x+CyJCFNHTGXu1XPJzs9m0LRB3PbpbRzJPrt2CGNMYLNE4G0PPwxHj7oqoioyov0I1ty6hrv73c2/lv2Lzi905pONxV/aNsaY8rFE4G1du8KECfDPf7ruJ6pI3bC6/H3k31n8m8U0imzE2OljmThjor1vYIypMEsEvvDnP0N2Njz4YJWfuk/zPiy7eRl/GfoXZq6fSa9XevHT3p+q/DrGmNrLEoEvdOoE//M/8MYb8MMPVX760OBQ/t+g/8fC6xeSk59D/9f78/ry16lp3YcYY/zDEoGvPPQQNGsGt98O+fleuUT/lv1ZfvNyBrUexE2zbuLGT27keO5xr1zLGFN7WCLwlfr1XYPx8uXw6qteu0xs3VjmXDWHhwc/zFsr3qL/6/3ZnL7Za9czxtR8lgh8acIE11X1H/4ABw547TLBQcE8MuQRPrvqM1KOpNDrlV7MXDfTa9czxtRslgh8ScR1RHfkiEsGXjaqwyh+uuUnOsd2Ztz/jWPK51PIyc/x+nWNMTWLJQJf69oV7roLXnsNlizx+uVaNWzFwhsWMqXvFJ7977MMenMQuw7v8vp1jTE1hyUCf3jkEYiPdw3HBd7vQC4sOIynRz3NjPEzWH9gPT3+1YNPN33q9esaY2oGSwT+0KCB66J6yRJ4/XWfXfbKzley7OZltGrYikveu4Q/zP+DVRUZY2yoSr9RdQ3H69bBpk3QqJHPLp2Vm8WUz6fwyvJXqBdWjwvaXsDI9iMZ2X4k7Ru191kcxhjf8dtQlSIySkQ2isgWEfl9Gfv1FpF8ERnnzXiqlcKG40OH4NZbXWLwkcjQSP516b/44uovuDrxalbtX8Xtn91Oh+c60PG5jtzx2R18uulTGxHNmADhtRKBiAQDm4ALgRRgCTBJVdeVsN884ATwhqrOKOu8taZEUOivf3VdT7z0Ekye7JcQVJXNBzczd8tc5m6dy9c7vuZ47nHqhNbhwnYXMiZhDBd3vJj4evF+ic8Yc/bKKhF4MxH0Bx5R1ZGezw8CqOoTxfabAuQCvYHZAZcICgrcsJZffw2LF0OPHv6OiOy8bBbsWMAnGz9h1qZZ7D6yG0Ho07wPozuMpm+LvvRu1puYOjH+DtUYU07+SgTjgFGqepPn8zVAX1W9o8g+zYF3gQuA1yklEYjIzcDNAK1ateq1c+dOr8TsN2lpLgFERsKyZa4xuZpQVVbuX8msjbP4ZNMnLNuzDMX9N9Muuh19mvehd7PeDGo9iORmJf43ZoypBspKBCHevG4J64pnnWeAB1Q1X6Sk3T0Hqb4CvAKuRFBVAVYbsbEwfToMGQK//a1bLuPv4UsiQvcm3enepDsPDX6II9lHWLZnGT/+/CNL9ixh0e5FTF8zHYD7BtzHE8OeIDgo2M9RG2MqwpuJIAVoWeRzC2BPsX2SgemeJNAYuEhE8lT1Iy/GVT2dfz48/jj8/vcuIdx6q78jKlGD8AYMbTuUoW2Hnly3/+h+Hlv4GFMXTWVN6hreu/I9GkY09GOUxpiK8OZTQ0uAjiLSVkTCgInAL4bRUtW2qtpGVdsAM4DbAjIJFLrvPhg9GqZMgZ9qzpgC8fXief6i53n54peZt20e/V7vZx3dGVODeC0RqGoecAcwF1gPvK+qa0Vksoj45/GY6i4oCP79b4iLg/HjXZ9ENcgtybfw5TVfknYsjT6v9WHe1nn+DskYUw72Qll19P337mWzYcPgww+hTh1/R1Qh2zO2M3b6WNalreOpEU8xsetE6oXVo25oXcpqCzLGeI9fnhryloBIBABvvgk33QT9+8Ps2RAV5e+IKiQzO5NrPryGjzd+fHKdINQNq0v9sPrUC6tHj6Y9uKTjJYzuOJrGdRr7MVpjaj9LBDXVjBnw619D584wd67rqK4GKdACZm2cxZ7MPRzNOUpmTqabZ2dyKPsQ3+78lv3H9hMkQfRr0Y9LO13KJZ0uoUtsFys5GFPFLBHUZF98AZdf7oa5nDcP2rTxd0RVpkALWL53ObM3zWb2ptks27sMgPph9WlWv9lpU/cm3RnSZoh/gzamhrJEUNMtXgwXXQR167rE0LmzvyPyij2Ze/hs82esSV3Dnsw9v5iy87MBuKXXLTw98mkiQyP9HK0xNYslgtpg9WoYMQJyc2HOHOjd298R+YyqknEig799/zee/P5JusV34/3x79MpplOVXmf34d3kaz5totpU6XmNqQ781vuoqUKJifDdd677icGD4d13/R2Rz4gIjSIb8dfhf+XTX396chzm91a/d9q+qsqKfSu4f979dH2xK+PeH8fbK9/mYNbBEs+dmZ3Jmz+9ydC3htLqmVa0e7YdE2ZMYPX+1d6+LWOqDSsR1DT798OvfgULF8LvfucGuAkN9XdUPrX78G4mzpzIot2LTlYV7T26l/dWv8c7q99h/YH1hASFMLj1YNYfWM+ezD0ESzADWw9kTKcxXJpwKdsztvPWyrf4YP0HZOVl0bFRR67tdi3Hc4/z/I/Pk5mTyRXnXsFDgx6ie5Pu/r5lY86aVQ3VNrm5cP/98MwzMHAgvP8+NGni76h8Kjc/l4e+fognv3+SxnUac+D4AQAGthrIVYlXMa7zOGLqxFCgBSzbs4yPN37Mxxs/Zk3qmpPniIqIYkKXCVzX7Tr6teh38kmlg1kHefaHZ3n2v89yOPswYxLGcHvv22kQ3gBBEJGT84iQCM5tfK71r2SqPUsEtdW777p3DaKj3aOm/fv7OyKf+2zzZ7y45EUGthrIxK4TaR3Vusz9tx7cypwtc4ivG8+lCZcSERJR6r6HThziuf8+x9M/PE3GiYxS94uOiGZE+xGM7jCaUR1GVWrchuy8bI7nHic6MrrCxxpTHpYIarNVq9zjpbt3uxLCrbdWm55La4sj2Uf4IeUH8gvyURRVPTk/nH2Y+dvn8/mWz9l3dB8APZv2ZHSH0Vx2zmX0atqrzHciUo+l8tKSl3hhyQukHU/j3MbnMrj1YAa1HsTgNoNpVr+Zr27T1HKWCGq7jAy46ir3NNH558MLL0BSkr+jCigFWsDKfSuZs2UOc7bMYfHuxeRrPq0btmZc53GM6zyOPs37ECTu+Yy1qWt5+oen+c+q/5Cdn80lnS6hX/N+fL/7e77b9R2ZOZkAtI9uT78W/YirG0d0RDSNIhsRHRlNdEQ0MXViSIhJKFdPr6rK/mP7yczOpE5oHSJDI6kTWofw4HB7eS9AWCIIBAUFrluKBx5w4yDfcQf8+c/Q0LqD9oeDWQf5ZOMnzFg3gy+2fkFuQS4tGrTg8nMuZ1P6JuZunUtkSCTXdbuOKf2mkNA44eSxeQV5rNy3km92fsPCnQtZvnc5B7MOciz3WInXatmgJUnxSSTGJZIYn0iX2C4czDrI2rS1rE1dy9q0taxJXVNi9ZYgRIZGEl83noGtBzKk9RAGtxlM26i2liBqGUsEgeTgQfjjH+Hll10vplOnwtVXW3WRHx06cYjZm2YzY90MPt/yOdGR0dzR+w5uSb6lQn0s5eTncOjEITKyMsg4kUHqsVTWpa1jdepqVu9fzfoD68kryPvFMVERUXSJ7eKmuC40imxEVm4Wx3OPk5Xn5sdzj7P90HYW7lx4stG9ZYOWDG4zmIGtBnJO43Po2KgjTeo1seRQg1kiCETLlsHtt8N//+uqi+6+272dHB7u78gC2om8E4QEhRASVPVjQuXk57DxwEbWpa2jUWQjusR1oWm9puX+8i7QAtanrWfBjgV8s/Mbvtn5DanHUk9urxtalw6NOtChUQfaRbejTmgdgiWYIAn6xXQs99jJZJVxIoODWQfJyMogPCScdtHtaBfVzs09U9P6TU9WmYlnYEMRITc/l5QjKew6vIudh3eenO/N3Eu3+G5cmnAp57c63yt/y9rIEkGgKqwueugh2LsXGjWCCRPg2muhb18rJZgyqSo7Du1g88HNbDm4hc3pm08ub8vYRm5BbqnHNghvQHRE9Mn2jOjIaE7knWB7xna2ZWw72WVIRQRLMC0atCC2biyr9q8iJz+H6IhoRncczaWdLmVUh1FERUSRk59D+vF00rPSOXD8AOnH0xER2ka1pV10uyofPU9Vydd8giW43Ek3vyCf9Kx04urGVWksZbFEEOjy8uDLL92gNx99BFlZ0LEjXHONe/y0aVN/R2hqIFWlQAvI13wKtMAtF+QTGRpZ5q/0Ai1gb+ZetmVsY1vGNvYf23/yfADqGdo8SIJoXr85raNa07pha5rWb3ryvJnZmczbNo9Zm2Yxe9NsDhw/QEhQCHVC63Aku+wBnaIjomkX3Y620W1pWq8pufm5ZOdnuynv1PxE3okSp9yCXPIK8sjNd/N8zQfg3Mbncu+Ae7kq8SrCQ0oueecV5DF9zXQe//ZxNhzYwLC2w7hvwH2MaD/C69VulgjMKUeOwMyZ8Pbb8PXXEBHhHjl94IEa1821MeB+Xf/35//y6aZPOZZ7jMZ1GhMTGUPjOo3dcp0Y8gry2J6xne2HtrtSyaFtbM/Yzr6j+wgLDiM8JJyIkAjCg8MJDwknPNh9Lj6FB4cTFhx2snovNDj0ZHL6aMNHrNy/kmb1mzGl7xRuSb6FBuENAFdt9/bKt3niuyfYmrGVxLhELu54Mf9e9W/2ZO4hMS6Rewfcy8SuEwkLDvvF/RU+8bXxwEbi68VzTuNzKvV3skRgSrZlCzz+uCsphIe7J43uuw9iY/0dmTE1jqryxdYv+Nuiv/HV9q9oEN6AW5NvpUWDFkxdNJVdh3fRq2kvHhr0EJcmXEqQBJGTn8O7q9/lqUVPsTZtLc3rN2dy8mQKtICN6RvZlL6JTembTpZy7u1/L1NHTK1UfH5LBCIyCngWCAZeU9W/Ftt+FfCA5+NR4FZVXVnWOS0ReMGmTfDYY+5N5chIuPNOV23UpIl7a9naEoypkKV7ljJ10VRmrJtBgRYwoOUAHhr0ECPbjyyxCkhVmbNlDlMXTWXBjgUAtGrYioSYBDrFdDo5T4pPomn9ylXl+iURiEgwsAm4EEgBlgCTVHVdkX0GAOtVNUNERgOPqGrfss5ricCLNmyARx+F6dOh8L+LsDD3GGqTJq7qqEsXuOUWaNfOv7EaUwNsy9jGwayDZ3zDvKg9mXuIioiiTmjVjlXur0TQH/fFPtLz+UEAVX2ilP2jgTWq2rys81oi8IFNm9zjp/v2ud5Oi87XrIH8fBgzxvV+OmSIlRiMqQHKSgTefAC3ObC7yOcUoKxf+78B5ngxHlNenTq5qSR79sBLL7kX1j7+2HVlcdddbmzlSBs1zJiayJsD05T0M7HE4oeIDMUlggdK2X6ziCwVkaVpaWlVGKKpsGbNXHvCrl3w+utu3U03uWqjvn1dn0cPP+yeSlq8GOzfy5hqz+9VQyKSBHwIjFbVTWc6r1UNVTOqsGCBGxNhyxY37drlXmYr1KEDDBsGF1wAQ4faU0nG+IG/2ghCcI3Fw4CfcY3Fv1bVtUX2aQV8BVyrqovKc15LBDVATg7s2OGSwvr18M03bjriedEnKcklhXPPdSWJolOdqm0gM8Y4/nx89CLgGdzjo2+o6uMiMhlAVV8WkdeAK4GdnkPySgu0kCWCGiovzzVAz58PX30F338PJ06cvl+9epCQ4EoOQ4e6Edjq1/d9vMbUMvZCmal+cnLck0ipqW5eOO3bBytWuPaFnBwIDoY+fVxS6NULgoJcdVTRKSwMunWDVq3sCSZjSuGvp4aMKV1YGLRs6aaSHD/uksFXX7npySfdY6tliYtzSaNvXzfv1cuN71w00RQmn9atYdQoaN++6u/NmBrGEoGpnurUcQ3Mw4a5z5mZrs0B3K/+otPx467a6ccfXbfbs2eXfe7QUJcgwHW+N3q0mwYPtkdgTUCyqiFT+xw+DEuWuCqmyMjTG6QbNHBJ5fPP3fCeX3/t2isiIlz7BJyqdipcDg52bRX167vjGzRwy40aQc+e0K+f646jNLm5Lp4ffnD7XXSRO9YYH7E2AmPKkpUFCxe6pLBt26mSBpxazsuDo0fdk09HjrgSypEjrjRSqHNnGDDATcnJsHu3axT//ntXWsnKOrVvcLArgVx2GYwd69o3CqlCSop74mrDBjfq3MCBboAhG1jIVJIlAmO85ehRV/pYtMhNixdDRpGxgYODoUcPOO88lyD693eDBH38sRsbYp2n662ePV1pZNMm9+V/rITxievUcY3mI0e6qWNHl6QKCtw1U1PdC3wHDpzqFyoqyhd/BVMDWCIwxlcKCtyX+dKl0KIF9O4NdeuWvv+mTS4pfPyxKwUkJLj3K84559S8bl1XfTV3rpsK20qaNXMllfT00hvSmzeHrl1dUuja1SWI4k9dFX4HFG13CQpy85AQVw0WFQUNG7p5RERV/sWMj1giMKY22bbNJYTvv3elhLg497Z2bKxbjolxfUKtWQNr17r5+vUlv7dRGeHhLjmEhroST3CwSxyF84gI1zZTp84v5yEhLnHl57t54TL8ct/CqW7dU/cUH+/mcXHuuuCq2jIyTk2HDrm4OnRwo+5V9aPEWVmwebNLrjEx5TtG1f04CA6u2lgqwRKBMYEuP98lkMJqq+JPXsHppYSCAvdlfeSI+5I9dMg1xBfOC7/ICwp+Oc/Odm0nWVm/nOflnUoeISGn5qqn75tdxpjGDRu6pFbWPnXquIRQODVs6EpO6emuzaVwOTvbldxat3btNIXz2FjYutUl0cKEumXLqdJTp06umq+wuq9zZ7d+82b46Sc3LV/u5ocPu+TRpo07f+HUsqV7YCA62k1RUV5NGJYIjDE1S36+a39JSzv10mHhPC3NlR4Kv0CLfpEeOnSqz6vNm9182zb3cmKdOu6XfKNGbh4T495nSUmBnTvdPC/vl3EEB7u2mK5d3ZSQ4LpPWbzYtQkdOOD2q1/fJcLCtp2wMEhMdO1DsbHuwYGdO09dp2hfXEU1aOCSFpwqNRWd7rnHdfpYCfZCmTGmZgkOdl+IDRu6X/QVMWLELz/n57vHd8/UtpGf7xryd+1yCaddO/fFX9pxqq7UsHixeyy48MGAnj1d+05YWMnH5ebCzz+7qWjVVuF0+PCp9pmiU3CwK314gZUIjDEmAJRVIvDmeATGGGNqAEsExhgT4CwRGGNMgLNEYIwxAc4SgTHGBDhLBMYYE+AsERhjTICzRGCMMQGuxr1QJiJpnBrsvqIaAweqMJyaJFDv3e47sNh9l661qsaWtKHGJYKzISJLS3uzrrYL1Hu3+w4sdt+VY1VDxhgT4CwRGGNMgAu0RPCKvwPwo0C9d7vvwGL3XQkB1UZgjDHmdIFWIjDGGFOMJQJjjAlwAZMIRGSUiGwUkS0i8nt/x+MtIvKGiKSKyJoi6xqJyDwR2eyZR/szRm8QkZYi8rWIrBeRtSLyO8/6Wn3vIhIhIj+KyErPff/Zs75W33chEQkWkZ9EZLbnc62/bxHZISKrRWSFiCz1rDur+w6IRCAiwcALwGigMzBJRDr7NyqvmQaMKrbu98B8Ve0IzPd8rm3ygHtU9VygH3C759+4tt97NnCBqnYDugOjRKQftf++C/0OWF/kc6Dc91BV7V7k3YGzuu+ASARAH2CLqm5T1RxgOjDWzzF5haouBA4WWz0WeMuz/BZwmS9j8gVV3auqyz3Lmbgvh+bU8ntX56jnY6hnUmr5fQOISAvgYuC1Iqtr/X2X4qzuO1ASQXNgd5HPKZ51gSJeVfeC+8IE4vwcj1eJSBugB/BfAuDePdUjK4BUYJ6qBsR9A88A9wMFRdYFwn0r8IWILBORmz3rzuq+Q6o4wOpKSlhnz83WQiJSD5gJTFHVIyIl/dPXLqqaD3QXkSjgQxHp6ueQvE5ELgFSVXWZiAzxczi+dp6q7hGROGCeiGw42xMGSokgBWhZ5HMLYI+fYvGH/SLSFMAzT/VzPF4hIqG4JPCOqn7gWR0Q9w6gqoeABbg2otp+3+cBY0RkB66q9wIR+Q+1/75R1T2eeSrwIa7q+6zuO1ASwRKgo4i0FZEwYCLwiZ9j8qVPgOs8y9cBH/sxFq8Q99P/dWC9qv6jyKZafe8iEuspCSAikcBwYAO1/L5V9UFVbaGqbXD/P3+lqldTy+9bROqKSP3CZWAEsIazvO+AebNYRC7C1SkGA2+o6uP+jcg7ROQ9YAiuW9r9wMPAR8D7QCtgFzBeVYs3KNdoInI+8C2wmlN1xn/AtRPU2nsXkSRc42Aw7ofd+6r6qIjEUIvvuyhP1dC9qnpJbb9vEWmHKwWAq9p/V1UfP9v7DphEYIwxpmSBUjVkjDGmFJYIjDEmwFkiMMaYAGeJwBhjApwlAmOMCXCWCIzxEJF8T4+OhVOVdVgmIm2K9ghrTHUSKF1MGFMeWara3d9BGONrViIw5gw8/b8/6en3/0cR6eBZ31pE5ovIKs+8lWd9vIh86BkjYKWIDPCcKlhEXvWMG/CF501gROQuEVnnOc90P92mCWCWCIw5JbJY1dCEItuOqGof4HncG+p4lv+tqknAO8A/Pev/CXzjGSOgJ7DWs74j8IKqdgEOAVd61v8e6OE5z2Tv3JoxpbM3i43xEJGjqlqvhPU7cIO/bPN0bLdPVWNE5ADQVFVzPev3qmpjEUkDWqhqdpFztMF1Ed3R8/kBIFRV/yIinwNHcV2BfFRkfAFjfMJKBMaUj5ayXNo+JckuspzPqTa6i3Ej6PUClomItd0Zn7JEYEz5TCgyX+xZXoTr+RLgKuA7z/J84FY4OWhMg9JOKiJBQEtV/Ro3yEoUcFqpxBhvsl8expwS6Rnpq9Dnqlr4CGm4iPwX9+NpkmfdXcAbInIfkAbc4Fn/O+AVEfkN7pf/rcDeUq4ZDPxHRBriBlB62jOugDE+Y20ExpyBp40gWVUP+DsWY7zBqoaMMSbAWYnAGGMCnJUIjDEmwFkiMMaYAGeJwBhjApwlAmOMCXCWCIwxJsD9//AdajuZC8WHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# get training and validation loss\n",
    "epochs = [i for i in range(len(gs.best_estimator_.history))]\n",
    "train_loss = gs.best_estimator_.history[:,'train_loss']\n",
    "valid_loss = gs.best_estimator_.history[:,'valid_loss']\n",
    "plt.plot(epochs,train_loss,'g-')\n",
    "plt.plot(epochs,valid_loss,'r-')\n",
    "plt.title('Training Loss Curves')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error rate')\n",
    "plt.legend(['Train','Validation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our model is good fit according to shape of the curve. It is discussed on the report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I have a look at the grid search results as a sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>param_module__dropout</th>\n",
       "      <th>param_module__hidden_dim</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.586750</td>\n",
       "      <td>0.980956</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.5, 'module__h...</td>\n",
       "      <td>0.936069</td>\n",
       "      <td>0.961326</td>\n",
       "      <td>0.872038</td>\n",
       "      <td>0.923144</td>\n",
       "      <td>0.037580</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.761943</td>\n",
       "      <td>0.121078</td>\n",
       "      <td>0.025930</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.5, 'module__h...</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.910813</td>\n",
       "      <td>0.915482</td>\n",
       "      <td>0.907371</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.951448</td>\n",
       "      <td>0.425166</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.5, 'module__h...</td>\n",
       "      <td>0.960537</td>\n",
       "      <td>0.939227</td>\n",
       "      <td>0.944708</td>\n",
       "      <td>0.948157</td>\n",
       "      <td>0.009035</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.763604</td>\n",
       "      <td>0.047998</td>\n",
       "      <td>0.020944</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.5, 'module__h...</td>\n",
       "      <td>0.902131</td>\n",
       "      <td>0.909234</td>\n",
       "      <td>0.906003</td>\n",
       "      <td>0.905790</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.738351</td>\n",
       "      <td>0.379095</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.5, 'module__h...</td>\n",
       "      <td>0.726125</td>\n",
       "      <td>0.854775</td>\n",
       "      <td>0.936809</td>\n",
       "      <td>0.839236</td>\n",
       "      <td>0.086710</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.857021</td>\n",
       "      <td>0.050107</td>\n",
       "      <td>0.028923</td>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.5, 'module__h...</td>\n",
       "      <td>0.907656</td>\n",
       "      <td>0.915549</td>\n",
       "      <td>0.913112</td>\n",
       "      <td>0.912106</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.340741</td>\n",
       "      <td>0.079417</td>\n",
       "      <td>0.028258</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.8, 'module__h...</td>\n",
       "      <td>0.722178</td>\n",
       "      <td>0.921863</td>\n",
       "      <td>0.710900</td>\n",
       "      <td>0.784981</td>\n",
       "      <td>0.096900</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.474538</td>\n",
       "      <td>0.044166</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.8, 'module__h...</td>\n",
       "      <td>0.880821</td>\n",
       "      <td>0.889503</td>\n",
       "      <td>0.884676</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.520594</td>\n",
       "      <td>0.323342</td>\n",
       "      <td>0.032912</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.8, 'module__h...</td>\n",
       "      <td>0.729282</td>\n",
       "      <td>0.930545</td>\n",
       "      <td>0.946288</td>\n",
       "      <td>0.868705</td>\n",
       "      <td>0.098796</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.542196</td>\n",
       "      <td>0.429490</td>\n",
       "      <td>0.025265</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.8, 'module__h...</td>\n",
       "      <td>0.887924</td>\n",
       "      <td>0.887135</td>\n",
       "      <td>0.894155</td>\n",
       "      <td>0.889738</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.549517</td>\n",
       "      <td>0.178781</td>\n",
       "      <td>0.019614</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.8, 'module__h...</td>\n",
       "      <td>0.951066</td>\n",
       "      <td>0.948698</td>\n",
       "      <td>0.961295</td>\n",
       "      <td>0.953686</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.145257</td>\n",
       "      <td>0.099315</td>\n",
       "      <td>0.025598</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.1, 'module__dropout': 0.8, 'module__h...</td>\n",
       "      <td>0.892660</td>\n",
       "      <td>0.898974</td>\n",
       "      <td>0.897314</td>\n",
       "      <td>0.896316</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.368327</td>\n",
       "      <td>0.089991</td>\n",
       "      <td>0.023937</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.5, 'module__...</td>\n",
       "      <td>0.969219</td>\n",
       "      <td>0.973954</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.971579</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.140604</td>\n",
       "      <td>0.100171</td>\n",
       "      <td>0.025942</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.5, 'module__...</td>\n",
       "      <td>0.708761</td>\n",
       "      <td>0.676401</td>\n",
       "      <td>0.739336</td>\n",
       "      <td>0.708166</td>\n",
       "      <td>0.025697</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.317796</td>\n",
       "      <td>0.079689</td>\n",
       "      <td>0.022606</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.5, 'module__...</td>\n",
       "      <td>0.970008</td>\n",
       "      <td>0.973954</td>\n",
       "      <td>0.969984</td>\n",
       "      <td>0.971315</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.970391</td>\n",
       "      <td>0.029691</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.5, 'module__...</td>\n",
       "      <td>0.737964</td>\n",
       "      <td>0.741910</td>\n",
       "      <td>0.757504</td>\n",
       "      <td>0.745793</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.325461</td>\n",
       "      <td>0.527274</td>\n",
       "      <td>0.023259</td>\n",
       "      <td>0.004895</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.5, 'module__...</td>\n",
       "      <td>0.951855</td>\n",
       "      <td>0.947908</td>\n",
       "      <td>0.936809</td>\n",
       "      <td>0.945524</td>\n",
       "      <td>0.006370</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.100710</td>\n",
       "      <td>0.144010</td>\n",
       "      <td>0.022950</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.5, 'module__...</td>\n",
       "      <td>0.771113</td>\n",
       "      <td>0.752960</td>\n",
       "      <td>0.807267</td>\n",
       "      <td>0.777113</td>\n",
       "      <td>0.022573</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.204122</td>\n",
       "      <td>0.025965</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.8, 'module__...</td>\n",
       "      <td>0.964483</td>\n",
       "      <td>0.968429</td>\n",
       "      <td>0.963665</td>\n",
       "      <td>0.965526</td>\n",
       "      <td>0.002080</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.970059</td>\n",
       "      <td>0.011545</td>\n",
       "      <td>0.023603</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.8, 'module__...</td>\n",
       "      <td>0.731650</td>\n",
       "      <td>0.709550</td>\n",
       "      <td>0.725908</td>\n",
       "      <td>0.722369</td>\n",
       "      <td>0.009363</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.347383</td>\n",
       "      <td>0.048206</td>\n",
       "      <td>0.020944</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.8, 'module__...</td>\n",
       "      <td>0.966062</td>\n",
       "      <td>0.972376</td>\n",
       "      <td>0.967615</td>\n",
       "      <td>0.968684</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.092730</td>\n",
       "      <td>0.153118</td>\n",
       "      <td>0.017620</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.8, 'module__...</td>\n",
       "      <td>0.738753</td>\n",
       "      <td>0.737964</td>\n",
       "      <td>0.725118</td>\n",
       "      <td>0.733945</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.855717</td>\n",
       "      <td>0.200748</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.8, 'module__...</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>0.947119</td>\n",
       "      <td>0.947867</td>\n",
       "      <td>0.948421</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.126640</td>\n",
       "      <td>0.081988</td>\n",
       "      <td>0.019947</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.01, 'module__dropout': 0.8, 'module__...</td>\n",
       "      <td>0.766377</td>\n",
       "      <td>0.756117</td>\n",
       "      <td>0.778041</td>\n",
       "      <td>0.766845</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.640933</td>\n",
       "      <td>0.280694</td>\n",
       "      <td>0.028590</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.5, 'module_...</td>\n",
       "      <td>0.861878</td>\n",
       "      <td>0.868982</td>\n",
       "      <td>0.873618</td>\n",
       "      <td>0.868159</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.956428</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.026262</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.5, 'module_...</td>\n",
       "      <td>0.292818</td>\n",
       "      <td>0.271507</td>\n",
       "      <td>0.340442</td>\n",
       "      <td>0.301589</td>\n",
       "      <td>0.028818</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.221388</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.027603</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.5, 'module_...</td>\n",
       "      <td>0.900552</td>\n",
       "      <td>0.910813</td>\n",
       "      <td>0.927330</td>\n",
       "      <td>0.912899</td>\n",
       "      <td>0.011031</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.087411</td>\n",
       "      <td>0.048054</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.5, 'module_...</td>\n",
       "      <td>0.288871</td>\n",
       "      <td>0.247830</td>\n",
       "      <td>0.283570</td>\n",
       "      <td>0.273424</td>\n",
       "      <td>0.018227</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.421519</td>\n",
       "      <td>0.045851</td>\n",
       "      <td>0.022273</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.5, 'module_...</td>\n",
       "      <td>0.913970</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>0.921011</td>\n",
       "      <td>0.917369</td>\n",
       "      <td>0.002880</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.268594</td>\n",
       "      <td>0.326548</td>\n",
       "      <td>0.027260</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.5, 'module_...</td>\n",
       "      <td>0.334649</td>\n",
       "      <td>0.474349</td>\n",
       "      <td>0.417062</td>\n",
       "      <td>0.408686</td>\n",
       "      <td>0.057339</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.132957</td>\n",
       "      <td>0.054659</td>\n",
       "      <td>0.021952</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.8, 'module_...</td>\n",
       "      <td>0.861878</td>\n",
       "      <td>0.884767</td>\n",
       "      <td>0.844392</td>\n",
       "      <td>0.863679</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.026883</td>\n",
       "      <td>0.087747</td>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.8, 'module_...</td>\n",
       "      <td>0.318863</td>\n",
       "      <td>0.231255</td>\n",
       "      <td>0.332543</td>\n",
       "      <td>0.294221</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.264938</td>\n",
       "      <td>0.051889</td>\n",
       "      <td>0.021609</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.8, 'module_...</td>\n",
       "      <td>0.887924</td>\n",
       "      <td>0.916338</td>\n",
       "      <td>0.913112</td>\n",
       "      <td>0.905791</td>\n",
       "      <td>0.012702</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.097385</td>\n",
       "      <td>0.128038</td>\n",
       "      <td>0.022275</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.8, 'module_...</td>\n",
       "      <td>0.337017</td>\n",
       "      <td>0.343331</td>\n",
       "      <td>0.368878</td>\n",
       "      <td>0.349742</td>\n",
       "      <td>0.013775</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.352702</td>\n",
       "      <td>0.059586</td>\n",
       "      <td>0.022939</td>\n",
       "      <td>0.002156</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.8, 'module_...</td>\n",
       "      <td>0.910813</td>\n",
       "      <td>0.913970</td>\n",
       "      <td>0.919431</td>\n",
       "      <td>0.914738</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.087744</td>\n",
       "      <td>0.072967</td>\n",
       "      <td>0.025266</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.8</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>{'lr': 0.001, 'module__dropout': 0.8, 'module_...</td>\n",
       "      <td>0.403315</td>\n",
       "      <td>0.333860</td>\n",
       "      <td>0.319905</td>\n",
       "      <td>0.352360</td>\n",
       "      <td>0.036478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_lr  \\\n",
       "0        2.586750      0.980956         0.020611        0.002050      0.1   \n",
       "1        3.761943      0.121078         0.025930        0.003551      0.1   \n",
       "2        1.951448      0.425166         0.022939        0.004534      0.1   \n",
       "3        3.763604      0.047998         0.020944        0.000814      0.1   \n",
       "4        1.738351      0.379095         0.026928        0.005086      0.1   \n",
       "5        3.857021      0.050107         0.028923        0.004953      0.1   \n",
       "6        2.340741      0.079417         0.028258        0.003290      0.1   \n",
       "7        3.474538      0.044166         0.024268        0.002488      0.1   \n",
       "8        2.520594      0.323342         0.032912        0.001628      0.1   \n",
       "9        3.542196      0.429490         0.025265        0.009851      0.1   \n",
       "10       1.549517      0.178781         0.019614        0.001695      0.1   \n",
       "11       3.145257      0.099315         0.025598        0.001880      0.1   \n",
       "12       3.368327      0.089991         0.023937        0.002443     0.01   \n",
       "13       3.140604      0.100171         0.025942        0.000829     0.01   \n",
       "14       3.317796      0.079689         0.022606        0.002049     0.01   \n",
       "15       2.970391      0.029691         0.022939        0.005086     0.01   \n",
       "16       2.325461      0.527274         0.023259        0.004895     0.01   \n",
       "17       3.100710      0.144010         0.022950        0.003735     0.01   \n",
       "18       3.204122      0.025965         0.023261        0.004183     0.01   \n",
       "19       2.970059      0.011545         0.023603        0.006632     0.01   \n",
       "20       3.347383      0.048206         0.020944        0.002443     0.01   \n",
       "21       3.092730      0.153118         0.017620        0.000940     0.01   \n",
       "22       1.855717      0.200748         0.020600        0.005900     0.01   \n",
       "23       3.126640      0.081988         0.019947        0.002155     0.01   \n",
       "24       3.640933      0.280694         0.028590        0.005235    0.001   \n",
       "25       2.956428      0.045611         0.026262        0.001880    0.001   \n",
       "26       3.221388      0.007464         0.027603        0.002052    0.001   \n",
       "27       3.087411      0.048054         0.018285        0.001243    0.001   \n",
       "28       3.421519      0.045851         0.022273        0.004702    0.001   \n",
       "29       3.268594      0.326548         0.027260        0.005421    0.001   \n",
       "30       3.132957      0.054659         0.021952        0.002941    0.001   \n",
       "31       3.026883      0.087747         0.022607        0.005236    0.001   \n",
       "32       3.264938      0.051889         0.021609        0.002860    0.001   \n",
       "33       3.097385      0.128038         0.022275        0.001244    0.001   \n",
       "34       3.352702      0.059586         0.022939        0.002156    0.001   \n",
       "35       3.087744      0.072967         0.025266        0.004772    0.001   \n",
       "\n",
       "   param_module__dropout param_module__hidden_dim  \\\n",
       "0                    0.5                       11   \n",
       "1                    0.5                       11   \n",
       "2                    0.5                       21   \n",
       "3                    0.5                       21   \n",
       "4                    0.5                       42   \n",
       "5                    0.5                       42   \n",
       "6                    0.8                       11   \n",
       "7                    0.8                       11   \n",
       "8                    0.8                       21   \n",
       "9                    0.8                       21   \n",
       "10                   0.8                       42   \n",
       "11                   0.8                       42   \n",
       "12                   0.5                       11   \n",
       "13                   0.5                       11   \n",
       "14                   0.5                       21   \n",
       "15                   0.5                       21   \n",
       "16                   0.5                       42   \n",
       "17                   0.5                       42   \n",
       "18                   0.8                       11   \n",
       "19                   0.8                       11   \n",
       "20                   0.8                       21   \n",
       "21                   0.8                       21   \n",
       "22                   0.8                       42   \n",
       "23                   0.8                       42   \n",
       "24                   0.5                       11   \n",
       "25                   0.5                       11   \n",
       "26                   0.5                       21   \n",
       "27                   0.5                       21   \n",
       "28                   0.5                       42   \n",
       "29                   0.5                       42   \n",
       "30                   0.8                       11   \n",
       "31                   0.8                       11   \n",
       "32                   0.8                       21   \n",
       "33                   0.8                       21   \n",
       "34                   0.8                       42   \n",
       "35                   0.8                       42   \n",
       "\n",
       "                    param_optimizer  \\\n",
       "0   <class 'torch.optim.adam.Adam'>   \n",
       "1     <class 'torch.optim.sgd.SGD'>   \n",
       "2   <class 'torch.optim.adam.Adam'>   \n",
       "3     <class 'torch.optim.sgd.SGD'>   \n",
       "4   <class 'torch.optim.adam.Adam'>   \n",
       "5     <class 'torch.optim.sgd.SGD'>   \n",
       "6   <class 'torch.optim.adam.Adam'>   \n",
       "7     <class 'torch.optim.sgd.SGD'>   \n",
       "8   <class 'torch.optim.adam.Adam'>   \n",
       "9     <class 'torch.optim.sgd.SGD'>   \n",
       "10  <class 'torch.optim.adam.Adam'>   \n",
       "11    <class 'torch.optim.sgd.SGD'>   \n",
       "12  <class 'torch.optim.adam.Adam'>   \n",
       "13    <class 'torch.optim.sgd.SGD'>   \n",
       "14  <class 'torch.optim.adam.Adam'>   \n",
       "15    <class 'torch.optim.sgd.SGD'>   \n",
       "16  <class 'torch.optim.adam.Adam'>   \n",
       "17    <class 'torch.optim.sgd.SGD'>   \n",
       "18  <class 'torch.optim.adam.Adam'>   \n",
       "19    <class 'torch.optim.sgd.SGD'>   \n",
       "20  <class 'torch.optim.adam.Adam'>   \n",
       "21    <class 'torch.optim.sgd.SGD'>   \n",
       "22  <class 'torch.optim.adam.Adam'>   \n",
       "23    <class 'torch.optim.sgd.SGD'>   \n",
       "24  <class 'torch.optim.adam.Adam'>   \n",
       "25    <class 'torch.optim.sgd.SGD'>   \n",
       "26  <class 'torch.optim.adam.Adam'>   \n",
       "27    <class 'torch.optim.sgd.SGD'>   \n",
       "28  <class 'torch.optim.adam.Adam'>   \n",
       "29    <class 'torch.optim.sgd.SGD'>   \n",
       "30  <class 'torch.optim.adam.Adam'>   \n",
       "31    <class 'torch.optim.sgd.SGD'>   \n",
       "32  <class 'torch.optim.adam.Adam'>   \n",
       "33    <class 'torch.optim.sgd.SGD'>   \n",
       "34  <class 'torch.optim.adam.Adam'>   \n",
       "35    <class 'torch.optim.sgd.SGD'>   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'lr': 0.1, 'module__dropout': 0.5, 'module__h...           0.936069   \n",
       "1   {'lr': 0.1, 'module__dropout': 0.5, 'module__h...           0.895817   \n",
       "2   {'lr': 0.1, 'module__dropout': 0.5, 'module__h...           0.960537   \n",
       "3   {'lr': 0.1, 'module__dropout': 0.5, 'module__h...           0.902131   \n",
       "4   {'lr': 0.1, 'module__dropout': 0.5, 'module__h...           0.726125   \n",
       "5   {'lr': 0.1, 'module__dropout': 0.5, 'module__h...           0.907656   \n",
       "6   {'lr': 0.1, 'module__dropout': 0.8, 'module__h...           0.722178   \n",
       "7   {'lr': 0.1, 'module__dropout': 0.8, 'module__h...           0.880821   \n",
       "8   {'lr': 0.1, 'module__dropout': 0.8, 'module__h...           0.729282   \n",
       "9   {'lr': 0.1, 'module__dropout': 0.8, 'module__h...           0.887924   \n",
       "10  {'lr': 0.1, 'module__dropout': 0.8, 'module__h...           0.951066   \n",
       "11  {'lr': 0.1, 'module__dropout': 0.8, 'module__h...           0.892660   \n",
       "12  {'lr': 0.01, 'module__dropout': 0.5, 'module__...           0.969219   \n",
       "13  {'lr': 0.01, 'module__dropout': 0.5, 'module__...           0.708761   \n",
       "14  {'lr': 0.01, 'module__dropout': 0.5, 'module__...           0.970008   \n",
       "15  {'lr': 0.01, 'module__dropout': 0.5, 'module__...           0.737964   \n",
       "16  {'lr': 0.01, 'module__dropout': 0.5, 'module__...           0.951855   \n",
       "17  {'lr': 0.01, 'module__dropout': 0.5, 'module__...           0.771113   \n",
       "18  {'lr': 0.01, 'module__dropout': 0.8, 'module__...           0.964483   \n",
       "19  {'lr': 0.01, 'module__dropout': 0.8, 'module__...           0.731650   \n",
       "20  {'lr': 0.01, 'module__dropout': 0.8, 'module__...           0.966062   \n",
       "21  {'lr': 0.01, 'module__dropout': 0.8, 'module__...           0.738753   \n",
       "22  {'lr': 0.01, 'module__dropout': 0.8, 'module__...           0.950276   \n",
       "23  {'lr': 0.01, 'module__dropout': 0.8, 'module__...           0.766377   \n",
       "24  {'lr': 0.001, 'module__dropout': 0.5, 'module_...           0.861878   \n",
       "25  {'lr': 0.001, 'module__dropout': 0.5, 'module_...           0.292818   \n",
       "26  {'lr': 0.001, 'module__dropout': 0.5, 'module_...           0.900552   \n",
       "27  {'lr': 0.001, 'module__dropout': 0.5, 'module_...           0.288871   \n",
       "28  {'lr': 0.001, 'module__dropout': 0.5, 'module_...           0.913970   \n",
       "29  {'lr': 0.001, 'module__dropout': 0.5, 'module_...           0.334649   \n",
       "30  {'lr': 0.001, 'module__dropout': 0.8, 'module_...           0.861878   \n",
       "31  {'lr': 0.001, 'module__dropout': 0.8, 'module_...           0.318863   \n",
       "32  {'lr': 0.001, 'module__dropout': 0.8, 'module_...           0.887924   \n",
       "33  {'lr': 0.001, 'module__dropout': 0.8, 'module_...           0.337017   \n",
       "34  {'lr': 0.001, 'module__dropout': 0.8, 'module_...           0.910813   \n",
       "35  {'lr': 0.001, 'module__dropout': 0.8, 'module_...           0.403315   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.961326           0.872038         0.923144        0.037580   \n",
       "1            0.910813           0.915482         0.907371        0.008389   \n",
       "2            0.939227           0.944708         0.948157        0.009035   \n",
       "3            0.909234           0.906003         0.905790        0.002904   \n",
       "4            0.854775           0.936809         0.839236        0.086710   \n",
       "5            0.915549           0.913112         0.912106        0.003300   \n",
       "6            0.921863           0.710900         0.784981        0.096900   \n",
       "7            0.889503           0.884676         0.885000        0.003552   \n",
       "8            0.930545           0.946288         0.868705        0.098796   \n",
       "9            0.887135           0.894155         0.889738        0.003140   \n",
       "10           0.948698           0.961295         0.953686        0.005467   \n",
       "11           0.898974           0.897314         0.896316        0.002673   \n",
       "12           0.973954           0.971564         0.971579        0.001933   \n",
       "13           0.676401           0.739336         0.708166        0.025697   \n",
       "14           0.973954           0.969984         0.971315        0.001866   \n",
       "15           0.741910           0.757504         0.745793        0.008436   \n",
       "16           0.947908           0.936809         0.945524        0.006370   \n",
       "17           0.752960           0.807267         0.777113        0.022573   \n",
       "18           0.968429           0.963665         0.965526        0.002080   \n",
       "19           0.709550           0.725908         0.722369        0.009363   \n",
       "20           0.972376           0.967615         0.968684        0.002686   \n",
       "21           0.737964           0.725118         0.733945        0.006250   \n",
       "22           0.947119           0.947867         0.948421        0.001347   \n",
       "23           0.756117           0.778041         0.766845        0.008957   \n",
       "24           0.868982           0.873618         0.868159        0.004828   \n",
       "25           0.271507           0.340442         0.301589        0.028818   \n",
       "26           0.910813           0.927330         0.912899        0.011031   \n",
       "27           0.247830           0.283570         0.273424        0.018227   \n",
       "28           0.917127           0.921011         0.917369        0.002880   \n",
       "29           0.474349           0.417062         0.408686        0.057339   \n",
       "30           0.884767           0.844392         0.863679        0.016532   \n",
       "31           0.231255           0.332543         0.294221        0.044872   \n",
       "32           0.916338           0.913112         0.905791        0.012702   \n",
       "33           0.343331           0.368878         0.349742        0.013775   \n",
       "34           0.913970           0.919431         0.914738        0.003560   \n",
       "35           0.333860           0.319905         0.352360        0.036478   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 9  \n",
       "1                14  \n",
       "2                 7  \n",
       "3                16  \n",
       "4                23  \n",
       "5                13  \n",
       "6                24  \n",
       "7                19  \n",
       "8                20  \n",
       "9                18  \n",
       "10                5  \n",
       "11               17  \n",
       "12                1  \n",
       "13               30  \n",
       "14                2  \n",
       "15               27  \n",
       "16                8  \n",
       "17               25  \n",
       "18                4  \n",
       "19               29  \n",
       "20                3  \n",
       "21               28  \n",
       "22                6  \n",
       "23               26  \n",
       "24               21  \n",
       "25               34  \n",
       "26               12  \n",
       "27               36  \n",
       "28               10  \n",
       "29               31  \n",
       "30               22  \n",
       "31               35  \n",
       "32               15  \n",
       "33               33  \n",
       "34               11  \n",
       "35               32  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearchMLP=pd.DataFrame(gs.cv_results_)\n",
    "gridsearchMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saved the grid search record as an Excel sheet for further reference for the report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearchMLP.to_csv(\"gridsearchMLP.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will find out at the best parameters to figure out and use them to remodelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.01,\n",
       " 'module__dropout': 0.5,\n",
       " 'module__hidden_dim': 11,\n",
       " 'optimizer': torch.optim.adam.Adam}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the best parameters as model parameters and form it, then cross validate it best scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8270\u001b[0m       \u001b[32m0.3470\u001b[0m        \u001b[35m1.3662\u001b[0m  0.0469\n",
      "      2        \u001b[36m1.2922\u001b[0m       \u001b[32m0.7418\u001b[0m        \u001b[35m1.1573\u001b[0m  0.0479\n",
      "      3        \u001b[36m1.1527\u001b[0m       \u001b[32m0.7911\u001b[0m        \u001b[35m0.9270\u001b[0m  0.0608\n",
      "      4        \u001b[36m0.9395\u001b[0m       \u001b[32m0.8141\u001b[0m        \u001b[35m0.7183\u001b[0m  0.0628\n",
      "      5        \u001b[36m0.7713\u001b[0m       \u001b[32m0.8816\u001b[0m        \u001b[35m0.5664\u001b[0m  0.0568\n",
      "      6        \u001b[36m0.6388\u001b[0m       \u001b[32m0.9046\u001b[0m        \u001b[35m0.4576\u001b[0m  0.0648\n",
      "      7        \u001b[36m0.5753\u001b[0m       0.9046        \u001b[35m0.3823\u001b[0m  0.0608\n",
      "      8        \u001b[36m0.4934\u001b[0m       \u001b[32m0.9062\u001b[0m        \u001b[35m0.3322\u001b[0m  0.0708\n",
      "      9        \u001b[36m0.4389\u001b[0m       \u001b[32m0.9095\u001b[0m        \u001b[35m0.2992\u001b[0m  0.0588\n",
      "     10        \u001b[36m0.4164\u001b[0m       \u001b[32m0.9145\u001b[0m        \u001b[35m0.2710\u001b[0m  0.0549\n",
      "     11        \u001b[36m0.3923\u001b[0m       \u001b[32m0.9161\u001b[0m        \u001b[35m0.2513\u001b[0m  0.0489\n",
      "     12        \u001b[36m0.3606\u001b[0m       \u001b[32m0.9211\u001b[0m        \u001b[35m0.2314\u001b[0m  0.0499\n",
      "     13        \u001b[36m0.3438\u001b[0m       0.9211        \u001b[35m0.2262\u001b[0m  0.0439\n",
      "     14        \u001b[36m0.3427\u001b[0m       \u001b[32m0.9276\u001b[0m        \u001b[35m0.2060\u001b[0m  0.0499\n",
      "     15        \u001b[36m0.3134\u001b[0m       0.9260        \u001b[35m0.2004\u001b[0m  0.0559\n",
      "     16        \u001b[36m0.2917\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m0.1837\u001b[0m  0.0499\n",
      "     17        0.2952       0.9359        \u001b[35m0.1819\u001b[0m  0.0588\n",
      "     18        \u001b[36m0.2755\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m0.1700\u001b[0m  0.0568\n",
      "     19        \u001b[36m0.2686\u001b[0m       0.9424        \u001b[35m0.1644\u001b[0m  0.0758\n",
      "     20        \u001b[36m0.2501\u001b[0m       \u001b[32m0.9490\u001b[0m        \u001b[35m0.1557\u001b[0m  0.0539\n",
      "     21        \u001b[36m0.2456\u001b[0m       0.9441        \u001b[35m0.1555\u001b[0m  0.0529\n",
      "     22        0.2582       \u001b[32m0.9523\u001b[0m        \u001b[35m0.1454\u001b[0m  0.0459\n",
      "     23        \u001b[36m0.2391\u001b[0m       0.9490        0.1478  0.0608\n",
      "     24        \u001b[36m0.2268\u001b[0m       \u001b[32m0.9539\u001b[0m        \u001b[35m0.1367\u001b[0m  0.0449\n",
      "     25        \u001b[36m0.2180\u001b[0m       0.9539        0.1386  0.0638\n",
      "     26        0.2309       \u001b[32m0.9589\u001b[0m        \u001b[35m0.1298\u001b[0m  0.0648\n",
      "     27        \u001b[36m0.2114\u001b[0m       0.9539        0.1320  0.0559\n",
      "     28        0.2195       \u001b[32m0.9605\u001b[0m        \u001b[35m0.1223\u001b[0m  0.0598\n",
      "     29        \u001b[36m0.1938\u001b[0m       0.9605        \u001b[35m0.1193\u001b[0m  0.0608\n",
      "     30        \u001b[36m0.1877\u001b[0m       0.9605        0.1199  0.0618\n",
      "     31        0.1998       \u001b[32m0.9622\u001b[0m        \u001b[35m0.1132\u001b[0m  0.0748\n",
      "     32        \u001b[36m0.1859\u001b[0m       0.9622        0.1173  0.0608\n",
      "     33        0.1983       0.9622        \u001b[35m0.1088\u001b[0m  0.0479\n",
      "     34        0.1894       0.9622        0.1109  0.0568\n",
      "     35        \u001b[36m0.1849\u001b[0m       0.9605        \u001b[35m0.1076\u001b[0m  0.0539\n",
      "     36        0.1855       0.9622        \u001b[35m0.1069\u001b[0m  0.0628\n",
      "     37        \u001b[36m0.1748\u001b[0m       0.9622        \u001b[35m0.1066\u001b[0m  0.0549\n",
      "     38        0.1805       0.9622        \u001b[35m0.1032\u001b[0m  0.0449\n",
      "     39        \u001b[36m0.1716\u001b[0m       0.9622        \u001b[35m0.1030\u001b[0m  0.0499\n",
      "     40        0.1734       0.9605        0.1037  0.0578\n",
      "     41        \u001b[36m0.1635\u001b[0m       0.9622        \u001b[35m0.1013\u001b[0m  0.0439\n",
      "     42        0.1652       0.9605        \u001b[35m0.1002\u001b[0m  0.0439\n",
      "     43        0.1665       \u001b[32m0.9655\u001b[0m        \u001b[35m0.0989\u001b[0m  0.0459\n",
      "     44        \u001b[36m0.1628\u001b[0m       0.9622        \u001b[35m0.0940\u001b[0m  0.0549\n",
      "     45        0.1693       0.9638        \u001b[35m0.0925\u001b[0m  0.0708\n",
      "     46        \u001b[36m0.1605\u001b[0m       0.9622        0.0933  0.0578\n",
      "     47        \u001b[36m0.1597\u001b[0m       0.9655        0.0940  0.0668\n",
      "     48        \u001b[36m0.1592\u001b[0m       0.9638        \u001b[35m0.0914\u001b[0m  0.0638\n",
      "     49        0.1614       0.9622        \u001b[35m0.0901\u001b[0m  0.0588\n",
      "     50        \u001b[36m0.1512\u001b[0m       0.9655        0.0912  0.0678\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8173\u001b[0m       \u001b[32m0.3224\u001b[0m        \u001b[35m1.3765\u001b[0m  0.0578\n",
      "      2        \u001b[36m1.2885\u001b[0m       \u001b[32m0.7599\u001b[0m        \u001b[35m1.1550\u001b[0m  0.0808\n",
      "      3        \u001b[36m1.1485\u001b[0m       0.7582        \u001b[35m0.9330\u001b[0m  0.0648\n",
      "      4        \u001b[36m0.9473\u001b[0m       \u001b[32m0.7961\u001b[0m        \u001b[35m0.7318\u001b[0m  0.0608\n",
      "      5        \u001b[36m0.7820\u001b[0m       \u001b[32m0.8717\u001b[0m        \u001b[35m0.5791\u001b[0m  0.0509\n",
      "      6        \u001b[36m0.6467\u001b[0m       \u001b[32m0.8947\u001b[0m        \u001b[35m0.4660\u001b[0m  0.0688\n",
      "      7        \u001b[36m0.5562\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m0.3875\u001b[0m  0.0549\n",
      "      8        \u001b[36m0.5033\u001b[0m       \u001b[32m0.9079\u001b[0m        \u001b[35m0.3358\u001b[0m  0.0628\n",
      "      9        \u001b[36m0.4444\u001b[0m       0.9062        \u001b[35m0.3018\u001b[0m  0.0698\n",
      "     10        \u001b[36m0.4133\u001b[0m       \u001b[32m0.9194\u001b[0m        \u001b[35m0.2708\u001b[0m  0.0549\n",
      "     11        \u001b[36m0.3790\u001b[0m       0.9194        \u001b[35m0.2511\u001b[0m  0.0618\n",
      "     12        \u001b[36m0.3676\u001b[0m       \u001b[32m0.9342\u001b[0m        \u001b[35m0.2321\u001b[0m  0.0588\n",
      "     13        \u001b[36m0.3365\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m0.2168\u001b[0m  0.0539\n",
      "     14        \u001b[36m0.3157\u001b[0m       0.9441        \u001b[35m0.2046\u001b[0m  0.0598\n",
      "     15        \u001b[36m0.3141\u001b[0m       \u001b[32m0.9507\u001b[0m        \u001b[35m0.1927\u001b[0m  0.0618\n",
      "     16        \u001b[36m0.2967\u001b[0m       \u001b[32m0.9539\u001b[0m        \u001b[35m0.1856\u001b[0m  0.0509\n",
      "     17        \u001b[36m0.2915\u001b[0m       0.9523        \u001b[35m0.1744\u001b[0m  0.0519\n",
      "     18        \u001b[36m0.2824\u001b[0m       \u001b[32m0.9605\u001b[0m        \u001b[35m0.1674\u001b[0m  0.0678\n",
      "     19        \u001b[36m0.2689\u001b[0m       0.9589        \u001b[35m0.1602\u001b[0m  0.0718\n",
      "     20        \u001b[36m0.2494\u001b[0m       0.9556        \u001b[35m0.1564\u001b[0m  0.0748\n",
      "     21        0.2522       \u001b[32m0.9688\u001b[0m        \u001b[35m0.1463\u001b[0m  0.0539\n",
      "     22        \u001b[36m0.2368\u001b[0m       0.9572        \u001b[35m0.1453\u001b[0m  0.0608\n",
      "     23        0.2405       0.9638        \u001b[35m0.1385\u001b[0m  0.0598\n",
      "     24        \u001b[36m0.2130\u001b[0m       0.9589        0.1390  0.0598\n",
      "     25        0.2295       0.9688        \u001b[35m0.1308\u001b[0m  0.0598\n",
      "     26        0.2174       0.9638        \u001b[35m0.1304\u001b[0m  0.0638\n",
      "     27        0.2228       0.9655        \u001b[35m0.1201\u001b[0m  0.0648\n",
      "     28        \u001b[36m0.2014\u001b[0m       0.9671        0.1209  0.0459\n",
      "     29        0.2127       0.9688        \u001b[35m0.1147\u001b[0m  0.0608\n",
      "     30        0.2022       0.9688        0.1148  0.0748\n",
      "     31        \u001b[36m0.1928\u001b[0m       0.9671        \u001b[35m0.1134\u001b[0m  0.0519\n",
      "     32        \u001b[36m0.1766\u001b[0m       0.9655        0.1155  0.0539\n",
      "     33        0.2008       0.9671        \u001b[35m0.1078\u001b[0m  0.0628\n",
      "     34        0.1817       \u001b[32m0.9704\u001b[0m        \u001b[35m0.1052\u001b[0m  0.0509\n",
      "     35        0.1874       0.9671        \u001b[35m0.1030\u001b[0m  0.0698\n",
      "     36        \u001b[36m0.1570\u001b[0m       0.9688        0.1037  0.0529\n",
      "     37        0.1798       0.9688        \u001b[35m0.1003\u001b[0m  0.0469\n",
      "     38        0.1733       \u001b[32m0.9753\u001b[0m        \u001b[35m0.0975\u001b[0m  0.0638\n",
      "     39        0.1683       0.9737        0.0976  0.0519\n",
      "     40        0.1747       0.9737        \u001b[35m0.0955\u001b[0m  0.0658\n",
      "     41        0.1716       0.9720        \u001b[35m0.0953\u001b[0m  0.0628\n",
      "     42        0.1692       0.9753        \u001b[35m0.0932\u001b[0m  0.0469\n",
      "     43        0.1631       0.9753        0.0938  0.0628\n",
      "     44        0.1600       0.9737        \u001b[35m0.0900\u001b[0m  0.0748\n",
      "     45        \u001b[36m0.1490\u001b[0m       \u001b[32m0.9770\u001b[0m        \u001b[35m0.0896\u001b[0m  0.0439\n",
      "     46        0.1626       0.9753        \u001b[35m0.0869\u001b[0m  0.0489\n",
      "     47        0.1588       0.9737        0.0876  0.0688\n",
      "     48        0.1654       0.9720        \u001b[35m0.0846\u001b[0m  0.0778\n",
      "     49        \u001b[36m0.1482\u001b[0m       0.9753        \u001b[35m0.0840\u001b[0m  0.0549\n",
      "     50        0.1565       0.9770        \u001b[35m0.0828\u001b[0m  0.0678\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8170\u001b[0m       \u001b[32m0.2862\u001b[0m        \u001b[35m1.3732\u001b[0m  0.0618\n",
      "      2        \u001b[36m1.2745\u001b[0m       \u001b[32m0.7549\u001b[0m        \u001b[35m1.1165\u001b[0m  0.0559\n",
      "      3        \u001b[36m1.1048\u001b[0m       0.7533        \u001b[35m0.8822\u001b[0m  0.0529\n",
      "      4        \u001b[36m0.8932\u001b[0m       \u001b[32m0.7993\u001b[0m        \u001b[35m0.6892\u001b[0m  0.0559\n",
      "      5        \u001b[36m0.7354\u001b[0m       \u001b[32m0.8849\u001b[0m        \u001b[35m0.5419\u001b[0m  0.0578\n",
      "      6        \u001b[36m0.6090\u001b[0m       \u001b[32m0.8898\u001b[0m        \u001b[35m0.4368\u001b[0m  0.0578\n",
      "      7        \u001b[36m0.5171\u001b[0m       \u001b[32m0.8947\u001b[0m        \u001b[35m0.3662\u001b[0m  0.0449\n",
      "      8        \u001b[36m0.4622\u001b[0m       \u001b[32m0.9013\u001b[0m        \u001b[35m0.3193\u001b[0m  0.0439\n",
      "      9        \u001b[36m0.4094\u001b[0m       \u001b[32m0.9194\u001b[0m        \u001b[35m0.2829\u001b[0m  0.0578\n",
      "     10        \u001b[36m0.3709\u001b[0m       \u001b[32m0.9276\u001b[0m        \u001b[35m0.2568\u001b[0m  0.0578\n",
      "     11        \u001b[36m0.3673\u001b[0m       \u001b[32m0.9326\u001b[0m        \u001b[35m0.2358\u001b[0m  0.0728\n",
      "     12        \u001b[36m0.3357\u001b[0m       \u001b[32m0.9342\u001b[0m        \u001b[35m0.2217\u001b[0m  0.0638\n",
      "     13        \u001b[36m0.3235\u001b[0m       \u001b[32m0.9523\u001b[0m        \u001b[35m0.2014\u001b[0m  0.0618\n",
      "     14        \u001b[36m0.2906\u001b[0m       0.9391        \u001b[35m0.1942\u001b[0m  0.0608\n",
      "     15        0.2993       0.9507        \u001b[35m0.1792\u001b[0m  0.0489\n",
      "     16        \u001b[36m0.2690\u001b[0m       0.9507        \u001b[35m0.1723\u001b[0m  0.0449\n",
      "     17        \u001b[36m0.2641\u001b[0m       \u001b[32m0.9638\u001b[0m        \u001b[35m0.1614\u001b[0m  0.0499\n",
      "     18        \u001b[36m0.2563\u001b[0m       0.9539        \u001b[35m0.1557\u001b[0m  0.0519\n",
      "     19        \u001b[36m0.2486\u001b[0m       0.9638        \u001b[35m0.1466\u001b[0m  0.0509\n",
      "     20        \u001b[36m0.2418\u001b[0m       0.9572        \u001b[35m0.1450\u001b[0m  0.0558\n",
      "     21        \u001b[36m0.2328\u001b[0m       \u001b[32m0.9704\u001b[0m        \u001b[35m0.1351\u001b[0m  0.0648\n",
      "     22        \u001b[36m0.2305\u001b[0m       0.9556        0.1382  0.0648\n",
      "     23        \u001b[36m0.2297\u001b[0m       0.9688        \u001b[35m0.1278\u001b[0m  0.0479\n",
      "     24        \u001b[36m0.2054\u001b[0m       0.9556        0.1290  0.0638\n",
      "     25        \u001b[36m0.1983\u001b[0m       0.9704        \u001b[35m0.1196\u001b[0m  0.0668\n",
      "     26        0.2051       0.9605        0.1207  0.0718\n",
      "     27        0.2055       \u001b[32m0.9720\u001b[0m        \u001b[35m0.1124\u001b[0m  0.0708\n",
      "     28        \u001b[36m0.1935\u001b[0m       0.9655        0.1133  0.0558\n",
      "     29        0.2067       0.9688        \u001b[35m0.1073\u001b[0m  0.0529\n",
      "     30        \u001b[36m0.1714\u001b[0m       0.9589        0.1175  0.0618\n",
      "     31        0.1960       0.9655        0.1074  0.0698\n",
      "     32        0.1859       0.9720        \u001b[35m0.1035\u001b[0m  0.0608\n",
      "     33        0.1769       \u001b[32m0.9737\u001b[0m        \u001b[35m0.0992\u001b[0m  0.0798\n",
      "     34        0.1869       0.9704        0.1009  0.0598\n",
      "     35        0.1841       0.9655        \u001b[35m0.0972\u001b[0m  0.0559\n",
      "     36        \u001b[36m0.1537\u001b[0m       0.9720        0.0996  0.0598\n",
      "     37        0.1759       0.9671        \u001b[35m0.0937\u001b[0m  0.0578\n",
      "     38        0.1560       0.9720        0.0954  0.0658\n",
      "     39        0.1609       0.9720        \u001b[35m0.0898\u001b[0m  0.0489\n",
      "     40        \u001b[36m0.1506\u001b[0m       0.9737        0.0947  0.0499\n",
      "     41        0.1800       \u001b[32m0.9753\u001b[0m        \u001b[35m0.0881\u001b[0m  0.0578\n",
      "     42        \u001b[36m0.1484\u001b[0m       0.9688        0.0948  0.0708\n",
      "     43        0.1596       0.9688        0.0907  0.0608\n",
      "     44        \u001b[36m0.1478\u001b[0m       0.9720        0.0939  0.0558\n",
      "     45        0.1704       0.9671        0.0953  0.0499\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.7827\u001b[0m       \u001b[32m0.3158\u001b[0m        \u001b[35m1.3558\u001b[0m  0.0489\n",
      "      2        \u001b[36m1.2768\u001b[0m       \u001b[32m0.7418\u001b[0m        \u001b[35m1.1113\u001b[0m  0.0568\n",
      "      3        \u001b[36m1.0997\u001b[0m       \u001b[32m0.7714\u001b[0m        \u001b[35m0.8714\u001b[0m  0.0718\n",
      "      4        \u001b[36m0.8715\u001b[0m       \u001b[32m0.7993\u001b[0m        \u001b[35m0.6813\u001b[0m  0.0628\n",
      "      5        \u001b[36m0.7168\u001b[0m       \u001b[32m0.8717\u001b[0m        \u001b[35m0.5374\u001b[0m  0.0499\n",
      "      6        \u001b[36m0.6056\u001b[0m       \u001b[32m0.8898\u001b[0m        \u001b[35m0.4374\u001b[0m  0.0608\n",
      "      7        \u001b[36m0.5028\u001b[0m       \u001b[32m0.8980\u001b[0m        \u001b[35m0.3654\u001b[0m  0.0469\n",
      "      8        \u001b[36m0.4434\u001b[0m       \u001b[32m0.9030\u001b[0m        \u001b[35m0.3190\u001b[0m  0.0608\n",
      "      9        \u001b[36m0.4065\u001b[0m       \u001b[32m0.9095\u001b[0m        \u001b[35m0.2871\u001b[0m  0.0439\n",
      "     10        \u001b[36m0.3778\u001b[0m       \u001b[32m0.9227\u001b[0m        \u001b[35m0.2625\u001b[0m  0.0628\n",
      "     11        \u001b[36m0.3444\u001b[0m       \u001b[32m0.9391\u001b[0m        \u001b[35m0.2413\u001b[0m  0.0628\n",
      "     12        \u001b[36m0.3250\u001b[0m       \u001b[32m0.9424\u001b[0m        \u001b[35m0.2253\u001b[0m  0.0588\n",
      "     13        \u001b[36m0.3109\u001b[0m       0.9391        \u001b[35m0.2168\u001b[0m  0.0638\n",
      "     14        \u001b[36m0.2981\u001b[0m       \u001b[32m0.9490\u001b[0m        \u001b[35m0.2031\u001b[0m  0.0598\n",
      "     15        \u001b[36m0.2760\u001b[0m       \u001b[32m0.9523\u001b[0m        \u001b[35m0.1914\u001b[0m  0.0598\n",
      "     16        \u001b[36m0.2723\u001b[0m       \u001b[32m0.9539\u001b[0m        \u001b[35m0.1830\u001b[0m  0.0499\n",
      "     17        \u001b[36m0.2625\u001b[0m       \u001b[32m0.9572\u001b[0m        \u001b[35m0.1774\u001b[0m  0.0509\n",
      "     18        0.2640       0.9507        \u001b[35m0.1746\u001b[0m  0.0688\n",
      "     19        \u001b[36m0.2607\u001b[0m       \u001b[32m0.9605\u001b[0m        \u001b[35m0.1602\u001b[0m  0.0469\n",
      "     20        \u001b[36m0.2247\u001b[0m       0.9523        0.1635  0.0539\n",
      "     21        0.2487       \u001b[32m0.9622\u001b[0m        \u001b[35m0.1521\u001b[0m  0.0558\n",
      "     22        \u001b[36m0.2152\u001b[0m       0.9539        0.1578  0.0608\n",
      "     23        0.2277       \u001b[32m0.9638\u001b[0m        \u001b[35m0.1451\u001b[0m  0.0499\n",
      "     24        \u001b[36m0.2085\u001b[0m       0.9539        0.1565  0.0728\n",
      "     25        0.2252       0.9638        \u001b[35m0.1394\u001b[0m  0.0489\n",
      "     26        \u001b[36m0.1994\u001b[0m       0.9539        0.1517  0.0578\n",
      "     27        0.2221       0.9638        \u001b[35m0.1329\u001b[0m  0.0888\n",
      "     28        \u001b[36m0.1970\u001b[0m       0.9622        0.1373  0.0678\n",
      "     29        0.1984       \u001b[32m0.9671\u001b[0m        \u001b[35m0.1295\u001b[0m  0.0678\n",
      "     30        \u001b[36m0.1888\u001b[0m       0.9605        0.1346  0.0529\n",
      "     31        0.2020       0.9655        \u001b[35m0.1252\u001b[0m  0.0608\n",
      "     32        \u001b[36m0.1870\u001b[0m       0.9638        0.1267  0.0638\n",
      "     33        \u001b[36m0.1854\u001b[0m       0.9655        \u001b[35m0.1200\u001b[0m  0.0549\n",
      "     34        \u001b[36m0.1730\u001b[0m       0.9638        0.1256  0.0549\n",
      "     35        0.1806       0.9655        \u001b[35m0.1168\u001b[0m  0.0608\n",
      "     36        \u001b[36m0.1721\u001b[0m       0.9638        0.1237  0.0618\n",
      "     37        0.1797       0.9638        \u001b[35m0.1140\u001b[0m  0.0559\n",
      "     38        \u001b[36m0.1606\u001b[0m       0.9605        0.1254  0.0519\n",
      "     39        0.1810       0.9638        \u001b[35m0.1118\u001b[0m  0.0788\n",
      "     40        \u001b[36m0.1459\u001b[0m       0.9638        0.1230  0.0519\n",
      "     41        0.1889       0.9671        0.1143  0.0628\n",
      "     42        0.1596       0.9655        0.1209  0.0638\n",
      "     43        0.1737       0.9589        0.1162  0.0479\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.8236\u001b[0m       \u001b[32m0.2763\u001b[0m        \u001b[35m1.3780\u001b[0m  0.0568\n",
      "      2        \u001b[36m1.2888\u001b[0m       \u001b[32m0.7796\u001b[0m        \u001b[35m1.1420\u001b[0m  0.0499\n",
      "      3        \u001b[36m1.1254\u001b[0m       0.7500        \u001b[35m0.9102\u001b[0m  0.0539\n",
      "      4        \u001b[36m0.9170\u001b[0m       0.7763        \u001b[35m0.7104\u001b[0m  0.0628\n",
      "      5        \u001b[36m0.7471\u001b[0m       \u001b[32m0.8651\u001b[0m        \u001b[35m0.5623\u001b[0m  0.0489\n",
      "      6        \u001b[36m0.6372\u001b[0m       \u001b[32m0.8832\u001b[0m        \u001b[35m0.4533\u001b[0m  0.0479\n",
      "      7        \u001b[36m0.5389\u001b[0m       \u001b[32m0.8997\u001b[0m        \u001b[35m0.3760\u001b[0m  0.0608\n",
      "      8        \u001b[36m0.4664\u001b[0m       0.8980        \u001b[35m0.3279\u001b[0m  0.0808\n",
      "      9        \u001b[36m0.4253\u001b[0m       \u001b[32m0.9013\u001b[0m        \u001b[35m0.2903\u001b[0m  0.0449\n",
      "     10        \u001b[36m0.3957\u001b[0m       \u001b[32m0.9161\u001b[0m        \u001b[35m0.2634\u001b[0m  0.0489\n",
      "     11        \u001b[36m0.3681\u001b[0m       \u001b[32m0.9178\u001b[0m        \u001b[35m0.2460\u001b[0m  0.0578\n",
      "     12        \u001b[36m0.3542\u001b[0m       \u001b[32m0.9260\u001b[0m        \u001b[35m0.2259\u001b[0m  0.0628\n",
      "     13        \u001b[36m0.3369\u001b[0m       \u001b[32m0.9276\u001b[0m        \u001b[35m0.2156\u001b[0m  0.0668\n",
      "     14        \u001b[36m0.3281\u001b[0m       \u001b[32m0.9457\u001b[0m        \u001b[35m0.1970\u001b[0m  0.0668\n",
      "     15        \u001b[36m0.3020\u001b[0m       0.9391        \u001b[35m0.1924\u001b[0m  0.0529\n",
      "     16        \u001b[36m0.2930\u001b[0m       \u001b[32m0.9490\u001b[0m        \u001b[35m0.1769\u001b[0m  0.0469\n",
      "     17        \u001b[36m0.2574\u001b[0m       0.9474        \u001b[35m0.1723\u001b[0m  0.0758\n",
      "     18        0.2583       \u001b[32m0.9589\u001b[0m        \u001b[35m0.1624\u001b[0m  0.0578\n",
      "     19        0.2588       0.9490        \u001b[35m0.1606\u001b[0m  0.0728\n",
      "     20        \u001b[36m0.2543\u001b[0m       \u001b[32m0.9638\u001b[0m        \u001b[35m0.1475\u001b[0m  0.0698\n",
      "     21        \u001b[36m0.2323\u001b[0m       0.9490        0.1513  0.0678\n",
      "     22        0.2437       \u001b[32m0.9688\u001b[0m        \u001b[35m0.1347\u001b[0m  0.0638\n",
      "     23        \u001b[36m0.2124\u001b[0m       0.9474        0.1458  0.0519\n",
      "     24        0.2360       0.9655        \u001b[35m0.1295\u001b[0m  0.0708\n",
      "     25        \u001b[36m0.2115\u001b[0m       0.9507        0.1448  0.0748\n",
      "     26        \u001b[36m0.2092\u001b[0m       0.9605        \u001b[35m0.1261\u001b[0m  0.0588\n",
      "     27        \u001b[36m0.1907\u001b[0m       0.9490        0.1424  0.0618\n",
      "     28        0.2205       0.9622        \u001b[35m0.1225\u001b[0m  0.0459\n",
      "     29        \u001b[36m0.1800\u001b[0m       0.9490        0.1424  0.0598\n",
      "     30        0.2180       0.9638        \u001b[35m0.1148\u001b[0m  0.0628\n",
      "     31        \u001b[36m0.1678\u001b[0m       0.9605        0.1245  0.0648\n",
      "     32        0.1940       0.9655        \u001b[35m0.1078\u001b[0m  0.0529\n",
      "     33        \u001b[36m0.1668\u001b[0m       0.9572        0.1216  0.0598\n",
      "     34        0.1925       0.9638        \u001b[35m0.1043\u001b[0m  0.0509\n",
      "     35        0.1752       0.9572        0.1188  0.0568\n",
      "     36        0.1761       0.9655        \u001b[35m0.1026\u001b[0m  0.0648\n",
      "     37        \u001b[36m0.1622\u001b[0m       0.9655        0.1101  0.0559\n",
      "     38        0.1907       0.9655        \u001b[35m0.1013\u001b[0m  0.0668\n",
      "     39        0.1666       0.9589        0.1102  0.0559\n",
      "     40        0.1778       0.9688        \u001b[35m0.0986\u001b[0m  0.0529\n",
      "     41        \u001b[36m0.1598\u001b[0m       0.9655        0.1076  0.0449\n",
      "     42        0.1833       0.9671        \u001b[35m0.0971\u001b[0m  0.0559\n",
      "     43        \u001b[36m0.1588\u001b[0m       0.9688        0.1009  0.0648\n",
      "     44        0.1679       0.9688        \u001b[35m0.0967\u001b[0m  0.0748\n",
      "     45        \u001b[36m0.1422\u001b[0m       0.9688        0.0982  0.0728\n",
      "     46        0.1673       0.9655        \u001b[35m0.0889\u001b[0m  0.0499\n",
      "     47        0.1504       0.9688        0.0930  0.0559\n",
      "     48        0.1564       0.9671        0.0892  0.0688\n",
      "     49        0.1537       0.9688        0.0965  0.0758\n",
      "     50        0.1533       0.9688        0.0903  0.0608\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "torch.manual_seed(0)\n",
    "\n",
    "net_final = NeuralNetClassifier(\n",
    "    CarClassificationNN(),\n",
    "    max_epochs=50,\n",
    "    callbacks=[EarlyStopping()],\n",
    "    lr=0.01,\n",
    "    optimizer=torch.optim.Adam\n",
    ")\n",
    "\n",
    "#Since dropout is already 0.5 on our CarClassificationNN, we have not change it here.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "scores = cross_validate(net_final, X_train_torch, y_train_torch, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the scores of cross validation is analysed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([3.46170998, 3.66719556, 3.2722497 , 3.10469723, 3.64525461]),\n",
       " 'score_time': array([0.01196837, 0.01396203, 0.01296639, 0.01097059, 0.01894712]),\n",
       " 'test_score': array([0.97368421, 0.96973684, 0.96842105, 0.95131579, 0.97368421])}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test score mean of the validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96736842"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.97368421, 0.96973684, 0.96842105, 0.95131579, 0.97368421])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I save my model using pickle library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mlp_model.pkl', 'wb') as f:\n",
    "    pickle.dump(net_final, f)\n",
    "    \n",
    "net_final.initialize()\n",
    "net_final.save_params(\n",
    "    f_params='model.pkl', f_optimizer='opt.pkl', f_history='history.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets do an alternative fitting with the imbalanced data, before SMOTE for the comparison with the best model selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3042\u001b[0m       \u001b[32m0.6878\u001b[0m        \u001b[35m0.9869\u001b[0m  0.0259\n",
      "      2        \u001b[36m0.8979\u001b[0m       0.6878        \u001b[35m0.7904\u001b[0m  0.0189\n",
      "      3        \u001b[36m0.7917\u001b[0m       0.6878        \u001b[35m0.6960\u001b[0m  0.0269\n",
      "      4        \u001b[36m0.7022\u001b[0m       \u001b[32m0.7828\u001b[0m        \u001b[35m0.5993\u001b[0m  0.0220\n",
      "      5        \u001b[36m0.6041\u001b[0m       \u001b[32m0.7873\u001b[0m        \u001b[35m0.5004\u001b[0m  0.0189\n",
      "      6        \u001b[36m0.5078\u001b[0m       \u001b[32m0.8597\u001b[0m        \u001b[35m0.4287\u001b[0m  0.0269\n",
      "      7        \u001b[36m0.4485\u001b[0m       \u001b[32m0.8824\u001b[0m        \u001b[35m0.3803\u001b[0m  0.0180\n",
      "      8        \u001b[36m0.4135\u001b[0m       0.8688        \u001b[35m0.3437\u001b[0m  0.0209\n",
      "      9        \u001b[36m0.3693\u001b[0m       \u001b[32m0.9005\u001b[0m        \u001b[35m0.3115\u001b[0m  0.0180\n",
      "     10        \u001b[36m0.3499\u001b[0m       0.8959        \u001b[35m0.2837\u001b[0m  0.0229\n",
      "     11        \u001b[36m0.3149\u001b[0m       \u001b[32m0.9050\u001b[0m        \u001b[35m0.2612\u001b[0m  0.0160\n",
      "     12        \u001b[36m0.2961\u001b[0m       \u001b[32m0.9140\u001b[0m        \u001b[35m0.2436\u001b[0m  0.0189\n",
      "     13        \u001b[36m0.2736\u001b[0m       \u001b[32m0.9186\u001b[0m        \u001b[35m0.2297\u001b[0m  0.0170\n",
      "     14        \u001b[36m0.2715\u001b[0m       \u001b[32m0.9276\u001b[0m        \u001b[35m0.2151\u001b[0m  0.0239\n",
      "     15        \u001b[36m0.2620\u001b[0m       \u001b[32m0.9321\u001b[0m        \u001b[35m0.2037\u001b[0m  0.0249\n",
      "     16        \u001b[36m0.2561\u001b[0m       \u001b[32m0.9412\u001b[0m        \u001b[35m0.1927\u001b[0m  0.0160\n",
      "     17        \u001b[36m0.2459\u001b[0m       0.9367        \u001b[35m0.1833\u001b[0m  0.0239\n",
      "     18        \u001b[36m0.2280\u001b[0m       \u001b[32m0.9502\u001b[0m        \u001b[35m0.1786\u001b[0m  0.0189\n",
      "     19        0.2306       0.9412        \u001b[35m0.1723\u001b[0m  0.0319\n",
      "     20        \u001b[36m0.2246\u001b[0m       0.9321        \u001b[35m0.1677\u001b[0m  0.0189\n",
      "     21        \u001b[36m0.2108\u001b[0m       0.9412        \u001b[35m0.1616\u001b[0m  0.0259\n",
      "     22        \u001b[36m0.2001\u001b[0m       0.9502        \u001b[35m0.1563\u001b[0m  0.0180\n",
      "     23        0.2127       0.9502        \u001b[35m0.1525\u001b[0m  0.0170\n",
      "     24        \u001b[36m0.1979\u001b[0m       0.9502        \u001b[35m0.1496\u001b[0m  0.0269\n",
      "     25        0.1982       0.9502        \u001b[35m0.1468\u001b[0m  0.0239\n",
      "     26        0.2111       0.9502        \u001b[35m0.1418\u001b[0m  0.0279\n",
      "     27        0.1991       0.9457        \u001b[35m0.1394\u001b[0m  0.0180\n",
      "     28        \u001b[36m0.1850\u001b[0m       0.9502        \u001b[35m0.1354\u001b[0m  0.0160\n",
      "     29        0.1912       0.9457        \u001b[35m0.1345\u001b[0m  0.0249\n",
      "     30        0.1907       0.9457        0.1347  0.0269\n",
      "     31        0.1935       0.9457        \u001b[35m0.1338\u001b[0m  0.0239\n",
      "     32        0.1854       0.9412        \u001b[35m0.1329\u001b[0m  0.0170\n",
      "     33        0.1877       0.9412        \u001b[35m0.1303\u001b[0m  0.0189\n",
      "     34        \u001b[36m0.1754\u001b[0m       0.9457        \u001b[35m0.1266\u001b[0m  0.0299\n",
      "     35        \u001b[36m0.1673\u001b[0m       0.9502        \u001b[35m0.1237\u001b[0m  0.0219\n",
      "     36        0.1726       0.9457        \u001b[35m0.1231\u001b[0m  0.0170\n",
      "     37        0.1814       0.9457        \u001b[35m0.1226\u001b[0m  0.0189\n",
      "     38        0.1751       0.9457        \u001b[35m0.1221\u001b[0m  0.0180\n",
      "     39        \u001b[36m0.1648\u001b[0m       0.9457        0.1226  0.0309\n",
      "     40        0.1771       0.9502        0.1234  0.0349\n",
      "     41        0.1721       \u001b[32m0.9548\u001b[0m        \u001b[35m0.1213\u001b[0m  0.0180\n",
      "     42        0.1660       0.9502        \u001b[35m0.1206\u001b[0m  0.0160\n",
      "     43        0.1713       0.9412        \u001b[35m0.1204\u001b[0m  0.0199\n",
      "     44        0.1657       0.9457        \u001b[35m0.1201\u001b[0m  0.0199\n",
      "     45        0.1655       \u001b[32m0.9683\u001b[0m        \u001b[35m0.1179\u001b[0m  0.0229\n",
      "     46        \u001b[36m0.1620\u001b[0m       0.9548        \u001b[35m0.1168\u001b[0m  0.0170\n",
      "     47        0.1659       0.9548        \u001b[35m0.1160\u001b[0m  0.0239\n",
      "     48        0.1633       0.9548        0.1183  0.0349\n",
      "     49        0.1704       0.9548        0.1202  0.0299\n",
      "     50        \u001b[36m0.1546\u001b[0m       0.9502        0.1189  0.0249\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3109\u001b[0m       \u001b[32m0.6878\u001b[0m        \u001b[35m0.9822\u001b[0m  0.0289\n",
      "      2        \u001b[36m0.9219\u001b[0m       0.6878        \u001b[35m0.7789\u001b[0m  0.0219\n",
      "      3        \u001b[36m0.7838\u001b[0m       \u001b[32m0.6923\u001b[0m        \u001b[35m0.6807\u001b[0m  0.0309\n",
      "      4        \u001b[36m0.6810\u001b[0m       \u001b[32m0.7828\u001b[0m        \u001b[35m0.5790\u001b[0m  0.0209\n",
      "      5        \u001b[36m0.5829\u001b[0m       \u001b[32m0.8190\u001b[0m        \u001b[35m0.4811\u001b[0m  0.0219\n",
      "      6        \u001b[36m0.4976\u001b[0m       \u001b[32m0.8462\u001b[0m        \u001b[35m0.4141\u001b[0m  0.0209\n",
      "      7        \u001b[36m0.4337\u001b[0m       \u001b[32m0.8643\u001b[0m        \u001b[35m0.3637\u001b[0m  0.0189\n",
      "      8        \u001b[36m0.3858\u001b[0m       0.8643        \u001b[35m0.3285\u001b[0m  0.0209\n",
      "      9        \u001b[36m0.3652\u001b[0m       0.8597        \u001b[35m0.3001\u001b[0m  0.0259\n",
      "     10        \u001b[36m0.3489\u001b[0m       \u001b[32m0.8778\u001b[0m        \u001b[35m0.2777\u001b[0m  0.0289\n",
      "     11        \u001b[36m0.3262\u001b[0m       \u001b[32m0.8914\u001b[0m        \u001b[35m0.2641\u001b[0m  0.0219\n",
      "     12        \u001b[36m0.3165\u001b[0m       0.8914        \u001b[35m0.2500\u001b[0m  0.0269\n",
      "     13        \u001b[36m0.2807\u001b[0m       \u001b[32m0.9005\u001b[0m        \u001b[35m0.2308\u001b[0m  0.0329\n",
      "     14        \u001b[36m0.2670\u001b[0m       \u001b[32m0.9050\u001b[0m        \u001b[35m0.2230\u001b[0m  0.0239\n",
      "     15        \u001b[36m0.2608\u001b[0m       \u001b[32m0.9095\u001b[0m        \u001b[35m0.2096\u001b[0m  0.0319\n",
      "     16        \u001b[36m0.2569\u001b[0m       \u001b[32m0.9186\u001b[0m        \u001b[35m0.2004\u001b[0m  0.0299\n",
      "     17        \u001b[36m0.2421\u001b[0m       0.9095        \u001b[35m0.1977\u001b[0m  0.0229\n",
      "     18        \u001b[36m0.2336\u001b[0m       0.9186        \u001b[35m0.1867\u001b[0m  0.0189\n",
      "     19        \u001b[36m0.2301\u001b[0m       \u001b[32m0.9231\u001b[0m        \u001b[35m0.1840\u001b[0m  0.0239\n",
      "     20        \u001b[36m0.2180\u001b[0m       \u001b[32m0.9276\u001b[0m        \u001b[35m0.1768\u001b[0m  0.0189\n",
      "     21        0.2265       0.9276        \u001b[35m0.1720\u001b[0m  0.0239\n",
      "     22        \u001b[36m0.2162\u001b[0m       0.9231        0.1721  0.0189\n",
      "     23        \u001b[36m0.2111\u001b[0m       0.9276        \u001b[35m0.1656\u001b[0m  0.0199\n",
      "     24        \u001b[36m0.2019\u001b[0m       0.9276        0.1675  0.0239\n",
      "     25        0.2073       \u001b[32m0.9321\u001b[0m        \u001b[35m0.1612\u001b[0m  0.0189\n",
      "     26        \u001b[36m0.1922\u001b[0m       0.9321        \u001b[35m0.1583\u001b[0m  0.0319\n",
      "     27        0.1963       0.9321        0.1614  0.0269\n",
      "     28        0.1936       \u001b[32m0.9367\u001b[0m        \u001b[35m0.1558\u001b[0m  0.0219\n",
      "     29        0.1989       0.9231        \u001b[35m0.1556\u001b[0m  0.0269\n",
      "     30        \u001b[36m0.1873\u001b[0m       0.9276        \u001b[35m0.1537\u001b[0m  0.0339\n",
      "     31        0.1906       0.9321        \u001b[35m0.1506\u001b[0m  0.0219\n",
      "     32        0.1889       0.9321        \u001b[35m0.1505\u001b[0m  0.0309\n",
      "     33        \u001b[36m0.1812\u001b[0m       0.9276        0.1528  0.0160\n",
      "     34        0.1825       0.9367        \u001b[35m0.1459\u001b[0m  0.0170\n",
      "     35        \u001b[36m0.1728\u001b[0m       0.9321        \u001b[35m0.1452\u001b[0m  0.0299\n",
      "     36        0.1839       0.9321        \u001b[35m0.1413\u001b[0m  0.0170\n",
      "     37        \u001b[36m0.1651\u001b[0m       \u001b[32m0.9412\u001b[0m        \u001b[35m0.1377\u001b[0m  0.0289\n",
      "     38        0.1806       0.9276        0.1410  0.0249\n",
      "     39        0.1757       0.9367        0.1410  0.0249\n",
      "     40        0.1818       0.9367        0.1398  0.0219\n",
      "     41        \u001b[36m0.1635\u001b[0m       0.9412        \u001b[35m0.1347\u001b[0m  0.0349\n",
      "     42        0.1743       0.9412        0.1360  0.0269\n",
      "     43        0.1662       \u001b[32m0.9457\u001b[0m        \u001b[35m0.1334\u001b[0m  0.0259\n",
      "     44        0.1746       \u001b[32m0.9502\u001b[0m        \u001b[35m0.1255\u001b[0m  0.0199\n",
      "     45        0.1714       0.9457        0.1348  0.0199\n",
      "     46        0.1689       0.9412        0.1354  0.0180\n",
      "     47        \u001b[36m0.1481\u001b[0m       0.9457        0.1294  0.0279\n",
      "     48        0.1707       0.9412        0.1286  0.0209\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3117\u001b[0m       \u001b[32m0.6847\u001b[0m        \u001b[35m1.0024\u001b[0m  0.0209\n",
      "      2        \u001b[36m0.9082\u001b[0m       0.6847        \u001b[35m0.7965\u001b[0m  0.0339\n",
      "      3        \u001b[36m0.7839\u001b[0m       0.6847        \u001b[35m0.7021\u001b[0m  0.0249\n",
      "      4        \u001b[36m0.7044\u001b[0m       \u001b[32m0.8243\u001b[0m        \u001b[35m0.6012\u001b[0m  0.0189\n",
      "      5        \u001b[36m0.5939\u001b[0m       0.8243        \u001b[35m0.4982\u001b[0m  0.0289\n",
      "      6        \u001b[36m0.5018\u001b[0m       \u001b[32m0.8514\u001b[0m        \u001b[35m0.4242\u001b[0m  0.0189\n",
      "      7        \u001b[36m0.4444\u001b[0m       \u001b[32m0.8694\u001b[0m        \u001b[35m0.3702\u001b[0m  0.0239\n",
      "      8        \u001b[36m0.4049\u001b[0m       0.8604        \u001b[35m0.3383\u001b[0m  0.0209\n",
      "      9        \u001b[36m0.3718\u001b[0m       0.8694        \u001b[35m0.3121\u001b[0m  0.0269\n",
      "     10        \u001b[36m0.3400\u001b[0m       0.8694        \u001b[35m0.2879\u001b[0m  0.0310\n",
      "     11        \u001b[36m0.3137\u001b[0m       \u001b[32m0.8829\u001b[0m        \u001b[35m0.2687\u001b[0m  0.0249\n",
      "     12        \u001b[36m0.2936\u001b[0m       \u001b[32m0.8874\u001b[0m        \u001b[35m0.2562\u001b[0m  0.0239\n",
      "     13        \u001b[36m0.2658\u001b[0m       \u001b[32m0.8964\u001b[0m        \u001b[35m0.2434\u001b[0m  0.0190\n",
      "     14        0.2686       0.8919        \u001b[35m0.2340\u001b[0m  0.0189\n",
      "     15        \u001b[36m0.2571\u001b[0m       \u001b[32m0.9009\u001b[0m        \u001b[35m0.2211\u001b[0m  0.0209\n",
      "     16        \u001b[36m0.2477\u001b[0m       0.8919        \u001b[35m0.2175\u001b[0m  0.0189\n",
      "     17        \u001b[36m0.2407\u001b[0m       \u001b[32m0.9054\u001b[0m        \u001b[35m0.2085\u001b[0m  0.0229\n",
      "     18        \u001b[36m0.2343\u001b[0m       \u001b[32m0.9144\u001b[0m        \u001b[35m0.1996\u001b[0m  0.0219\n",
      "     19        \u001b[36m0.2255\u001b[0m       0.9144        0.1997  0.0180\n",
      "     20        \u001b[36m0.2158\u001b[0m       \u001b[32m0.9234\u001b[0m        \u001b[35m0.1863\u001b[0m  0.0180\n",
      "     21        \u001b[36m0.2055\u001b[0m       0.9189        0.1867  0.0180\n",
      "     22        0.2122       0.9234        \u001b[35m0.1807\u001b[0m  0.0209\n",
      "     23        \u001b[36m0.1918\u001b[0m       0.9234        \u001b[35m0.1777\u001b[0m  0.0180\n",
      "     24        0.2013       0.9234        \u001b[35m0.1722\u001b[0m  0.0189\n",
      "     25        0.1918       0.9234        0.1774  0.0199\n",
      "     26        \u001b[36m0.1865\u001b[0m       0.9234        \u001b[35m0.1700\u001b[0m  0.0180\n",
      "     27        0.1900       0.9234        \u001b[35m0.1633\u001b[0m  0.0219\n",
      "     28        \u001b[36m0.1741\u001b[0m       0.9234        \u001b[35m0.1592\u001b[0m  0.0229\n",
      "     29        0.1809       \u001b[32m0.9279\u001b[0m        \u001b[35m0.1564\u001b[0m  0.0160\n",
      "     30        0.1852       0.9234        0.1600  0.0170\n",
      "     31        \u001b[36m0.1740\u001b[0m       0.9279        0.1591  0.0240\n",
      "     32        0.1754       0.9234        0.1649  0.0199\n",
      "     33        \u001b[36m0.1646\u001b[0m       0.9279        \u001b[35m0.1543\u001b[0m  0.0180\n",
      "     34        0.1737       0.9279        0.1576  0.0249\n",
      "     35        0.1868       0.9279        \u001b[35m0.1535\u001b[0m  0.0259\n",
      "     36        0.1716       0.9279        0.1541  0.0219\n",
      "     37        0.1655       0.9279        \u001b[35m0.1522\u001b[0m  0.0229\n",
      "     38        \u001b[36m0.1585\u001b[0m       0.9279        \u001b[35m0.1482\u001b[0m  0.0219\n",
      "     39        0.1675       0.9279        0.1536  0.0189\n",
      "     40        \u001b[36m0.1551\u001b[0m       0.9279        \u001b[35m0.1478\u001b[0m  0.0189\n",
      "     41        0.1562       0.9279        \u001b[35m0.1464\u001b[0m  0.0249\n",
      "     42        0.1630       0.9234        0.1482  0.0289\n",
      "     43        \u001b[36m0.1504\u001b[0m       0.9279        \u001b[35m0.1412\u001b[0m  0.0179\n",
      "     44        0.1726       0.9279        0.1472  0.0209\n",
      "     45        0.1535       0.9279        0.1488  0.0319\n",
      "     46        0.1580       0.9279        0.1445  0.0170\n",
      "     47        0.1549       0.9279        0.1423  0.0269\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.3019\u001b[0m       \u001b[32m0.6847\u001b[0m        \u001b[35m0.9902\u001b[0m  0.0269\n",
      "      2        \u001b[36m0.8965\u001b[0m       0.6847        \u001b[35m0.7922\u001b[0m  0.0259\n",
      "      3        \u001b[36m0.8002\u001b[0m       0.6847        \u001b[35m0.6908\u001b[0m  0.0309\n",
      "      4        \u001b[36m0.6951\u001b[0m       \u001b[32m0.8108\u001b[0m        \u001b[35m0.5906\u001b[0m  0.0199\n",
      "      5        \u001b[36m0.5752\u001b[0m       0.8063        \u001b[35m0.4950\u001b[0m  0.0309\n",
      "      6        \u001b[36m0.4989\u001b[0m       \u001b[32m0.8514\u001b[0m        \u001b[35m0.4229\u001b[0m  0.0170\n",
      "      7        \u001b[36m0.4472\u001b[0m       0.8514        \u001b[35m0.3757\u001b[0m  0.0209\n",
      "      8        \u001b[36m0.4042\u001b[0m       0.8514        \u001b[35m0.3403\u001b[0m  0.0299\n",
      "      9        \u001b[36m0.3593\u001b[0m       \u001b[32m0.8559\u001b[0m        \u001b[35m0.3128\u001b[0m  0.0170\n",
      "     10        \u001b[36m0.3228\u001b[0m       \u001b[32m0.8739\u001b[0m        \u001b[35m0.2899\u001b[0m  0.0219\n",
      "     11        \u001b[36m0.3171\u001b[0m       \u001b[32m0.8874\u001b[0m        \u001b[35m0.2755\u001b[0m  0.0349\n",
      "     12        \u001b[36m0.2931\u001b[0m       \u001b[32m0.9009\u001b[0m        \u001b[35m0.2585\u001b[0m  0.0269\n",
      "     13        \u001b[36m0.2741\u001b[0m       0.8874        \u001b[35m0.2507\u001b[0m  0.0219\n",
      "     14        0.2766       0.8964        \u001b[35m0.2413\u001b[0m  0.0190\n",
      "     15        \u001b[36m0.2572\u001b[0m       0.8964        \u001b[35m0.2293\u001b[0m  0.0309\n",
      "     16        \u001b[36m0.2485\u001b[0m       0.8964        \u001b[35m0.2242\u001b[0m  0.0229\n",
      "     17        \u001b[36m0.2416\u001b[0m       \u001b[32m0.9054\u001b[0m        \u001b[35m0.2195\u001b[0m  0.0199\n",
      "     18        0.2468       \u001b[32m0.9144\u001b[0m        \u001b[35m0.2091\u001b[0m  0.0299\n",
      "     19        \u001b[36m0.2363\u001b[0m       0.9144        \u001b[35m0.2070\u001b[0m  0.0180\n",
      "     20        \u001b[36m0.2310\u001b[0m       0.9144        \u001b[35m0.2009\u001b[0m  0.0299\n",
      "     21        \u001b[36m0.2115\u001b[0m       0.9099        0.2049  0.0219\n",
      "     22        \u001b[36m0.2063\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m0.1921\u001b[0m  0.0180\n",
      "     23        \u001b[36m0.2008\u001b[0m       \u001b[32m0.9234\u001b[0m        \u001b[35m0.1893\u001b[0m  0.0189\n",
      "     24        \u001b[36m0.1923\u001b[0m       0.9234        \u001b[35m0.1866\u001b[0m  0.0239\n",
      "     25        \u001b[36m0.1882\u001b[0m       0.9189        \u001b[35m0.1835\u001b[0m  0.0269\n",
      "     26        0.1933       0.9144        0.1925  0.0289\n",
      "     27        0.1988       0.9234        \u001b[35m0.1795\u001b[0m  0.0229\n",
      "     28        0.1935       0.9234        \u001b[35m0.1769\u001b[0m  0.0199\n",
      "     29        \u001b[36m0.1836\u001b[0m       0.9189        0.1810  0.0349\n",
      "     30        0.1999       \u001b[32m0.9324\u001b[0m        \u001b[35m0.1722\u001b[0m  0.0219\n",
      "     31        \u001b[36m0.1796\u001b[0m       0.9279        \u001b[35m0.1696\u001b[0m  0.0299\n",
      "     32        0.1869       0.9234        \u001b[35m0.1687\u001b[0m  0.0299\n",
      "     33        0.1877       0.9279        0.1708  0.0249\n",
      "     34        0.1822       \u001b[32m0.9369\u001b[0m        \u001b[35m0.1606\u001b[0m  0.0239\n",
      "     35        0.1820       0.9324        0.1668  0.0170\n",
      "     36        0.1851       0.9279        0.1766  0.0249\n",
      "     37        \u001b[36m0.1781\u001b[0m       0.9279        0.1709  0.0199\n",
      "     38        \u001b[36m0.1692\u001b[0m       0.9324        0.1666  0.0259\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m1.2979\u001b[0m       \u001b[32m0.6847\u001b[0m        \u001b[35m0.9862\u001b[0m  0.0259\n",
      "      2        \u001b[36m0.9168\u001b[0m       0.6847        \u001b[35m0.7927\u001b[0m  0.0349\n",
      "      3        \u001b[36m0.7704\u001b[0m       0.6847        \u001b[35m0.6916\u001b[0m  0.0220\n",
      "      4        \u001b[36m0.6750\u001b[0m       \u001b[32m0.8153\u001b[0m        \u001b[35m0.5901\u001b[0m  0.0229\n",
      "      5        \u001b[36m0.5802\u001b[0m       \u001b[32m0.8288\u001b[0m        \u001b[35m0.4854\u001b[0m  0.0189\n",
      "      6        \u001b[36m0.4933\u001b[0m       \u001b[32m0.8333\u001b[0m        \u001b[35m0.4147\u001b[0m  0.0229\n",
      "      7        \u001b[36m0.4351\u001b[0m       \u001b[32m0.8649\u001b[0m        \u001b[35m0.3616\u001b[0m  0.0189\n",
      "      8        \u001b[36m0.3865\u001b[0m       0.8649        \u001b[35m0.3284\u001b[0m  0.0199\n",
      "      9        \u001b[36m0.3632\u001b[0m       \u001b[32m0.8739\u001b[0m        \u001b[35m0.3027\u001b[0m  0.0239\n",
      "     10        \u001b[36m0.3329\u001b[0m       \u001b[32m0.8874\u001b[0m        \u001b[35m0.2764\u001b[0m  0.0229\n",
      "     11        \u001b[36m0.3188\u001b[0m       0.8874        \u001b[35m0.2617\u001b[0m  0.0369\n",
      "     12        \u001b[36m0.2893\u001b[0m       \u001b[32m0.8919\u001b[0m        \u001b[35m0.2445\u001b[0m  0.0199\n",
      "     13        \u001b[36m0.2649\u001b[0m       \u001b[32m0.9099\u001b[0m        \u001b[35m0.2294\u001b[0m  0.0209\n",
      "     14        \u001b[36m0.2542\u001b[0m       0.9099        \u001b[35m0.2195\u001b[0m  0.0339\n",
      "     15        \u001b[36m0.2477\u001b[0m       0.9099        \u001b[35m0.2102\u001b[0m  0.0259\n",
      "     16        \u001b[36m0.2347\u001b[0m       0.9099        \u001b[35m0.2047\u001b[0m  0.0269\n",
      "     17        \u001b[36m0.2327\u001b[0m       \u001b[32m0.9189\u001b[0m        \u001b[35m0.1943\u001b[0m  0.0179\n",
      "     18        0.2336       0.9189        \u001b[35m0.1930\u001b[0m  0.0180\n",
      "     19        \u001b[36m0.2178\u001b[0m       \u001b[32m0.9279\u001b[0m        \u001b[35m0.1854\u001b[0m  0.0239\n",
      "     20        \u001b[36m0.2090\u001b[0m       0.9279        \u001b[35m0.1803\u001b[0m  0.0309\n",
      "     21        \u001b[36m0.2085\u001b[0m       0.9279        0.1810  0.0209\n",
      "     22        \u001b[36m0.1952\u001b[0m       0.9234        \u001b[35m0.1711\u001b[0m  0.0199\n",
      "     23        0.1968       \u001b[32m0.9324\u001b[0m        \u001b[35m0.1662\u001b[0m  0.0199\n",
      "     24        \u001b[36m0.1925\u001b[0m       0.9324        0.1698  0.0180\n",
      "     25        0.1940       0.9324        \u001b[35m0.1649\u001b[0m  0.0249\n",
      "     26        \u001b[36m0.1760\u001b[0m       0.9324        \u001b[35m0.1598\u001b[0m  0.0259\n",
      "     27        0.1850       \u001b[32m0.9369\u001b[0m        \u001b[35m0.1532\u001b[0m  0.0299\n",
      "     28        0.1789       0.9324        0.1588  0.0200\n",
      "     29        0.1842       0.9279        \u001b[35m0.1499\u001b[0m  0.0249\n",
      "     30        0.1773       0.9324        0.1615  0.0339\n",
      "     31        \u001b[36m0.1701\u001b[0m       0.9369        0.1536  0.0160\n",
      "     32        0.1773       0.9279        \u001b[35m0.1442\u001b[0m  0.0180\n",
      "     33        0.1701       0.9324        0.1545  0.0199\n",
      "     34        0.1725       0.9324        0.1500  0.0180\n",
      "     35        \u001b[36m0.1594\u001b[0m       0.9324        0.1493  0.0249\n",
      "     36        0.1605       0.9324        0.1450  0.0279\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n"
     ]
    }
   ],
   "source": [
    "X_train_t= torch.FloatTensor(X_train)\n",
    "y_train_t= torch.LongTensor(y_train)\n",
    "scores_alternative = cross_validate(net_final, X_train_t, y_train_t, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.44812465, 1.52791452, 1.37631869, 1.2347002 , 1.10305214]),\n",
       " 'score_time': array([0.00598502, 0.00698256, 0.00498724, 0.00498414, 0.00598478]),\n",
       " 'test_score': array([0.93862816, 0.9566787 , 0.92753623, 0.94202899, 0.94202899])}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9413802139999999"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.93862816, 0.9566787 , 0.92753623, 0.94202899, 0.94202899])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relevant libraries are imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "clf=OneVsRestClassifier(SVC(probability=True)).fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model selection, grid search is conducted with 3 folds stratified cross validation with selected hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   35.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=1, shuffle=True),\n",
       "             estimator=OneVsRestClassifier(estimator=SVC(probability=True)),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'estimator__C': [0.05, 0.1, 0.5, 1, 5],\n",
       "                         'estimator__gamma': [5, 1, 0.5, 0.05, 0.01],\n",
       "                         'estimator__kernel': ['poly', 'linear']},\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "parameters = {\n",
    "    \"estimator__C\": [0.05, 0.1,0.5, 1, 5],\n",
    "    \"estimator__kernel\": [\"poly\",\"linear\"],\n",
    "    \"estimator__gamma\": [5, 1, 0.5, 0.05, 0.01]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, parameters, verbose = 3, scoring='accuracy' ,refit=True, n_jobs=-1, cv=kfold)\n",
    "\n",
    "grid_search.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search is analysed through as a sheet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_estimator__C</th>\n",
       "      <th>param_estimator__gamma</th>\n",
       "      <th>param_estimator__kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.669538</td>\n",
       "      <td>0.042592</td>\n",
       "      <td>0.036566</td>\n",
       "      <td>1.243334e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 5, ...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.027245</td>\n",
       "      <td>0.025883</td>\n",
       "      <td>0.108377</td>\n",
       "      <td>1.695825e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 5, ...</td>\n",
       "      <td>0.853197</td>\n",
       "      <td>0.864246</td>\n",
       "      <td>0.851501</td>\n",
       "      <td>0.856315</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.693803</td>\n",
       "      <td>0.039613</td>\n",
       "      <td>0.041889</td>\n",
       "      <td>8.104673e-07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 1, ...</td>\n",
       "      <td>0.996054</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.996842</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.037551</td>\n",
       "      <td>0.085588</td>\n",
       "      <td>0.109374</td>\n",
       "      <td>4.017366e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 1, ...</td>\n",
       "      <td>0.853197</td>\n",
       "      <td>0.864246</td>\n",
       "      <td>0.851501</td>\n",
       "      <td>0.856315</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.046195</td>\n",
       "      <td>0.020217</td>\n",
       "      <td>0.067486</td>\n",
       "      <td>1.243900e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 0.5...</td>\n",
       "      <td>0.982636</td>\n",
       "      <td>0.988161</td>\n",
       "      <td>0.979463</td>\n",
       "      <td>0.983420</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.075783</td>\n",
       "      <td>0.069032</td>\n",
       "      <td>0.110704</td>\n",
       "      <td>4.534071e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 0.5...</td>\n",
       "      <td>0.853197</td>\n",
       "      <td>0.864246</td>\n",
       "      <td>0.851501</td>\n",
       "      <td>0.856315</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.751635</td>\n",
       "      <td>0.017940</td>\n",
       "      <td>0.229386</td>\n",
       "      <td>8.143934e-04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 0.0...</td>\n",
       "      <td>0.859511</td>\n",
       "      <td>0.852407</td>\n",
       "      <td>0.868088</td>\n",
       "      <td>0.860002</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.098057</td>\n",
       "      <td>0.035367</td>\n",
       "      <td>0.110704</td>\n",
       "      <td>1.410739e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 0.0...</td>\n",
       "      <td>0.853197</td>\n",
       "      <td>0.864246</td>\n",
       "      <td>0.851501</td>\n",
       "      <td>0.856315</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.333088</td>\n",
       "      <td>0.041032</td>\n",
       "      <td>0.224733</td>\n",
       "      <td>3.083398e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 0.0...</td>\n",
       "      <td>0.868982</td>\n",
       "      <td>0.816890</td>\n",
       "      <td>0.857030</td>\n",
       "      <td>0.847634</td>\n",
       "      <td>0.022280</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.078775</td>\n",
       "      <td>0.065715</td>\n",
       "      <td>0.110039</td>\n",
       "      <td>2.859982e-03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.05, 'estimator__gamma': 0.0...</td>\n",
       "      <td>0.853197</td>\n",
       "      <td>0.864246</td>\n",
       "      <td>0.851501</td>\n",
       "      <td>0.856315</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.690148</td>\n",
       "      <td>0.045735</td>\n",
       "      <td>0.040891</td>\n",
       "      <td>3.731658e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 5, '...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.868004</td>\n",
       "      <td>0.040788</td>\n",
       "      <td>0.098403</td>\n",
       "      <td>2.049061e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 5, '...</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.860526</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.728710</td>\n",
       "      <td>0.047191</td>\n",
       "      <td>0.039893</td>\n",
       "      <td>1.410852e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 1, '...</td>\n",
       "      <td>0.997632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998947</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.876649</td>\n",
       "      <td>0.056893</td>\n",
       "      <td>0.099401</td>\n",
       "      <td>1.244452e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 1, '...</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.860526</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.972393</td>\n",
       "      <td>0.052486</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>4.702465e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 0.5,...</td>\n",
       "      <td>0.992897</td>\n",
       "      <td>0.996054</td>\n",
       "      <td>0.992891</td>\n",
       "      <td>0.993947</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.917872</td>\n",
       "      <td>0.043343</td>\n",
       "      <td>0.100398</td>\n",
       "      <td>1.243752e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 0.5,...</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.860526</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.903230</td>\n",
       "      <td>0.042229</td>\n",
       "      <td>0.242352</td>\n",
       "      <td>1.628981e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 0.05...</td>\n",
       "      <td>0.860300</td>\n",
       "      <td>0.853197</td>\n",
       "      <td>0.867299</td>\n",
       "      <td>0.860265</td>\n",
       "      <td>0.005757</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.934494</td>\n",
       "      <td>0.037867</td>\n",
       "      <td>0.099068</td>\n",
       "      <td>1.694952e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 0.05...</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.860526</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.510946</td>\n",
       "      <td>0.034379</td>\n",
       "      <td>0.235703</td>\n",
       "      <td>2.617596e-03</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 0.01...</td>\n",
       "      <td>0.870560</td>\n",
       "      <td>0.816890</td>\n",
       "      <td>0.858610</td>\n",
       "      <td>0.848687</td>\n",
       "      <td>0.023007</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.951449</td>\n",
       "      <td>0.034330</td>\n",
       "      <td>0.099733</td>\n",
       "      <td>8.138094e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.1, 'estimator__gamma': 0.01...</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>0.857820</td>\n",
       "      <td>0.860526</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.785560</td>\n",
       "      <td>0.044560</td>\n",
       "      <td>0.040557</td>\n",
       "      <td>1.243964e-03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 5, '...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.629643</td>\n",
       "      <td>0.066141</td>\n",
       "      <td>0.077459</td>\n",
       "      <td>5.170913e-03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 5, '...</td>\n",
       "      <td>0.874507</td>\n",
       "      <td>0.878453</td>\n",
       "      <td>0.875987</td>\n",
       "      <td>0.876316</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.765280</td>\n",
       "      <td>0.069875</td>\n",
       "      <td>0.040225</td>\n",
       "      <td>9.400433e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 1, '...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.630640</td>\n",
       "      <td>0.093134</td>\n",
       "      <td>0.074135</td>\n",
       "      <td>1.696012e-03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 1, '...</td>\n",
       "      <td>0.874507</td>\n",
       "      <td>0.878453</td>\n",
       "      <td>0.875987</td>\n",
       "      <td>0.876316</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.828777</td>\n",
       "      <td>0.052073</td>\n",
       "      <td>0.043550</td>\n",
       "      <td>2.859049e-03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 0.5,...</td>\n",
       "      <td>0.996054</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.997105</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.647595</td>\n",
       "      <td>0.070159</td>\n",
       "      <td>0.077127</td>\n",
       "      <td>1.243901e-03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 0.5,...</td>\n",
       "      <td>0.874507</td>\n",
       "      <td>0.878453</td>\n",
       "      <td>0.875987</td>\n",
       "      <td>0.876316</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.025571</td>\n",
       "      <td>0.048053</td>\n",
       "      <td>0.293216</td>\n",
       "      <td>2.112456e-02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 0.05...</td>\n",
       "      <td>0.860300</td>\n",
       "      <td>0.852407</td>\n",
       "      <td>0.866509</td>\n",
       "      <td>0.859739</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.661557</td>\n",
       "      <td>0.087720</td>\n",
       "      <td>0.078457</td>\n",
       "      <td>2.487673e-03</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 0.05...</td>\n",
       "      <td>0.874507</td>\n",
       "      <td>0.878453</td>\n",
       "      <td>0.875987</td>\n",
       "      <td>0.876316</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.937806</td>\n",
       "      <td>0.050311</td>\n",
       "      <td>0.266287</td>\n",
       "      <td>1.791607e-02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 0.01...</td>\n",
       "      <td>0.867403</td>\n",
       "      <td>0.823994</td>\n",
       "      <td>0.857030</td>\n",
       "      <td>0.849476</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.730374</td>\n",
       "      <td>0.060670</td>\n",
       "      <td>0.094746</td>\n",
       "      <td>2.249362e-02</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 0.5, 'estimator__gamma': 0.01...</td>\n",
       "      <td>0.874507</td>\n",
       "      <td>0.878453</td>\n",
       "      <td>0.875987</td>\n",
       "      <td>0.876316</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.918206</td>\n",
       "      <td>0.142352</td>\n",
       "      <td>0.043548</td>\n",
       "      <td>1.879637e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 5, 'es...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.988350</td>\n",
       "      <td>0.082440</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>1.628009e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 5, 'es...</td>\n",
       "      <td>0.883978</td>\n",
       "      <td>0.886346</td>\n",
       "      <td>0.882306</td>\n",
       "      <td>0.884210</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.005637</td>\n",
       "      <td>0.065557</td>\n",
       "      <td>0.042221</td>\n",
       "      <td>1.694765e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 1, 'es...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.194798</td>\n",
       "      <td>0.146066</td>\n",
       "      <td>0.077460</td>\n",
       "      <td>2.487163e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 1, 'es...</td>\n",
       "      <td>0.883978</td>\n",
       "      <td>0.886346</td>\n",
       "      <td>0.882306</td>\n",
       "      <td>0.884210</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.023921</td>\n",
       "      <td>0.092221</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>1.244198e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 0.5, '...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.211088</td>\n",
       "      <td>0.134446</td>\n",
       "      <td>0.090093</td>\n",
       "      <td>1.882333e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 0.5, '...</td>\n",
       "      <td>0.883978</td>\n",
       "      <td>0.886346</td>\n",
       "      <td>0.882306</td>\n",
       "      <td>0.884210</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.285874</td>\n",
       "      <td>0.090834</td>\n",
       "      <td>0.263961</td>\n",
       "      <td>1.795753e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 0.05, ...</td>\n",
       "      <td>0.860300</td>\n",
       "      <td>0.853197</td>\n",
       "      <td>0.866509</td>\n",
       "      <td>0.860002</td>\n",
       "      <td>0.005439</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.020264</td>\n",
       "      <td>0.103826</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>8.141015e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 0.05, ...</td>\n",
       "      <td>0.883978</td>\n",
       "      <td>0.886346</td>\n",
       "      <td>0.882306</td>\n",
       "      <td>0.884210</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.291194</td>\n",
       "      <td>0.079896</td>\n",
       "      <td>0.280582</td>\n",
       "      <td>2.473031e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 0.01, ...</td>\n",
       "      <td>0.868193</td>\n",
       "      <td>0.849250</td>\n",
       "      <td>0.864929</td>\n",
       "      <td>0.860791</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.055504</td>\n",
       "      <td>0.029664</td>\n",
       "      <td>0.075798</td>\n",
       "      <td>2.820467e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 1, 'estimator__gamma': 0.01, ...</td>\n",
       "      <td>0.883978</td>\n",
       "      <td>0.886346</td>\n",
       "      <td>0.882306</td>\n",
       "      <td>0.884210</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.913549</td>\n",
       "      <td>0.087618</td>\n",
       "      <td>0.049867</td>\n",
       "      <td>1.058621e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 5, 'es...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>3.432489</td>\n",
       "      <td>0.053710</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>4.071772e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 5, 'es...</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.910813</td>\n",
       "      <td>0.910742</td>\n",
       "      <td>0.905791</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2.313814</td>\n",
       "      <td>0.172642</td>\n",
       "      <td>0.043882</td>\n",
       "      <td>8.144908e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 1, 'es...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3.594723</td>\n",
       "      <td>0.139902</td>\n",
       "      <td>0.081115</td>\n",
       "      <td>3.083432e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 1, 'es...</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.910813</td>\n",
       "      <td>0.910742</td>\n",
       "      <td>0.905791</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.293534</td>\n",
       "      <td>0.153067</td>\n",
       "      <td>0.048205</td>\n",
       "      <td>3.083698e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 0.5, '...</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.998421</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>3.947445</td>\n",
       "      <td>0.241562</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>8.145881e-04</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 0.5, '...</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.910813</td>\n",
       "      <td>0.910742</td>\n",
       "      <td>0.905791</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3.959519</td>\n",
       "      <td>0.174345</td>\n",
       "      <td>0.176597</td>\n",
       "      <td>1.686167e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 0.05, ...</td>\n",
       "      <td>0.929755</td>\n",
       "      <td>0.940805</td>\n",
       "      <td>0.926540</td>\n",
       "      <td>0.932367</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3.433559</td>\n",
       "      <td>0.149747</td>\n",
       "      <td>0.070966</td>\n",
       "      <td>2.171021e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 0.05, ...</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.910813</td>\n",
       "      <td>0.910742</td>\n",
       "      <td>0.905791</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4.126939</td>\n",
       "      <td>0.051176</td>\n",
       "      <td>0.151933</td>\n",
       "      <td>5.691219e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 0.01, ...</td>\n",
       "      <td>0.860300</td>\n",
       "      <td>0.854775</td>\n",
       "      <td>0.867299</td>\n",
       "      <td>0.860791</td>\n",
       "      <td>0.005124</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2.460227</td>\n",
       "      <td>0.036462</td>\n",
       "      <td>0.035808</td>\n",
       "      <td>1.278563e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'estimator__C': 5, 'estimator__gamma': 0.01, ...</td>\n",
       "      <td>0.895817</td>\n",
       "      <td>0.910813</td>\n",
       "      <td>0.910742</td>\n",
       "      <td>0.905791</td>\n",
       "      <td>0.007053</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        1.669538      0.042592         0.036566    1.243334e-03   \n",
       "1        2.027245      0.025883         0.108377    1.695825e-03   \n",
       "2        1.693803      0.039613         0.041889    8.104673e-07   \n",
       "3        2.037551      0.085588         0.109374    4.017366e-03   \n",
       "4        2.046195      0.020217         0.067486    1.243900e-03   \n",
       "5        2.075783      0.069032         0.110704    4.534071e-03   \n",
       "6        3.751635      0.017940         0.229386    8.143934e-04   \n",
       "7        2.098057      0.035367         0.110704    1.410739e-03   \n",
       "8        3.333088      0.041032         0.224733    3.083398e-03   \n",
       "9        2.078775      0.065715         0.110039    2.859982e-03   \n",
       "10       1.690148      0.045735         0.040891    3.731658e-03   \n",
       "11       1.868004      0.040788         0.098403    2.049061e-03   \n",
       "12       1.728710      0.047191         0.039893    1.410852e-03   \n",
       "13       1.876649      0.056893         0.099401    1.244452e-03   \n",
       "14       1.972393      0.052486         0.057512    4.702465e-04   \n",
       "15       1.917872      0.043343         0.100398    1.243752e-03   \n",
       "16       3.903230      0.042229         0.242352    1.628981e-03   \n",
       "17       1.934494      0.037867         0.099068    1.694952e-03   \n",
       "18       3.510946      0.034379         0.235703    2.617596e-03   \n",
       "19       1.951449      0.034330         0.099733    8.138094e-04   \n",
       "20       1.785560      0.044560         0.040557    1.243964e-03   \n",
       "21       1.629643      0.066141         0.077459    5.170913e-03   \n",
       "22       1.765280      0.069875         0.040225    9.400433e-04   \n",
       "23       1.630640      0.093134         0.074135    1.696012e-03   \n",
       "24       1.828777      0.052073         0.043550    2.859049e-03   \n",
       "25       1.647595      0.070159         0.077127    1.243901e-03   \n",
       "26       4.025571      0.048053         0.293216    2.112456e-02   \n",
       "27       1.661557      0.087720         0.078457    2.487673e-03   \n",
       "28       3.937806      0.050311         0.266287    1.791607e-02   \n",
       "29       1.730374      0.060670         0.094746    2.249362e-02   \n",
       "30       1.918206      0.142352         0.043548    1.879637e-03   \n",
       "31       1.988350      0.082440         0.074800    1.628009e-03   \n",
       "32       2.005637      0.065557         0.042221    1.694765e-03   \n",
       "33       2.194798      0.146066         0.077460    2.487163e-03   \n",
       "34       2.023921      0.092221         0.042553    1.244198e-03   \n",
       "35       2.211088      0.134446         0.090093    1.882333e-02   \n",
       "36       4.285874      0.090834         0.263961    1.795753e-02   \n",
       "37       2.020264      0.103826         0.074800    8.141015e-04   \n",
       "38       4.291194      0.079896         0.280582    2.473031e-02   \n",
       "39       2.055504      0.029664         0.075798    2.820467e-03   \n",
       "40       1.913549      0.087618         0.049867    1.058621e-02   \n",
       "41       3.432489      0.053710         0.074800    4.071772e-03   \n",
       "42       2.313814      0.172642         0.043882    8.144908e-04   \n",
       "43       3.594723      0.139902         0.081115    3.083432e-03   \n",
       "44       2.293534      0.153067         0.048205    3.083698e-03   \n",
       "45       3.947445      0.241562         0.074800    8.145881e-04   \n",
       "46       3.959519      0.174345         0.176597    1.686167e-02   \n",
       "47       3.433559      0.149747         0.070966    2.171021e-03   \n",
       "48       4.126939      0.051176         0.151933    5.691219e-03   \n",
       "49       2.460227      0.036462         0.035808    1.278563e-03   \n",
       "\n",
       "   param_estimator__C param_estimator__gamma param_estimator__kernel  \\\n",
       "0                0.05                      5                    poly   \n",
       "1                0.05                      5                  linear   \n",
       "2                0.05                      1                    poly   \n",
       "3                0.05                      1                  linear   \n",
       "4                0.05                    0.5                    poly   \n",
       "5                0.05                    0.5                  linear   \n",
       "6                0.05                   0.05                    poly   \n",
       "7                0.05                   0.05                  linear   \n",
       "8                0.05                   0.01                    poly   \n",
       "9                0.05                   0.01                  linear   \n",
       "10                0.1                      5                    poly   \n",
       "11                0.1                      5                  linear   \n",
       "12                0.1                      1                    poly   \n",
       "13                0.1                      1                  linear   \n",
       "14                0.1                    0.5                    poly   \n",
       "15                0.1                    0.5                  linear   \n",
       "16                0.1                   0.05                    poly   \n",
       "17                0.1                   0.05                  linear   \n",
       "18                0.1                   0.01                    poly   \n",
       "19                0.1                   0.01                  linear   \n",
       "20                0.5                      5                    poly   \n",
       "21                0.5                      5                  linear   \n",
       "22                0.5                      1                    poly   \n",
       "23                0.5                      1                  linear   \n",
       "24                0.5                    0.5                    poly   \n",
       "25                0.5                    0.5                  linear   \n",
       "26                0.5                   0.05                    poly   \n",
       "27                0.5                   0.05                  linear   \n",
       "28                0.5                   0.01                    poly   \n",
       "29                0.5                   0.01                  linear   \n",
       "30                  1                      5                    poly   \n",
       "31                  1                      5                  linear   \n",
       "32                  1                      1                    poly   \n",
       "33                  1                      1                  linear   \n",
       "34                  1                    0.5                    poly   \n",
       "35                  1                    0.5                  linear   \n",
       "36                  1                   0.05                    poly   \n",
       "37                  1                   0.05                  linear   \n",
       "38                  1                   0.01                    poly   \n",
       "39                  1                   0.01                  linear   \n",
       "40                  5                      5                    poly   \n",
       "41                  5                      5                  linear   \n",
       "42                  5                      1                    poly   \n",
       "43                  5                      1                  linear   \n",
       "44                  5                    0.5                    poly   \n",
       "45                  5                    0.5                  linear   \n",
       "46                  5                   0.05                    poly   \n",
       "47                  5                   0.05                  linear   \n",
       "48                  5                   0.01                    poly   \n",
       "49                  5                   0.01                  linear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'estimator__C': 0.05, 'estimator__gamma': 5, ...           0.998421   \n",
       "1   {'estimator__C': 0.05, 'estimator__gamma': 5, ...           0.853197   \n",
       "2   {'estimator__C': 0.05, 'estimator__gamma': 1, ...           0.996054   \n",
       "3   {'estimator__C': 0.05, 'estimator__gamma': 1, ...           0.853197   \n",
       "4   {'estimator__C': 0.05, 'estimator__gamma': 0.5...           0.982636   \n",
       "5   {'estimator__C': 0.05, 'estimator__gamma': 0.5...           0.853197   \n",
       "6   {'estimator__C': 0.05, 'estimator__gamma': 0.0...           0.859511   \n",
       "7   {'estimator__C': 0.05, 'estimator__gamma': 0.0...           0.853197   \n",
       "8   {'estimator__C': 0.05, 'estimator__gamma': 0.0...           0.868982   \n",
       "9   {'estimator__C': 0.05, 'estimator__gamma': 0.0...           0.853197   \n",
       "10  {'estimator__C': 0.1, 'estimator__gamma': 5, '...           0.998421   \n",
       "11  {'estimator__C': 0.1, 'estimator__gamma': 5, '...           0.856354   \n",
       "12  {'estimator__C': 0.1, 'estimator__gamma': 1, '...           0.997632   \n",
       "13  {'estimator__C': 0.1, 'estimator__gamma': 1, '...           0.856354   \n",
       "14  {'estimator__C': 0.1, 'estimator__gamma': 0.5,...           0.992897   \n",
       "15  {'estimator__C': 0.1, 'estimator__gamma': 0.5,...           0.856354   \n",
       "16  {'estimator__C': 0.1, 'estimator__gamma': 0.05...           0.860300   \n",
       "17  {'estimator__C': 0.1, 'estimator__gamma': 0.05...           0.856354   \n",
       "18  {'estimator__C': 0.1, 'estimator__gamma': 0.01...           0.870560   \n",
       "19  {'estimator__C': 0.1, 'estimator__gamma': 0.01...           0.856354   \n",
       "20  {'estimator__C': 0.5, 'estimator__gamma': 5, '...           0.998421   \n",
       "21  {'estimator__C': 0.5, 'estimator__gamma': 5, '...           0.874507   \n",
       "22  {'estimator__C': 0.5, 'estimator__gamma': 1, '...           0.998421   \n",
       "23  {'estimator__C': 0.5, 'estimator__gamma': 1, '...           0.874507   \n",
       "24  {'estimator__C': 0.5, 'estimator__gamma': 0.5,...           0.996054   \n",
       "25  {'estimator__C': 0.5, 'estimator__gamma': 0.5,...           0.874507   \n",
       "26  {'estimator__C': 0.5, 'estimator__gamma': 0.05...           0.860300   \n",
       "27  {'estimator__C': 0.5, 'estimator__gamma': 0.05...           0.874507   \n",
       "28  {'estimator__C': 0.5, 'estimator__gamma': 0.01...           0.867403   \n",
       "29  {'estimator__C': 0.5, 'estimator__gamma': 0.01...           0.874507   \n",
       "30  {'estimator__C': 1, 'estimator__gamma': 5, 'es...           0.998421   \n",
       "31  {'estimator__C': 1, 'estimator__gamma': 5, 'es...           0.883978   \n",
       "32  {'estimator__C': 1, 'estimator__gamma': 1, 'es...           0.998421   \n",
       "33  {'estimator__C': 1, 'estimator__gamma': 1, 'es...           0.883978   \n",
       "34  {'estimator__C': 1, 'estimator__gamma': 0.5, '...           0.998421   \n",
       "35  {'estimator__C': 1, 'estimator__gamma': 0.5, '...           0.883978   \n",
       "36  {'estimator__C': 1, 'estimator__gamma': 0.05, ...           0.860300   \n",
       "37  {'estimator__C': 1, 'estimator__gamma': 0.05, ...           0.883978   \n",
       "38  {'estimator__C': 1, 'estimator__gamma': 0.01, ...           0.868193   \n",
       "39  {'estimator__C': 1, 'estimator__gamma': 0.01, ...           0.883978   \n",
       "40  {'estimator__C': 5, 'estimator__gamma': 5, 'es...           0.998421   \n",
       "41  {'estimator__C': 5, 'estimator__gamma': 5, 'es...           0.895817   \n",
       "42  {'estimator__C': 5, 'estimator__gamma': 1, 'es...           0.998421   \n",
       "43  {'estimator__C': 5, 'estimator__gamma': 1, 'es...           0.895817   \n",
       "44  {'estimator__C': 5, 'estimator__gamma': 0.5, '...           0.998421   \n",
       "45  {'estimator__C': 5, 'estimator__gamma': 0.5, '...           0.895817   \n",
       "46  {'estimator__C': 5, 'estimator__gamma': 0.05, ...           0.929755   \n",
       "47  {'estimator__C': 5, 'estimator__gamma': 0.05, ...           0.895817   \n",
       "48  {'estimator__C': 5, 'estimator__gamma': 0.01, ...           0.860300   \n",
       "49  {'estimator__C': 5, 'estimator__gamma': 0.01, ...           0.895817   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.998421           0.999210         0.998684        0.000372   \n",
       "1            0.864246           0.851501         0.856315        0.005651   \n",
       "2            0.998421           0.996051         0.996842        0.001117   \n",
       "3            0.864246           0.851501         0.856315        0.005651   \n",
       "4            0.988161           0.979463         0.983420        0.003594   \n",
       "5            0.864246           0.851501         0.856315        0.005651   \n",
       "6            0.852407           0.868088         0.860002        0.006411   \n",
       "7            0.864246           0.851501         0.856315        0.005651   \n",
       "8            0.816890           0.857030         0.847634        0.022280   \n",
       "9            0.864246           0.851501         0.856315        0.005651   \n",
       "10           0.998421           0.999210         0.998684        0.000372   \n",
       "11           0.867403           0.857820         0.860526        0.004900   \n",
       "12           1.000000           0.999210         0.998947        0.000984   \n",
       "13           0.867403           0.857820         0.860526        0.004900   \n",
       "14           0.996054           0.992891         0.993947        0.001490   \n",
       "15           0.867403           0.857820         0.860526        0.004900   \n",
       "16           0.853197           0.867299         0.860265        0.005757   \n",
       "17           0.867403           0.857820         0.860526        0.004900   \n",
       "18           0.816890           0.858610         0.848687        0.023007   \n",
       "19           0.867403           0.857820         0.860526        0.004900   \n",
       "20           0.998421           0.999210         0.998684        0.000372   \n",
       "21           0.878453           0.875987         0.876316        0.001628   \n",
       "22           0.998421           0.999210         0.998684        0.000372   \n",
       "23           0.878453           0.875987         0.876316        0.001628   \n",
       "24           0.999211           0.996051         0.997105        0.001489   \n",
       "25           0.878453           0.875987         0.876316        0.001628   \n",
       "26           0.852407           0.866509         0.859739        0.005771   \n",
       "27           0.878453           0.875987         0.876316        0.001628   \n",
       "28           0.823994           0.857030         0.849476        0.018509   \n",
       "29           0.878453           0.875987         0.876316        0.001628   \n",
       "30           0.998421           0.999210         0.998684        0.000372   \n",
       "31           0.886346           0.882306         0.884210        0.001657   \n",
       "32           0.998421           0.999210         0.998684        0.000372   \n",
       "33           0.886346           0.882306         0.884210        0.001657   \n",
       "34           1.000000           0.999210         0.999211        0.000644   \n",
       "35           0.886346           0.882306         0.884210        0.001657   \n",
       "36           0.853197           0.866509         0.860002        0.005439   \n",
       "37           0.886346           0.882306         0.884210        0.001657   \n",
       "38           0.849250           0.864929         0.860791        0.008268   \n",
       "39           0.886346           0.882306         0.884210        0.001657   \n",
       "40           0.998421           0.999210         0.998684        0.000372   \n",
       "41           0.910813           0.910742         0.905791        0.007053   \n",
       "42           0.998421           0.999210         0.998684        0.000372   \n",
       "43           0.910813           0.910742         0.905791        0.007053   \n",
       "44           0.998421           0.999210         0.998684        0.000372   \n",
       "45           0.910813           0.910742         0.905791        0.007053   \n",
       "46           0.940805           0.926540         0.932367        0.006109   \n",
       "47           0.910813           0.910742         0.905791        0.007053   \n",
       "48           0.854775           0.867299         0.860791        0.005124   \n",
       "49           0.910813           0.910742         0.905791        0.007053   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 3  \n",
       "1                43  \n",
       "2                13  \n",
       "3                43  \n",
       "4                15  \n",
       "5                43  \n",
       "6                40  \n",
       "7                43  \n",
       "8                50  \n",
       "9                43  \n",
       "10                3  \n",
       "11               34  \n",
       "12                2  \n",
       "13               34  \n",
       "14               14  \n",
       "15               34  \n",
       "16               39  \n",
       "17               34  \n",
       "18               49  \n",
       "19               34  \n",
       "20                3  \n",
       "21               27  \n",
       "22                3  \n",
       "23               27  \n",
       "24               12  \n",
       "25               27  \n",
       "26               42  \n",
       "27               27  \n",
       "28               48  \n",
       "29               27  \n",
       "30                3  \n",
       "31               22  \n",
       "32                3  \n",
       "33               22  \n",
       "34                1  \n",
       "35               22  \n",
       "36               41  \n",
       "37               22  \n",
       "38               33  \n",
       "39               22  \n",
       "40                3  \n",
       "41               17  \n",
       "42                3  \n",
       "43               17  \n",
       "44                3  \n",
       "45               17  \n",
       "46               16  \n",
       "47               17  \n",
       "48               32  \n",
       "49               17  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearchSVM=pd.DataFrame(grid_search.cv_results_)\n",
    "gridsearchSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearchSVM.to_csv(\"gridsearchSVM.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation scores are analysed with best estimator hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validate(grid_search.best_estimator_, X_resampled, y_resampled, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.98137355, 0.98333836, 1.02525997, 0.97544217, 0.98042345]),\n",
       " 'score_time': array([0.01196623, 0.0119679 , 0.01296568, 0.01391315, 0.0119679 ]),\n",
       " 'test_score': array([0.99868421, 0.99736842, 0.99868421, 0.99868421, 0.99736842])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding out best estimators of SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1, gamma=0.5, kernel='poly',\n",
       "                                  probability=True))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the best model via pickle library for reusing in the test side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm_model.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search.best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting learning curve to analyse learning regime of the selected model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1080 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "title = r\"Learning Curves (SVM, Polynomial kernel, C=0.1, gamma=1))\"\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "plot_learning_curve(grid_search.best_estimator_, title, X_resampled, y_resampled, axes, cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
